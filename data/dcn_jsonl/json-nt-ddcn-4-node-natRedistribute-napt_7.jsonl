{"timestamp_utc": "2024-07-31T05:08:30.001Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Started by upstream project \"project/fss3/ci-regression\" build number 2999 <NL> originally caused by: <NL> Started by user Meenakshisundaram, Balaji (BMEENAKS)"}
{"timestamp_utc": "2024-07-31T05:08:30.054Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] Start of Pipeline"}
{"timestamp_utc": "2024-07-31T05:08:30.060Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] library"}
{"timestamp_utc": "2024-07-31T05:08:30.061Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Loading library cic-shared-library@project_latest <NL> Attempting to resolve project_latest from remote references... <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:08:30.217Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3' <NL> > git ls-remote -- ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:08:30.590Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Found match: refs/tags/project_latest revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a <NL> Resolving tag commit... (remote references may be a lightweight tag or an annotated tag)"}
{"timestamp_utc": "2024-07-31T05:10:12.928Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git rev-parse --resolve-git-dir /atldata/jenkins/caches/git-81d7c0835bf8496255df022a875c0e23/.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:13.021Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Setting origin to ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git config remote.origin.url ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:13.111Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching origin... <NL> Fetching upstream changes from origin <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:13.220Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3' <NL> > git config --get remote.origin.url # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:13.264Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git fetch --tags --force --progress -- origin +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:15.006Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git rev-parse refs/tags/project_latest^{commit} # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:15.112Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Resolved tag project_latest revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a"}
{"timestamp_utc": "2024-07-31T05:10:15.113Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "The recommended git tool is: git <NL> Warning: CredentialId \"jenkins\" could not be found. <NL> Cloning the remote Git repository <NL> Cloning with configured refspecs honoured and with tags <NL> Cloning repository ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git init /atldata/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt_libs/e62eae340757e7d61d5116e39951ef47814af05333dabd029e21d997a41ab976 # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:15.212Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching upstream changes from ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:15.261Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3' <NL> > git fetch --tags --force --progress -- ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:28.470Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git config remote.origin.url ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:28.535Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git config --add remote.origin.fetch +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:28.629Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Avoid second fetch <NL> Checking out Revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a (project_latest) <NL> > git config core.sparsecheckout # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:28.753Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git checkout -f 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:29.079Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Commit message: \"saving manifest for tag project_cd1474\""}
{"timestamp_utc": "2024-07-31T05:10:29.702Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false"}
{"timestamp_utc": "2024-07-31T05:10:29.703Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:29.815Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp32 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt"}
{"timestamp_utc": "2024-07-31T05:10:29.816Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T05:10:29.820Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:30.087Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.001 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.001"}
{"timestamp_utc": "2024-07-31T05:10:30.094Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:30.104Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:30.374Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.001/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.001/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:30.383Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T05:10:30.406Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:30.694Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git bootstrap-repo-subdir <NL> Cloning into 'bootstrap-repo-subdir'..."}
{"timestamp_utc": "2024-07-31T05:10:30.948Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental"}
{"timestamp_utc": "2024-07-31T05:10:30.949Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name"}
{"timestamp_utc": "2024-07-31T05:10:30.959Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:31.264Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (bootstrap-repo-subdir/jenkins/bootstrap-pipeline.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:31.267Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:31.272Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:31.276Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:31.280Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:31.545Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.001/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.001/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:31.549Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:31.551Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T05:10:31.653Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false"}
{"timestamp_utc": "2024-07-31T05:10:31.654Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:31.729Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp32 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt"}
{"timestamp_utc": "2024-07-31T05:10:31.730Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T05:10:31.735Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:32.195Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.002 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.002"}
{"timestamp_utc": "2024-07-31T05:10:32.212Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:32.218Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:32.492Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.002/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.002/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:32.498Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T05:10:32.499Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:32.772Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt"}
{"timestamp_utc": "2024-07-31T05:10:32.776Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T05:10:32.785Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> ===== parameter values: ===== <NL> PIPELINE_JOB_NAME                  \"json-nt-ddcn-4-node-natRedistribute-napt\" <NL> PIPELINE_JOB_FULL_NAME             \"project/fss3/json-nt-ddcn-4-node-natRedistribute-napt\" <NL> PIPELINE_JOB_PROJECT_FOLDER_NAME   \"fss3\" <NL> RECIPE_REPO_BASE_JOB_NAME          null <NL> (dflt) PROJECT_NAME                       \"fss3\" <NL> (dflt) RECIPE_REPO_NAME                   null <NL> (user) CI_BASE_BRANCH_NAME                \"fss3\" <NL> (user) NETWORK_TOPOLOGY_BRANCH_NAME       \"ntp_latest\" <NL> (user) CI_SUBMODULE_BRANCH_NAME           \"project_latest\" <NL> (user) PROJECT_INFO_BRANCH_NAME           \"master_cd23138\" <NL> (user) GROOVY_SCRIPT_NAME                 \"continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy\" <NL> ===== ===== ===== ===== ====="}
{"timestamp_utc": "2024-07-31T05:10:32.787Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:33.057Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ git clone --branch fss3 --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration.git continuous-integration <NL> Cloning into 'continuous-integration'..."}
{"timestamp_utc": "2024-07-31T05:10:33.312Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ rm -rf continuous-integration/continuous-integration-common <NL> + cd continuous-integration <NL> + git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git continuous-integration-common <NL> Cloning into 'continuous-integration-common'..."}
{"timestamp_utc": "2024-07-31T05:10:33.567Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd continuous-integration-common <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf repo <NL> + git clone --branch master --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/repo.git repo <NL> Cloning into 'repo'..."}
{"timestamp_utc": "2024-07-31T05:10:33.822Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cd repo <NL> + rm -rf .git <NL> + cd .."}
{"timestamp_utc": "2024-07-31T05:10:33.826Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:34.476Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:34.480Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:34.483Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:34.490Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:34.726Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.utilities.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:34.732Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:34.736Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:34.742Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:34.819Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.user_input.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:34.847Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:34.857Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:34.861Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:35.841Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.json_pipeline.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:35.848Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:35.870Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:35.882Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:36.306Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.gitscm.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:36.313Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:36.320Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:36.333Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:36.353Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:36.643Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.002/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.002/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:36.648Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:36.752Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T05:10:36.769Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> PIPELINE_JOB_NAME                 \"json-nt-ddcn-4-node-natRedistribute-napt\" <NL> PIPELINE_JOB_FULL_NAME            \"project/fss3/json-nt-ddcn-4-node-natRedistribute-napt\" <NL> PIPELINE_JOB_PROJECT_FOLDER_NAME  \"fss3\" <NL> PROJECT_NAME                      \"fss3\" <NL> CI_BASE_BRANCH_NAME               \"fss3\" <NL> CI_SUBMODULE_BRANCH_NAME          \"project_latest\" <NL> CI_BUILD_URL                      \"\" <NL> CI_JOB_PARENT_ARTIFACT_INFO_FNAME \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\" <NL> GROOVY_SCRIPT_NAME                \"continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy\""}
{"timestamp_utc": "2024-07-31T05:10:36.770Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "JPARAM_JOB_JSON_STRING            \"{\"job_type\":\"explicit\",\"job_timeout_unit\":\"HOURS\",\"job_timeout_amount\":6,\"job_propagate_flag\":true,\"job_template\":\"ci-pipeline-job.xml\",\"disable_flag.ci-release-recipe-repo\":true,\"disable_flag.ci-review\":true,\"disable_flag.ci-release-project\":true,\"job_command_list\":[\"ci-project-sanity-tfwk\",\"--\",\"--testcases-project-name\",\"fss3\",\"--\",\"--test-engine\",\"Warrior\",\"--topology-tag-name\",\"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\",\"--define-attr-defaults\",\"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\",\"--define-instance-attr\",\"NE1/main\",\"shelf-num=1\",\"--define-instance-attr\",\"NE1/main\",\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\",\"--define-instance-attr\",\"NE1/trib1\",\"shelf-num=2\",\"--define-instance-attr\",\"NE1/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE2/main\",\"shelf-num=1\",\"--define-instance-attr\",\"NE2/main\",\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\",\"--define-instance-attr\",\"NE2/trib1\",\"shelf-num=2\",\"--define-instance-attr\",\"NE2/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE3/main\",\"shelf-num=200\",\"--define-instance-attr\",\"NE3/main\",\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\",\"--define-instance-attr\",\"NE3/trib1\",\"shelf-num=1\",\"--define-instance-attr\",\"NE3/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE4/main\",\"shelf-num=200\",\"--define-instance-attr\",\"NE4/main\",\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\",\"--define-instance-attr\",\"NE4/trib1\",\"shelf-num=1\",\"--define-instance-attr\",\"NE4/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--add-instance\",\"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\",\"--device-wait-startup-timeout\",\"1200\",\"--test-engine-begin\",\"--no_logger\",\"--test-engine-end\",\"--\",\"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml\"],\"disable_flag.ci-update-manifest\":true,\"job_name\":\"nt-ddcn-4-node-natRedistribute-napt\",\"job_quiet_period\":0,\"job_docker_container_flag\":true,\"job_wait_flag\":true,\"job_failure_handling\":\"pipeline-failure\",\"job_unstash_flag\":true,\"disable_flag.ci-update-manifest-recipe-repo\":true,\"disable_flag.ci-review-recipe-repo\":true,\"job_agent\":\"regression-sanity-docker\",\"previous_job_method\":\"previous-job\",\"job_stash_flag\":true,\"job_label\":\"nt-ddcn-4-node-natRedistribute-napt\",\"job_docker_container_info\":null,\"job_kubernetes_info\":null,\"job_command_prefix\":[\"ci-get-archive-artifacts\",\"--project-info-basename\",\"project-info.json\",\"--project-info-extended-basename\",\"project-info-extended.json\",\"--\",\"ci-job-info\"],\"logstash_flag\":false,\"parent_info\":{\"jenkins_master\":\"jenkins.fnc.fujitsu.com\",\"jenkins_job_BUILD_URL\":\"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\",\"jenkins_job_full_name\":\"project/fss3/ci-regression\",\"jenkins_job_name\":\"ci-regression\",\"jenkins_job_build_number\":2999,\"jenkins_job_full_build_name\":\"project/fss3/ci-regression/2999\"},\"parent_pipeline_context_info\":{\"pipeline_type\":\"ci-regression\",\"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\":\"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\"}}\" <NL> json_text: { <NL> \"job_type\": \"explicit\", <NL> \"job_timeout_unit\": \"HOURS\", <NL> \"job_timeout_amount\": 6, <NL> \"logstash_flag\": false, <NL> \"job_propagate_flag\": true, <NL> \"job_template\": \"ci-pipeline-job.xml\", <NL> \"job_quiet_period\": 0, <NL> \"job_docker_container_flag\": true, <NL> \"disable_flag.ci-update-manifest-recipe-repo\": true, <NL> \"previous_job_method\": \"previous-job\", <NL> \"job_docker_container_info\": null, <NL> \"job_stash_flag\": true, <NL> \"parent_info\": { <NL> \"jenkins_job_build_number\": 2999, <NL> \"jenkins_job_full_name\": \"project/fss3/ci-regression\", <NL> \"jenkins_job_name\": \"ci-regression\", <NL> \"jenkins_job_full_build_name\": \"project/fss3/ci-regression/2999\", <NL> \"jenkins_master\": \"jenkins.fnc.fujitsu.com\", <NL> \"jenkins_job_BUILD_URL\": \"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\" <NL> }, <NL> \"job_label\": \"nt-ddcn-4-node-natRedistribute-napt\", <NL> \"job_command_prefix\": [ <NL> \"ci-get-archive-artifacts\", <NL> \"--project-info-basename\", <NL> \"project-info.json\", <NL> \"--project-info-extended-basename\", <NL> \"project-info-extended.json\", <NL> \"--\", <NL> \"ci-job-info\" <NL> ], <NL> \"disable_flag.ci-release-recipe-repo\": true, <NL> \"disable_flag.ci-review\": true, <NL> \"disable_flag.ci-release-project\": true, <NL> \"job_command_list\": [ <NL> \"ci-project-sanity-tfwk\", <NL> \"--\", <NL> \"--testcases-project-name\", <NL> \"fss3\", <NL> \"--\", <NL> \"--test-engine\", <NL> \"Warrior\", <NL> \"--topology-tag-name\", <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\", <NL> \"--define-attr-defaults\", <NL> \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--add-instance\", <NL> \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\", <NL> \"--device-wait-startup-timeout\", <NL> \"1200\", <NL> \"--test-engine-begin\", <NL> \"--no_logger\", <NL> \"--test-engine-end\", <NL> \"--\", <NL> \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml\" <NL> ], <NL> \"job_kubernetes_info\": null, <NL> \"disable_flag.ci-update-manifest\": true, <NL> \"job_name\": \"nt-ddcn-4-node-natRedistribute-napt\", <NL> \"job_wait_flag\": true, <NL> \"job_failure_handling\": \"pipeline-failure\", <NL> \"job_unstash_flag\": true, <NL> \"parent_pipeline_context_info\": { <NL> \"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\", <NL> \"pipeline_type\": \"ci-regression\" <NL> }, <NL> \"disable_flag.ci-review-recipe-repo\": true, <NL> \"job_agent\": \"regression-sanity-docker\" <NL> }"}
{"timestamp_utc": "2024-07-31T05:10:36.779Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> pipeline_init: currentBuild.result 'SUCCESS' <NL> ===== ===== ===== ===== ====="}
{"timestamp_utc": "2024-07-31T05:10:36.814Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T05:10:36.815Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "running_in_k8s_flag : false <NL> [Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:51.834Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Still waiting to schedule task"}
{"timestamp_utc": "2024-07-31T05:10:51.835Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Waiting for next available executor on \u2018regression-sanity-docker\u2019"}
{"timestamp_utc": "2024-07-31T08:07:04.907Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp85 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:07:04.919Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:05.195Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.003 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.003"}
{"timestamp_utc": "2024-07-31T08:07:05.204Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:07:05.214Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:05.489Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.003/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.003/node-info.json"}
{"timestamp_utc": "2024-07-31T08:07:05.495Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage"}
{"timestamp_utc": "2024-07-31T08:07:05.496Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (Init)"}
{"timestamp_utc": "2024-07-31T08:07:05.506Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] timeout <NL> Timeout set to expire in 1 hr 0 min <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:07:05.515Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:07:05.516Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:05.785Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt"}
{"timestamp_utc": "2024-07-31T08:07:05.790Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T08:07:05.798Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:07:05.805Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // timeout"}
{"timestamp_utc": "2024-07-31T08:07:05.813Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:07:05.819Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:07:05.827Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] timeout <NL> Timeout set to expire in 6 hr 0 min"}
{"timestamp_utc": "2024-07-31T08:07:05.828Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:07:05.836Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:07:05.839Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:06.114Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "++ hostname <NL> ++ hostname -i <NL> + echo '{ \"hostname\": \"rtxoialp85.fnc.net.local\", \"hostip\": \"167.254.217.214\" }' <NL> + cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/hostname.json"}
{"timestamp_utc": "2024-07-31T08:07:06.115Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "{ \"hostname\": \"rtxoialp85.fnc.net.local\", \"hostip\": \"167.254.217.214\" }"}
{"timestamp_utc": "2024-07-31T08:07:06.122Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] readFile"}
{"timestamp_utc": "2024-07-31T08:07:06.130Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T08:07:06.131Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "host_info_name_dict: { <NL> \"hostname\": \"rtxoialp85.fnc.net.local\", <NL> \"hostip\": \"167.254.217.214\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:07:06.139Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:07:06.151Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:07:06.152Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage"}
{"timestamp_utc": "2024-07-31T08:07:06.153Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (Execute)"}
{"timestamp_utc": "2024-07-31T08:07:06.160Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:07:06.162Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:06.433Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt"}
{"timestamp_utc": "2024-07-31T08:07:06.441Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T08:07:06.449Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:07:06.460Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:07:06.469Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:07:06.477Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:07:06.485Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag: false"}
{"timestamp_utc": "2024-07-31T08:07:06.493Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:07:06.534Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:07:06.620Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] isUnix"}
{"timestamp_utc": "2024-07-31T08:07:06.621Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:07:06.629Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:06.900Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker pull harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest <NL> Trying to pull repository harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build ... <NL> latest: Pulling from harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build <NL> Digest: sha256:f649c9d54a8d0322e20c4524897fb6d43164df14359f965f27d7fedcf395eb95 <NL> Status: Image is up to date for harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:07:06.905Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:07:06.914Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:07:06.930Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] isUnix"}
{"timestamp_utc": "2024-07-31T08:07:06.937Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:07.209Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker run -d --privileged --user root --cap-add NET_ADMIN --cap-add SYS_ADMIN --device /dev/kvm:/dev/kvm --device /dev/net/tun:/dev/net/tun --device /dev/vhost-net:/dev/vhost-net --publish :22 --workdir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt --detach --volume /var/run/docker.sock:/var/run/docker.sock --volume /proj/bitbake:/proj/bitbake:shared --volume /proj/artifacts:/proj/artifacts:shared --volume /repo:/repo:ro,shared --volume /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt:shared harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:07:08.669Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:07:08.941Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ hostname <NL> rtxoialp85.fnc.net.local <NL> + pwd <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt <NL> + id"}
{"timestamp_utc": "2024-07-31T08:07:09.196Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "uid=51016(jenkins) gid=50063(common) groups=50063(common),36(kvm),905(dockerroot),548600513(domain users),548601197(9949 atp's-r),548601199(itgcd01),548601201(ontblan - prjfiles-r),548606239(qdc-c),548612341(106admin),548619018(itgfile3_marketing-r),548619025(itgfile3_procq_r),548619027(itgfile3_qdc-c),548619031(itgfile3_rel-r),548619037(itgfile3_svcq_r),548619041(itgfile3_tpubs-dvt$-r),548619046(itgfile3_tpubs-users),548619089(itgfile4_antivirus-r),548619106(itgfile4_corpq_r),548619129(itgfile4_fns_bp - r),548619134(itgfile4_fns-busmodel-r),548619154(itgfile4_markmfg-r),548619161(itgfile4_naprojects-c),548619164(itgfile4_net ops - r),548619167(itgfile4_networkdev_dev),548619170(itgfile4_networkdoc_prod-r),548619177(itgfile4_oracle-r),548619186(itgfile4_priso9001 - r),548619203(itgfile4_sapsuperusers-r),548619209(itgfile4_siebel docs - r),548619211(itgfile4_siebelitg-s),548619214(itgfile4_software-r),548619216(itgfile4_sw-iso9002-r),548619223(itgfile4_tech_ops-r),548619238(itgfile4_xeroxps-r),548619566(netval3admin),548619568(tsc_users),548650281(rchnetapp2_mobile_newsletters-r),548657500(rchnetapp2_coursera_sdn-002_r),548658825(rchfile2_techserv_r),548664859(fnc.engftp),548671195(g05_qdc_share_c),548671198(rtxnasop01_lr_toolkit-r),548671199(rtxnasop01_lr_output-c),548674493(mxl1400dhc-w10-admins),548677213(rtxnasop01_qdc-c) <NL> + '[' '!' -d continuous-integration ']' <NL> + git clone --branch fss3 --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration.git continuous-integration"}
{"timestamp_utc": "2024-07-31T08:07:09.451Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Cloning into 'continuous-integration'... <NL> + rm -rf continuous-integration/continuous-integration-common <NL> + cd continuous-integration <NL> + git log -1 <NL> + '[' '!' -d continuous-integration-common ']' <NL> + git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git continuous-integration-common <NL> Cloning into 'continuous-integration-common'..."}
{"timestamp_utc": "2024-07-31T08:07:09.706Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd continuous-integration-common <NL> + git log -1 <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf .git <NL> + cd .. <NL> + '[' '!' -d network-topology ']' <NL> + git clone --branch ntp_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/network-topology.git network-topology <NL> Cloning into 'network-topology'..."}
{"timestamp_utc": "2024-07-31T08:07:09.962Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '9dd57f75190f0d255e5fd5a19408ee684d8e30fb'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd network-topology <NL> + git log -1 <NL> + rm -rf .git <NL> + cd .. <NL> + '[' '!' -d repo ']' <NL> + git clone --branch master --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/repo.git repo <NL> Cloning into 'repo'..."}
{"timestamp_utc": "2024-07-31T08:07:10.218Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cd repo <NL> + rm -rf .git <NL> + cd .. <NL> + set +xe <NL> -- show continuous-integration/version.txt <NL> commit 46d558a518beb700cd21573f2815e8a9d270df94 <NL> Author: pmadiraj <pavankumar.madirajukeshavaraju@us.fujitsu.com> <NL> Date:   Thu Sep 19 09:40:06 2019 -0500 <NL> add missing recipe repo groovy links <NL> -- show continuous-integration/continuous-integration-common/version.txt <NL> commit 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a <NL> Author: Jenkins <jenkins_noreply@fnc.fujitsu.com> <NL> Date:   Tue Jul 30 04:49:43 2024 -0500 <NL> saving manifest for tag project_cd1474 <NL> -- show network-topology/version.txt <NL> commit 9dd57f75190f0d255e5fd5a19408ee684d8e30fb <NL> Author: Parween, Sagufta <sparween@localhost> <NL> Date:   Thu Jul 25 00:09:36 2024 -0500 <NL> saving manifest for tag ntp_cd118 <NL> -- done <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/jenkins-job-command-list.json <NL> [ <NL> \"ci-get-archive-artifacts\", <NL> \"--project-info-basename\", <NL> \"project-info.json\", <NL> \"--project-info-extended-basename\", <NL> \"project-info-extended.json\", <NL> \"--\", <NL> \"ci-job-info\", <NL> \"ci-project-sanity-tfwk\", <NL> \"--\", <NL> \"--testcases-project-name\", <NL> \"fss3\", <NL> \"--\", <NL> \"--test-engine\", <NL> \"Warrior\", <NL> \"--topology-tag-name\", <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\", <NL> \"--define-attr-defaults\", <NL> \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--add-instance\", <NL> \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\", <NL> \"--device-wait-startup-timeout\", <NL> \"1200\", <NL> \"--test-engine-begin\", <NL> \"--no_logger\", <NL> \"--test-engine-end\", <NL> \"--\", <NL> \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml\" <NL> ] <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/jenkins-job-environment-map.json <NL> { <NL> \"CI_BASE_BRANCH_NAME\": \"fss3\", <NL> \"CI_SUBMODULE_BRANCH_NAME\": \"project_latest\", <NL> \"PROJECT_INFO_BRANCH_NAME\": \"master_cd23138\", <NL> \"NETWORK_TOPOLOGY_BRANCH_NAME\": \"ntp_latest\", <NL> \"CI_BUILD_URL\": \"\", <NL> \"CI_JOB_PARENT_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\","}
{"timestamp_utc": "2024-07-31T08:07:10.219Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"JPARAM_JOB_JSON_STRING\": \"{\\\"job_type\\\":\\\"explicit\\\",\\\"job_timeout_unit\\\":\\\"HOURS\\\",\\\"job_timeout_amount\\\":6,\\\"job_propagate_flag\\\":true,\\\"job_template\\\":\\\"ci-pipeline-job.xml\\\",\\\"disable_flag.ci-release-recipe-repo\\\":true,\\\"disable_flag.ci-review\\\":true,\\\"disable_flag.ci-release-project\\\":true,\\\"job_command_list\\\":[\\\"ci-project-sanity-tfwk\\\",\\\"--\\\",\\\"--testcases-project-name\\\",\\\"fss3\\\",\\\"--\\\",\\\"--test-engine\\\",\\\"Warrior\\\",\\\"--topology-tag-name\\\",\\\"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\\\",\\\"--define-attr-defaults\\\",\\\"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\\\",\\\"--define-instance-attr\\\",\\\"NE1/main\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE1/main\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE1/trib1\\\",\\\"shelf-num=2\\\",\\\"--define-instance-attr\\\",\\\"NE1/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE2/main\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE2/main\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE2/trib1\\\",\\\"shelf-num=2\\\",\\\"--define-instance-attr\\\",\\\"NE2/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE3/main\\\",\\\"shelf-num=200\\\",\\\"--define-instance-attr\\\",\\\"NE3/main\\\",\\\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\\\",\\\"--define-instance-attr\\\",\\\"NE3/trib1\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE3/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE4/main\\\",\\\"shelf-num=200\\\",\\\"--define-instance-attr\\\",\\\"NE4/main\\\",\\\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\\\",\\\"--define-instance-attr\\\",\\\"NE4/trib1\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE4/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--add-instance\\\",\\\"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\\\",\\\"--device-wait-startup-timeout\\\",\\\"1200\\\",\\\"--test-engine-begin\\\",\\\"--no_logger\\\",\\\"--test-engine-end\\\",\\\"--\\\",\\\"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml\\\"],\\\"disable_flag.ci-update-manifest\\\":true,\\\"job_name\\\":\\\"nt-ddcn-4-node-natRedistribute-napt\\\",\\\"job_quiet_period\\\":0,\\\"job_docker_container_flag\\\":true,\\\"job_wait_flag\\\":true,\\\"job_failure_handling\\\":\\\"pipeline-failure\\\",\\\"job_unstash_flag\\\":true,\\\"disable_flag.ci-update-manifest-recipe-repo\\\":true,\\\"disable_flag.ci-review-recipe-repo\\\":true,\\\"job_agent\\\":\\\"regression-sanity-docker\\\",\\\"previous_job_method\\\":\\\"previous-job\\\",\\\"job_stash_flag\\\":true,\\\"job_label\\\":\\\"nt-ddcn-4-node-natRedistribute-napt\\\",\\\"job_docker_container_info\\\":null,\\\"job_kubernetes_info\\\":null,\\\"job_command_prefix\\\":[\\\"ci-get-archive-artifacts\\\",\\\"--project-info-basename\\\",\\\"project-info.json\\\",\\\"--project-info-extended-basename\\\",\\\"project-info-extended.json\\\",\\\"--\\\",\\\"ci-job-info\\\"],\\\"logstash_flag\\\":false,\\\"parent_info\\\":{\\\"jenkins_master\\\":\\\"jenkins.fnc.fujitsu.com\\\",\\\"jenkins_job_BUILD_URL\\\":\\\"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\\\",\\\"jenkins_job_full_name\\\":\\\"project/fss3/ci-regression\\\",\\\"jenkins_job_name\\\":\\\"ci-regression\\\",\\\"jenkins_job_build_number\\\":2999,\\\"jenkins_job_full_build_name\\\":\\\"project/fss3/ci-regression/2999\\\"},\\\"parent_pipeline_context_info\\\":{\\\"pipeline_type\\\":\\\"ci-regression\\\",\\\"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\\\":\\\"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\\\"}}\", <NL> \"BUILD_NUMBER\": \"7\", <NL> \"CI_JENKINS_EXECUTOR_HOSTNAME\": \"rtxoialp85.fnc.net.local\", <NL> \"CI_JENKINS_EXECUTOR_HOSTIP\": \"167.254.217.214\", <NL> \"WORKSPACE\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt\", <NL> \"JOB_NAME\": \"project/fss3/json-nt-ddcn-4-node-natRedistribute-napt\", <NL> \"LANG\": \"en_US.UTF-8\", <NL> \"PARENT_PIPELINE_CONTEXT_INFO_MAP_JSON_FNAME\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/parent-pipeline-context-info-map.json\" <NL> } <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/parent-pipeline-context-info-map.json <NL> { <NL> \"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\", <NL> \"pipeline_type\": \"ci-regression\" <NL> } <NL> == done <NL> user jenkins <NL> container.id a60c81e010e505685c0da3de47e0e97e49c4bc14876516538940519c7634c717"}
{"timestamp_utc": "2024-07-31T08:07:10.780Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ exec ci-execute-json-command-list --command-json-fname /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/jenkins-job-command-list.json"}
{"timestamp_utc": "2024-07-31T08:07:11.035Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-get-archive-artifacts: creating local_data_dir \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/ci-data\""}
{"timestamp_utc": "2024-07-31T08:07:11.289Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-get-archive-artifacts: started with parent info from CI_JOB_PARENT_ARTIFACT_INFO_FNAME \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\" <NL> ci-get-archive-artifacts: copying ci-data files from CI_JOB_ARTIFACT_CI_DATA_DIR \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.ci-data\" into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/ci-data\" <NL> ./ <NL> ./manifest.json <NL> ./project-info-status.json <NL> ./gitscm-info.json <NL> ./data.json <NL> ./project-info-extended.json <NL> ./project-info.json <NL> ./project-info-complete.json"}
{"timestamp_utc": "2024-07-31T08:07:12.770Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info-recipe-repo.json <NL> ci-get-archive-artifacts: pwd \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt\" <NL> ci-get-archive-artifacts: calling command:  \"ci-job-info\" \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml\" <NL> ci-job-info: started on Wed Jul 31 03:07:12 CDT 2024 <NL> start_job: Wed Jul 31 03:07:12 CDT 2024"}
{"timestamp_utc": "2024-07-31T08:07:13.331Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_subsequent_job <NL> ci-job-info: start_subsequent_job: ----- ----- ----- ----- -----"}
{"timestamp_utc": "2024-07-31T08:07:13.891Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_job: save existing info file into what will be the parent info file /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/data.parent.json"}
{"timestamp_utc": "2024-07-31T08:07:15.856Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_job: ----- ----- ----- ----- -----"}
{"timestamp_utc": "2024-07-31T08:07:15.857Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: calling command: \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml\" <NL> ci-project-sanity-tfwk: starting"}
{"timestamp_utc": "2024-07-31T08:07:16.113Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ '[' 0 -eq 0 ']' <NL> + echo 'ci-project-sanity-tfwk: not setting up workspace' <NL> ci-project-sanity-tfwk: not setting up workspace <NL> + rm -rf /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts <NL> + mkdir -p /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts <NL> + '[' 0 -eq 1 ']' <NL> + cd /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts <NL> + '[' 67 -le 0 ']' <NL> + ci-project-sanity-tfwk.py --testcases-project-name fss3 -- --test-engine Warrior --topology-tag-name DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1 --define-attr-defaults machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute --define-instance-attr NE1/main shelf-num=1 --define-instance-attr NE1/main image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2 --define-instance-attr NE1/trib1 shelf-num=2 --define-instance-attr NE1/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE2/main shelf-num=1 --define-instance-attr NE2/main image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2 --define-instance-attr NE2/trib1 shelf-num=2 --define-instance-attr NE2/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE3/main shelf-num=200 --define-instance-attr NE3/main image-name=fss-aggr-image-validation-T,image-info-config-name=main --define-instance-attr NE3/trib1 shelf-num=1 --define-instance-attr NE3/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE4/main shelf-num=200 --define-instance-attr NE4/main image-name=fss-aggr-image-validation-T,image-info-config-name=main --define-instance-attr NE4/trib1 shelf-num=1 --define-instance-attr NE4/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --add-instance NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1 --device-wait-startup-timeout 1200 --test-engine-begin --no_logger --test-engine-end -- warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml"}
{"timestamp_utc": "2024-07-31T08:07:16.673Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Fetching project \"manifests\" <NL> Cloning into 'manifests'..."}
{"timestamp_utc": "2024-07-31T08:07:16.928Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "remote: Enumerating objects: 22649, done.\u001b[K"}
{"timestamp_utc": "2025-05-28T08:09:08.121Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "remote: Total 22649 (delta 3951), reused 100 (delta 98), pack-reused 17567\u001b[K"}
{"timestamp_utc": "2024-07-31T08:07:17.999Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch fss3 set up to track remote branch fss3 from origin. <NL> Switched to a new branch 'fss3'"}
{"timestamp_utc": "2024-07-31T08:07:18.255Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://bitbucket.fnc.fujitsu.com:7999/iprepo/testcase-manifests <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date."}
{"timestamp_utc": "2024-07-31T08:07:18.814Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# manifest_filename \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/.repo/manifests/default.xml\" <NL> Fetching project \"test_framework\" <NL> Warning: Permanently added '[rtx-swtl-git.fnc.net.local]:7999' (RSA) to the list of known hosts."}
{"timestamp_utc": "2024-07-31T08:07:26.950Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'tfwk_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c5a96c8... saving manifest for tag tfwk_cd101 <NL> Fetching project \"test_framework/network-topology\" <NL> Note: checking out 'ntp_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 9dd57f7... saving manifest for tag ntp_cd118 <NL> Fetching project \"test_framework/network-topology-data\" <NL> Note: checking out 'ntpd_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name"}
{"timestamp_utc": "2024-07-31T08:07:26.951Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c580e72... saving manifest for tag ntpd_cd28 <NL> Fetching project \"test_framework/common_tools\""}
{"timestamp_utc": "2024-07-31T08:07:28.410Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'common-tools_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 6617d9d... saving manifest for tag common-tools_cd30 <NL> Fetching project \"test_framework/warrior-testcases/common\""}
{"timestamp_utc": "2024-07-31T08:07:28.665Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch DEVOPS-415_hw_sanity_tc_py3 set up to track remote branch DEVOPS-415_hw_sanity_tc_py3 from origin. <NL> Switched to a new branch 'DEVOPS-415_hw_sanity_tc_py3' <NL> Fetching project \"test_framework/testcase-config\""}
{"timestamp_utc": "2024-07-31T08:07:29.226Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch fss3 set up to track remote branch fss3 from origin. <NL> Switched to a new branch 'fss3'"}
{"timestamp_utc": "2024-07-31T08:07:29.483Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://rtx-swtl-git.fnc.net.local:7999/iprepo/testcase-config <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date. <NL> Fetching project \"test_framework/warrior-testcases/1finity\""}
{"timestamp_utc": "2024-07-31T08:07:41.652Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-tseries_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 93cf8df... Pull request #1586: L1TC-2668-increasing-rang-for-pm-value <NL> Fetching project \"test_framework/warrior-testcases/trp_base\" <NL> Note: checking out 'proj-fss3-recipe-trp_base_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 0e5f339... Pull request #19: TRPBASE-1278 changed auto-negotiation disabled <NL> Fetching project \"test_framework/warrior-testcases/dcn\""}
{"timestamp_utc": "2024-07-31T08:07:56.484Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Checking out files:  49% (6169/12577) <NL> Checking out files:  50% (6289/12577) <NL> Checking out files:  51% (6415/12577) <NL> Checking out files:  52% (6541/12577) <NL> Checking out files:  53% (6666/12577) <NL> Checking out files:  54% (6792/12577) <NL> Checking out files:  55% (6918/12577) <NL> Checking out files:  56% (7044/12577) <NL> Checking out files:  57% (7169/12577) <NL> Checking out files:  58% (7295/12577) <NL> Checking out files:  59% (7421/12577) <NL> Checking out files:  60% (7547/12577) <NL> Checking out files:  61% (7672/12577) <NL> Checking out files:  62% (7798/12577) <NL> Checking out files:  63% (7924/12577) <NL> Checking out files:  64% (8050/12577) <NL> Checking out files:  65% (8176/12577) <NL> Checking out files:  66% (8301/12577) <NL> Checking out files:  67% (8427/12577) <NL> Checking out files:  68% (8553/12577) <NL> Checking out files:  69% (8679/12577) <NL> Checking out files:  70% (8804/12577) <NL> Checking out files:  71% (8930/12577) <NL> Checking out files:  72% (9056/12577) <NL> Checking out files:  73% (9182/12577) <NL> Checking out files:  74% (9307/12577) <NL> Checking out files:  75% (9433/12577) <NL> Checking out files:  76% (9559/12577) <NL> Checking out files:  77% (9685/12577) <NL> Checking out files:  78% (9811/12577) <NL> Checking out files:  79% (9936/12577) <NL> Checking out files:  80% (10062/12577) <NL> Checking out files:  81% (10188/12577) <NL> Checking out files:  82% (10314/12577) <NL> Checking out files:  83% (10439/12577) <NL> Checking out files:  84% (10565/12577) <NL> Checking out files:  84% (10625/12577) <NL> Checking out files:  85% (10691/12577) <NL> Checking out files:  86% (10817/12577) <NL> Checking out files:  87% (10942/12577) <NL> Checking out files:  88% (11068/12577) <NL> Checking out files:  89% (11194/12577) <NL> Checking out files:  90% (11320/12577) <NL> Checking out files:  91% (11446/12577) <NL> Checking out files:  92% (11571/12577) <NL> Checking out files:  93% (11697/12577) <NL> Checking out files:  94% (11823/12577) <NL> Checking out files:  95% (11949/12577) <NL> Checking out files:  96% (12074/12577) <NL> Checking out files:  97% (12200/12577) <NL> Checking out files:  98% (12326/12577) <NL> Checking out files:  99% (12452/12577) <NL> Checking out files: 100% (12577/12577) <NL> Checking out files: 100% (12577/12577), done. <NL> Note: checking out 'proj-fss3-recipe-dcn_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 2dbf363... Pull request #579: DCN-10811 remove the dhcp process chcek <NL> Fetching project \"test_framework/warrior-testcases/snmp\""}
{"timestamp_utc": "2024-07-31T08:07:57.538Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-snmp_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 1c1d5c5... Pull request #63: FSS2SNMP-914 reduce TAT of SNMP L jobs <NL> Fetching project \"test_framework/warrior-testcases/ops\""}
{"timestamp_utc": "2024-07-31T08:08:02.573Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-ops_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c8e9ba9... Pull request #170: OPS-8964: Updated the client IP after Kubernetes server patching <NL> Fetching project \"test_framework/pycit-testcases/cit/lseries_test_cases\""}
{"timestamp_utc": "2024-07-31T08:08:03.498Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-lseries_test_cases_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at ce78bba... PF-9776 rdm-service check after mcu-p reboot <NL> Fetching project \"test_framework/pycit-testcases/cit/cit_l1cc\""}
{"timestamp_utc": "2024-07-31T08:08:03.753Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-cit_l1cc_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 3801263... Pull request #80: L1TC-2661 restore-profile-attr-testcases-commented <NL> Fetching project \"test_framework/warrior-keywords/ops_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:05.114Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-ops_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at b90c727... Pull request #9: OPS-7896 <NL> Fetching project \"test_framework/warrior-keywords/snmp_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:06.143Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-snmp_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at d00ee1e... Pull request #1: OPS-7722 <NL> Fetching project \"test_framework/robot-testcases/webui_automation-py3\""}
{"timestamp_utc": "2024-07-31T08:08:10.308Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-webui_automation-py3_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at f9b2864... Pull request #9: FSSFWK-8781: Initial commit #1. <NL> Fetching project \"test_framework/warrior-keywords/dcn_1finity\" <NL> Note: checking out 'proj-fss3-recipe-dcn_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 8ea07fa... Pull request #21: DCN-10811 increase the retry and correct the renew sed cmd <NL> Fetching project \"test_framework/warrior-testcases/openconfig-t\""}
{"timestamp_utc": "2024-07-31T08:08:10.883Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-openconfig-t_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c0f0ec8... Pull request #27: OPCG-323 <NL> Fetching project \"test_framework/warrior-keywords/kw_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:12.243Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-kw_1finity_latest_passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at e873a09... FSSVSW-1166 update pip conf file <NL> Fetching project \"test_framework/warrior-keywords/onefinity\""}
{"timestamp_utc": "2024-07-31T08:08:14.127Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-onefinity_latest_passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 93ebd8e... Pull request #60: Made the input text case insensitive for not-allowed <NL> Fetching project \"test_framework/robot_core\""}
{"timestamp_utc": "2024-07-31T08:08:14.382Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'robot-core_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 5b56560... HOTFIX: Fix refactoring mistake (used 'alias' kwarg instead of 'session_name') <NL> Fetching project \"test_framework/robot_tests\""}
{"timestamp_utc": "2024-07-31T08:08:15.307Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-robot_tests_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 6adf37a... Pull request #143: RF-733 update for 24.2 changes <NL> Fetching project \"test_framework/warrior-testcases/owb_lseries_att\""}
{"timestamp_utc": "2024-07-31T08:08:16.232Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-owb_lseries_att_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 78dd82a... Pull request #199: OWBSW-2496"}
{"timestamp_utc": "2024-07-31T08:08:16.486Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# manifest_filename \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/.repo/manifests/default.xml\" <NL> Fetching project \"test_framework\""}
{"timestamp_utc": "2024-07-31T08:08:16.741Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c5a96c8... saving manifest for tag tfwk_cd101 <NL> Fetching project \"test_framework/network-topology\""}
{"timestamp_utc": "2024-07-31T08:08:16.996Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 9dd57f7... saving manifest for tag ntp_cd118 <NL> Fetching project \"test_framework/network-topology-data\""}
{"timestamp_utc": "2024-07-31T08:08:17.251Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c580e72... saving manifest for tag ntpd_cd28 <NL> Fetching project \"test_framework/common_tools\" <NL> HEAD is now at 6617d9d... saving manifest for tag common-tools_cd30 <NL> Fetching project \"test_framework/warrior-testcases/common\""}
{"timestamp_utc": "2024-07-31T08:08:17.506Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Already on 'DEVOPS-415_hw_sanity_tc_py3' <NL> Fetching project \"test_framework/testcase-config\""}
{"timestamp_utc": "2024-07-31T08:08:18.065Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://rtx-swtl-git.fnc.net.local:7999/iprepo/testcase-config <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date. <NL> Fetching project \"test_framework/warrior-testcases/1finity\""}
{"timestamp_utc": "2024-07-31T08:08:18.625Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 93cf8df... Pull request #1586: L1TC-2668-increasing-rang-for-pm-value <NL> Fetching project \"test_framework/warrior-testcases/trp_base\" <NL> HEAD is now at 0e5f339... Pull request #19: TRPBASE-1278 changed auto-negotiation disabled <NL> Fetching project \"test_framework/warrior-testcases/dcn\""}
{"timestamp_utc": "2024-07-31T08:08:19.185Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 2dbf363... Pull request #579: DCN-10811 remove the dhcp process chcek <NL> Fetching project \"test_framework/warrior-testcases/snmp\""}
{"timestamp_utc": "2024-07-31T08:08:19.745Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 1c1d5c5... Pull request #63: FSS2SNMP-914 reduce TAT of SNMP L jobs <NL> Fetching project \"test_framework/warrior-testcases/ops\""}
{"timestamp_utc": "2024-07-31T08:08:20.000Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c8e9ba9... Pull request #170: OPS-8964: Updated the client IP after Kubernetes server patching <NL> Fetching project \"test_framework/pycit-testcases/cit/lseries_test_cases\""}
{"timestamp_utc": "2024-07-31T08:08:20.255Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at ce78bba... PF-9776 rdm-service check after mcu-p reboot <NL> Fetching project \"test_framework/pycit-testcases/cit/cit_l1cc\""}
{"timestamp_utc": "2024-07-31T08:08:20.511Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 3801263... Pull request #80: L1TC-2661 restore-profile-attr-testcases-commented <NL> Fetching project \"test_framework/warrior-keywords/ops_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:20.766Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at b90c727... Pull request #9: OPS-7896 <NL> Fetching project \"test_framework/warrior-keywords/snmp_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:21.127Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at d00ee1e... Pull request #1: OPS-7722 <NL> Fetching project \"test_framework/robot-testcases/webui_automation-py3\""}
{"timestamp_utc": "2024-07-31T08:08:21.383Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at f9b2864... Pull request #9: FSSFWK-8781: Initial commit #1. <NL> Fetching project \"test_framework/warrior-keywords/dcn_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:21.638Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 8ea07fa... Pull request #21: DCN-10811 increase the retry and correct the renew sed cmd <NL> Fetching project \"test_framework/warrior-testcases/openconfig-t\" <NL> HEAD is now at c0f0ec8... Pull request #27: OPCG-323 <NL> Fetching project \"test_framework/warrior-keywords/kw_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:21.894Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at e873a09... FSSVSW-1166 update pip conf file <NL> Fetching project \"test_framework/warrior-keywords/onefinity\""}
{"timestamp_utc": "2024-07-31T08:08:22.452Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 93ebd8e... Pull request #60: Made the input text case insensitive for not-allowed"}
{"timestamp_utc": "2024-07-31T08:08:22.453Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching project \"test_framework/robot_core\" <NL> HEAD is now at 5b56560... HOTFIX: Fix refactoring mistake (used 'alias' kwarg instead of 'session_name') <NL> Fetching project \"test_framework/robot_tests\""}
{"timestamp_utc": "2024-07-31T08:08:22.707Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 6adf37a... Pull request #143: RF-733 update for 24.2 changes <NL> Fetching project \"test_framework/warrior-testcases/owb_lseries_att\""}
{"timestamp_utc": "2024-07-31T08:08:22.963Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 78dd82a... Pull request #199: OWBSW-2496 <NL> # fnc-init-test-env: TEST_FRAMEWORK_ROOT_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework\" <NL> ntpd-setup.sh: NETWORK_TOPOLOGY_DATA_ROOT_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data\""}
{"timestamp_utc": "2024-07-31T08:08:23.523Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__before_variables') <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__variables') <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__normal') <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.add_topology_tag_name: arg_item_obj: { <NL> \"def_item_obj\": { <NL> \"const\": false, <NL> \"default\": null, <NL> \"dest\": \"discard_topology_tag_name\", <NL> \"input_type\": \"text\", <NL> \"name\": \"--topology-tag-name\", <NL> \"nargs\": 2, <NL> \"phase\": \"phase__normal\", <NL> \"required\": false, <NL> \"set_attributes_func\": \"<bound method args_derived_cl.add_topology_tag_name of <__main__.args_derived_cl object at 0x7f1abb8f38d0>>\", <NL> \"subtype\": null, <NL> \"type\": \"list\" <NL> }, <NL> \"item_list\": [ <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" <NL> ] <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: get_topology_tag_pre_and_post_file_lists: - checking topology_tag_name 'DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1' <NL> # 03:08:23 tfwk-exec-test-agent INFO: get_topology_tag_pre_and_post_file_lists:   topology_tag_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags' <NL> # 03:08:23 tfwk-exec-test-agent INFO: add_from_testcase_group_config_fname: testcase_group_config_fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/conf/local-config.json' <NL> # 03:08:23 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155'] <NL> # 03:08:23 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir'] <NL> # 03:08:23 tfwk-exec-test-agent INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json'] <NL> # 03:08:23 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-setup', '-v', '-v', '--work-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155', '--pid', '155', '--shared-store-tag', 'tag', '--out-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json'] <NL> # 03:08:23 ntp-topology-setup INFO: args: { <NL> \"container_local_base_dir\": null, <NL> \"out_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json\", <NL> \"parent_hostip\": null, <NL> \"parent_hostname\": null, <NL> \"pid\": \"155\", <NL> \"script_dir\": null, <NL> \"shared_store_base_dir\": null, <NL> \"shared_store_tag\": \"tag\", <NL> \"shared_store_type\": null, <NL> \"topology_options\": null, <NL> \"topology_type\": null, <NL> \"verbosity\": 2, <NL> \"work_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155\", <NL> \"work_dir_tag\": null, <NL> \"work_dir_type\": null <NL> } <NL> # 03:08:23 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/docker: stdout b'/bin/docker\\n'"}
{"timestamp_utc": "2024-07-31T08:08:23.778Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-topology-setup INFO: get_have_docker_flag: sudo /bin/docker info --format {{.ID}}: stdout b'KOKZ:H6GU:EMLK:EZ3K:QZZA:4VEX:JJEO:TZML:25TS:EMA2:3UUU:Z4TS\\n' <NL> # 03:08:23 ntp-topology-setup INFO: get_in_docker_container_flag: /proc/1/cgroup: '12:memory:/system.slice/docker-a60c81e010e505685c0da3de47e0e97e49c4bc14876516538940519c7634c717.scope\\n' <NL> # 03:08:23 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/podman: stderr b'sudo: /bin/podman: command not found\\n' <NL> # 03:08:23 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/podman: returncode 1 <NL> # 03:08:23 ntp-topology-setup INFO: get_in_kubernetes_flag: KUBERNETES_SERVICE_HOST None <NL> # 03:08:23 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /usr/local/bin/vmmng_interface.py: stderr b'sudo: /usr/local/bin/vmmng_interface.py: command not found\\n' <NL> # 03:08:23 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /usr/local/bin/vmmng_interface.py: returncode 1 <NL> # 03:08:23 ntp-topology-setup INFO: main: have_docker_flag True <NL> # 03:08:23 ntp-topology-setup INFO: main: have_docker_socket_flag True <NL> # 03:08:23 ntp-topology-setup INFO: main: in_docker_container_flag True <NL> # 03:08:23 ntp-topology-setup INFO: main: have_podman_flag False <NL> # 03:08:23 ntp-topology-setup INFO: main: have_podman_socket_flag False <NL> # 03:08:23 ntp-topology-setup INFO: main: in_podman_container_flag False <NL> # 03:08:23 ntp-topology-setup INFO: main: in_kubernetes_flag False <NL> # 03:08:23 ntp-topology-setup INFO: main: have_sudo_vmmng_flag False <NL> # 03:08:23 ntp-topology-setup INFO: main: defaulting topology_type to 'single' <NL> # 03:08:23 ntp-topology-setup INFO: get_network_topology_tag: shared_store_tag = tag <NL> # 03:08:23 ntp-topology-setup INFO: get_network_topology_tag: network_topology_tag  'tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e' (len 51) <NL> # 03:08:23 ntp-topology-setup INFO: main: shared_store_mount_dir        '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e' <NL> # 03:08:23 ntp-topology-setup INFO: main: shared_store_dir              '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e' <NL> # 03:08:23 ntp-topology-setup INFO: main: container_workspace_basedir   '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace' <NL> # 03:08:23 ntp-topology-setup INFO: main: container_logs_basedir        '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs' <NL> # 03:08:23 ntp-topology-setup INFO: main: container_local_base_dir      None <NL> # 03:08:23 ntp-topology-setup INFO: main: container_fake_local_base_dir None (fake can only be used when using remote store) <NL> # 03:08:23 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e'] <NL> # 03:08:23 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace'] <NL> # 03:08:23 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs'] <NL> # 03:08:23 ntp-topology-setup INFO: exec_cmd: ['chmod', 'a+rwx', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs'] <NL> # 03:08:23 ntp-topology-setup INFO: ntp_info_cl.write_json_dict: ntp_info_obj into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json': { <NL> \"_NETWORK_TOPOLOGY_TAG\": \"tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> \"_SHARED_STORE_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> \"_TOPOLOGY_TYPE\": \"container-docker-single\" <NL> } <NL> # 03:08:23 ntp-topology-setup INFO: shared_store_info_cl.write_json_dict: shared_store_info_dict into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json': { <NL> \"REMOTE_STORE_FLAG\": false, <NL> \"SHARED_STORE_MOUNT_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> \"UNIQUE_SHARED_SUBDIR\": \"ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: main: begin: calling set_attributes() to perform the delayed evaluation <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__delayed') <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE1/device:main' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json'"}
{"timestamp_utc": "2024-07-31T08:08:24.033Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 tfwk-exec-test-agent INFO: get_output: command ['ci-get-pipeline-image-location-info', '--project-name', '{#project_name#}', '--project-label', '{#project_label#}', '--branch-name', '{#branch_name#}', '--regression-group', '{#regression_group#}', '--machine-name', '{#machine_name#}', '--image-name', '{#image_name#}']:"}
{"timestamp_utc": "2024-07-31T08:08:24.034Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 tfwk-exec-test-agent INFO: get_output:   stdout: {  \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\" } <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_cl.get_image_location_info_dict: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:23 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:23 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"2\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:23 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE2/device:main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\","}
{"timestamp_utc": "2024-07-31T08:08:24.035Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"2\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none"}
{"timestamp_utc": "2024-07-31T08:08:24.294Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE3/device:main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"shelf-num\": \"200\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-aggr-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T']: <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T': product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip'"}
{"timestamp_utc": "2024-07-31T08:08:24.295Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE4/device:main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"shelf-num\": \"200\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-aggr-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T']: <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T': product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:24 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": {"}
{"timestamp_utc": "2024-07-31T08:08:24.296Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main: end: calling set_attributes() to perform the delayed evaluation <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.non_explicit_instance_context_add: define_instance_attr_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"2\" <NL> } <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"2\" <NL> } <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"200\" <NL> } <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"200\" <NL> } <NL> }, <NL> \"network-element:NE4/device:trib1\": { <NL> \"name\": \"network-element:NE4/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\", <NL> \"network-element:NE4/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-attr\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: args_derived_cl.non_explicit_instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\" <NL> }, <NL> \"network-element:NE4/device:trib1\": { <NL> \"name\": \"network-element:NE4/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\", <NL> \"network-element:NE4/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main: ntp_topology_run: [ <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE1/device:main\", <NL> \"main-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE1/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE1/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE1/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE1/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE1/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE1/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE1/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE1/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE1/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE2/device:main\", <NL> \"main-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE2/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE2/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE2/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE2/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE2/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE2/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE2/device:trib1\","}
{"timestamp_utc": "2024-07-31T08:08:24.297Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE2/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE2/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE3/device:main\", <NL> \"main\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE3/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE3/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE3/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE3/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE3/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE3/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE3/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE3/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE3/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE4/device:main\", <NL> \"main\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE4/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE4/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE4/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE4/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE4/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE4/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE4/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE4/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE4/device:trib1\" <NL> ] <NL> # 03:08:24 tfwk-exec-test-agent INFO: main: - new exec status info: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   topology_active_flag=False <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   topology_state='initializing' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   topology info for work dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155': <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     topology_tag_name: ['DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1'] <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     topology_pre_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json'] <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     topology_post_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json'] <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:main'"}
{"timestamp_utc": "2024-07-31T08:08:24.298Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:trib1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:24 tfwk-exec-test-agent INFO: main: args_obj.execute_wait_for_devices_flag True <NL> # 03:08:24 tfwk-exec-test-agent INFO: main: local_exec_test_agent_flag True (defaulted from args_obj.execute_wait_for_devices_flag) <NL> # 03:08:24 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-run.py', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json', '--services-legacy-env-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-legacy-env.json', '--services-env-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', '--image-info-configuration-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/image-info-configuration.json', '--ntp-topology-pre-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--ntp-topology-post-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--parent-hostname', 'rtxoialp85.fnc.net.local', '--parent-hostip', '167.254.217.214', '--ntp-instance-context-image-info-config-name', 'network-element:NE1/device:main', 'main-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE1/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE1/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE1/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE1/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE1/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE1/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE1/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE1/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}', '--ntp-instance-context-add', 'network-element:NE1/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE2/device:main', 'main-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE2/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE2/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE2/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE2/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE2/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE2/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE2/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE2/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}', '--ntp-instance-context-add', 'network-element:NE2/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE3/device:main', 'main', '--ntp-instance-context-image-location-type', 'network-element:NE3/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE3/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE3/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}', '--ntp-instance-context-add', 'network-element:NE3/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE3/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE3/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE3/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE3/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE3/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE4/device:main', 'main', '--ntp-instance-context-image-location-type', 'network-element:NE4/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE4/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE4/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}', '--ntp-instance-context-add', 'network-element:NE4/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE4/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE4/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE4/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE4/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE4/device:trib1'] <NL> # 03:08:24 ntp-topology-run.py INFO: main: { <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"_instance_context_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:main\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": {"}
{"timestamp_utc": "2024-07-31T08:08:24.299Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main-L1-OTSG2\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE1/device:main\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:trib1\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE1/device:trib1\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:main\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main-L1-OTSG2\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE2/device:main\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:trib1\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE2/device:trib1\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:main\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE3/device:main\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:trib1\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE3/device:trib1\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:main\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE4/device:main\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:trib1\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE4/device:trib1\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         } <NL> # 03:08:24 ntp-topology-run.py INFO: main:     }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"_instance_context_list\": [ <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:main\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:trib1\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:main\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:trib1\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:main\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:trib1\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:main\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:trib1\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:     ], <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"_ntp_topology_obj_list\": [ <NL> # 03:08:24 ntp-topology-run.py INFO: main:         { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"--ntp-topology-pre-fname\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"value\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:24 ntp-topology-run.py INFO: main:         { <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"name\": \"--ntp-topology-post-fname\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:             \"value\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\" <NL> # 03:08:24 ntp-topology-run.py INFO: main:         } <NL> # 03:08:24 ntp-topology-run.py INFO: main:     ], <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"abort_before_create_flag\": false, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"create_image_info_from_tag_command\": null, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"get_image_location_info_command\": null, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"image_info_configuration_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/image-info-configuration.json\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"ntp_topology_tag_dir\": null, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"parent_hostip\": \"167.254.217.214\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"parent_hostname\": \"rtxoialp85.fnc.net.local\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"services_env_bash_fname\": null, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"services_env_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"services_global_host_info_flag\": true, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"services_legacy_env_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-legacy-env.json\", <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"services_ntp_json_fname\": null, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"show_topology_flag\": true, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"verify_topology_flag\": false, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"verify_topology_image_info_path\": null, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"verify_topology_kernel_path\": null, <NL> # 03:08:24 ntp-topology-run.py INFO: main:     \"verify_topology_rootfs_path\": null <NL> # 03:08:24 ntp-topology-run.py INFO: main: } <NL> # 03:08:24 ntp-topology-run.py INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/image-info'] <NL> # 03:08:24 ntp-topology-run.py INFO: create_flist_file: - input_topology_json_fname_list: <NL> # 03:08:24 ntp-topology-run.py INFO: create_flist_file:   item '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json' <NL> # 03:08:24 ntp-topology-run.py INFO: create_flist_file: - input_topology_post_json_fname_list: <NL> # 03:08:24 ntp-topology-run.py INFO: create_flist_file:   item '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json' <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:osc1"}
{"timestamp_utc": "2024-07-31T08:08:24.300Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lcn1 referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lcn1 from referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lcn2 referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lcn2 from referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lmp referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lmp from referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:osc1 referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:osc1 from referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:osc2 referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:osc2 from referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lcn1 referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lcn1 from referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lcn2 referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lcn2 from referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lmp referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lmp from referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:osc1 referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:osc1 from referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:osc2 referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:osc2 from referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lcn1 referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lcn1 from referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lcn2 referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lcn2 from referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lmp referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lmp from referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:osc1 referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:osc1 from referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:osc2 referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:osc2 from referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lcn1 referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lcn1 from referencing network:lcn1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lcn2 referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lcn2 from referencing network:lcn2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lmp referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lmp from referencing network:lmp <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:osc1 referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:osc1 from referencing network:osc1 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:osc2 referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:osc2 from referencing network:osc2 <NL> # 03:08:24 ntp-topology-run.py INFO: operating_system_cl.get_current_operating_system_tag: PRETTY_NAME 'CentOS Linux 7 (Core)', ID 'centos', MAJOR_VERSION_ID '7' <NL> # 03:08:24 ntp-topology-run.py INFO: create_dynamic_defaults: operating_system_tag 'rhel-7' <NL> # 03:08:24 ntp-topology-run.py INFO: add_dynamic_defaults_for_qemu_defs: qemu_command None <NL> # 03:08:24 ntp-topology-run.py INFO: add_dynamic_defaults_for_docker_defs: docker_image_name None <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE1/device:main' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE2/device:main' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE3/device:main' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE4/device:main' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:24 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.instance.create_instance_new: \"definitions:instance-configure\" <NL> # 03:08:24 ntp-topology-run.py INFO: ntp.definitions_instance_configure.instance_configure_cl.write_amend_file: saved amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json' <NL> # 03:08:24 ntp-topology-run.py INFO: exec_cmd: ['rm', '-f', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json'] <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE1/device:main' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:08:24.301Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE1/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'main-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:24.556Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE1/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE1/device:main\" <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE1/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom/image' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE1/device.main/data/qemu/cdrom/image' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    71 Jul 31 03:08 .' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    27 Jul 31 03:08 ..' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:08:24.557Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"08-qemu-main-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"main-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict'"}
{"timestamp_utc": "2024-07-31T08:08:24.811Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "network-element.NE1/device.main/data/qemu <NL> network-element.NE1/device.main/data/qemu/cdrom <NL> network-element.NE1/device.main/data/qemu/cdrom/image <NL> network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:08:24.812Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE1/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:25.067Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE1/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE1/device:trib1\" <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE1/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE1/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    71 Jul 31 03:08 .' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    27 Jul 31 03:08 ..' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE1/device.trib1/data/qemu <NL> network-element.NE1/device.trib1/data/qemu/cdrom <NL> network-element.NE1/device.trib1/data/qemu/cdrom/image <NL> network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:24 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE2/device:main'"}
{"timestamp_utc": "2024-07-31T08:08:25.068Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:24 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main-L1-OTSG2' <NL> # 03:08:24 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE2/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'main-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:25.322Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:25 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE2/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\","}
{"timestamp_utc": "2024-07-31T08:08:25.323Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE2/device:main\" <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE2/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom/image' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE2/device.main/data/qemu/cdrom/image' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    71 Jul 31 03:08 .' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    27 Jul 31 03:08 ..' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main-L1-OTSG2' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"08-qemu-main-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"main-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE2/device.main/data/qemu <NL> network-element.NE2/device.main/data/qemu/cdrom <NL> network-element.NE2/device.main/data/qemu/cdrom/image <NL> network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2' <NL> # 03:08:25 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE2/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:25.579Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:25 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE2/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE2/device:trib1\" <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE2/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE2/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    71 Jul 31 03:08 .' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    27 Jul 31 03:08 ..' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE2/device.trib1/data/qemu <NL> network-element.NE2/device.trib1/data/qemu/cdrom <NL> network-element.NE2/device.trib1/data/qemu/cdrom/image <NL> network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE3/device:main' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main' <NL> # 03:08:25 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE3/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--image-info-configuration-name', 'main']"}
{"timestamp_utc": "2024-07-31T08:08:25.965Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:25 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"instance_context\": \"network-element:NE3/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE3/device:main\" <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 18:00   cdrom/image/' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2568482816  07-26-2024 17:57   cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    32881  07-26-2024 17:58   cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE3/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> inflating: network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom/image' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE3/device.main/data/qemu/cdrom/image' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    76 Jul 31 03:08 .' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    27 Jul 31 03:08 ..' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 32881 Jul 26 17:58 fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json': ['main-BDC2-C200', 'main_prot-BDC2-C200', 'main', 'main_prot'] <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"03-qemu-main-image-config-values.json\" <NL> ], <NL> \"configuration-name\": \"main\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE3/device.main/data/qemu <NL> network-element.NE3/device.main/data/qemu/cdrom <NL> network-element.NE3/device.main/data/qemu/cdrom/image <NL> network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:25 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:25 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:08:25.966Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:25 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE3/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:26.254Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:26 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null,"}
{"timestamp_utc": "2024-07-31T08:08:26.255Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE3/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE3/device:trib1\" <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE3/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE3/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    63 Jul 31 03:08 .' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    19 Jul 31 03:08 ..' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE3/device.trib1/data/qemu <NL> network-element.NE3/device.trib1/data/qemu/cdrom <NL> network-element.NE3/device.trib1/data/qemu/cdrom/image <NL> network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE4/device:main' <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main' <NL> # 03:08:26 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE4/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--image-info-configuration-name', 'main']"}
{"timestamp_utc": "2024-07-31T08:08:26.510Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:26 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\","}
{"timestamp_utc": "2024-07-31T08:08:26.511Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_context\": \"network-element:NE4/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE4/device:main\" <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 18:00   cdrom/image/' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2568482816  07-26-2024 17:57   cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    32881  07-26-2024 17:58   cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE4/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> inflating: network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom/image' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE4/device.main/data/qemu/cdrom/image' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    76 Jul 31 03:08 .' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    27 Jul 31 03:08 ..' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 32881 Jul 26 17:58 fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json': ['main-BDC2-C200', 'main_prot-BDC2-C200', 'main', 'main_prot'] <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"03-qemu-main-image-config-values.json\" <NL> ], <NL> \"configuration-name\": \"main\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE4/device.main/data/qemu <NL> network-element.NE4/device.main/data/qemu/cdrom <NL> network-element.NE4/device.main/data/qemu/cdrom/image <NL> network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:26 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2' <NL> # 03:08:26 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--instance-context', 'network-element:NE4/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:26.766Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:26 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE4/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE4/device:trib1\" <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE4/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE4/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 36' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins    71 Jul 31 03:08 .' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins    27 Jul 31 03:08 ..' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$'"}
{"timestamp_utc": "2024-07-31T08:08:26.767Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:26 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE4/device.trib1/data/qemu <NL> network-element.NE4/device.trib1/data/qemu/cdrom <NL> network-element.NE4/device.trib1/data/qemu/cdrom/image <NL> network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip"}
{"timestamp_utc": "2024-07-31T08:08:27.027Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:26 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\" <NL> # 03:08:26 ntp-topology-run.py INFO: exec_cmd: ['cat', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json'] <NL> [ <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:27.028Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"1\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"1\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE1\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\","}
{"timestamp_utc": "2024-07-31T08:08:27.029Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ]"}
{"timestamp_utc": "2024-07-31T08:08:27.030Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "}, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE1\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\","}
{"timestamp_utc": "2024-07-31T08:08:27.031Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"1\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"1\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE2\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\""}
{"timestamp_utc": "2024-07-31T08:08:27.032Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "}, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:27.033Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "{ <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE2\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:27.034Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"{#cpu_model#}\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"cpu_model\\\": \\\"qemu64\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"redundancyMode\\\": \\\"WORK\\\", \\\"serialNum\\\": \\\"12345\\\", \\\"shelfNumber\\\": \\\"200\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"200\\\", \\\"smp\\\": \\\"1\\\", \\\"unitCode\\\": \\\"0xc200\\\", \\\"unitName\\\": \\\"BDC2-C200\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\","}
{"timestamp_utc": "2024-07-31T08:08:27.035Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE3\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:27.036Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE3\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ],"}
{"timestamp_utc": "2024-07-31T08:08:27.037Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:27.038Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"{#cpu_model#}\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"cpu_model\\\": \\\"qemu64\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"redundancyMode\\\": \\\"WORK\\\", \\\"serialNum\\\": \\\"12345\\\", \\\"shelfNumber\\\": \\\"200\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"200\\\", \\\"smp\\\": \\\"1\\\", \\\"unitCode\\\": \\\"0xc200\\\", \\\"unitName\\\": \\\"BDC2-C200\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE4\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\","}
{"timestamp_utc": "2024-07-31T08:08:27.039Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:27.040Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE4\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\","}
{"timestamp_utc": "2024-07-31T08:08:27.041Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> } <NL> ]# 03:08:26 ntp-topology-run.py INFO: exec_cmd: ['ntp-amend-for-qemu', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json', '--out-mode', 'create', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json'] <NL> # 03:08:26 ntp-amend-for-qemu INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json\", <NL> \"out_mode\": \"create\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:27.297Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-qemu INFO: handle_phase_1: - begin <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE1/device:main', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:main/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:main/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE1/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:trib1/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:trib1/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE2/device:main', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:main/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:main/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE2/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:trib1/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:trib1/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE3/device:main', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:main/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:main/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE3/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:trib1/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:trib1/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE4/device:main', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:main/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:main/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE4/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:trib1/serial-interface:serial-1\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:trib1/serial-interface:serial-2\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE1/device:main/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lmp\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE1/device:trib1/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE2/device:main/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lmp\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE2/device:trib1/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE3/device:main/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lmp\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE3/device:trib1/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE4/device:main/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lmp\" already has a network defined"}
{"timestamp_utc": "2024-07-31T08:08:27.298Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE4/device:trib1/interface:debug\" <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:27 ntp-amend-for-qemu INFO: handle_phase_1: ----- <NL> # 03:08:27 ntp-topology-run.py INFO: exec_cmd: ['ntp-amend-for-docker-containers', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json', '--out-mode', 'append', '--topology-tag', 'tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e', '--topology-type', 'container-docker-single', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json'] <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json\", <NL> \"out_mode\": \"append\", <NL> \"topology_tag\": \"tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> \"topology_type\": \"container-docker-single\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:27.556Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: topology_definitions_cl.__init__: new_topology_type \"container-docker-single\""}
{"timestamp_utc": "2024-07-31T08:08:27.557Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: topology_definitions_cl.__init__: new termination-signal 15(SIGTERM) <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: main: topology_type \"container-docker-single\" <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE1/device:main', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE1/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE2/device:main', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE2/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE3/device:main', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE3/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE4/device:main', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE4/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: create_group_instances: <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_new: \"definitions:topology/device_group:group-device-group-type-qemu-01\" <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: create_group_instances: get_instance_dict: { <NL> \"instance_info\": { <NL> \"group_type\": \"device-group-type-qemu\", <NL> \"instance_action\": \"create-new\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"topology\", <NL> \"instance_type\": \"definitions\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"group-device-group-type-qemu-01\", <NL> \"instance_type\": \"device_group\" <NL> } <NL> } <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main\" (ref \"network-element:NE1/device:main\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1\" (ref \"network-element:NE1/device:trib1\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main\" (ref \"network-element:NE2/device:main\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1\" (ref \"network-element:NE2/device:trib1\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main\" (ref \"network-element:NE3/device:main\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1\" (ref \"network-element:NE3/device:trib1\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main\" (ref \"network-element:NE4/device:main\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1\" (ref \"network-element:NE4/device:trib1\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: create_default_docker_bridge_networks: <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_new: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-console\" (ref \"network-element:NE1/device:main/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-debug-ssh\" (ref \"network-element:NE1/device:main/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-cli\" (ref \"network-element:NE1/device:main/service:cli\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\")"}
{"timestamp_utc": "2024-07-31T08:08:27.558Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-netconf\" (ref \"network-element:NE1/device:main/service:netconf\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gnmi\" (ref \"network-element:NE1/device:main/service:gnmi\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-snmp\" (ref \"network-element:NE1/device:main/service:snmp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-webui\" (ref \"network-element:NE1/device:main/service:webui\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-https\" (ref \"network-element:NE1/device:main/service:https\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-zmq\" (ref \"network-element:NE1/device:main/service:zmq\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb\" (ref \"network-element:NE1/device:main/service:gdb\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb-ops-additional\" (ref \"network-element:NE1/device:main/service:gdb-ops-additional\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ospl\" (ref \"network-element:NE1/device:main/service:ospl\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ftp\" (ref \"network-element:NE1/device:main/service:ftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-sftp\" (ref \"network-element:NE1/device:main/service:sftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-telnet\" (ref \"network-element:NE1/device:main/service:telnet\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-console\" (ref \"network-element:NE1/device:trib1/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-debug-ssh\" (ref \"network-element:NE1/device:trib1/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-console\" (ref \"network-element:NE2/device:main/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-debug-ssh\" (ref \"network-element:NE2/device:main/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-cli\" (ref \"network-element:NE2/device:main/service:cli\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-netconf\" (ref \"network-element:NE2/device:main/service:netconf\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gnmi\" (ref \"network-element:NE2/device:main/service:gnmi\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-snmp\" (ref \"network-element:NE2/device:main/service:snmp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-webui\" (ref \"network-element:NE2/device:main/service:webui\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-https\" (ref \"network-element:NE2/device:main/service:https\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-zmq\" (ref \"network-element:NE2/device:main/service:zmq\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb\" (ref \"network-element:NE2/device:main/service:gdb\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb-ops-additional\" (ref \"network-element:NE2/device:main/service:gdb-ops-additional\")"}
{"timestamp_utc": "2024-07-31T08:08:27.559Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ospl\" (ref \"network-element:NE2/device:main/service:ospl\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ftp\" (ref \"network-element:NE2/device:main/service:ftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-sftp\" (ref \"network-element:NE2/device:main/service:sftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-telnet\" (ref \"network-element:NE2/device:main/service:telnet\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-console\" (ref \"network-element:NE2/device:trib1/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-debug-ssh\" (ref \"network-element:NE2/device:trib1/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-console\" (ref \"network-element:NE3/device:main/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-debug-ssh\" (ref \"network-element:NE3/device:main/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-cli\" (ref \"network-element:NE3/device:main/service:cli\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-netconf\" (ref \"network-element:NE3/device:main/service:netconf\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gnmi\" (ref \"network-element:NE3/device:main/service:gnmi\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-snmp\" (ref \"network-element:NE3/device:main/service:snmp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-webui\" (ref \"network-element:NE3/device:main/service:webui\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-https\" (ref \"network-element:NE3/device:main/service:https\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-zmq\" (ref \"network-element:NE3/device:main/service:zmq\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb\" (ref \"network-element:NE3/device:main/service:gdb\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb-ops-additional\" (ref \"network-element:NE3/device:main/service:gdb-ops-additional\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ospl\" (ref \"network-element:NE3/device:main/service:ospl\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ftp\" (ref \"network-element:NE3/device:main/service:ftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-sftp\" (ref \"network-element:NE3/device:main/service:sftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-telnet\" (ref \"network-element:NE3/device:main/service:telnet\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-console\" (ref \"network-element:NE3/device:trib1/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-debug-ssh\" (ref \"network-element:NE3/device:trib1/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-console\" (ref \"network-element:NE4/device:main/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\")"}
{"timestamp_utc": "2024-07-31T08:08:27.560Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-debug-ssh\" (ref \"network-element:NE4/device:main/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-cli\" (ref \"network-element:NE4/device:main/service:cli\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-netconf\" (ref \"network-element:NE4/device:main/service:netconf\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gnmi\" (ref \"network-element:NE4/device:main/service:gnmi\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-snmp\" (ref \"network-element:NE4/device:main/service:snmp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-webui\" (ref \"network-element:NE4/device:main/service:webui\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-https\" (ref \"network-element:NE4/device:main/service:https\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-zmq\" (ref \"network-element:NE4/device:main/service:zmq\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb\" (ref \"network-element:NE4/device:main/service:gdb\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb-ops-additional\" (ref \"network-element:NE4/device:main/service:gdb-ops-additional\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ospl\" (ref \"network-element:NE4/device:main/service:ospl\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ftp\" (ref \"network-element:NE4/device:main/service:ftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-sftp\" (ref \"network-element:NE4/device:main/service:sftp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-telnet\" (ref \"network-element:NE4/device:main/service:telnet\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-console\" (ref \"network-element:NE4/device:trib1/service:console\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-debug-ssh\" (ref \"network-element:NE4/device:trib1/service:debug-ssh\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: begin <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge', network_type 'external' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc1', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lmp', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lcn1', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lcn2', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE1/network:ilan', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc2', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc1-2', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc2-2', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE2/network:ilan', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE3/network:ilan', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE4/network:ilan', network_type 'internal' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types: group_id group-device-group-type-qemu-01"}
{"timestamp_utc": "2024-07-31T08:08:27.561Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   external: resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     this is the container's default docker bridge network, do not create again <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id None <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1\" (ref \"network:osc1\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp\" (ref \"network:lmp\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1\" (ref \"network:lcn1\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2\" (ref \"network:lcn2\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan\" (ref \"network-element:NE1/network:ilan\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2\" (ref \"network:osc2\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2\" (ref \"network:osc1-2\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2\" (ref \"network:osc2-2\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan\" (ref \"network-element:NE2/network:ilan\")"}
{"timestamp_utc": "2024-07-31T08:08:27.562Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan\" (ref \"network-element:NE3/network:ilan\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan\" (ref \"network-element:NE4/network:ilan\") <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show: networks by group <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id None <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan"}
{"timestamp_utc": "2024-07-31T08:08:27.563Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show: groups by network <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:   group_id group-device-group-type-qemu-01 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id None <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:27 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- -----"}
{"timestamp_utc": "2024-07-31T08:08:27.564Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-topology-run.py INFO: exec_cmd: ['ntp-update-instance-sequence-numbers', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json', '--out-mode', 'append', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json']"}
{"timestamp_utc": "2024-07-31T08:08:27.819Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json\", <NL> \"out_mode\": \"append\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:28.076Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: main: ----- collecting existing counts <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: ----- setting new counts <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:docker-container\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:docker-container\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"definitions:docker-network\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"definitions:docker-network\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"definitions:instance-configure\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"definitions:instance-configure\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"definitions:instance-defaults\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"definitions:instance-defaults\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"definitions:kubernetes-cluster\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"definitions:kubernetes-cluster\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"definitions:qemu-configuration\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"definitions:qemu-configuration\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"definitions:topology\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"definitions:topology\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network:lcn1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network:lcn2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network:lmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network:osc1-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network:osc1-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network:osc2-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network:osc2-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE1/device:main\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc2\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:28.077Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 61\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc2\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:28.078Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 62\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 63\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 64\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 65\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 66\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 67\": create-new instance_context_absolute_id \"network-element:NE1/network:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 68\": create-new instance_context_absolute_id \"network-element:NE2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 69\": create-new instance_context_absolute_id \"network-element:NE2/device:main\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE2/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 70\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 71\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 72\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 73\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 74\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 75\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 76\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 77\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 78\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 79\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 80\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 81\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 82\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 83\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 84\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 85\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 86\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 87\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 88\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 89\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 90\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 91\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 92\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 93\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 94\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 95\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 96\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 97\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 98\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 99\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:28.079Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"100\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"101\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"102\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"103\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"104\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"105\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"106\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"107\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"108\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"109\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"110\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"111\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"112\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"113\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"114\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"115\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"116\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"117\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"118\": create-new instance_context_absolute_id \"network-element:NE2/network:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE2/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"119\": create-new instance_context_absolute_id \"network-element:NE3\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE3\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"120\": create-new instance_context_absolute_id \"network-element:NE3/device:main\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE3/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"121\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"122\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"123\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"124\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"125\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"126\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"127\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"128\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"129\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"130\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"131\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"132\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"133\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"134\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"135\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"136\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"137\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:28.080Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"138\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"139\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"140\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"141\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"142\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"143\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"144\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"145\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"146\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"147\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"148\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"149\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"150\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"151\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"152\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"153\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"154\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"155\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"156\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"157\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"158\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"159\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"160\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"161\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"162\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"163\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"164\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"165\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"166\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"167\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"168\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"169\": create-new instance_context_absolute_id \"network-element:NE3/network:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE3/network:ilan\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:28.081Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"170\": create-new instance_context_absolute_id \"network-element:NE4\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE4\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"171\": create-new instance_context_absolute_id \"network-element:NE4/device:main\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE4/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"172\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"173\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"174\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"175\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"176\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"177\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"178\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"179\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"180\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"181\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"182\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"183\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"184\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"185\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"186\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"187\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"188\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"189\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"190\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"191\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"192\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"193\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"194\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"195\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"196\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"197\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"198\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 61\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"199\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"200\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 62\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"201\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"202\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 63\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"203\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"204\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 64\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"205\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"206\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 65\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"207\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:28.082Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"208\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 66\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"209\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"210\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"211\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"212\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"213\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"214\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"215\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"216\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"217\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 67\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"218\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 68\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"219\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \"220\": create-new instance_context_absolute_id \"network-element:NE4/network:ilan\" (instance-sequence-number) <NL> # 03:08:27 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE4/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:27 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-json-flist', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--use-relative-path', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json'] <NL> # 03:08:28 ntp-create-json-flist INFO: arg_dict: { <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json\" <NL> ], <NL> \"use_absolute_path_flag\": false, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:28 ntp-create-json-flist DEBUG: json_flist ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/topology-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/docker-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/kubernetes-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/qemu-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/data/instance-defaults-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-01-dynamic-defaults.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-02-config.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-03-user.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/amend-04-setup.json'] <NL> # 03:08:28 ntp-create-json-flist DEBUG: flist_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\" <NL> # 03:08:28 ntp-create-json-flist DEBUG: workspace_root_dir \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace\" <NL> # 03:08:28 ntp-create-json-flist DEBUG: flist_fpath \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\""}
{"timestamp_utc": "2024-07-31T08:08:38.078Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology-run.py INFO: exec_cmd: ['ntp-get-image-info-configuration-json', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--image-info-configuration-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/image-info-configuration.json'] <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration: container_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE1/device:main"}
{"timestamp_utc": "2024-07-31T08:08:38.079Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:37 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:37 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-docker-containers', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json', '--container-parent-hostip', '167.254.217.214', '--container-parent-hostname', 'rtxoialp85.fnc.net.local'] <NL> # 03:08:38 ntp-configure-docker-containers INFO: arg_dict: { <NL> \"container_parent_hostip\": \"167.254.217.214\", <NL> \"container_parent_hostname\": \"rtxoialp85.fnc.net.local\", <NL> \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:38.333Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-configure-docker-containers INFO: save_amend_changes: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.docker-container/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE1/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:38.588Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE1/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:38 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:38.843Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE1/device:main\" <NL> # 03:08:38 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE1/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}'] <NL> # 03:08:38 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE1/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:38 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"2\", <NL> \"simulatedShelf\": \"2\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:39.098Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE1/device:trib1\" <NL> # 03:08:39 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:39 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE2/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:39.353Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE2/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:39 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:39.609Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE2/device:main\" <NL> # 03:08:39 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:39 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE2/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}'] <NL> # 03:08:39 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE2/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:39 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"2\", <NL> \"simulatedShelf\": \"2\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:39.864Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE2/device:trib1\" <NL> # 03:08:39 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:39 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE3/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:40.123Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE3/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:39 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"200\", <NL> \"simulatedShelf\": \"200\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:40.381Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE3/device:main\" <NL> # 03:08:40 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:40 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE3/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}'] <NL> # 03:08:40 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE3/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:40 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:40.637Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE3/device:trib1\" <NL> # 03:08:40 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:40 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE4/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:40.891Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE4/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:40.892Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"200\", <NL> \"simulatedShelf\": \"200\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:41.146Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE4/device:main\" <NL> # 03:08:41 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:41 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE4/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}'] <NL> # 03:08:41 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE4/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:41 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:41.401Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE4/device:trib1\" <NL> # 03:08:41 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:41.656Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json', '--action', 'prepare'] <NL> # 03:08:41 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace' <NL> # 03:08:41 ntp-topology INFO: main: starting action 'prepare'"}
{"timestamp_utc": "2024-07-31T08:08:42.218Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5000 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5000:None for 'network-element:NE1/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5000 for network-element:NE1/device:main/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5001 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5001:6022 for 'network-element:NE1/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5001 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5002 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5002:22 for 'network-element:NE1/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5002 for network-element:NE1/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE1/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5003 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5003:830 for 'network-element:NE1/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5003 for network-element:NE1/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE1/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5004 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5004:6030 for 'network-element:NE1/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5004 for network-element:NE1/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE1/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5005 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5005:161/udp for 'network-element:NE1/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5005 for network-element:NE1/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE1/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5006 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5006:80 for 'network-element:NE1/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5006 for network-element:NE1/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE1/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5007"}
{"timestamp_utc": "2024-07-31T08:08:42.219Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5007:443 for 'network-element:NE1/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5007 for network-element:NE1/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE1/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5008 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5008:5555 for 'network-element:NE1/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5008 for network-element:NE1/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE1/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5009 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5009:10000 for 'network-element:NE1/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5009 for network-element:NE1/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE1/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5010 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5010:32767 for 'network-element:NE1/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5010 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5011 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5011:50000 for 'network-element:NE1/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5011 for network-element:NE1/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE1/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5012 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5012:21 for 'network-element:NE1/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5012 for network-element:NE1/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE1/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5013 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5013:2202 for 'network-element:NE1/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5013 for network-element:NE1/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE1/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5014 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5014:23 for 'network-element:NE1/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5014 for network-element:NE1/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE1/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5015 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5015:None for 'network-element:NE1/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5015 for network-element:NE1/device:trib1/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5016 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5016:6022 for 'network-element:NE1/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5016 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5017 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5017:None for 'network-element:NE2/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5017 for network-element:NE2/device:main/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5018 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5018:6022 for 'network-element:NE2/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5018 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5019 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5019:22 for 'network-element:NE2/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5019 for network-element:NE2/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE2/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5020 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5020:830 for 'network-element:NE2/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5020 for network-element:NE2/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE2/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5021 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5021:6030 for 'network-element:NE2/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5021 for network-element:NE2/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE2/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5022 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5022:161/udp for 'network-element:NE2/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5022 for network-element:NE2/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE2/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5023 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5023:80 for 'network-element:NE2/device:main/service:webui', device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:08:42.220Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5023 for network-element:NE2/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE2/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5024 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5024:443 for 'network-element:NE2/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5024 for network-element:NE2/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE2/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5025 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5025:5555 for 'network-element:NE2/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5025 for network-element:NE2/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE2/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5026 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5026:10000 for 'network-element:NE2/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5026 for network-element:NE2/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE2/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5027 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5027:32767 for 'network-element:NE2/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5027 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5028 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5028:50000 for 'network-element:NE2/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5028 for network-element:NE2/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE2/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5029 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5029:21 for 'network-element:NE2/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5029 for network-element:NE2/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE2/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5030 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5030:2202 for 'network-element:NE2/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5030 for network-element:NE2/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE2/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5031 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5031:23 for 'network-element:NE2/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5031 for network-element:NE2/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE2/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5032 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5032:None for 'network-element:NE2/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5032 for network-element:NE2/device:trib1/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5033 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5033:6022 for 'network-element:NE2/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5033 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5034 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5034:None for 'network-element:NE3/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5034 for network-element:NE3/device:main/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5035 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5035:6022 for 'network-element:NE3/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5035 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5036 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5036:22 for 'network-element:NE3/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5036 for network-element:NE3/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE3/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5037 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5037:830 for 'network-element:NE3/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5037 for network-element:NE3/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE3/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5038 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5038:6030 for 'network-element:NE3/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5038 for network-element:NE3/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE3/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5039 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5039:161/udp for 'network-element:NE3/device:main/service:snmp', device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:08:42.221Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5039 for network-element:NE3/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE3/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5040 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5040:80 for 'network-element:NE3/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5040 for network-element:NE3/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE3/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5041 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5041:443 for 'network-element:NE3/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5041 for network-element:NE3/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE3/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5042 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5042:5555 for 'network-element:NE3/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5042 for network-element:NE3/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE3/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5043 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5043:10000 for 'network-element:NE3/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5043 for network-element:NE3/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE3/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5044 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5044:32767 for 'network-element:NE3/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5044 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5045 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5045:50000 for 'network-element:NE3/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5045 for network-element:NE3/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE3/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5046 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5046:21 for 'network-element:NE3/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5046 for network-element:NE3/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE3/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5047 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5047:2202 for 'network-element:NE3/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5047 for network-element:NE3/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE3/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5048 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5048:23 for 'network-element:NE3/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5048 for network-element:NE3/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE3/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5049 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5049:None for 'network-element:NE3/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5049 for network-element:NE3/device:trib1/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5050 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5050:6022 for 'network-element:NE3/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5050 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5051 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5051:None for 'network-element:NE4/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5051 for network-element:NE4/device:main/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5052 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5052:6022 for 'network-element:NE4/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5052 for network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5053 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5053:22 for 'network-element:NE4/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5053 for network-element:NE4/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE4/device:main/service:cli <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5054 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5054:830 for 'network-element:NE4/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5054 for network-element:NE4/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE4/device:main/service:netconf <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5055"}
{"timestamp_utc": "2024-07-31T08:08:42.222Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5055:6030 for 'network-element:NE4/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5055 for network-element:NE4/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE4/device:main/service:gnmi <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5056 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5056:161/udp for 'network-element:NE4/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5056 for network-element:NE4/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE4/device:main/service:snmp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5057 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5057:80 for 'network-element:NE4/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5057 for network-element:NE4/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE4/device:main/service:webui <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5058 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5058:443 for 'network-element:NE4/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5058 for network-element:NE4/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE4/device:main/service:https <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5059 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5059:5555 for 'network-element:NE4/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5059 for network-element:NE4/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE4/device:main/service:zmq <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5060 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5060:10000 for 'network-element:NE4/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5060 for network-element:NE4/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE4/device:main/service:gdb <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5061 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5061:32767 for 'network-element:NE4/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5061 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5062 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5062:50000 for 'network-element:NE4/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5062 for network-element:NE4/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE4/device:main/service:ospl <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5063 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5063:21 for 'network-element:NE4/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5063 for network-element:NE4/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE4/device:main/service:ftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5064 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5064:2202 for 'network-element:NE4/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5064 for network-element:NE4/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE4/device:main/service:sftp <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5065 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5065:23 for 'network-element:NE4/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5065 for network-element:NE4/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE4/device:main/service:telnet <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5066 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5066:None for 'network-element:NE4/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5066 for network-element:NE4/device:trib1/service:console <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5067 <NL> # 03:08:41 ntp-topology INFO: prepare_service_ports:   found port 5067:6022 for 'network-element:NE4/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:41 ntp-topology INFO: amend_service_ports: amending external_port_number to 5067 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:42 ntp-topology INFO: handle_prepare_networks: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type external <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name eth0 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag True"}
{"timestamp_utc": "2024-07-31T08:08:42.223Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text a00000 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 9 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0002\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0002\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE1-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 10 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 3 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0003\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0003\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE2-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 11 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 4 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0004\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0004\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE3-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 12 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 5 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0005\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0005\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE4-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 6 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0006\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0006\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 3 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 7 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0007\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0007\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 4 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 8 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0008\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0008\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 5 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 9 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0009\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0009\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 6 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 10 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000a\""}
{"timestamp_utc": "2024-07-31T08:08:42.224Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000a\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc1-2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 7 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 11 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000b\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000b\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 8 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 12 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000c\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000c\" up <NL> # 03:08:42 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc2-2/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:42.490Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1' <NL> # 03:08:42 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE4/device:main'"}
{"timestamp_utc": "2024-07-31T08:08:42.491Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:42 ntp-topology INFO: prepare_devices: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE1/device:main\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5000:None for service \"network-element:NE1/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5001:6022 for service \"network-element:NE1/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5002:22 for service \"network-element:NE1/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5003:830 for service \"network-element:NE1/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5004:6030 for service \"network-element:NE1/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5005:161/udp for service \"network-element:NE1/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5006:80 for service \"network-element:NE1/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5007:443 for service \"network-element:NE1/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\""}
{"timestamp_utc": "2024-07-31T08:08:42.492Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5008:5555 for service \"network-element:NE1/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5009:10000 for service \"network-element:NE1/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5010:32767 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5011:50000 for service \"network-element:NE1/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5012:21 for service \"network-element:NE1/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5013:2202 for service \"network-element:NE1/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5014:23 for service \"network-element:NE1/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:01' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5000:None (network-element:NE1/device:main/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5001:6022 (network-element:NE1/device:main/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5002:22 (network-element:NE1/device:main/service:cli) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5003:830 (network-element:NE1/device:main/service:netconf) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5004:6030 (network-element:NE1/device:main/service:gnmi) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5005:161 (network-element:NE1/device:main/service:snmp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5006:80 (network-element:NE1/device:main/service:webui) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5007:443 (network-element:NE1/device:main/service:https) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5008:5555 (network-element:NE1/device:main/service:zmq) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5009:10000 (network-element:NE1/device:main/service:gdb) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5010:32767 (network-element:NE1/device:main/service:gdb-ops-additional) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5011:50000 (network-element:NE1/device:main/service:ospl) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5012:21 (network-element:NE1/device:main/service:ftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5013:2202 (network-element:NE1/device:main/service:sftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5014:23 (network-element:NE1/device:main/service:telnet) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5001-:6022,hostfwd=tcp::5002-:22,hostfwd=tcp::5003-:830,hostfwd=tcp::5004-:6030,hostfwd=udp::5005-:161,hostfwd=tcp::5006-:80,hostfwd=tcp::5007-:443,hostfwd=tcp::5008-:5555,hostfwd=tcp::5009-:10000,hostfwd=tcp::5010-:32767,hostfwd=tcp::5011-:50000,hostfwd=tcp::5012-:21,hostfwd=tcp::5013-:2202,hostfwd=tcp::5014-:23\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:06' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0006,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:06\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:05' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0005,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:05\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None"}
{"timestamp_utc": "2024-07-31T08:08:42.493Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:03' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0003,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:03\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:04' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-0004,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:04\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE1/network:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0002' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:02' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0002,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:02\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:07' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0007,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:07\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5000 for network-element:NE1/device:main/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\","}
{"timestamp_utc": "2024-07-31T08:08:42.494Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"link\", <NL> \"set\", <NL> \"tap-0006\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0005\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0003\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0004\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0002\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0007\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0006\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lmp\" <NL> ],"}
{"timestamp_utc": "2024-07-31T08:08:42.495Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "[ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0005\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0003\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0004\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0002\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0007\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\","}
{"timestamp_utc": "2024-07-31T08:08:42.496Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5001-:6022,hostfwd=tcp::5002-:22,hostfwd=tcp::5003-:830,hostfwd=tcp::5004-:6030,hostfwd=udp::5005-:161,hostfwd=tcp::5006-:80,hostfwd=tcp::5007-:443,hostfwd=tcp::5008-:5555,hostfwd=tcp::5009-:10000,hostfwd=tcp::5010-:32767,hostfwd=tcp::5011-:50000,hostfwd=tcp::5012-:21,hostfwd=tcp::5013-:2202,hostfwd=tcp::5014-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0006,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:06\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0005,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:05\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0003,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:03\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-0004,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:04\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0002,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:02\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0007,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:07\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5000, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE1/device:trib1\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\","}
{"timestamp_utc": "2024-07-31T08:08:42.497Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5015:None for service \"network-element:NE1/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5016:6022 for service \"network-element:NE1/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:08' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5015:None (network-element:NE1/device:trib1/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5016:6022 (network-element:NE1/device:trib1/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5016-:6022\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE1/network:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0002' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:09' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0009,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:09\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0a' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-000a,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:0a\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0b' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-000b,script=no,downscript=no\""}
{"timestamp_utc": "2024-07-31T08:08:42.498Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:0b\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5015 for network-element:NE1/device:trib1/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0009\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0009\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\","}
{"timestamp_utc": "2024-07-31T08:08:42.499Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5016-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0009,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:09\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-000a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:0a\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-000b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:0b\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5015, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE2/device:main\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:42.500Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "{ <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5017:None for service \"network-element:NE2/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5018:6022 for service \"network-element:NE2/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5019:22 for service \"network-element:NE2/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5020:830 for service \"network-element:NE2/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5021:6030 for service \"network-element:NE2/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5022:161/udp for service \"network-element:NE2/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5023:80 for service \"network-element:NE2/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5024:443 for service \"network-element:NE2/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5025:5555 for service \"network-element:NE2/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5026:10000 for service \"network-element:NE2/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5027:32767 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5028:50000 for service \"network-element:NE2/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5029:21 for service \"network-element:NE2/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5030:2202 for service \"network-element:NE2/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5031:23 for service \"network-element:NE2/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0c' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5017:None (network-element:NE2/device:main/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5018:6022 (network-element:NE2/device:main/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5019:22 (network-element:NE2/device:main/service:cli) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5020:830 (network-element:NE2/device:main/service:netconf) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5021:6030 (network-element:NE2/device:main/service:gnmi) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5022:161 (network-element:NE2/device:main/service:snmp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5023:80 (network-element:NE2/device:main/service:webui) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5024:443 (network-element:NE2/device:main/service:https) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5025:5555 (network-element:NE2/device:main/service:zmq) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5026:10000 (network-element:NE2/device:main/service:gdb) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5027:32767 (network-element:NE2/device:main/service:gdb-ops-additional) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5028:50000 (network-element:NE2/device:main/service:ospl) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5029:21 (network-element:NE2/device:main/service:ftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5030:2202 (network-element:NE2/device:main/service:sftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5031:23 (network-element:NE2/device:main/service:telnet)"}
{"timestamp_utc": "2024-07-31T08:08:42.501Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5018-:6022,hostfwd=tcp::5019-:22,hostfwd=tcp::5020-:830,hostfwd=tcp::5021-:6030,hostfwd=udp::5022-:161,hostfwd=tcp::5023-:80,hostfwd=tcp::5024-:443,hostfwd=tcp::5025-:5555,hostfwd=tcp::5026-:10000,hostfwd=tcp::5027-:32767,hostfwd=tcp::5028-:50000,hostfwd=tcp::5029-:21,hostfwd=tcp::5030-:2202,hostfwd=tcp::5031-:23\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:11' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0011,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:11\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:10' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0010,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:10\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0e' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-000e,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:0e\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0f' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-000f,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:0f\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE2/network:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0003' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0d' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-000d,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:0d\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:42.502Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:12' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0012,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:12\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5017 for network-element:NE2/device:main/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0011\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0010\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000e\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000f\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\","}
{"timestamp_utc": "2024-07-31T08:08:42.503Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"dev\", <NL> \"tap-000d\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000d\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0012\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0011\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0010\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000e\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000f\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000d\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\","}
{"timestamp_utc": "2024-07-31T08:08:42.504Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0012\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5018-:6022,hostfwd=tcp::5019-:22,hostfwd=tcp::5020-:830,hostfwd=tcp::5021-:6030,hostfwd=udp::5022-:161,hostfwd=tcp::5023-:80,hostfwd=tcp::5024-:443,hostfwd=tcp::5025-:5555,hostfwd=tcp::5026-:10000,hostfwd=tcp::5027-:32767,hostfwd=tcp::5028-:50000,hostfwd=tcp::5029-:21,hostfwd=tcp::5030-:2202,hostfwd=tcp::5031-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0011,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:11\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0010,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:10\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-000e,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:0e\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-000f,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:0f\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-000d,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:0d\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0012,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:12\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5017, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE2/device:trib1\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:42.505Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5032:None for service \"network-element:NE2/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5033:6022 for service \"network-element:NE2/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:13' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5032:None (network-element:NE2/device:trib1/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5033:6022 (network-element:NE2/device:trib1/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5033-:6022\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE2/network:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0003' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:14' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0014,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:14\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:42.506Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:15' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0015,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:15\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:16' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0016,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:16\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5032 for network-element:NE2/device:trib1/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0014\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0015\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0016\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\","}
{"timestamp_utc": "2024-07-31T08:08:42.507Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0014\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0015\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0016\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5033-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0014,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:14\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0015,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:15\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0016,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:16\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5032, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE3/device:main\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:42.508Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5034:None for service \"network-element:NE3/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5035:6022 for service \"network-element:NE3/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5036:22 for service \"network-element:NE3/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5037:830 for service \"network-element:NE3/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5038:6030 for service \"network-element:NE3/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5039:161/udp for service \"network-element:NE3/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5040:80 for service \"network-element:NE3/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5041:443 for service \"network-element:NE3/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5042:5555 for service \"network-element:NE3/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5043:10000 for service \"network-element:NE3/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5044:32767 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5045:50000 for service \"network-element:NE3/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5046:21 for service \"network-element:NE3/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5047:2202 for service \"network-element:NE3/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5048:23 for service \"network-element:NE3/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:17' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True"}
{"timestamp_utc": "2024-07-31T08:08:42.509Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5034:None (network-element:NE3/device:main/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5035:6022 (network-element:NE3/device:main/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5036:22 (network-element:NE3/device:main/service:cli) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5037:830 (network-element:NE3/device:main/service:netconf) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5038:6030 (network-element:NE3/device:main/service:gnmi) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5039:161 (network-element:NE3/device:main/service:snmp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5040:80 (network-element:NE3/device:main/service:webui) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5041:443 (network-element:NE3/device:main/service:https) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5042:5555 (network-element:NE3/device:main/service:zmq) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5043:10000 (network-element:NE3/device:main/service:gdb) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5044:32767 (network-element:NE3/device:main/service:gdb-ops-additional) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5045:50000 (network-element:NE3/device:main/service:ospl) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5046:21 (network-element:NE3/device:main/service:ftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5047:2202 (network-element:NE3/device:main/service:sftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5048:23 (network-element:NE3/device:main/service:telnet) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5035-:6022,hostfwd=tcp::5036-:22,hostfwd=tcp::5037-:830,hostfwd=tcp::5038-:6030,hostfwd=udp::5039-:161,hostfwd=tcp::5040-:80,hostfwd=tcp::5041-:443,hostfwd=tcp::5042-:5555,hostfwd=tcp::5043-:10000,hostfwd=tcp::5044-:32767,hostfwd=tcp::5045-:50000,hostfwd=tcp::5046-:21,hostfwd=tcp::5047-:2202,hostfwd=tcp::5048-:23\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1c' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-001c,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:1c\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1b' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-001b,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:1b\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:19' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0019,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:19\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1a' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-001a,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:1a\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:42.510Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE3/network:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0004' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:18' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0018,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:18\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1d' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-001d,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:1d\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5034 for network-element:NE3/device:main/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001c\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ],"}
{"timestamp_utc": "2024-07-31T08:08:42.511Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "[ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0019\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0018\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001d\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001c\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0019\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn2\" <NL> ], <NL> ["}
{"timestamp_utc": "2024-07-31T08:08:42.512Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0018\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001d\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5035-:6022,hostfwd=tcp::5036-:22,hostfwd=tcp::5037-:830,hostfwd=tcp::5038-:6030,hostfwd=udp::5039-:161,hostfwd=tcp::5040-:80,hostfwd=tcp::5041-:443,hostfwd=tcp::5042-:5555,hostfwd=tcp::5043-:10000,hostfwd=tcp::5044-:32767,hostfwd=tcp::5045-:50000,hostfwd=tcp::5046-:21,hostfwd=tcp::5047-:2202,hostfwd=tcp::5048-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-001c,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:1c\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-001b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:1b\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0019,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:19\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-001a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:1a\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0018,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:18\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-001d,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:1d\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5034, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE3/device:trib1\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\","}
{"timestamp_utc": "2024-07-31T08:08:42.513Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5049:None for service \"network-element:NE3/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5050:6022 for service \"network-element:NE3/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1e' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5049:None (network-element:NE3/device:trib1/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5050:6022 (network-element:NE3/device:trib1/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5050-:6022\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE3/network:ilan'"}
{"timestamp_utc": "2024-07-31T08:08:42.514Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0004' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1f' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-001f,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:1f\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:20' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0020,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:20\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:21' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0021,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:21\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5049 for network-element:NE3/device:trib1/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001f\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0020\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\","}
{"timestamp_utc": "2024-07-31T08:08:42.515Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"set\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0021\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001f\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0020\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0021\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5050-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-001f,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:1f\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0020,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:20\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0021,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:21\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5049,"}
{"timestamp_utc": "2024-07-31T08:08:42.516Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"socket_daemon_prog_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE4/device:main\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5051:None for service \"network-element:NE4/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5052:6022 for service \"network-element:NE4/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5053:22 for service \"network-element:NE4/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5054:830 for service \"network-element:NE4/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5055:6030 for service \"network-element:NE4/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5056:161/udp for service \"network-element:NE4/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5057:80 for service \"network-element:NE4/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5058:443 for service \"network-element:NE4/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5059:5555 for service \"network-element:NE4/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\""}
{"timestamp_utc": "2024-07-31T08:08:42.517Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5060:10000 for service \"network-element:NE4/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5061:32767 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5062:50000 for service \"network-element:NE4/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5063:21 for service \"network-element:NE4/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5064:2202 for service \"network-element:NE4/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5065:23 for service \"network-element:NE4/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:22' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5051:None (network-element:NE4/device:main/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5052:6022 (network-element:NE4/device:main/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5053:22 (network-element:NE4/device:main/service:cli) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5054:830 (network-element:NE4/device:main/service:netconf) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5055:6030 (network-element:NE4/device:main/service:gnmi) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5056:161 (network-element:NE4/device:main/service:snmp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5057:80 (network-element:NE4/device:main/service:webui) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5058:443 (network-element:NE4/device:main/service:https) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5059:5555 (network-element:NE4/device:main/service:zmq) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5060:10000 (network-element:NE4/device:main/service:gdb) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5061:32767 (network-element:NE4/device:main/service:gdb-ops-additional) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5062:50000 (network-element:NE4/device:main/service:ospl) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5063:21 (network-element:NE4/device:main/service:ftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5064:2202 (network-element:NE4/device:main/service:sftp) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5065:23 (network-element:NE4/device:main/service:telnet) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5052-:6022,hostfwd=tcp::5053-:22,hostfwd=tcp::5054-:830,hostfwd=tcp::5055-:6030,hostfwd=udp::5056-:161,hostfwd=tcp::5057-:80,hostfwd=tcp::5058-:443,hostfwd=tcp::5059-:5555,hostfwd=tcp::5060-:10000,hostfwd=tcp::5061-:32767,hostfwd=tcp::5062-:50000,hostfwd=tcp::5063-:21,hostfwd=tcp::5064-:2202,hostfwd=tcp::5065-:23\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:27' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0027,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:27\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:26' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0026,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:26\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1'"}
{"timestamp_utc": "2024-07-31T08:08:42.518Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:24' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False"}
{"timestamp_utc": "2024-07-31T08:08:42.775Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0024,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:24\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:25' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-0025,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:25\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE4/network:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0005' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:23' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0023,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:23\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:28' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0028,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:28\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5051 for network-element:NE4/device:main/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\","}
{"timestamp_utc": "2024-07-31T08:08:42.776Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"tap-0027\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0027\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0026\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0024\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0025\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0023\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0028\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0027\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0026\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0024\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0025\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0023\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\","}
{"timestamp_utc": "2024-07-31T08:08:42.777Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0028\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5052-:6022,hostfwd=tcp::5053-:22,hostfwd=tcp::5054-:830,hostfwd=tcp::5055-:6030,hostfwd=udp::5056-:161,hostfwd=tcp::5057-:80,hostfwd=tcp::5058-:443,hostfwd=tcp::5059-:5555,hostfwd=tcp::5060-:10000,hostfwd=tcp::5061-:32767,hostfwd=tcp::5062-:50000,hostfwd=tcp::5063-:21,hostfwd=tcp::5064-:2202,hostfwd=tcp::5065-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0027,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:27\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0026,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:26\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0024,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:24\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-0025,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:25\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0023,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:23\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0028,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:28\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5051, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE4/device:trib1\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:42 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ]"}
{"timestamp_utc": "2024-07-31T08:08:42.778Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5066:None for service \"network-element:NE4/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: get_device_service_ports:   found port chain None:5067:6022 for service \"network-element:NE4/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:29' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5066:None (network-element:NE4/device:trib1/service:console) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5067:6022 (network-element:NE4/device:trib1/service:debug-ssh) <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5067-:6022\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE4/network:ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0005' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2a' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-002a,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:2a\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2b' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-002b,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:2b\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2c' <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-002c,script=no,downscript=no\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:2c\" <NL> # 03:08:42 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:42 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   found ports None:5066 for network-element:NE4/device:trib1/service:console <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\""}
{"timestamp_utc": "2024-07-31T08:08:42.779Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002c\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002c\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5067-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-002a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:2a\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-002b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:2b\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-002c,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:2c\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5066, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:42 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: prepare_devices:   saved device_group amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:42 ntp-topology INFO: main: completed action 'prepare' <NL> # 03:08:42 ntp-topology INFO: done <NL> # 03:08:42 ntp-topology-run.py INFO: exec_cmd: ['ntp-show-current-topology', '-v', '-v', '--sort-instances', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json']"}
{"timestamp_utc": "2024-07-31T08:08:43.038Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-show-current-topology INFO: + ( 0) None      : <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:docker-container"}
{"timestamp_utc": "2024-07-31T08:08:43.039Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:docker-network <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:instance-configure <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:instance-defaults <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:kubernetes-cluster <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:qemu-configuration <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:topology <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     create-new: definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-cli <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:cli <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:ftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gdb <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-https <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:https <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-netconf <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:netconf <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ospl <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:ospl <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-sftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:sftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-snmp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:snmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-telnet <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:telnet <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-webui <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:webui <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-zmq <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:zmq <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-cli <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:cli <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:ftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gdb <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gdb-ops-additional"}
{"timestamp_utc": "2024-07-31T08:08:43.040Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-https <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:https <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-netconf <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:netconf <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ospl <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:ospl <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-sftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:sftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-snmp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:snmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-telnet <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:telnet <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-webui <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:webui <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-zmq <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:zmq <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-cli <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:cli <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:ftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gdb <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-https <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:https <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-netconf <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:netconf <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ospl <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:ospl <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-sftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:sftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-snmp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:snmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-telnet <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:telnet <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-webui <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:webui <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-zmq <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:zmq <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-cli <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:cli <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:ftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gdb <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-https <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:https <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-netconf <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:netconf <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ospl <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:ospl <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-sftp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:sftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-snmp <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:snmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-telnet <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:telnet <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-webui <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:webui <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-zmq <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:zmq <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-console <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1/service:console"}
{"timestamp_utc": "2024-07-31T08:08:43.041Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/device:main <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:debug <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/interface:debug/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:ilan/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lmp/network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc1/network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc2/network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/serial-interface:serial-1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/serial-interface:serial-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:cli <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:cli/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:console/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:debug-ssh/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:ftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:ftp/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gdb <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gdb/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gnmi/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:https <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:https/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:https/port-number:internal-https-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:netconf <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:netconf/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:ospl <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:ospl/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:sftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:sftp/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:snmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:snmp/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:telnet <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:telnet/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:webui <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:webui/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:zmq <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:zmq/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/device:trib1"}
{"timestamp_utc": "2024-07-31T08:08:43.042Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:debug <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/interface:debug/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:ilan/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/serial-interface:serial-1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/serial-interface:serial-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/service:console/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/device:main <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:debug <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/interface:debug/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:ilan/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lmp/network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc1/network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc2/network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/serial-interface:serial-1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/serial-interface:serial-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:cli <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:cli/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:console/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:debug-ssh/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:ftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:ftp/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gdb <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gdb/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gnmi <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gnmi/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:https <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:https/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:https/port-number:internal-https-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:netconf <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:netconf/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:ospl"}
{"timestamp_utc": "2024-07-31T08:08:43.043Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:ospl/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:sftp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:sftp/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:snmp <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:snmp/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:telnet <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:telnet/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:webui <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:webui/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:zmq <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:zmq/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/device:trib1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:debug <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/interface:debug/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:ilan/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc1-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc2-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/serial-interface:serial-1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/serial-interface:serial-2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/service:console <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/service:console/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/network:ilan <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:42 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lmp <NL> # 03:08:42 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE3 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/device:main <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:debug <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/interface:debug/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:ilan/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lmp/network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc1/network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc2/network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/serial-interface:serial-1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/serial-interface:serial-2"}
{"timestamp_utc": "2024-07-31T08:08:43.044Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:cli <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:cli/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:console <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:console/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:debug-ssh/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:ftp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:ftp/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gdb <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gdb/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gnmi <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gnmi/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:https <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:https/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:https/port-number:internal-https-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:netconf <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:netconf/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:ospl <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:ospl/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:sftp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:sftp/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:snmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:snmp/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:telnet <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:telnet/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:webui <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:webui/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:zmq <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:zmq/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/device:trib1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:debug <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/interface:debug/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:ilan/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/serial-interface:serial-1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/serial-interface:serial-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/service:console <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/service:console/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc2"}
{"timestamp_utc": "2024-07-31T08:08:43.045Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE4 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/device:main <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:debug <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/interface:debug/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:ilan/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lmp/network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc1/network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc2/network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/serial-interface:serial-1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/serial-interface:serial-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:cli <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:cli/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:console <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:console/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:debug-ssh/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:ftp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:ftp/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gdb <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gdb/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gnmi <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gnmi/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:https <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:https/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:https/port-number:internal-https-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:netconf <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:netconf/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:ospl <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:ospl/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:sftp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:sftp/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:snmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:snmp/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:telnet <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:telnet/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:webui <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:webui/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:zmq <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:zmq/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/device:trib1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:debug <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/interface:debug/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:ilan/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:ilan"}
{"timestamp_utc": "2024-07-31T08:08:43.046Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/serial-interface:serial-1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/serial-interface:serial-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/service:console <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/service:console/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ----- ----- ----- ----- ----- <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network:lmp <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2-2 <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/network:ilan <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan : 'network-element:NE1/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan : 'network-element:NE2/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan : 'network-element:NE3/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan : 'network-element:NE4/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1     : 'network:lcn1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2     : 'network:lcn2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp      : 'network:lmp' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1     : 'network:osc1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2   : 'network:osc1-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2     : 'network:osc2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2   : 'network:osc2-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:ilan/network:ilan                      : 'network-element:NE1/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE1/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:ilan/network:ilan                      : 'network-element:NE2/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE2/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:ilan/network:ilan                      : 'network-element:NE3/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE3/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:ilan/network:ilan                      : 'network-element:NE4/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc2/network:osc2                      : 'network:osc2'"}
{"timestamp_utc": "2024-07-31T08:08:43.047Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE4/network:ilan' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:43 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:43 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json', '--action', 'create']"}
{"timestamp_utc": "2024-07-31T08:08:43.301Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:43 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace' <NL> # 03:08:43 ntp-topology INFO: main: starting action 'create'"}
{"timestamp_utc": "2024-07-31T08:08:44.226Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:43 ntp-topology INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01'] <NL> # 03:08:43 ntp-topology INFO: exec_cmd: ['chmod', 'a+rwx', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01'] <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: parent_hostname rtxoialp85.fnc.net.local <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: parent_hostip 167.254.217.214 <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_context_names topology-group-device-group-type-qemu-01 <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_type device-group-type-qemu <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge', network_type 'external', default_docker_bridge_network_flag True <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:43 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   container_network_name_list [] <NL> # 03:08:43 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'pull', 'harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest'] <NL> # 03:08:44 ntp-topology INFO: docker_command: stdout: Trying to pull repository harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build ... <NL> # 03:08:44 ntp-topology INFO: docker_command: stdout: latest: Pulling from harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build <NL> # 03:08:44 ntp-topology INFO: docker_command: stdout: Digest: sha256:f649c9d54a8d0322e20c4524897fb6d43164df14359f965f27d7fedcf395eb95 <NL> # 03:08:44 ntp-topology INFO: docker_command: stdout: Status: Image is up to date for harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5000 for service \"network-element:NE1/device:main/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5001 for service \"network-element:NE1/device:main/service:debug-ssh\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5002 for service \"network-element:NE1/device:main/service:cli\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5003 for service \"network-element:NE1/device:main/service:netconf\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5004 for service \"network-element:NE1/device:main/service:gnmi\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5005/udp for service \"network-element:NE1/device:main/service:snmp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5006 for service \"network-element:NE1/device:main/service:webui\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5007 for service \"network-element:NE1/device:main/service:https\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5008 for service \"network-element:NE1/device:main/service:zmq\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5009 for service \"network-element:NE1/device:main/service:gdb\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5010 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5011 for service \"network-element:NE1/device:main/service:ospl\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5012 for service \"network-element:NE1/device:main/service:ftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5013 for service \"network-element:NE1/device:main/service:sftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5014 for service \"network-element:NE1/device:main/service:telnet\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5015 for service \"network-element:NE1/device:trib1/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5016 for service \"network-element:NE1/device:trib1/service:debug-ssh\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5017 for service \"network-element:NE2/device:main/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5018 for service \"network-element:NE2/device:main/service:debug-ssh\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5019 for service \"network-element:NE2/device:main/service:cli\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5020 for service \"network-element:NE2/device:main/service:netconf\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5021 for service \"network-element:NE2/device:main/service:gnmi\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5022/udp for service \"network-element:NE2/device:main/service:snmp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5023 for service \"network-element:NE2/device:main/service:webui\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5024 for service \"network-element:NE2/device:main/service:https\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5025 for service \"network-element:NE2/device:main/service:zmq\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5026 for service \"network-element:NE2/device:main/service:gdb\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5027 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5028 for service \"network-element:NE2/device:main/service:ospl\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5029 for service \"network-element:NE2/device:main/service:ftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5030 for service \"network-element:NE2/device:main/service:sftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5031 for service \"network-element:NE2/device:main/service:telnet\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5032 for service \"network-element:NE2/device:trib1/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5033 for service \"network-element:NE2/device:trib1/service:debug-ssh\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5034 for service \"network-element:NE3/device:main/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5035 for service \"network-element:NE3/device:main/service:debug-ssh\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5036 for service \"network-element:NE3/device:main/service:cli\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5037 for service \"network-element:NE3/device:main/service:netconf\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5038 for service \"network-element:NE3/device:main/service:gnmi\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5039/udp for service \"network-element:NE3/device:main/service:snmp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5040 for service \"network-element:NE3/device:main/service:webui\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5041 for service \"network-element:NE3/device:main/service:https\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5042 for service \"network-element:NE3/device:main/service:zmq\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5043 for service \"network-element:NE3/device:main/service:gdb\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5044 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5045 for service \"network-element:NE3/device:main/service:ospl\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5046 for service \"network-element:NE3/device:main/service:ftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5047 for service \"network-element:NE3/device:main/service:sftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5048 for service \"network-element:NE3/device:main/service:telnet\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5049 for service \"network-element:NE3/device:trib1/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5050 for service \"network-element:NE3/device:trib1/service:debug-ssh\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5051 for service \"network-element:NE4/device:main/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5052 for service \"network-element:NE4/device:main/service:debug-ssh\""}
{"timestamp_utc": "2024-07-31T08:08:44.227Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5053 for service \"network-element:NE4/device:main/service:cli\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5054 for service \"network-element:NE4/device:main/service:netconf\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5055 for service \"network-element:NE4/device:main/service:gnmi\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5056/udp for service \"network-element:NE4/device:main/service:snmp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5057 for service \"network-element:NE4/device:main/service:webui\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5058 for service \"network-element:NE4/device:main/service:https\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5059 for service \"network-element:NE4/device:main/service:zmq\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5060 for service \"network-element:NE4/device:main/service:gdb\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5061 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5062 for service \"network-element:NE4/device:main/service:ospl\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5063 for service \"network-element:NE4/device:main/service:ftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5064 for service \"network-element:NE4/device:main/service:sftp\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5065 for service \"network-element:NE4/device:main/service:telnet\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5066 for service \"network-element:NE4/device:trib1/service:console\" <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: expose port None:5067 for service \"network-element:NE4/device:trib1/service:debug-ssh\" <NL> # 03:08:44 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'create', '--privileged', '--user', 'root', '--device', '/dev/kvm:/dev/kvm', '--device', '/dev/net/tun:/dev/net/tun', '--device', '/dev/vhost-net:/dev/vhost-net', '--volume', '/proj/artifacts:/proj/artifacts:ro,shared', '--volume', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e', '--volume', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology:ro', '--publish', ':5000', '--publish', ':5001', '--publish', ':5002', '--publish', ':5003', '--publish', ':5004', '--publish', ':5005/udp', '--publish', ':5006', '--publish', ':5007', '--publish', ':5008', '--publish', ':5009', '--publish', ':5010', '--publish', ':5011', '--publish', ':5012', '--publish', ':5013', '--publish', ':5014', '--publish', ':5015', '--publish', ':5016', '--publish', ':5017', '--publish', ':5018', '--publish', ':5019', '--publish', ':5020', '--publish', ':5021', '--publish', ':5022/udp', '--publish', ':5023', '--publish', ':5024', '--publish', ':5025', '--publish', ':5026', '--publish', ':5027', '--publish', ':5028', '--publish', ':5029', '--publish', ':5030', '--publish', ':5031', '--publish', ':5032', '--publish', ':5033', '--publish', ':5034', '--publish', ':5035', '--publish', ':5036', '--publish', ':5037', '--publish', ':5038', '--publish', ':5039/udp', '--publish', ':5040', '--publish', ':5041', '--publish', ':5042', '--publish', ':5043', '--publish', ':5044', '--publish', ':5045', '--publish', ':5046', '--publish', ':5047', '--publish', ':5048', '--publish', ':5049', '--publish', ':5050', '--publish', ':5051', '--publish', ':5052', '--publish', ':5053', '--publish', ':5054', '--publish', ':5055', '--publish', ':5056/udp', '--publish', ':5057', '--publish', ':5058', '--publish', ':5059', '--publish', ':5060', '--publish', ':5061', '--publish', ':5062', '--publish', ':5063', '--publish', ':5064', '--publish', ':5065', '--publish', ':5066', '--publish', ':5067', 'harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest']"}
{"timestamp_utc": "2024-07-31T08:08:44.482Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:44 ntp-topology INFO: docker_command: stdout: 875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14 <NL> # 03:08:44 ntp-topology INFO: create_single_docker_container: create: \"875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14\" <NL> # 03:08:44 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'start', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14']"}
{"timestamp_utc": "2024-07-31T08:09:02.515Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_command: stdout: 875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14 <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: running ['sudo', '/bin/docker', 'inspect', '--type', 'container', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14'] <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout: [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Id\": \"875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Created\": \"2024-07-31T08:08:44.236611729Z\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Path\": \"/usr/bin/tini\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Args\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"--\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"/usr/sbin/sshd\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"-D\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"State\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Status\": \"running\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Running\": true, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Paused\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Restarting\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"OOMKilled\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Dead\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Pid\": 118429, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"ExitCode\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Error\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"StartedAt\": \"2024-07-31T08:09:01.115358105Z\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"FinishedAt\": \"0001-01-01T00:00:00Z\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Image\": \"sha256:e6ab72684bf033e695847013b10678ea3fd26f1eb52d6ad59f865602619223ab\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"ResolvConfPath\": \"/var/lib/docker/containers/875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14/resolv.conf\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"HostnamePath\": \"/var/lib/docker/containers/875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14/hostname\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"HostsPath\": \"/var/lib/docker/containers/875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14/hosts\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"LogPath\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Name\": \"/agitated_pare\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"RestartCount\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Driver\": \"overlay2\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"MountLabel\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"ProcessLabel\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"AppArmorProfile\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"ExecIDs\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"HostConfig\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Binds\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"/proj/artifacts:/proj/artifacts:ro,shared\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology:ro\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"ContainerIDFile\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"LogConfig\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"journald\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Config\": {} <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"NetworkMode\": \"default\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"PortBindings\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": ["}
{"timestamp_utc": "2024-07-31T08:09:02.516Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\","}
{"timestamp_utc": "2024-07-31T08:09:02.517Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     {"}
{"timestamp_utc": "2024-07-31T08:09:02.518Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ] <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"RestartPolicy\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Name\": \"no\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"MaximumRetryCount\": 0 <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"AutoRemove\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"VolumeDriver\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"VolumesFrom\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CapAdd\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CapDrop\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Dns\": [], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"DnsOptions\": [], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"DnsSearch\": [], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"ExtraHosts\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"GroupAdd\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"IpcMode\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Cgroup\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Links\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"OomScoreAdj\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"PidMode\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Privileged\": true, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"PublishAllPorts\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"ReadonlyRootfs\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"SecurityOpt\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"label=disable\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"UTSMode\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"UsernsMode\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"ShmSize\": 67108864, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Runtime\": \"docker-runc\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"ConsoleSize\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 0 <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Isolation\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuShares\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Memory\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"NanoCpus\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CgroupParent\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioWeight\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioWeightDevice\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceReadBps\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceWriteBps\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceReadIOps\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceWriteIOps\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuPeriod\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuQuota\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuRealtimePeriod\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuRealtimeRuntime\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpusetCpus\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpusetMems\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Devices\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/kvm\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/kvm\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/net/tun\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/net/tun\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/vhost-net\","}
{"timestamp_utc": "2024-07-31T08:09:02.519Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/vhost-net\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"DiskQuota\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"KernelMemory\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"MemoryReservation\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"MemorySwap\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"MemorySwappiness\": -1, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"OomKillDisable\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"PidsLimit\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Ulimits\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuCount\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuPercent\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"IOMaximumIOps\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"IOMaximumBandwidth\": 0 <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"GraphDriver\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Name\": \"overlay2\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Data\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"LowerDir\": \"/var/lib/docker/overlay2/4e878f0cf4b1036f21a845e401dd654fbe9e1d02e04e265d8d8238cd2b1cd3f8-init/diff:/var/lib/docker/overlay2/9cea0b5ce2c1f7a0ed980adf6188b2b57813a91cdbc8f06d49928e141038a394/diff:/var/lib/docker/overlay2/3fab84e3883f81e7bddaf9169cd4930fb20e40b7d677a1a8e119a552be2c285a/diff:/var/lib/docker/overlay2/c1783b5142f04280c1eb25c0ebedda2212a1fd9c25fb543f7992e09a966c994f/diff:/var/lib/docker/overlay2/9dafdf6583146035a515f805663a407a9bed3fbb4de969ba240dc266b5e73062/diff\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"MergedDir\": \"/var/lib/docker/overlay2/4e878f0cf4b1036f21a845e401dd654fbe9e1d02e04e265d8d8238cd2b1cd3f8/merged\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"UpperDir\": \"/var/lib/docker/overlay2/4e878f0cf4b1036f21a845e401dd654fbe9e1d02e04e265d8d8238cd2b1cd3f8/diff\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"WorkDir\": \"/var/lib/docker/overlay2/4e878f0cf4b1036f21a845e401dd654fbe9e1d02e04e265d8d8238cd2b1cd3f8/work\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Mounts\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/proj/artifacts\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/proj/artifacts\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"ro,shared\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"shared\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": true, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"rprivate\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"ro\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"rprivate\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"Config\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Hostname\": \"875e59d3f20d\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Domainname\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"User\": \"root\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStdin\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStdout\": true, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStderr\": true, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"ExposedPorts\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"22/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": {},"}
{"timestamp_utc": "2024-07-31T08:09:02.520Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": {} <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Tty\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"OpenStdin\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"StdinOnce\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Env\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"HOME=/home/jenkins\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"LC_ALL=en_US.UTF-8\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"LANG=en_US.UTF-8\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Cmd\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"/usr/sbin/sshd\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"-D\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Image\": \"harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Volumes\": {}, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"WorkingDir\": \"/home/jenkins\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Entrypoint\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"/usr/bin/tini\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"--\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"OnBuild\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Labels\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"io.buildah.version\": \"1.31.3\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.build-date\": \"20201113\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.license\": \"GPLv2\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.name\": \"CentOS Base Image\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.schema-version\": \"1.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.vendor\": \"CentOS\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.created\": \"2020-11-13 00:00:00+00:00\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.licenses\": \"GPL-2.0-only\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.title\": \"CentOS Base Image\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.vendor\": \"CentOS\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         \"NetworkSettings\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Bridge\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"SandboxID\": \"affe20e2952413573923edf12979975fa529902da9489133eb9cf1dbfdbcf2b1\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"HairpinMode\": false, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"LinkLocalIPv6Address\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"LinkLocalIPv6PrefixLen\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Ports\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"22/tcp\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46535\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46534\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46533\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46532\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46531\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"33105\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46530\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46529\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46528\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46527\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46526\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46525\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46524\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": ["}
{"timestamp_utc": "2024-07-31T08:09:02.521Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46523\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46522\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46521\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46520\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46519\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46518\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46517\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46516\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46515\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"33104\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46514\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46513\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46512\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46511\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46510\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46509\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46508\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46507\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46506\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46505\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46504\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46503\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46502\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46501\""}
{"timestamp_utc": "2024-07-31T08:09:02.522Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46500\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46499\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"33103\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46498\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46497\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46496\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46495\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46494\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46493\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46492\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46491\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46490\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46489\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46488\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46487\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46486\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46485\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46484\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46483\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"33102\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46482\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46481\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46480\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46479\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     {"}
{"timestamp_utc": "2024-07-31T08:09:02.523Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46478\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46477\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46476\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46475\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46474\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46473\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": [ <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"46472\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 ] <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"SandboxKey\": \"/var/run/docker/netns/affe20e29524\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"SecondaryIPAddresses\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"SecondaryIPv6Addresses\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"EndpointID\": \"0e7d577416e867b74669826310df96cfe8f647e7e53a3f33a3b918d32bfe89f4\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Gateway\": \"172.17.0.1\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"GlobalIPv6Address\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"GlobalIPv6PrefixLen\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"IPAddress\": \"172.17.0.45\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"IPPrefixLen\": 16, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"IPv6Gateway\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"MacAddress\": \"02:42:ac:11:00:2d\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             \"Networks\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 \"bridge\": { <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPAMConfig\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"Links\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"Aliases\": null, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"NetworkID\": \"769b774cadb6e1de7fa33dcb8de9bc0c8816480c9c16520f02cc9d54bfbc25b8\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"EndpointID\": \"0e7d577416e867b74669826310df96cfe8f647e7e53a3f33a3b918d32bfe89f4\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"Gateway\": \"172.17.0.1\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPAddress\": \"172.17.0.45\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPPrefixLen\": 16, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPv6Gateway\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"GlobalIPv6Address\": \"\", <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"GlobalIPv6PrefixLen\": 0, <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                     \"MacAddress\": \"02:42:ac:11:00:2d\" <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:                 } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:         } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout:     } <NL> # 03:09:01 ntp-topology INFO: docker_inspect_command: stdout: ] <NL> # 03:09:01 ntp-topology INFO: create_single_docker_container: created actual_container_id \"875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14\"(name \"agitated_pare\") for requested name \"topology-group-device-group-type-qemu-01\" <NL> # 03:09:01 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   saved container amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', 'agitated_pare'] <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5010/tcp -> 0.0.0.0:46526 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5024/tcp -> 0.0.0.0:46513 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5027/tcp -> 0.0.0.0:46510 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5061/tcp -> 0.0.0.0:46478 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5047/tcp -> 0.0.0.0:46491 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5049/tcp -> 0.0.0.0:46489 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5004/tcp -> 0.0.0.0:46531 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5055/tcp -> 0.0.0.0:46483 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5001/tcp -> 0.0.0.0:46534 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5002/tcp -> 0.0.0.0:46533 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5003/tcp -> 0.0.0.0:46532 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5012/tcp -> 0.0.0.0:46524 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5030/tcp -> 0.0.0.0:46507 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5035/tcp -> 0.0.0.0:46502 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5046/tcp -> 0.0.0.0:46492 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5050/tcp -> 0.0.0.0:46488 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5013/tcp -> 0.0.0.0:46523 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5016/tcp -> 0.0.0.0:46520 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5025/tcp -> 0.0.0.0:46512 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5040/tcp -> 0.0.0.0:46498 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5048/tcp -> 0.0.0.0:46490 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5051/tcp -> 0.0.0.0:46487 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5008/tcp -> 0.0.0.0:46528 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5011/tcp -> 0.0.0.0:46525 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5029/tcp -> 0.0.0.0:46508 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5036/tcp -> 0.0.0.0:46501 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5059/tcp -> 0.0.0.0:46480 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5006/tcp -> 0.0.0.0:46530 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5042/tcp -> 0.0.0.0:46496 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5045/tcp -> 0.0.0.0:46493 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5018/tcp -> 0.0.0.0:46518 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5020/tcp -> 0.0.0.0:46516 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5021/tcp -> 0.0.0.0:46515 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5063/tcp -> 0.0.0.0:46476 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5023/tcp -> 0.0.0.0:46514 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5026/tcp -> 0.0.0.0:46511 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5043/tcp -> 0.0.0.0:46495 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5054/tcp -> 0.0.0.0:46484 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5056/udp -> 0.0.0.0:33102 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5057/tcp -> 0.0.0.0:46482 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5064/tcp -> 0.0.0.0:46475 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5000/tcp -> 0.0.0.0:46535 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5014/tcp -> 0.0.0.0:46522 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5033/tcp -> 0.0.0.0:46504 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5039/udp -> 0.0.0.0:33103 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5052/tcp -> 0.0.0.0:46486 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5058/tcp -> 0.0.0.0:46481"}
{"timestamp_utc": "2024-07-31T08:09:02.524Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_command: stdout: 5067/tcp -> 0.0.0.0:46472 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5009/tcp -> 0.0.0.0:46527 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5022/udp -> 0.0.0.0:33104 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5041/tcp -> 0.0.0.0:46497 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5060/tcp -> 0.0.0.0:46479 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5062/tcp -> 0.0.0.0:46477 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5066/tcp -> 0.0.0.0:46473 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5007/tcp -> 0.0.0.0:46529 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5015/tcp -> 0.0.0.0:46521 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5017/tcp -> 0.0.0.0:46519 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5028/tcp -> 0.0.0.0:46509 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5034/tcp -> 0.0.0.0:46503 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5037/tcp -> 0.0.0.0:46500 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5053/tcp -> 0.0.0.0:46485 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5019/tcp -> 0.0.0.0:46517 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5031/tcp -> 0.0.0.0:46506 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5005/udp -> 0.0.0.0:33105 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5032/tcp -> 0.0.0.0:46505 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5038/tcp -> 0.0.0.0:46499 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5044/tcp -> 0.0.0.0:46494 <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 5065/tcp -> 0.0.0.0:46474 <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5000'] <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46535 <NL> # 03:09:01 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46535 for service \"network-element:NE1/device:main/service:console\" <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5001'] <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46534 <NL> # 03:09:01 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46534 for service \"network-element:NE1/device:main/service:debug-ssh\" <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5002'] <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46533 <NL> # 03:09:01 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46533 for service \"network-element:NE1/device:main/service:cli\" <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5003'] <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46532 <NL> # 03:09:01 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46532 for service \"network-element:NE1/device:main/service:netconf\" <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5004'] <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46531 <NL> # 03:09:01 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46531 for service \"network-element:NE1/device:main/service:gnmi\" <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5005/udp'] <NL> # 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:33105 <NL> # 03:09:02 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 33105 for service \"network-element:NE1/device:main/service:snmp\" <NL> # 03:09:02 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5006'] <NL> # 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46530 <NL> # 03:09:02 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46530 for service \"network-element:NE1/device:main/service:webui\" <NL> # 03:09:02 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5007'] <NL> # 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46529 <NL> # 03:09:02 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46529 for service \"network-element:NE1/device:main/service:https\" <NL> # 03:09:02 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5008']"}
{"timestamp_utc": "2024-07-31T08:09:02.779Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46528 <NL> # 03:09:02 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46528 for service \"network-element:NE1/device:main/service:zmq\" <NL> # 03:09:02 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5009'] <NL> # 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46527 <NL> # 03:09:02 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46527 for service \"network-element:NE1/device:main/service:gdb\" <NL> # 03:09:02 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5010']"}
{"timestamp_utc": "2024-07-31T08:09:03.035Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46526 <NL> # 03:09:02 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46526 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" <NL> # 03:09:02 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5011'] <NL> # 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46525 <NL> # 03:09:02 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46525 for service \"network-element:NE1/device:main/service:ospl\" <NL> # 03:09:02 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5012'] <NL> # 03:09:02 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46524 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46524 for service \"network-element:NE1/device:main/service:ftp\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5013']"}
{"timestamp_utc": "2024-07-31T08:09:03.290Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46523 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46523 for service \"network-element:NE1/device:main/service:sftp\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5014'] <NL> # 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46522 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46522 for service \"network-element:NE1/device:main/service:telnet\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5015']"}
{"timestamp_utc": "2024-07-31T08:09:03.545Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46521 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46521 for service \"network-element:NE1/device:trib1/service:console\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5016'] <NL> # 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46520 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46520 for service \"network-element:NE1/device:trib1/service:debug-ssh\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5017']"}
{"timestamp_utc": "2024-07-31T08:09:03.800Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46519 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46519 for service \"network-element:NE2/device:main/service:console\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5018'] <NL> # 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46518 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46518 for service \"network-element:NE2/device:main/service:debug-ssh\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5019']"}
{"timestamp_utc": "2024-07-31T08:09:04.055Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46517 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46517 for service \"network-element:NE2/device:main/service:cli\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5020'] <NL> # 03:09:03 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46516 <NL> # 03:09:03 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46516 for service \"network-element:NE2/device:main/service:netconf\" <NL> # 03:09:03 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5021']"}
{"timestamp_utc": "2024-07-31T08:09:04.310Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:04 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46515 <NL> # 03:09:04 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46515 for service \"network-element:NE2/device:main/service:gnmi\" <NL> # 03:09:04 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5022/udp'] <NL> # 03:09:04 ntp-topology INFO: docker_command: stdout: 0.0.0.0:33104 <NL> # 03:09:04 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 33104 for service \"network-element:NE2/device:main/service:snmp\" <NL> # 03:09:04 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5023']"}
{"timestamp_utc": "2024-07-31T08:09:04.566Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:04 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46514 <NL> # 03:09:04 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46514 for service \"network-element:NE2/device:main/service:webui\" <NL> # 03:09:04 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5024'] <NL> # 03:09:04 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46513 <NL> # 03:09:04 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46513 for service \"network-element:NE2/device:main/service:https\" <NL> # 03:09:04 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5025']"}
{"timestamp_utc": "2024-07-31T08:09:04.821Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:04 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46512 <NL> # 03:09:04 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46512 for service \"network-element:NE2/device:main/service:zmq\" <NL> # 03:09:04 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5026'] <NL> # 03:09:04 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46511 <NL> # 03:09:04 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46511 for service \"network-element:NE2/device:main/service:gdb\" <NL> # 03:09:04 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5027']"}
{"timestamp_utc": "2024-07-31T08:09:05.075Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:04 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46510 <NL> # 03:09:04 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46510 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" <NL> # 03:09:04 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5028'] <NL> # 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46509 <NL> # 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46509 for service \"network-element:NE2/device:main/service:ospl\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5029']"}
{"timestamp_utc": "2024-07-31T08:09:05.330Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46508 <NL> # 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46508 for service \"network-element:NE2/device:main/service:ftp\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5030'] <NL> # 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46507 <NL> # 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46507 for service \"network-element:NE2/device:main/service:sftp\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5031']"}
{"timestamp_utc": "2024-07-31T08:09:05.584Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46506 <NL> # 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46506 for service \"network-element:NE2/device:main/service:telnet\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5032'] <NL> # 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46505 <NL> # 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46505 for service \"network-element:NE2/device:trib1/service:console\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5033']"}
{"timestamp_utc": "2024-07-31T08:09:05.840Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46504 <NL> # 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46504 for service \"network-element:NE2/device:trib1/service:debug-ssh\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5034'] <NL> # 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46503 <NL> # 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46503 for service \"network-element:NE3/device:main/service:console\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5035']"}
{"timestamp_utc": "2024-07-31T08:09:06.095Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:05 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46502"}
{"timestamp_utc": "2024-07-31T08:09:06.096Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:05 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46502 for service \"network-element:NE3/device:main/service:debug-ssh\" <NL> # 03:09:05 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5036'] <NL> # 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46501 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46501 for service \"network-element:NE3/device:main/service:cli\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5037']"}
{"timestamp_utc": "2024-07-31T08:09:06.531Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46500 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46500 for service \"network-element:NE3/device:main/service:netconf\""}
{"timestamp_utc": "2024-07-31T08:09:06.532Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5038'] <NL> # 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46499 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46499 for service \"network-element:NE3/device:main/service:gnmi\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5039/udp'] <NL> # 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:33103 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 33103 for service \"network-element:NE3/device:main/service:snmp\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5040']"}
{"timestamp_utc": "2024-07-31T08:09:06.846Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46498 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46498 for service \"network-element:NE3/device:main/service:webui\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5041'] <NL> # 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46497 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46497 for service \"network-element:NE3/device:main/service:https\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5042'] <NL> # 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46496 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46496 for service \"network-element:NE3/device:main/service:zmq\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5043']"}
{"timestamp_utc": "2024-07-31T08:09:07.102Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46495 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46495 for service \"network-element:NE3/device:main/service:gdb\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5044'] <NL> # 03:09:06 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46494 <NL> # 03:09:06 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46494 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" <NL> # 03:09:06 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5045'] <NL> # 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46493"}
{"timestamp_utc": "2024-07-31T08:09:07.362Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46493 for service \"network-element:NE3/device:main/service:ospl\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5046'] <NL> # 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46492 <NL> # 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46492 for service \"network-element:NE3/device:main/service:ftp\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5047']"}
{"timestamp_utc": "2024-07-31T08:09:07.618Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46491 <NL> # 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46491 for service \"network-element:NE3/device:main/service:sftp\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5048'] <NL> # 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46490 <NL> # 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46490 for service \"network-element:NE3/device:main/service:telnet\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5049'] <NL> # 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46489 <NL> # 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46489 for service \"network-element:NE3/device:trib1/service:console\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5050']"}
{"timestamp_utc": "2024-07-31T08:09:07.874Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46488 <NL> # 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46488 for service \"network-element:NE3/device:trib1/service:debug-ssh\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5051'] <NL> # 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46487 <NL> # 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46487 for service \"network-element:NE4/device:main/service:console\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5052']"}
{"timestamp_utc": "2024-07-31T08:09:08.129Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:07 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46486 <NL> # 03:09:07 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46486 for service \"network-element:NE4/device:main/service:debug-ssh\" <NL> # 03:09:07 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5053'] <NL> # 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46485 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46485 for service \"network-element:NE4/device:main/service:cli\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5054']"}
{"timestamp_utc": "2024-07-31T08:09:08.384Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46484 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46484 for service \"network-element:NE4/device:main/service:netconf\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5055']"}
{"timestamp_utc": "2024-07-31T08:09:08.639Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46483 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46483 for service \"network-element:NE4/device:main/service:gnmi\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5056/udp'] <NL> # 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:33102 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 33102 for service \"network-element:NE4/device:main/service:snmp\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5057']"}
{"timestamp_utc": "2024-07-31T08:09:08.894Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46482 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46482 for service \"network-element:NE4/device:main/service:webui\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5058'] <NL> # 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46481 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46481 for service \"network-element:NE4/device:main/service:https\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5059'] <NL> # 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46480 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46480 for service \"network-element:NE4/device:main/service:zmq\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5060']"}
{"timestamp_utc": "2024-07-31T08:09:09.149Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:08 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46479 <NL> # 03:09:08 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46479 for service \"network-element:NE4/device:main/service:gdb\" <NL> # 03:09:08 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5061']"}
{"timestamp_utc": "2024-07-31T08:09:09.407Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:09 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46478 <NL> # 03:09:09 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46478 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" <NL> # 03:09:09 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5062'] <NL> # 03:09:09 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46477 <NL> # 03:09:09 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46477 for service \"network-element:NE4/device:main/service:ospl\" <NL> # 03:09:09 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5063']"}
{"timestamp_utc": "2024-07-31T08:09:09.664Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:09 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46476 <NL> # 03:09:09 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46476 for service \"network-element:NE4/device:main/service:ftp\" <NL> # 03:09:09 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5064'] <NL> # 03:09:09 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46475 <NL> # 03:09:09 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46475 for service \"network-element:NE4/device:main/service:sftp\" <NL> # 03:09:09 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5065']"}
{"timestamp_utc": "2024-07-31T08:09:09.919Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:09 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46474 <NL> # 03:09:09 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46474 for service \"network-element:NE4/device:main/service:telnet\" <NL> # 03:09:09 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5066'] <NL> # 03:09:09 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46473 <NL> # 03:09:09 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46473 for service \"network-element:NE4/device:trib1/service:console\" <NL> # 03:09:09 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '5067']"}
{"timestamp_utc": "2024-07-31T08:09:10.179Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:09 ntp-topology INFO: docker_command: stdout: 0.0.0.0:46472 <NL> # 03:09:09 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 46472 for service \"network-element:NE4/device:trib1/service:debug-ssh\" <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46535 for network-element:NE1/device:main/service:console <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46534 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46533 for network-element:NE1/device:main/service:cli <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:cli hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46532 for network-element:NE1/device:main/service:netconf <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:netconf hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46531 for network-element:NE1/device:main/service:gnmi"}
{"timestamp_utc": "2024-07-31T08:09:10.180Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:09 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gnmi hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 33105 for network-element:NE1/device:main/service:snmp <NL> # 03:09:09 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:09 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:snmp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46530 for network-element:NE1/device:main/service:webui <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:webui hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46529 for network-element:NE1/device:main/service:https <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:https hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46528 for network-element:NE1/device:main/service:zmq <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:zmq hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46527 for network-element:NE1/device:main/service:gdb <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gdb hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46526 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gdb-ops-additional hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46525 for network-element:NE1/device:main/service:ospl <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:ospl hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46524 for network-element:NE1/device:main/service:ftp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:ftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46523 for network-element:NE1/device:main/service:sftp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:sftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46522 for network-element:NE1/device:main/service:telnet <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:telnet hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46521 for network-element:NE1/device:trib1/service:console <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:trib1/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46520 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:trib1/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:09:10.181Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46519 for network-element:NE2/device:main/service:console <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46518 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46517 for network-element:NE2/device:main/service:cli <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:cli hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46516 for network-element:NE2/device:main/service:netconf <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:netconf hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46515 for network-element:NE2/device:main/service:gnmi <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gnmi hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 33104 for network-element:NE2/device:main/service:snmp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:snmp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46514 for network-element:NE2/device:main/service:webui <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:webui hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46513 for network-element:NE2/device:main/service:https <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:https hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46512 for network-element:NE2/device:main/service:zmq <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:zmq hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46511 for network-element:NE2/device:main/service:gdb <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gdb hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46510 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gdb-ops-additional hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46509 for network-element:NE2/device:main/service:ospl <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:ospl hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46508 for network-element:NE2/device:main/service:ftp"}
{"timestamp_utc": "2024-07-31T08:09:10.182Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:ftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46507 for network-element:NE2/device:main/service:sftp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:sftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46506 for network-element:NE2/device:main/service:telnet <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:telnet hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46505 for network-element:NE2/device:trib1/service:console <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:trib1/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46504 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:trib1/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46503 for network-element:NE3/device:main/service:console <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46502 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46501 for network-element:NE3/device:main/service:cli <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:cli hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46500 for network-element:NE3/device:main/service:netconf <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:netconf hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46499 for network-element:NE3/device:main/service:gnmi <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gnmi hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 33103 for network-element:NE3/device:main/service:snmp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:snmp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46498 for network-element:NE3/device:main/service:webui <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:webui hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46497 for network-element:NE3/device:main/service:https <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json'"}
{"timestamp_utc": "2024-07-31T08:09:10.183Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:https hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46496 for network-element:NE3/device:main/service:zmq <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:zmq hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46495 for network-element:NE3/device:main/service:gdb <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gdb hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46494 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gdb-ops-additional hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46493 for network-element:NE3/device:main/service:ospl <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:ospl hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46492 for network-element:NE3/device:main/service:ftp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:ftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46491 for network-element:NE3/device:main/service:sftp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:sftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46490 for network-element:NE3/device:main/service:telnet <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:telnet hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46489 for network-element:NE3/device:trib1/service:console <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:trib1/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46488 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:trib1/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46487 for network-element:NE4/device:main/service:console <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46486 for network-element:NE4/device:main/service:debug-ssh"}
{"timestamp_utc": "2024-07-31T08:09:10.184Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46485 for network-element:NE4/device:main/service:cli <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:cli hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46484 for network-element:NE4/device:main/service:netconf <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:netconf hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46483 for network-element:NE4/device:main/service:gnmi <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gnmi hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 33102 for network-element:NE4/device:main/service:snmp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:snmp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46482 for network-element:NE4/device:main/service:webui <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:webui hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46481 for network-element:NE4/device:main/service:https <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:https hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46480 for network-element:NE4/device:main/service:zmq <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:zmq hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46479 for network-element:NE4/device:main/service:gdb <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gdb hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46478 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gdb-ops-additional hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46477 for network-element:NE4/device:main/service:ospl <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:ospl hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46476 for network-element:NE4/device:main/service:ftp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:ftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46475 for network-element:NE4/device:main/service:sftp <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:sftp hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214"}
{"timestamp_utc": "2024-07-31T08:09:10.185Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46474 for network-element:NE4/device:main/service:telnet <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:telnet hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46473 for network-element:NE4/device:trib1/service:console <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:trib1/service:console hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 46472 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:09:10 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:trib1/service:debug-ssh hostname rtxoialp85.fnc.net.local, hostip 167.254.217.214 <NL> # 03:09:10 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:10 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: container_logs_command_log_fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.log' <NL> # 03:09:10 ntp-topology INFO: get_container_env_exec_command: network_topology_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology <NL> # 03:09:10 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: start_command ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-create'] <NL> # 03:09:10 ntp-topology INFO: create_container_log_fname: name='command' type='created'): fname_data_dict { <NL> \"status_text\": \"from handle_remote_create_in_new_device_group_containers\" <NL> } <NL> # 03:09:10 ntp-topology INFO: exec_cmd: ['mv', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.created.tmp', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.created'] <NL> # 03:09:10 ntp-topology INFO: exec_cmd: ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-create']"}
{"timestamp_utc": "2024-07-31T08:09:10.445Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: wait_for_containers_command_started: - waiting max 600s for container_logs_command_started_fname files: <NL> # 03:09:10 ntp-topology INFO: wait_for_containers_command_started:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.started' <NL> # 03:09:10 ntp-topology INFO: wait_for_containers_command_started: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.started'] <NL> # 03:09:10 ntp-topology INFO: wait_for_containers_command_started: 0.000s of 600.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:11.378Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized: - waiting max 1800s for container_logs_command_initialized_fname files: <NL> # 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized' <NL> # 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error' <NL> # 03:09:11 ntp-topology INFO: ntp.retry.group_list_cl.show: json_list: [ <NL> { <NL> \"all_of_file_list\": [ <NL> [ <NL> \"initialized\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized\" <NL> ] <NL> ], <NL> \"any_of_file_list\": [ <NL> [ <NL> \"error\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error\" <NL> ] <NL> ], <NL> \"group_name\": \"topology-group-device-group-type-qemu-01\" <NL> } <NL> ] <NL> # 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized: 0.000s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:12.792Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:12 ntp-topology INFO: wait_for_containers_command_initialized: 1.001s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:13.723Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:13 ntp-topology INFO: wait_for_containers_command_initialized: 2.002s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:14.649Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:14 ntp-topology INFO: wait_for_containers_command_initialized: 3.003s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:15.579Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:15 ntp-topology INFO: wait_for_containers_command_initialized: 4.004s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:16.511Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:16 ntp-topology INFO: wait_for_containers_command_initialized: 5.005s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:17.499Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:17 ntp-topology INFO: wait_for_containers_command_initialized: 6.006s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:18.427Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:18 ntp-topology INFO: wait_for_containers_command_initialized: 7.007s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:19.789Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:19 ntp-topology INFO: wait_for_containers_command_initialized: 8.008s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:20.716Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:20 ntp-topology INFO: wait_for_containers_command_initialized: 9.009s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:21.640Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:21 ntp-topology INFO: wait_for_containers_command_initialized: 10.010s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:22.564Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:22 ntp-topology INFO: wait_for_containers_command_initialized: 11.011s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:23.488Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:23 ntp-topology INFO: wait_for_containers_command_initialized: 12.012s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:24.415Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:24 ntp-topology INFO: wait_for_containers_command_initialized: 13.014s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:25.423Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:25 ntp-topology INFO: wait_for_containers_command_initialized: 14.015s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:26.784Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:26 ntp-topology INFO: wait_for_containers_command_initialized: 15.016s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:27.708Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:27 ntp-topology INFO: wait_for_containers_command_initialized: 16.017s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:28.633Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:28 ntp-topology INFO: wait_for_containers_command_initialized: 17.018s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:29.556Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:29 ntp-topology INFO: wait_for_containers_command_initialized: 18.020s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:30.481Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:30 ntp-topology INFO: wait_for_containers_command_initialized: 19.021s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:31.627Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:31 ntp-topology INFO: wait_for_containers_command_initialized: 20.022s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:32.554Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:32 ntp-topology INFO: wait_for_containers_command_initialized: 21.023s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:33.479Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:33 ntp-topology INFO: wait_for_containers_command_initialized: 22.024s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:34.407Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:34 ntp-topology INFO: wait_for_containers_command_initialized: 23.025s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:35.766Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:35 ntp-topology INFO: wait_for_containers_command_initialized: 24.026s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:36.690Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:36 ntp-topology INFO: wait_for_containers_command_initialized: 25.027s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:37.633Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:37 ntp-topology INFO: wait_for_containers_command_initialized: 26.028s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:38.579Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:38 ntp-topology INFO: wait_for_containers_command_initialized: 27.029s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:39.502Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:39 ntp-topology INFO: wait_for_containers_command_initialized: 28.030s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:40.424Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:40 ntp-topology INFO: wait_for_containers_command_initialized: 29.031s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:41.784Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:41 ntp-topology INFO: wait_for_containers_command_initialized: 30.032s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:42.708Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:42 ntp-topology INFO: wait_for_containers_command_initialized: 31.033s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:43.631Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:43 ntp-topology INFO: wait_for_containers_command_initialized: 32.034s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:44.554Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:44 ntp-topology INFO: wait_for_containers_command_initialized: 33.035s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:45.739Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:45 ntp-topology INFO: wait_for_containers_command_initialized: 34.036s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:46.666Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:46 ntp-topology INFO: wait_for_containers_command_initialized: 35.037s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:47.589Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:47 ntp-topology INFO: wait_for_containers_command_initialized: 36.038s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:48.513Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:09:48.514Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:48 ntp-topology INFO: wait_for_containers_command_initialized: 37.039s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:49.441Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:49 ntp-topology INFO: wait_for_containers_command_initialized: 38.040s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:50.804Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:50 ntp-topology INFO: wait_for_containers_command_initialized: 39.041s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:51.727Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:51 ntp-topology INFO: wait_for_containers_command_initialized: 40.042s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:52.506Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:52 ntp-topology INFO: wait_for_containers_command_initialized: 41.043s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:53.566Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:53 ntp-topology INFO: wait_for_containers_command_initialized: 42.044s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:54.492Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:54 ntp-topology INFO: wait_for_containers_command_initialized: 43.045s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:55.416Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:55 ntp-topology INFO: wait_for_containers_command_initialized: 44.046s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:56.820Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:56 ntp-topology INFO: wait_for_containers_command_initialized: 45.047s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:57.745Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:57 ntp-topology INFO: wait_for_containers_command_initialized: 46.048s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:58.759Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:58 ntp-topology INFO: wait_for_containers_command_initialized: 47.049s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:59.684Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:59 ntp-topology INFO: wait_for_containers_command_initialized: 48.050s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:00.654Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:00 ntp-topology INFO: wait_for_containers_command_initialized: 49.051s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:01.606Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:01 ntp-topology INFO: wait_for_containers_command_initialized: 50.052s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:02.532Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:02 ntp-topology INFO: wait_for_containers_command_initialized: 51.053s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:03.493Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:03 ntp-topology INFO: wait_for_containers_command_initialized: 52.054s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:04.418Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:04 ntp-topology INFO: wait_for_containers_command_initialized: 53.055s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:05.784Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:05 ntp-topology INFO: wait_for_containers_command_initialized: 54.056s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:06.711Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:06 ntp-topology INFO: wait_for_containers_command_initialized: 55.057s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:07.637Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:07 ntp-topology INFO: wait_for_containers_command_initialized: 56.058s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:08.563Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:08 ntp-topology INFO: wait_for_containers_command_initialized: 57.059s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:09.487Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:09 ntp-topology INFO: wait_for_containers_command_initialized: 58.060s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:10.851Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:10 ntp-topology INFO: wait_for_containers_command_initialized: 59.061s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:11.776Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:11 ntp-topology INFO: wait_for_containers_command_initialized: 60.062s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:12.701Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:12 ntp-topology INFO: wait_for_containers_command_initialized: 61.063s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:13.625Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:10:13.626Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:13 ntp-topology INFO: wait_for_containers_command_initialized: 62.064s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:14.550Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:14 ntp-topology INFO: wait_for_containers_command_initialized: 63.065s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:15.476Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:15 ntp-topology INFO: wait_for_containers_command_initialized: 64.066s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:16.838Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:16 ntp-topology INFO: wait_for_containers_command_initialized: 65.067s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:17.766Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:17 ntp-topology INFO: wait_for_containers_command_initialized: 66.068s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:18.692Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:18 ntp-topology INFO: wait_for_containers_command_initialized: 67.069s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:19.618Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:19 ntp-topology INFO: wait_for_containers_command_initialized: 68.070s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:20.544Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:20 ntp-topology INFO: wait_for_containers_command_initialized: 69.071s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:21.470Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:21 ntp-topology INFO: wait_for_containers_command_initialized: 70.072s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:22.833Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:22 ntp-topology INFO: wait_for_containers_command_initialized: 71.073s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:23.759Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:23 ntp-topology INFO: wait_for_containers_command_initialized: 72.074s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:24.683Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:24 ntp-topology INFO: wait_for_containers_command_initialized: 73.075s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:25.611Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:25 ntp-topology INFO: wait_for_containers_command_initialized: 74.076s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:26.536Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:26 ntp-topology INFO: wait_for_containers_command_initialized: 75.077s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:27.461Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:27 ntp-topology INFO: wait_for_containers_command_initialized: 76.078s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:28.823Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:28 ntp-topology INFO: wait_for_containers_command_initialized: 77.079s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:29.748Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:29 ntp-topology INFO: wait_for_containers_command_initialized: 78.080s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:30.675Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:30 ntp-topology INFO: wait_for_containers_command_initialized: 79.081s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:31.602Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:31 ntp-topology INFO: wait_for_containers_command_initialized: 80.082s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:32.527Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:32 ntp-topology INFO: wait_for_containers_command_initialized: 81.083s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:33.452Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:33 ntp-topology INFO: wait_for_containers_command_initialized: 82.084s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:34.813Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:34 ntp-topology INFO: wait_for_containers_command_initialized: 83.085s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:35.738Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:35 ntp-topology INFO: wait_for_containers_command_initialized: 84.086s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:36.663Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:36 ntp-topology INFO: wait_for_containers_command_initialized: 85.087s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:37.587Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:37 ntp-topology INFO: wait_for_containers_command_initialized: 86.088s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:38.513Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:38 ntp-topology INFO: wait_for_containers_command_initialized: 87.089s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:39.873Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:39 ntp-topology INFO: wait_for_containers_command_initialized: 88.090s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:40.802Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:40 ntp-topology INFO: wait_for_containers_command_initialized: 89.091s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:41.727Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:41 ntp-topology INFO: wait_for_containers_command_initialized: 90.092s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:42.653Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:42 ntp-topology INFO: wait_for_containers_command_initialized: 91.093s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:43.578Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:43 ntp-topology INFO: wait_for_containers_command_initialized: 92.094s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:44.513Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:44 ntp-topology INFO: wait_for_containers_command_initialized: 93.095s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:45.875Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:45 ntp-topology INFO: wait_for_containers_command_initialized: 94.096s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:46.800Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:46 ntp-topology INFO: wait_for_containers_command_initialized: 95.097s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:47.725Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:10:47.726Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:47 ntp-topology INFO: wait_for_containers_command_initialized: 96.098s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:48.651Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:48 ntp-topology INFO: wait_for_containers_command_initialized: 97.099s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:49.576Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:49 ntp-topology INFO: wait_for_containers_command_initialized: 98.100s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:50.503Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:50 ntp-topology INFO: wait_for_containers_command_initialized: 99.101s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:52.394Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:51 ntp-topology INFO: wait_for_containers_command_initialized: 100.102s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:52.703Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:52 ntp-topology INFO: wait_for_containers_command_initialized: 101.103s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:53.792Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:53 ntp-topology INFO: wait_for_containers_command_initialized: 102.105s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:54.717Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:54 ntp-topology INFO: wait_for_containers_command_initialized: 103.106s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:55.641Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:55 ntp-topology INFO: wait_for_containers_command_initialized: 104.107s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:56.566Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:56 ntp-topology INFO: wait_for_containers_command_initialized: 105.108s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:57.534Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:57 ntp-topology INFO: wait_for_containers_command_initialized: 106.109s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:58.494Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:58 ntp-topology INFO: wait_for_containers_command_initialized: 107.110s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:59.856Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:59 ntp-topology INFO: wait_for_containers_command_initialized: 108.111s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:00.782Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:00 ntp-topology INFO: wait_for_containers_command_initialized: 109.112s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:01.708Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:01 ntp-topology INFO: wait_for_containers_command_initialized: 110.113s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:02.632Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:02 ntp-topology INFO: wait_for_containers_command_initialized: 111.114s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:03.555Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:03 ntp-topology INFO: wait_for_containers_command_initialized: 112.115s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:04.480Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:04 ntp-topology INFO: wait_for_containers_command_initialized: 113.116s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:05.841Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:05 ntp-topology INFO: wait_for_containers_command_initialized: 114.117s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:06.765Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:06 ntp-topology INFO: wait_for_containers_command_initialized: 115.118s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:07.690Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:07 ntp-topology INFO: wait_for_containers_command_initialized: 116.119s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:08.615Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:08 ntp-topology INFO: wait_for_containers_command_initialized: 117.120s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:09.658Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:09 ntp-topology INFO: wait_for_containers_command_initialized: 118.121s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:10.582Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:10 ntp-topology INFO: wait_for_containers_command_initialized: 119.122s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:11.506Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:11 ntp-topology INFO: wait_for_containers_command_initialized: 120.123s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:12.522Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:12 ntp-topology INFO: wait_for_containers_command_initialized: 121.124s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:13.886Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:13 ntp-topology INFO: wait_for_containers_command_initialized: 122.125s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:14.815Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:14 ntp-topology INFO: wait_for_containers_command_initialized: 123.126s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:15.742Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:15 ntp-topology INFO: wait_for_containers_command_initialized: 124.127s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:16.666Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:16 ntp-topology INFO: wait_for_containers_command_initialized: 125.128s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:17.591Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:17 ntp-topology INFO: wait_for_containers_command_initialized: 126.129s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:18.517Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:18 ntp-topology INFO: wait_for_containers_command_initialized: 127.130s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:19.883Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:19 ntp-topology INFO: wait_for_containers_command_initialized: 128.131s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:20.809Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:20 ntp-topology INFO: wait_for_containers_command_initialized: 129.132s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:21.735Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:21 ntp-topology INFO: wait_for_containers_command_initialized: 130.133s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:22.660Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:22 ntp-topology INFO: wait_for_containers_command_initialized: 131.134s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:23.583Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:23 ntp-topology INFO: wait_for_containers_command_initialized: 132.135s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:24.508Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:24 ntp-topology INFO: wait_for_containers_command_initialized: 133.136s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:25.871Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:25 ntp-topology INFO: wait_for_containers_command_initialized: 134.137s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:26.796Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:26 ntp-topology INFO: wait_for_containers_command_initialized: 135.138s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:27.721Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:27 ntp-topology INFO: wait_for_containers_command_initialized: 136.139s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:28.646Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:28 ntp-topology INFO: wait_for_containers_command_initialized: 137.140s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:29.571Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:29 ntp-topology INFO: wait_for_containers_command_initialized: 138.141s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:30.933Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:30 ntp-topology INFO: wait_for_containers_command_initialized: 139.142s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:31.858Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:31 ntp-topology INFO: wait_for_containers_command_initialized: 140.143s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:32.784Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:32 ntp-topology INFO: wait_for_containers_command_initialized: 141.144s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:33.709Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:33 ntp-topology INFO: wait_for_containers_command_initialized: 142.145s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:34.634Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:34 ntp-topology INFO: wait_for_containers_command_initialized: 143.146s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:35.560Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:35 ntp-topology INFO: wait_for_containers_command_initialized: 144.147s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:36.928Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:36 ntp-topology INFO: wait_for_containers_command_initialized: 145.149s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:37.854Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:37 ntp-topology INFO: wait_for_containers_command_initialized: 146.150s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:38.779Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:38 ntp-topology INFO: wait_for_containers_command_initialized: 147.151s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:39.704Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:39 ntp-topology INFO: wait_for_containers_command_initialized: 148.152s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:40.631Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:40 ntp-topology INFO: wait_for_containers_command_initialized: 149.153s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:41.557Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:41 ntp-topology INFO: wait_for_containers_command_initialized: 150.154s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:42.921Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:42 ntp-topology INFO: wait_for_containers_command_initialized: 151.155s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:43.848Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:43 ntp-topology INFO: wait_for_containers_command_initialized: 152.156s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:44.775Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:44 ntp-topology INFO: wait_for_containers_command_initialized: 153.157s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:45.701Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:45 ntp-topology INFO: wait_for_containers_command_initialized: 154.158s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:46.628Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:46 ntp-topology INFO: wait_for_containers_command_initialized: 155.159s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:47.553Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:47 ntp-topology INFO: wait_for_containers_command_initialized: 156.160s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:48.919Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:48 ntp-topology INFO: wait_for_containers_command_initialized: 157.161s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:49.845Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:49 ntp-topology INFO: wait_for_containers_command_initialized: 158.162s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:50.774Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:50 ntp-topology INFO: wait_for_containers_command_initialized: 159.163s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:51.704Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:51 ntp-topology INFO: wait_for_containers_command_initialized: 160.164s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:52.629Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:52 ntp-topology INFO: wait_for_containers_command_initialized: 161.165s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:53.559Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:53 ntp-topology INFO: wait_for_containers_command_initialized: 162.166s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:54.926Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:54 ntp-topology INFO: wait_for_containers_command_initialized: ntp_container_name 'topology-group-device-group-type-qemu-01': error_file_present_flag False <NL> # 03:11:54 ntp-topology INFO: wait_for_containers_socket_deamon_info: - waiting max 1800s for socket daemon files, if we have any <NL> # 03:11:54 ntp-topology INFO: wait_for_containers_socket_deamon_info: container_workspace_basedir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace' <NL> # 03:11:54 ntp-topology INFO: wait_for_containers_socket_deamon_info:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error' <NL> # 03:11:54 ntp-topology INFO: wait_for_containers_socket_deamon_info: socket_daemon_info_list: [ <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE1/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE1/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE2/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE2/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE3/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE3/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE4/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE4/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> ] <NL> # 03:11:54 ntp-topology INFO: ntp.retry.group_list_cl.show: json_list: [ <NL> { <NL> \"all_of_file_list\": [ <NL> [ <NL> \"socket-daemon-info:network-element:NE1/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE1/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE2/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE2/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE3/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE3/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE4/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE4/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ] <NL> ], <NL> \"any_of_file_list\": [ <NL> [ <NL> \"error\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error\" <NL> ] <NL> ], <NL> \"group_name\": \"topology-group-device-group-type-qemu-01\" <NL> } <NL> ]"}
{"timestamp_utc": "2024-07-31T08:11:54.927Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:54 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:54 ntp-topology INFO: wait_for_containers_socket_deamon_info: 0.000s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:55.861Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:55 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:55 ntp-topology INFO: wait_for_containers_socket_deamon_info: 1.005s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:56.737Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:56 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:56 ntp-topology INFO: wait_for_containers_socket_deamon_info: 2.006s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:57.671Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:57 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:57 ntp-topology INFO: wait_for_containers_socket_deamon_info: 3.007s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:58.598Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:58 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:58 ntp-topology INFO: wait_for_containers_socket_deamon_info: 4.008s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:59.977Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:59 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:59 ntp-topology INFO: wait_for_containers_socket_deamon_info: 5.009s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:00.642Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:00 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:00 ntp-topology INFO: wait_for_containers_socket_deamon_info: 6.010s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:01.571Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': error_file_present_flag False <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE1/device:main': command_code 0 <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE1/device:trib1': command_code 0 <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE2/device:main': command_code 0 <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE2/device:trib1': command_code 0 <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE3/device:main': command_code 0 <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE3/device:trib1': command_code 0 <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE4/device:main': command_code 0 <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE4/device:trib1': command_code 0 <NL> # 03:12:01 ntp-topology INFO: main: completed action 'create' <NL> # 03:12:01 ntp-topology INFO: done"}
{"timestamp_utc": "2024-07-31T08:12:01.827Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:01 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json', '--action', 'request-remote-create']"}
{"timestamp_utc": "2024-07-31T08:12:02.083Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:01 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace' <NL> # 03:12:01 ntp-topology INFO: main: starting action 'request-remote-create' <NL> # 03:12:01 ntp-topology INFO: main: completed action 'request-remote-create' <NL> # 03:12:01 ntp-topology INFO: done <NL> # 03:12:01 ntp-topology-run.py INFO: exec_cmd: ['ntp-get-service-details', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace/topology-flist.json', '--out-format', 'json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/services-ntp.861.json']"}
{"timestamp_utc": "2024-07-31T08:12:02.651Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:trib1'"}
{"timestamp_utc": "2024-07-31T08:12:02.652Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE3/device:main'"}
{"timestamp_utc": "2024-07-31T08:12:02.653Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:cli' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:netconf' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gnmi' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:snmp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:webui' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:https' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:zmq' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gdb' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gdb-ops-additional' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:ospl' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:ftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:sftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:telnet' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:trib1/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:trib1/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:cli' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:netconf' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gnmi' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:snmp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:webui' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:https' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:zmq' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gdb' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gdb-ops-additional' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:ospl' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:ftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:sftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:telnet' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:trib1/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:trib1/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:cli' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:netconf' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gnmi' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:snmp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:webui' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:https'"}
{"timestamp_utc": "2024-07-31T08:12:02.654Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:zmq' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gdb' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gdb-ops-additional' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:ospl' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:ftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:sftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:telnet' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:trib1/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:trib1/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:cli' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:netconf' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gnmi' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:snmp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:webui' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:https' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:zmq' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gdb' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gdb-ops-additional' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:ospl' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:ftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:sftp' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:telnet' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:trib1/service:console' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:trib1/service:debug-ssh' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:02.655Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46535:5000:None for network-element:NE1/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46534:5001:6022 for network-element:NE1/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46533:5002:22 for network-element:NE1/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46532:5003:830 for network-element:NE1/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46531:5004:6030 for network-element:NE1/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 33105:5005:161/udp for network-element:NE1/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46530:5006:80 for network-element:NE1/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46529:5007:443 for network-element:NE1/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46528:5008:5555 for network-element:NE1/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46527:5009:10000 for network-element:NE1/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46526:5010:32767 for network-element:NE1/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46525:5011:50000 for network-element:NE1/device:main/service:ospl, device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:02.656Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46524:5012:21 for network-element:NE1/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46523:5013:2202 for network-element:NE1/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46522:5014:23 for network-element:NE1/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46521:5015:None for network-element:NE1/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46520:5016:6022 for network-element:NE1/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46519:5017:None for network-element:NE2/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46518:5018:6022 for network-element:NE2/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46517:5019:22 for network-element:NE2/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46516:5020:830 for network-element:NE2/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46515:5021:6030 for network-element:NE2/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 33104:5022:161/udp for network-element:NE2/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46514:5023:80 for network-element:NE2/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46513:5024:443 for network-element:NE2/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46512:5025:5555 for network-element:NE2/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46511:5026:10000 for network-element:NE2/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46510:5027:32767 for network-element:NE2/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46509:5028:50000 for network-element:NE2/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46508:5029:21 for network-element:NE2/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46507:5030:2202 for network-element:NE2/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46506:5031:23 for network-element:NE2/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46505:5032:None for network-element:NE2/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46504:5033:6022 for network-element:NE2/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46503:5034:None for network-element:NE3/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46502:5035:6022 for network-element:NE3/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46501:5036:22 for network-element:NE3/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46500:5037:830 for network-element:NE3/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46499:5038:6030 for network-element:NE3/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 33103:5039:161/udp for network-element:NE3/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46498:5040:80 for network-element:NE3/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46497:5041:443 for network-element:NE3/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46496:5042:5555 for network-element:NE3/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46495:5043:10000 for network-element:NE3/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46494:5044:32767 for network-element:NE3/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46493:5045:50000 for network-element:NE3/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46492:5046:21 for network-element:NE3/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46491:5047:2202 for network-element:NE3/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46490:5048:23 for network-element:NE3/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46489:5049:None for network-element:NE3/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46488:5050:6022 for network-element:NE3/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46487:5051:None for network-element:NE4/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46486:5052:6022 for network-element:NE4/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46485:5053:22 for network-element:NE4/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46484:5054:830 for network-element:NE4/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46483:5055:6030 for network-element:NE4/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 33102:5056:161/udp for network-element:NE4/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46482:5057:80 for network-element:NE4/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46481:5058:443 for network-element:NE4/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46480:5059:5555 for network-element:NE4/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46479:5060:10000 for network-element:NE4/device:main/service:gdb, device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:02.657Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46478:5061:32767 for network-element:NE4/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46477:5062:50000 for network-element:NE4/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46476:5063:21 for network-element:NE4/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46475:5064:2202 for network-element:NE4/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46474:5065:23 for network-element:NE4/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46473:5066:None for network-element:NE4/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp85.fnc.net.local|167.254.217.214] on ports 46472:5067:6022 for network-element:NE4/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:02 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-legacy-service-info-environment', '-v', '-v', '--service-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/services-ntp.861.json', '--environment-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-legacy-env.json', '--map-service-name', 'debug-ssh', 'dip'] <NL> # 03:12:02 ntp-create-legacy-service-info-environment INFO: arg_dict: { <NL> \"environment_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-legacy-env.json\", <NL> \"global_host_info_flag\": true, <NL> \"map_service_name\": [ <NL> [ <NL> \"debug-ssh\", <NL> \"dip\" <NL> ] <NL> ], <NL> \"service_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/services-ntp.861.json\", <NL> \"verbosity\": 2 <NL> } <NL> create-service-info-environment-json: service_info_json_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/services-ntp.861.json\" <NL> create-service-info-environment-json: environment_json_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-legacy-env.json\" <NL> # 03:12:02 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-service-info-environment', '-v', '-v', '--input-file', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/services-ntp.861.json', '--output-file', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', '--output-format', 'json'] <NL> # 03:12:02 ntp-create-service-info-environment INFO: Called with arguments: Namespace(input_file='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/services-ntp.861.json', output_file='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', output_format='json', verbosity=2) <NL> # 03:12:02 ntp-create-service-info-environment DEBUG: Writing: /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json <NL> # 03:12:02 ntp-topology-run.py INFO: exec_cmd: ['rm', '-f', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/services-ntp.861.json'] <NL> # 03:12:02 ntp-topology-run.py INFO: done <NL> # 03:12:02 tfwk-exec-test-agent INFO: create_autop_json_fname: device_list: [] <NL> # 03:12:02 tfwk-exec-test-agent INFO: create_autop_json_fname: saving device_list into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/image-info-autop.json' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs: - from fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-legacy-env.json' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_PORT'=46533 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_PORT'=46535 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_PORT'=46534 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_PORT'=46524 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_PORT'=46526 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_PORT'=46527 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_PORT'=46531 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_PORT'=46529 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_PORT'=46532 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_PORT'=46525 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_PORT'=46523 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_PORT'=33105 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_PORT'=46522"}
{"timestamp_utc": "2024-07-31T08:12:02.658Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_PORT'=46530 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_PORT'=46528 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_PORT'=46521 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_PORT'=46520 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_PORT'=46517 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_PORT'=46519 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_PORT'=46518 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_PORT'=46508 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_PORT'=46510 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_PORT'=46511 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_PORT'=46515 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_PORT'=46513 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_PORT'=46516 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_PORT'=46509 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_PORT'=46507 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_PORT'=33104 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_PORT'=46506 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_PORT'=46514 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_PORT'=46512 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_PORT'=46505 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_PORT'=46504 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_PORT'=46501 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_PORT'=46503 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_PORT'=46502 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_HOSTIP'='167.254.217.214'"}
{"timestamp_utc": "2024-07-31T08:12:02.659Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_PORT'=46492 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_PORT'=46494 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_PORT'=46495 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_PORT'=46499 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_PORT'=46497 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_PORT'=46500 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_PORT'=46493 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_PORT'=46491 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_PORT'=33103 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_PORT'=46490 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_PORT'=46498 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_PORT'=46496 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_PORT'=46489 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_PORT'=46488 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_PORT'=46485 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_PORT'=46487 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_PORT'=46486 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_PORT'=46476 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_PORT'=46478 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_PORT'=46479 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_PORT'=46483 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_PORT'=46481 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_PORT'=46484 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_PORT'=46477 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_PORT'=46475 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_PORT'=33102 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_PORT'=46474 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_PORT'=46482 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_PORT'=46480 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_PORT'=46473 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_PORT'=46472"}
{"timestamp_utc": "2024-07-31T08:12:02.660Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.HOSTIP'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.HOSTNAME'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs: - from fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli'=46533 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console'=46535 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh'=46534 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp'=46524 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb'=46527 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional'=46526 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi'=46531 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https'=46529 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf'=46532 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl'=46525 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp'=46523 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp'=33105 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet'=46522 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui'=46530 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq'=46528 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console'=46521 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh'=46520 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli'=46517 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console'=46519 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh'=46518 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp'=46508 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb'=46511 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional'=46510 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi'=46515 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https'=46513 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf'=46516 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl'=46509 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp'=46507 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp'=33104 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet'=46506"}
{"timestamp_utc": "2024-07-31T08:12:02.661Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui'=46514 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq'=46512 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console'=46505 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh'=46504 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli'=46501 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console'=46503 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh'=46502 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp'=46492 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb'=46495 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional'=46494 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi'=46499 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https'=46497 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf'=46500 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl'=46493 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp'=46491 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp'=33103 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet'=46490 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui'=46498 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq'=46496 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console'=46489 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh'=46488 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_hostip'='167.254.217.214'"}
{"timestamp_utc": "2024-07-31T08:12:02.918Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli'=46485 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console'=46487 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh'=46486 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp'=46476 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb'=46479 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional'=46478 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi'=46483 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https'=46481 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf'=46484 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl'=46477"}
{"timestamp_utc": "2024-07-31T08:12:02.919Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp'=46475 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp'=33102 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet'=46474 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui'=46482 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq'=46480 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console'=46473 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh'=46472 <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_hostip'='167.254.217.214' <NL> # 03:12:02 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_hostname'='rtxoialp85.fnc.net.local' <NL> # 03:12:02 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test-engine-output-dir'] <NL> # 03:12:02 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json', '--cmd-end', '--job-end'] <NL> # 03:12:02 ntp-wait-for-devices INFO: arg_dict: { <NL> \"autop_json_fname\": null, <NL> \"autop_processing\": null, <NL> \"flist_fname\": null, <NL> \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json\", <NL> \"overall_timeout\": 28800, <NL> \"startup_timeout\": \"1200\", <NL> \"trailer_command\": [ <NL> \"--\", <NL> \"--job-begin-command\", <NL> \"--name\", <NL> \"Warrior\", <NL> \"--cmd-begin\", <NL> \"run_init\", <NL> \"--runinit_venv_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\", <NL> \"--services_env\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json\", <NL> \"--work_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155\", <NL> \"-v\", <NL> \"-e\", <NL> \"warrior\", <NL> \"--test_engine_venv_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\", <NL> \"--test_engine\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json\", <NL> \"--cmd-end\", <NL> \"--job-end\" <NL> ], <NL> \"verbosity\": 2, <NL> \"virtualenv_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\", <NL> \"wait_period\": null,"}
{"timestamp_utc": "2024-07-31T08:12:02.920Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"wait_time\": null <NL> } <NL> # 03:12:02 ntp-wait-for-devices INFO: main: ntp_info_obj: { <NL> \"_NETWORK_TOPOLOGY_TAG\": \"tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> \"_SHARED_STORE_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e\", <NL> \"_TOPOLOGY_TYPE\": \"container-docker-single\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:12:03.181Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-console\": [rtxoialp85.fnc.net.local] 46535 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-debug-ssh\": [rtxoialp85.fnc.net.local] 46534 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True}"}
{"timestamp_utc": "2024-07-31T08:12:03.182Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-cli\": [rtxoialp85.fnc.net.local] 46533 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-cli\": [rtxoialp85.fnc.net.local] 46533 <NL> # 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE1-trib1-console\": [rtxoialp85.fnc.net.local] 46521 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE1-trib1-debug-ssh\": [rtxoialp85.fnc.net.local] 46520 <NL> # 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-console\": [rtxoialp85.fnc.net.local] 46519 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-debug-ssh\": [rtxoialp85.fnc.net.local] 46518 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-cli\": [rtxoialp85.fnc.net.local] 46517 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-cli\": [rtxoialp85.fnc.net.local] 46517 <NL> # 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE2-trib1-console\": [rtxoialp85.fnc.net.local] 46505 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE2-trib1-debug-ssh\": [rtxoialp85.fnc.net.local] 46504 <NL> # 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-console\": [rtxoialp85.fnc.net.local] 46503 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-debug-ssh\": [rtxoialp85.fnc.net.local] 46502"}
{"timestamp_utc": "2024-07-31T08:12:03.183Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-cli\": [rtxoialp85.fnc.net.local] 46501 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-cli\": [rtxoialp85.fnc.net.local] 46501 <NL> # 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE3-trib1-console\": [rtxoialp85.fnc.net.local] 46489 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE3-trib1-debug-ssh\": [rtxoialp85.fnc.net.local] 46488 <NL> # 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-console\": [rtxoialp85.fnc.net.local] 46487 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-debug-ssh\": [rtxoialp85.fnc.net.local] 46486 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-cli\": [rtxoialp85.fnc.net.local] 46485 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-cli\": [rtxoialp85.fnc.net.local] 46485 <NL> # 03:12:03 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE4-trib1-console\": [rtxoialp85.fnc.net.local] 46473 <NL> # 03:12:03 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:03 ntp-wait-for-devices INFO: main:     take job_name \"NE4-trib1-debug-ssh\": [rtxoialp85.fnc.net.local] 46472 <NL> pip3-virtualenv-install-and-execute-cmd: installing into VIRTUALENV_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\" <NL> pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"venv\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\""}
{"timestamp_utc": "2024-07-31T08:12:07.346Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"ensurepip\""}
{"timestamp_utc": "2024-07-31T08:12:09.234Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Requirement already satisfied: setuptools in ./.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib/python3.6/site-packages <NL> Requirement already satisfied: pip in ./.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib/python3.6/site-packages <NL> pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"pip\" \"install\" \"--upgrade\" \"pip\""}
{"timestamp_utc": "2024-07-31T08:12:10.160Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Collecting pip"}
{"timestamp_utc": "2024-07-31T08:12:10.417Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hInstalling collected packages: pip <NL> Found existing installation: pip 9.0.3"}
{"timestamp_utc": "2024-07-31T08:12:10.980Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Uninstalling pip-9.0.3:"}
{"timestamp_utc": "2024-07-31T08:12:11.664Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Successfully uninstalled pip-9.0.3"}
{"timestamp_utc": "2024-07-31T08:12:13.053Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Successfully installed pip-21.3.1 <NL> \u001b[33mYou are using pip version 21.3.1, however version 24.2 is available. <NL> You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m"}
{"timestamp_utc": "2024-07-31T08:12:13.308Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"pip\" \"install\" \"paramiko\""}
{"timestamp_utc": "2024-07-31T08:12:13.867Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Looking in indexes: https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/simple"}
{"timestamp_utc": "2024-07-31T08:12:14.426Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Collecting paramiko <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/ad/50/8792484502c8141c20c996b802fefa8435a9c018a2bb440a06b172782118/paramiko-3.4.0-py3-none-any.whl (225 kB)"}
{"timestamp_utc": "2024-07-31T08:12:15.790Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\u001b[?25hCollecting cryptography>=3.3"}
{"timestamp_utc": "2024-07-31T08:12:15.793Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\u001b[?25hCollecting pynacl>=1.5"}
{"timestamp_utc": "2024-07-31T08:12:16.306Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hCollecting bcrypt>=3.2 <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/aa/48/fd2b197a9741fa790ba0b88a9b10b5e88e62ff5cf3e1bc96d8354d7ce613/bcrypt-4.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (593 kB)"}
{"timestamp_utc": "2024-07-31T08:12:17.235Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hCollecting cffi>=1.12 <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/3a/12/d6066828014b9ccb2bbb8e1d9dc28872d20669b65aeb4a86806a0757813f/cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB) <NL> \u001b[?25hCollecting pycparser <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/62/d5/5f610ebe421e85889f2e55e33b7f9a6795bd982198517d912eb1c76e1a53/pycparser-2.21-py2.py3-none-any.whl (118 kB)"}
{"timestamp_utc": "2024-07-31T08:12:17.491Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hInstalling collected packages: pycparser, cffi, pynacl, cryptography, bcrypt, paramiko"}
{"timestamp_utc": "2024-07-31T08:12:18.417Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Successfully installed bcrypt-4.0.1 cffi-1.15.1 cryptography-40.0.2 paramiko-3.4.0 pycparser-2.21 pynacl-1.5.0"}
{"timestamp_utc": "2024-07-31T08:12:18.979Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: execute: \"exec-job-tree --timeout 28800 --job-begin-parallel --name all (p) --job-begin-command --name NE1-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46535 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE1-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46521 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE2-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46519 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE2-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46505 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE3-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46503 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE3-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46489 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE4-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46487 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE4-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp85.fnc.net.local --port 46473 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-serial --name start+user (s) --parallel-siblings-terminate-on-my-completion --job-begin-parallel --name startup (p) --timeout 1200 --job-begin-serial --name main-startup (s) --job-begin-command --name NE1-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46534 --delay 5 --cmd-end --job-end --job-begin-command --name NE1-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46533 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE1-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46520 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE2-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46518 --delay 5 --cmd-end --job-end --job-begin-command --name NE2-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46517 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE2-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46504 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE3-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46502 --delay 5 --cmd-end --job-end --job-begin-command --name NE3-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46501 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE3-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46488 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE4-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46486 --delay 5 --cmd-end --job-end --job-begin-command --name NE4-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46485 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE4-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp85.fnc.net.local --port 46472 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name Warrior --cmd-begin run_init --runinit_venv_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir --services_env /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json --work_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155 -v -e warrior --test_engine_venv_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir --test_engine /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json --cmd-end --job-end --job-end --job-end\""}
{"timestamp_utc": "2024-07-31T08:12:18.980Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"exec-job-tree\" \"--timeout\" \"28800\" \"--job-begin-parallel\" \"--name\" \"all (p)\" \"--job-begin-command\" \"--name\" \"NE1-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46535\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46521\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46519\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46505\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46503\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46489\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46487\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46473\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"start+user (s)\" \"--parallel-siblings-terminate-on-my-completion\" \"--job-begin-parallel\" \"--name\" \"startup (p)\" \"--timeout\" \"1200\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE1-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46534\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46533\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46520\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE2-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46518\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46517\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46504\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE3-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46502\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46501\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46488\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE4-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46486\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46485\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46472\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"Warrior\" \"--cmd-begin\" \"run_init\" \"--runinit_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\" \"--services_env\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json\" \"--work_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155\" \"-v\" \"-e\" \"warrior\" \"--test_engine_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\" \"--test_engine\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 0) arg timeout=\"28800\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 0) \"--job-begin-parallel\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   arg name=\"all (p)\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE1-main-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46535', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE1-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46521', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE2-main-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46519', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE2-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46505', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE3-main-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46503', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE3-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46489', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE4-main-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46487', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE4-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46473', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-serial\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"start+user (s)\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-begin-parallel\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       arg name=\"startup (p)\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       arg timeout=\"1200\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE1-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46534', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE1-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46533', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE1-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46520', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\""}
{"timestamp_utc": "2024-07-31T08:12:18.981Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE2-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46518', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE2-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46517', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE2-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46504', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE3-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46502', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE3-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46501', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE3-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46488', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE4-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46486', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE4-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46485', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE4-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46472', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-begin-command\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       arg name=\"Warrior\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       command ['run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json'] <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-end\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 0){ <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 0)  type \"none\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 0)  name \"none\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 0)  child_index None <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 0)  option \"timeout\" = \"28800\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 1)  { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 1)    type \"parallel\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 1)    name \"n01.all (p)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 1)    child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 1)    option \"name\" = \"all (p)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p01.NE1-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE1-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46535', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p02.NE1-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 1 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE1-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46521', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p03.NE2-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 2 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE2-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46519', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p04.NE2-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 3 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE2-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46505', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p05.NE3-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 4 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE3-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46503', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p06.NE3-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 5 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE3-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46489', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p07.NE4-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 6 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE4-main-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46487', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p08.NE4-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 7"}
{"timestamp_utc": "2024-07-31T08:12:18.982Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE4-trib1-console\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46473', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      type \"serial\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p09.start+user (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 8 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"start+user (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)      { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        type \"parallel\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        name \"n01.p09.s01.startup (p)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        option \"name\" = \"startup (p)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        option \"timeout\" = \"1200\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p01.main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE1-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46534', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p01.s02.NE1-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE1-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46533', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 1 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE1-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46520', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p03.main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 2 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE2-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46518', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p03.s02.NE2-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE2-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46517', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 3 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE2-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46504', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p05.main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 4 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE3-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46502', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p05.s02.NE3-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE3-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46501', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 5 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE3-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46488', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p07.main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 6 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE4-main-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46486', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p07.s02.NE4-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE4-main-cli\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46485', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 7 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE4-trib1-debug-ssh\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46472', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)      } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)      { <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        type \"command\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        name \"n01.p09.s02.Warrior\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        child_index 1 <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        option \"name\" = \"Warrior\" <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)        command ['run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 3)      } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 1)  } <NL> # 03:12:18 exec-job-tree INFO: job_cl::show: ##( 0)} <NL> # 03:12:18 exec-job-tree INFO: process_list_cl::__enter__"}
{"timestamp_utc": "2024-07-31T08:12:18.983Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46535', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p01.NE1-main-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p01.NE1-main-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46535', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p01.NE1-main-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46521', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p02.NE1-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p02.NE1-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46521', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p02.NE1-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46519', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p03.NE2-main-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p03.NE2-main-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46519', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p03.NE2-main-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46505', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p04.NE2-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p04.NE2-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46505', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p04.NE2-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46503', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p05.NE3-main-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p05.NE3-main-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46503', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p05.NE3-main-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46489', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p06.NE3-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p06.NE3-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46489', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p06.NE3-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46487', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p07.NE4-main-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p07.NE4-main-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46487', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p07.NE4-main-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46473', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p08.NE4-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p08.NE4-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp85.fnc.net.local', '--port', '46473', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p08.NE4-trib1-console) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46534', '--delay', '5'] (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46534', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46520', '--delay', '5'] (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46520', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46518', '--delay', '5'] (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46518', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46504', '--delay', '5'] (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46504', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46502', '--delay', '5'] (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46502', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46488', '--delay', '5'] (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46488', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46486', '--delay', '5'] (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46486', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46472', '--delay', '5'] (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46472', '--delay', '5'] <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 3)        (executing) type \"parallel\": started 8 children (n01.p09.s01.startup (p)) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"serial\": started child #0 (n01.p09.start+user (s)) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 1)    (executing) type \"parallel\": started 9 children (n01.all (p)) <NL> # 03:12:18 exec-job-tree INFO: job_cl::start:  ( 0)  (executing) type \"none\": started child #0 (none)"}
{"timestamp_utc": "2024-07-31T08:12:19.241Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "# 03:12:18 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p01.NE1-main-console\", type \"command\" <NL> # 03:12:18 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p02.NE1-trib1-console\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p03.NE2-main-console\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p04.NE2-trib1-console\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p05.NE3-main-console\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p06.NE3-trib1-console\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p07.NE4-main-console\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p08.NE4-trib1-console\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.main-startup (s)\", type \"serial\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.main-startup (s)\", type \"serial\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.main-startup (s)\", type \"serial\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.main-startup (s)\", type \"serial\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"command\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.startup (p)\", type \"parallel\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.start+user (s)\", type \"serial\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.all (p)\", type \"parallel\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"none\", type \"none\" <NL> # 03:12:19 exec-job-tree INFO: process_list_cl::wait: begin, timeout 28800.0 <NL> (process:677): GLib-WARNING **: 03:12:01.034: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980"}
{"timestamp_utc": "2024-07-31T08:12:19.242Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80 <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr b7854001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 4195097593 cycles <NL> [    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000023] tsc: Detected 2793.436 MHz processor <NL> [    0.001307] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.001383] x86/PAT: PAT not supported by the CPU. <NL> [    0.001392] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.001405] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.051013] found SMP MP-table at [mem 0x000f6340-0x000f634f] <NL> [    0.051145] check: Scanning 1 areas for low memory corruption <NL> [    0.052400] ACPI: Early table checksum verification disabled <NL> [    0.052443] ACPI: RSDP 0x00000000000F6110 000014 (v00 BOCHS ) <NL> [    0.052453] ACPI: RSDT 0x00000000BFFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.052469] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.052479] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.052485] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.052489] ACPI: SSDT 0x00000000BFFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.052493] ACPI: APIC 0x00000000BFFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.052498] ACPI: HPET 0x00000000BFFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.052502] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.052504] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.052505] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.052506] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffc33] <NL> [    0.052507] ACPI: Reserving APIC table memory at [mem 0xbffffc34-0xbffffcc3] <NL> [    0.052509] ACPI: Reserving HPET table memory at [mem 0xbffffcc4-0xbffffcfb] <NL> [    0.067547] Zone ranges: <NL> [    0.067563]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.067567]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.067570]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.067573] Movable zone start for each node <NL> [    0.067574] Early memory node ranges <NL> [    0.067576]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.067578]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.067580]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.067583] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.068500] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.068527] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.270126] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.270639] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.270661] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])"}
{"timestamp_utc": "2024-07-31T08:12:19.243Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    0.270707] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.270712] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.270716] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.270718] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.270729] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.270731] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.270741] Using ACPI (MADT) for SMP configuration information <NL> [    0.270744] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.270754] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.270795] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.270798] Booting paravirtualized kernel on KVM <NL> [    0.270836] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.270853] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.272064] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.272110] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.272120] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.272124] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.277532] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.278324] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.278430] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.443509] Memory: 4026256K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 167380K reserved, 0K cma-reserved) <NL> [    0.443588] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.443600] Kernel/User page tables isolation: enabled <NL> [    0.443634] ftrace: allocating 47967 entries in 188 pages <NL> [    0.708946] ftrace: allocated 188 pages with 5 groups <NL> [    0.709601] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.709603] rcu: \tRCU event tracing is enabled. <NL> [    0.709605] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.709608] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.709609] \tRude variant of Tasks RCU enabled. <NL> [    0.709610] \tTracing variant of Tasks RCU enabled. <NL> [    0.709612] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.709614] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.734183] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.779344] Console: colour VGA+ 80x25 <NL> [    1.207073] printk: console [ttyS0] enabled <NL> [    1.207504] ACPI: Core revision 20200925 <NL> [    1.208105] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    1.220213] APIC: Switch to symmetric I/O mode setup <NL> [    1.220968] x2apic enabled <NL> [    1.221576] Switched APIC routing to physical x2apic. <NL> [    1.223500] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    1.233693] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    1.234787] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    1.235906] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    1.236787] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    1.237796] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    1.238793] Spectre V2 : Mitigation: Retpolines <NL> [    1.239787] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    1.240789] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    1.241796] Speculative Store Bypass: Vulnerable <NL> [    1.242793] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    1.243787] MMIO Stale Data: Unknown: No mitigations <NL> [    1.244793] x86/fpu: x87 FPU will use FXSAVE <NL> [    1.284809] Freeing SMP alternatives memory: 48K <NL> [    1.285799] pid_max: default: 32768 minimum: 301 <NL> [    1.286822] LSM: Security Framework initializing <NL> [    1.288309] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.288815] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.324825] APIC calibration not consistent with PM-Timer: 92ms instead of 100ms <NL> [    1.325784] APIC delta adjusted to PM-Timer: 6250610 (5800648) <NL> [    1.325844] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    1.327099] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    1.328921] rcu: Hierarchical SRCU implementation. <NL> [    1.330105] smp: Bringing up secondary CPUs ... <NL> [    1.330965] x86: Booting SMP configuration: <NL> [    1.331528] .... node  #0, CPUs:      #1 <NL> [    0.489277] kvm-clock: cpu 1, msr b7854041, secondary cpu clock <NL> [    0.489277] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    1.340877] kvm-guest: stealtime: cpu 1, msr 13bc9b600 <NL> [    1.342024]  #2 <NL> [    0.489277] kvm-clock: cpu 2, msr b7854081, secondary cpu clock <NL> [    0.489277] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    1.353886] kvm-guest: stealtime: cpu 2, msr 13bd1b600 <NL> [    1.362042]  #3 <NL> [    0.489277] kvm-clock: cpu 3, msr b78540c1, secondary cpu clock <NL> [    0.489277] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    1.366867] kvm-guest: stealtime: cpu 3, msr 13bd9b600 <NL> [    1.373819] smp: Brought up 1 node, 4 CPUs <NL> [    1.374219] smpboot: Max logical packages: 4 <NL> [    1.374803] smpboot: Total of 4 processors activated (22347.48 BogoMIPS) <NL> [    1.397791] devtmpfs: initialized <NL> [    1.399950] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.400796] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    1.401789] pinctrl core: initialized pinctrl subsystem <NL> [    1.406455] NET: Registered protocol family 16 <NL> [    1.407092] thermal_sys: Registered thermal governor 'step_wise'"}
{"timestamp_utc": "2024-07-31T08:12:19.244Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    1.407094] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.409814] cpuidle: using governor menu <NL> [    1.411880] ACPI: bus type PCI registered <NL> [    1.412915] PCI: Using configuration type 1 for base access <NL> [    1.417516] Kprobes globally optimized <NL> [    1.542796] raid6: sse2x4   gen()  6224 MB/s <NL> [    1.560792] raid6: sse2x4   xor()  3952 MB/s <NL> [    1.578791] raid6: sse2x2   gen()  6309 MB/s <NL> [    1.596791] raid6: sse2x2   xor()  4007 MB/s <NL> [    1.614791] raid6: sse2x1   gen()  4444 MB/s <NL> [    1.632791] raid6: sse2x1   xor()  3509 MB/s <NL> [    1.634797] raid6: using algorithm sse2x2 gen() 6309 MB/s <NL> [    1.635800] raid6: .... xor() 4007 MB/s, rmw enabled <NL> [    1.636797] raid6: using intx1 recovery algorithm <NL> [    1.637890] ACPI: Added _OSI(Module Device) <NL> [    1.638797] ACPI: Added _OSI(Processor Device) <NL> [    1.639795] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.640795] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.641794] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.642791] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.643793] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.648404] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.651856] ACPI: Interpreter enabled <NL> [    1.652943] ACPI: (supports S0 S3 S5) <NL> [    1.653789] ACPI: Using IOAPIC for interrupt routing <NL> [    1.654825] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.657365] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.665966] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.667994] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.668819] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.670948] PCI host bridge to bus 0000:00 <NL> [    1.671798] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.672796] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.673793] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.674790] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.675796] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.676792] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.677791] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    1.678794] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.679851] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.683016] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.685352] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.690796] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    1.694268] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.694895] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.695799] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.696792] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.698986] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.700789] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.701805] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.703179] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.705846] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.709859] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    1.722844] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    1.726791] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.729795] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    1.732795] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.742795] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    1.745205] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.747792] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    1.749795] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.759794] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    1.761146] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.763793] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.766794] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.777810] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    1.779118] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.781825] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.784561] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.792799] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    1.794131] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    1.796796] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.799804] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    1.810795] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.812138] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    1.814794] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.817794] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    1.827584] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.828278] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    1.831582] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    1.833797] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    1.844566] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.845252] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.847796] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    1.851695] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    1.861949] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.862912] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11)"}
{"timestamp_utc": "2024-07-31T08:12:19.245Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    1.863956] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.864937] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.865904] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.869846] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.870784] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.870795] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.871791] vgaarb: loaded <NL> [    1.872411] SCSI subsystem initialized <NL> [    1.875903] ACPI: bus type USB registered <NL> [    1.876849] usbcore: registered new interface driver usbfs <NL> [    1.877823] usbcore: registered new interface driver hub <NL> [    1.878814] usbcore: registered new device driver usb <NL> [    1.879831] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.880789] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.881807] PTP clock support registered <NL> [    1.885345] Bluetooth: Core ver 2.22 <NL> [    1.885803] NET: Registered protocol family 31 <NL> [    1.886437] Bluetooth: HCI device and connection manager initialized <NL> [    1.886798] Bluetooth: HCI socket layer initialized <NL> [    1.887790] Bluetooth: L2CAP socket layer initialized <NL> [    1.888796] Bluetooth: SCO socket layer initialized <NL> [    1.889842] PCI: Using ACPI for IRQ routing <NL> [    1.890653] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.890815] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.891789] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.898171] clocksource: Switched to clocksource kvm-clock <NL> [    2.485801] pnp: PnP ACPI init <NL> [    2.489707] pnp: PnP ACPI: found 7 devices <NL> [    2.546270] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.576438] NET: Registered protocol family 2 <NL> [    2.577268] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    2.585394] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    2.587002] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    2.597688] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    2.639663] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    2.641954] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.653150] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.654831] NET: Registered protocol family 1 <NL> [    2.705128] RPC: Registered named UNIX socket transport module. <NL> [    2.751236] RPC: Registered udp transport module. <NL> [    2.751723] RPC: Registered tcp transport module. <NL> [    2.752165] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.752803] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.753424] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.754013] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.754644] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.780168] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.782845] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.803789] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    2.828005] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.836920] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.837782] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.838699] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.839920] PCI: CLS 0 bytes, default 64 <NL> [    2.840575] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    2.917044] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    2.927024] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    2.993672] check: Scanning for low memory corruption every 60 seconds <NL> [    3.004682] Initialise system trusted keyrings <NL> [    3.010498] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    3.025648] NFS: Registering the id_resolver key type <NL> [    3.026994] Key type id_resolver registered <NL> [    3.028008] Key type id_legacy registered <NL> [    3.060299] Key type cifs.idmap registered <NL> [    3.063416] 9p: Installing v9fs 9p2000 file system support <NL> [    3.065397] xor: measuring software checksum speed <NL> [    3.067646]    prefetch64-sse  : 14288 MB/sec <NL> [    3.070937]    generic_sse     : 13034 MB/sec <NL> [    3.081628] xor: using function: prefetch64-sse (14288 MB/sec) <NL> [    3.083878] Key type asymmetric registered <NL> [    3.085345] Asymmetric key parser 'x509' registered <NL> [    3.087194] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    3.116324] io scheduler mq-deadline registered <NL> [    3.117987] io scheduler kyber registered <NL> [    3.120786] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    3.130830] ACPI: Power Button [PWRF] <NL> [    3.148706] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    3.150220] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    3.152987] N_HDLC line discipline registered with maxframe=4096 <NL> [    3.160277] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    3.161894] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    3.168309] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    3.169513] Linux agpgart interface v0.103 <NL> [    3.171306] ACPI: bus type drm_connector registered <NL> [    3.179655] brd: module loaded <NL> [    3.183767] loop: module loaded <NL> [    3.190654] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    3.196808] vda: detected capacity change from 0 to 2576215040 <NL> [    3.206531] Uniform Multi-Platform E-IDE driver"}
{"timestamp_utc": "2024-07-31T08:12:19.246Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    3.208427] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    3.211362] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    3.213537] legacy IDE will be removed in 2021, please switch to libata <NL> [    3.213537] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    3.215436]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    3.240162]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    4.505197] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    5.144496] hdc: MWDMA2 mode selected <NL> [    5.147697] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    5.151197] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    5.163265] ide-gd driver 1.18 <NL> [    5.209205] e100: Intel(R) PRO/100 Network Driver <NL> [    5.213205] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    5.216799] e1000: Intel(R) PRO/1000 Network Driver <NL> [    5.227888] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.232566] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    6.039324] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    6.053119] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    6.063420] PCI Interrupt Link [LNKD] enabled at IRQ 11"}
{"timestamp_utc": "2024-07-31T08:12:19.509Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    7.105263] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:06 <NL> [    7.105925] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    7.107093] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    7.828876] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:05 <NL> [    7.830590] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    8.268789] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:03 <NL> [    8.281467] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    9.061116] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:04"}
{"timestamp_utc": "2024-07-31T08:12:19.510Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    9.065043] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    9.815270] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:02 <NL> [    9.817914] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [   11.058961] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:07 <NL> [   11.059669] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [   11.077009] e1000e: Intel(R) PRO/1000 Network Driver <NL> [   11.077517] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [   11.078120] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [   11.078652] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [   11.079230] PPP generic driver version 2.4.2 <NL> [   11.079827] PPP BSD Compression module registered <NL> [   11.098392] PPP Deflate Compression module registered <NL> [   11.098898] NET: Registered protocol family 24 <NL> [   11.099381] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [   11.100279] CSLIP: code copyright 1989 Regents of the University of California. <NL> [   11.100993] SLIP linefill/keepalive option. <NL> [   11.101447] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [   11.109113] ehci-pci: EHCI PCI platform driver <NL> [   11.109611] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [   11.110208] ohci-pci: OHCI PCI platform driver <NL> [   11.110651] uhci_hcd: USB Universal Host Controller Interface driver <NL> [   11.111367] usbcore: registered new interface driver usb-storage <NL> [   11.111991] usbcore: registered new interface driver usbserial_generic <NL> [   11.112646] usbserial: USB Serial support registered for generic <NL> [   11.119876] usbcore: registered new interface driver ftdi_sio <NL> [   11.121306] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [   11.123044] usbcore: registered new interface driver pl2303 <NL> [   11.123618] usbserial: USB Serial support registered for pl2303 <NL> [   11.129425] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [   11.130936] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [   11.131499] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [   11.132095] mousedev: PS/2 mouse device common for all mice <NL> [   11.176107] rtc_cmos 00:00: RTC can wake from S4 <NL> [   11.177702] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [   11.179114] rtc_cmos 00:00: registered as rtc0 <NL> [   11.185140] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:17 UTC (1722413537) <NL> [   11.187299] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [   11.198633] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [   11.200614] intel_pstate: CPU model not supported <NL> [   11.201202] sdhci: Secure Digital Host Controller Interface driver <NL> [   11.201846] sdhci: Copyright(c) Pierre Ossman <NL> [   11.202354] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [   11.203084] usbcore: registered new interface driver usbhid <NL> [   11.203665] usbhid: USB HID core driver <NL> [   11.204144] u32 classifier <NL> [   11.204443]     input device check on <NL> [   11.204797]     Actions configured <NL> [   11.222434] xt_time: kernel timezone is -0000 <NL> [   11.223028] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [   11.223763] gre: GRE over IPv4 demultiplexor driver <NL> [   11.224260] ip_gre: GRE over IPv4 tunneling driver <NL> [   11.225119] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [   11.232435] NET: Registered protocol family 10 <NL> [   11.249846] Segment Routing with IPv6 <NL> [   11.251067] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [   11.252929] ip6_gre: GRE over IPv6 tunneling driver <NL> [   11.254353] NET: Registered protocol family 17 <NL> [   11.255490] Bridge firewalling registered <NL> [   11.256614] 8021q: 802.1Q VLAN Support v1.8 <NL> [   11.257714] 9pnet: Installing 9P2000 support <NL> [   11.259553] Key type dns_resolver registered <NL> [   11.260087] NET: Registered protocol family 40 <NL> [   11.264603] IPI shorthand broadcast: enabled <NL> [   11.265084] sched_clock: Marking stable (10776045334, 488277529)->(12634773083, -1370450220) <NL> [   11.272594] registered taskstats version 1 <NL> [   11.273046] Loading compiled-in X.509 certificates <NL> [   11.292099] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [   11.293226] Key type .fscrypt registered <NL> [   11.295718] Key type fscrypt-provisioning registered <NL> [   11.303363] Btrfs loaded, crc32c=crc32c-generic <NL> [   11.316400] Key type encrypted registered <NL> [   11.317049] printk: console [netcon0] enabled <NL> [   11.318552] netconsole: network logging started <NL> [   11.804842] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   11.815344] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   11.848778] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   11.858960] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   11.870677] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   11.881057] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   11.891828] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   11.902354] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> # 03:12:18 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46535; retry every 5 seconds, waiting forever <NL> # 03:12:18 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46535 <NL> # 03:12:18 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46521; retry every 5 seconds, waiting forever <NL> # 03:12:18 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46521 <NL> (process:691): GLib-WARNING **: 03:12:01.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)..."}
{"timestamp_utc": "2024-07-31T08:12:19.511Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80 <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 102c54001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 2481727221 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000019] tsc: Detected 2793.436 MHz processor <NL> [    0.007369] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.007451] x86/PAT: PAT not supported by the CPU. <NL> [    0.007460] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.007476] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.027030] found SMP MP-table at [mem 0x000f6340-0x000f634f] <NL> [    0.027165] check: Scanning 1 areas for low memory corruption <NL> [    0.027417] ACPI: Early table checksum verification disabled <NL> [    0.027446] ACPI: RSDP 0x00000000000F6110 000014 (v00 BOCHS ) <NL> [    0.027459] ACPI: RSDT 0x00000000BFFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.027476] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.027485] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.027491] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.027496] ACPI: SSDT 0x00000000BFFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.027502] ACPI: APIC 0x00000000BFFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.027508] ACPI: HPET 0x00000000BFFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.027513] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.027515] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.027517] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.027519] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffc33] <NL> [    0.027521] ACPI: Reserving APIC table memory at [mem 0xbffffc34-0xbffffcc3] <NL> [    0.027522] ACPI: Reserving HPET table memory at [mem 0xbffffcc4-0xbffffcfb] <NL> [    0.028474] Zone ranges: <NL> [    0.028477]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.028480]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.028482]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.028485] Movable zone start for each node <NL> [    0.028486] Early memory node ranges <NL> [    0.028488]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.028491]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.028492]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.028495] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.029780] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.029806] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.115771] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.116309] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.116330] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.116374] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.116379] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.116383] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.116384] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.116394] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.116396] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.116405] Using ACPI (MADT) for SMP configuration information"}
{"timestamp_utc": "2024-07-31T08:12:19.512Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    0.116408] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.116419] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.116461] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.116463] Booting paravirtualized kernel on KVM <NL> [    0.116469] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.116485] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.117723] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.117771] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.117782] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.117785] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.126001] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.126955] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.127057] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.243991] Memory: 4026268K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 167368K reserved, 0K cma-reserved) <NL> [    0.244081] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.244094] Kernel/User page tables isolation: enabled <NL> [    0.244137] ftrace: allocating 47967 entries in 188 pages <NL> [    0.351160] ftrace: allocated 188 pages with 5 groups <NL> [    0.352243] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.352246] rcu: \tRCU event tracing is enabled. <NL> [    0.352248] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.352251] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.352252] \tRude variant of Tasks RCU enabled. <NL> [    0.352254] \tTracing variant of Tasks RCU enabled. <NL> [    0.352256] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.352258] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.361586] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.380651] Console: colour VGA+ 80x25 <NL> [    0.553915] printk: console [ttyS0] enabled <NL> [    0.554350] ACPI: Core revision 20200925 <NL> [    0.554937] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.555955] APIC: Switch to symmetric I/O mode setup <NL> [    0.566963] x2apic enabled <NL> [    0.567543] Switched APIC routing to physical x2apic. <NL> [    0.569386] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.570005] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    0.582644] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    0.583776] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.584642] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.585206] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.585644] Spectre V2 : Mitigation: Retpolines <NL> [    0.586641] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.587641] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.588308] Speculative Store Bypass: Vulnerable <NL> [    0.588643] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.589265] MMIO Stale Data: Unknown: No mitigations <NL> [    0.589658] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.620639] Freeing SMP alternatives memory: 48K <NL> [    0.620639] pid_max: default: 32768 minimum: 301 <NL> [    0.620639] LSM: Security Framework initializing <NL> [    0.620681] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.621673] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.663114] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.664004] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.666818] rcu: Hierarchical SRCU implementation. <NL> [    0.668020] smp: Bringing up secondary CPUs ... <NL> [    0.668845] x86: Booting SMP configuration: <NL> [    0.669643] .... node  #0, CPUs:      #1 <NL> [    0.211299] kvm-clock: cpu 1, msr 102c54041, secondary cpu clock <NL> [    0.211299] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.676685] kvm-guest: stealtime: cpu 1, msr 13bc9b600 <NL> [    0.678659]  #2 <NL> [    0.211299] kvm-clock: cpu 2, msr 102c54081, secondary cpu clock <NL> [    0.211299] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.686729] kvm-guest: stealtime: cpu 2, msr 13bd1b600 <NL> [    0.687728]  #3 <NL> [    0.211299] kvm-clock: cpu 3, msr 102c540c1, secondary cpu clock <NL> [    0.211299] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.692698] kvm-guest: stealtime: cpu 3, msr 13bd9b600 <NL> [    0.693661] smp: Brought up 1 node, 4 CPUs <NL> [    0.694660] smpboot: Max logical packages: 4 <NL> [    0.695077] smpboot: Total of 4 processors activated (22347.48 BogoMIPS) <NL> [    0.698109] devtmpfs: initialized <NL> [    0.704713] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.705653] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.706754] pinctrl core: initialized pinctrl subsystem <NL> [    0.712732] NET: Registered protocol family 16 <NL> [    0.714707] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.714709] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.715750] cpuidle: using governor menu <NL> [    0.717128] ACPI: bus type PCI registered <NL> [    0.717781] PCI: Using configuration type 1 for base access <NL> [    0.723187] Kprobes globally optimized <NL> [    0.885651] raid6: sse2x4   gen()  4836 MB/s <NL> [    0.902664] raid6: sse2x4   xor()  2827 MB/s <NL> [    0.921639] raid6: sse2x2   gen()  4766 MB/s <NL> [    0.939651] raid6: sse2x2   xor()  3684 MB/s <NL> [    0.957662] raid6: sse2x1   gen()  3861 MB/s <NL> [    0.975650] raid6: sse2x1   xor()  2949 MB/s"}
{"timestamp_utc": "2024-07-31T08:12:19.513Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    0.976654] raid6: using algorithm sse2x4 gen() 4836 MB/s <NL> [    0.977650] raid6: .... xor() 2827 MB/s, rmw enabled <NL> [    0.978652] raid6: using intx1 recovery algorithm <NL> [    0.979770] ACPI: Added _OSI(Module Device) <NL> [    0.980653] ACPI: Added _OSI(Processor Device) <NL> [    0.981652] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.982653] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.983656] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.984654] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.985649] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.990311] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.993121] ACPI: Interpreter enabled <NL> [    0.993682] ACPI: (supports S0 S3 S5) <NL> [    0.994648] ACPI: Using IOAPIC for interrupt routing <NL> [    0.995695] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.997921] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.005189] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.005677] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.006687] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.008752] PCI host bridge to bus 0000:00 <NL> [    1.009659] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.010654] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.011650] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.012659] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.013316] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.013662] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.014392] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    1.014661] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.015250] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.017136] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.018349] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.026360] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    1.028673] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.029659] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.030660] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.031325] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.033062] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.034056] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.034680] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.037123] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.040660] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.043710] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    1.054701] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    1.056896] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.059354] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    1.061653] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.069654] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    1.070993] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.074291] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    1.076660] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.084653] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    1.086944] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.089653] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.092675] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.100655] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    1.101993] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.104659] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.106647] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.114667] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    1.115971] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    1.118658] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.120645] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    1.128652] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.129975] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    1.131650] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.134304] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    1.141653] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.142975] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    1.145651] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    1.148300] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    1.156291] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.157863] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.160649] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    1.163306] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    1.172611] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.172826] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.173823] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.175835] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.176782] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.178944] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.179639] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.179671] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.180646] vgaarb: loaded <NL> [    1.183379] SCSI subsystem initialized <NL> [    1.187677] ACPI: bus type USB registered <NL> [    1.188232] usbcore: registered new interface driver usbfs <NL> [    1.188661] usbcore: registered new interface driver hub <NL> [    1.189190] usbcore: registered new device driver usb"}
{"timestamp_utc": "2024-07-31T08:12:19.514Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    1.189668] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.190151] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.190667] PTP clock support registered <NL> [    1.194190] Bluetooth: Core ver 2.22 <NL> [    1.194668] NET: Registered protocol family 31 <NL> [    1.195644] Bluetooth: HCI device and connection manager initialized <NL> [    1.196655] Bluetooth: HCI socket layer initialized <NL> [    1.197649] Bluetooth: L2CAP socket layer initialized <NL> [    1.198691] Bluetooth: SCO socket layer initialized <NL> [    1.200721] PCI: Using ACPI for IRQ routing <NL> [    1.201982] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.202672] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.203644] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.216378] clocksource: Switched to clocksource kvm-clock <NL> [    1.500963] pnp: PnP ACPI init <NL> [    1.510470] pnp: PnP ACPI: found 7 devices <NL> [    1.558090] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.570415] NET: Registered protocol family 2 <NL> [    1.581789] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    1.602993] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    1.664844] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    1.678187] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    1.686636] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    1.687412] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    1.688054] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    1.688835] NET: Registered protocol family 1 <NL> [    1.724582] RPC: Registered named UNIX socket transport module. <NL> [    1.734953] RPC: Registered udp transport module. <NL> [    1.741441] RPC: Registered tcp transport module. <NL> [    1.741897] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    1.746801] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.747387] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.747977] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.748584] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.749161] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.749730] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.775725] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    1.784298] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.784871] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.785454] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.786059] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.786939] PCI: CLS 0 bytes, default 64 <NL> [    1.787446] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    1.788066] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    1.788939] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    1.873893] check: Scanning for low memory corruption every 60 seconds <NL> [    1.876916] Initialise system trusted keyrings <NL> [    1.887746] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    1.919365] NFS: Registering the id_resolver key type <NL> [    1.928895] Key type id_resolver registered <NL> [    1.930604] Key type id_legacy registered <NL> [    1.984246] Key type cifs.idmap registered <NL> [    1.986685] 9p: Installing v9fs 9p2000 file system support <NL> [    1.988820] xor: measuring software checksum speed <NL> [    1.997768]    prefetch64-sse  : 14165 MB/sec <NL> [    2.004150]    generic_sse     : 12114 MB/sec <NL> [    2.013331] xor: using function: prefetch64-sse (14165 MB/sec) <NL> [    2.015589] Key type asymmetric registered <NL> [    2.023287] Asymmetric key parser 'x509' registered <NL> [    2.025117] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.072222] io scheduler mq-deadline registered <NL> [    2.074186] io scheduler kyber registered <NL> [    2.086179] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.108411] ACPI: Power Button [PWRF] <NL> [    2.129655] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    2.142236] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    2.153131] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.159701] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.163212] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.168095] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.172836] Linux agpgart interface v0.103 <NL> [    2.175644] ACPI: bus type drm_connector registered <NL> [    2.202103] brd: module loaded <NL> [    2.206574] loop: module loaded <NL> [    2.215497] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.224595] vda: detected capacity change from 0 to 2576215040 <NL> [    2.271098] Uniform Multi-Platform E-IDE driver <NL> [    2.275619] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00)"}
{"timestamp_utc": "2024-07-31T08:12:19.515Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    2.277563] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.278227] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.278227] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.280100]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    2.286723]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    3.582220] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.214267] hdc: MWDMA2 mode selected <NL> [    4.214851] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.215339] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.215996] ide-gd driver 1.18 <NL> [    4.250643] e100: Intel(R) PRO/100 Network Driver <NL> [    4.254292] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.258833] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.262533] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.268867] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    5.013027] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.017714] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.020588] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    5.381731] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:11 <NL> [    5.382407] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.388676] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    5.768737] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:10 <NL> [    5.773165] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.592007] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:0e <NL> [    6.606226] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    7.421912] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:0f <NL> [    7.426706] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    8.389114] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:0d <NL> [    8.389852] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    9.159497] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:12 <NL> [    9.160196] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    9.161434] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    9.165733] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    9.167221] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    9.168574] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    9.175143] PPP generic driver version 2.4.2 <NL> [    9.176376] PPP BSD Compression module registered <NL> [    9.177404] PPP Deflate Compression module registered <NL> [    9.178935] NET: Registered protocol family 24 <NL> [    9.184606] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    9.188800] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    9.191669] SLIP linefill/keepalive option. <NL> [    9.193211] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    9.193871] ehci-pci: EHCI PCI platform driver <NL> [    9.194424] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    9.195059] ohci-pci: OHCI PCI platform driver <NL> [    9.195519] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    9.196215] usbcore: registered new interface driver usb-storage <NL> [    9.196859] usbcore: registered new interface driver usbserial_generic <NL> [    9.197517] usbserial: USB Serial support registered for generic <NL> [    9.206447] usbcore: registered new interface driver ftdi_sio <NL> [    9.208626] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    9.210852] usbcore: registered new interface driver pl2303 <NL> [    9.212870] usbserial: USB Serial support registered for pl2303 <NL> [    9.215066] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    9.253070] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    9.256272] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    9.257058] mousedev: PS/2 mouse device common for all mice <NL> [    9.271313] rtc_cmos 00:00: RTC can wake from S4 <NL> [    9.299541] rtc_cmos 00:00: registered as rtc0 <NL> [    9.300708] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    9.301735] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:14 UTC (1722413534) <NL> [    9.302690] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    9.309485] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    9.310688] intel_pstate: CPU model not supported <NL> [    9.311207] sdhci: Secure Digital Host Controller Interface driver <NL> [    9.311812] sdhci: Copyright(c) Pierre Ossman <NL> [    9.312323] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    9.313052] usbcore: registered new interface driver usbhid <NL> [    9.313602] usbhid: USB HID core driver <NL> [    9.329161] u32 classifier <NL> [    9.329552]     input device check on <NL> [    9.329914]     Actions configured <NL> [    9.330949] xt_time: kernel timezone is -0000 <NL> [    9.331490] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.332468] gre: GRE over IPv4 demultiplexor driver <NL> [    9.333262] ip_gre: GRE over IPv4 tunneling driver <NL> [    9.334700] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    9.339284] NET: Registered protocol family 10 <NL> [    9.359773] Segment Routing with IPv6 <NL> [    9.364679] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.366121] ip6_gre: GRE over IPv6 tunneling driver <NL> [    9.367079] NET: Registered protocol family 17 <NL> [    9.367812] Bridge firewalling registered <NL> [    9.377393] 8021q: 802.1Q VLAN Support v1.8 <NL> [    9.380513] 9pnet: Installing 9P2000 support <NL> [    9.390811] Key type dns_resolver registered <NL> [    9.399185] NET: Registered protocol family 40 <NL> [    9.412591] IPI shorthand broadcast: enabled <NL> [    9.418280] sched_clock: Marking stable (9207890856, 210299664)->(11002156545, -1583966025) <NL> [    9.438247] registered taskstats version 1 <NL> [    9.438958] Loading compiled-in X.509 certificates <NL> [    9.488706] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870'"}
{"timestamp_utc": "2024-07-31T08:12:19.516Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    9.489788] Key type .fscrypt registered <NL> [    9.490185] Key type fscrypt-provisioning registered <NL> [    9.491408] Btrfs loaded, crc32c=crc32c-generic <NL> [    9.504320] Key type encrypted registered <NL> [    9.505087] printk: console [netcon0] enabled <NL> [    9.510458] netconsole: network logging started <NL> [   10.097952] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   10.375098] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   10.432588] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   10.444134] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   10.471197] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   10.479712] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   10.486166] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   10.517190] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   10.517901] IP-Config: Failed to open gretap0 <NL> [   10.534615] IP-Config: Failed to open erspan0 <NL> [   10.558104] Sending DHCP requests . <NL> # 03:12:18 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46519; retry every 5 seconds, waiting forever <NL> # 03:12:18 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46519 <NL> (process:674): GLib-WARNING **: 03:12:00.929: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 31254001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 3234416363 cycles <NL> [    0.000007] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000017] tsc: Detected 2793.436 MHz processor <NL> [    0.001855] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.001928] x86/PAT: PAT not supported by the CPU. <NL> [    0.001936] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.024553] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.024676] check: Scanning 1 areas for low memory corruption <NL> [    0.025023] ACPI: Early table checksum verification disabled <NL> [    0.025051] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.025062] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.025078] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.025088] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.025094] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.025099] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.025106] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.025111] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.025117] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.025119] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.025121] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.025123] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.025125] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.025127] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.025204] Zone ranges: <NL> [    0.025206]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.025209]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.025212]   Normal   empty <NL> [    0.025214] Movable zone start for each node <NL> [    0.025216] Early memory node ranges <NL> [    0.025218]   node   0: [mem 0x0000000000001000-0x000000000009efff]"}
{"timestamp_utc": "2024-07-31T08:12:19.517Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    0.025220]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.025223] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.034517] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.034546] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.042780] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.043302] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.043323] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.043369] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.043373] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.043377] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.043379] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.043387] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.043389] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.043399] Using ACPI (MADT) for SMP configuration information <NL> [    0.043402] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.043411] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.043449] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.043452] Booting paravirtualized kernel on KVM <NL> [    0.043457] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.043470] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.044602] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.044645] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.044653] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.044657] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.045170] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.045340] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.045425] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.049863] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.049936] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.049947] Kernel/User page tables isolation: enabled <NL> [    0.049981] ftrace: allocating 47967 entries in 188 pages <NL> [    0.130009] ftrace: allocated 188 pages with 5 groups <NL> [    0.273074] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.273080] rcu: \tRCU event tracing is enabled. <NL> [    0.273083] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.273086] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.273088] \tRude variant of Tasks RCU enabled. <NL> [    0.273089] \tTracing variant of Tasks RCU enabled. <NL> [    0.273091] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.273093] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.304796] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.319719] Console: colour VGA+ 80x25 <NL> [    0.528051] printk: console [ttyS0] enabled <NL> [    0.528493] ACPI: Core revision 20200925 <NL> [    0.529105] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.541456] APIC: Switch to symmetric I/O mode setup <NL> [    0.542326] x2apic enabled <NL> [    0.542879] Switched APIC routing to physical x2apic. <NL> [    0.544804] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.548733] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    0.549884] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    0.551015] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.551885] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.552886] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.553906] Spectre V2 : Mitigation: Retpolines <NL> [    0.554381] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.554884] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.555887] Speculative Store Bypass: Vulnerable <NL> [    0.556887] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.557887] MMIO Stale Data: Unknown: No mitigations <NL> [    0.558894] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.581881] Freeing SMP alternatives memory: 48K <NL> [    0.581881] pid_max: default: 32768 minimum: 301 <NL> [    0.581881] LSM: Security Framework initializing <NL> [    0.581897] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.582902] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.672881] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.673944] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.677290] rcu: Hierarchical SRCU implementation. <NL> [    0.679121] smp: Bringing up secondary CPUs ... <NL> [    0.679987] x86: Booting SMP configuration: <NL> [    0.680389] .... node  #0, CPUs:      #1 <NL> [    0.241764] kvm-clock: cpu 1, msr 31254041, secondary cpu clock <NL> [    0.241764] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.691931] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.694079]  #2 <NL> [    0.241764] kvm-clock: cpu 2, msr 31254081, secondary cpu clock <NL> [    0.241764] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.697923] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    0.701203]  #3 <NL> [    0.241764] kvm-clock: cpu 3, msr 312540c1, secondary cpu clock <NL> [    0.241764] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.710996] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    0.711898] smp: Brought up 1 node, 4 CPUs <NL> [    0.713899] smpboot: Max logical packages: 4 <NL> [    0.714888] smpboot: Total of 4 processors activated (22347.48 BogoMIPS) <NL> [    0.722892] devtmpfs: initialized"}
{"timestamp_utc": "2024-07-31T08:12:19.518Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    0.726946] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.727915] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.729052] pinctrl core: initialized pinctrl subsystem <NL> [    0.739071] NET: Registered protocol family 16 <NL> [    0.740903] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.740905] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.743928] cpuidle: using governor menu <NL> [    0.746019] ACPI: bus type PCI registered <NL> [    0.747933] PCI: Using configuration type 1 for base access <NL> [    0.755547] Kprobes globally optimized <NL> [    0.892889] raid6: sse2x4   gen()  7807 MB/s <NL> [    0.910893] raid6: sse2x4   xor()  4114 MB/s <NL> [    0.928893] raid6: sse2x2   gen()  6385 MB/s <NL> [    0.946893] raid6: sse2x2   xor()  5667 MB/s <NL> [    0.964891] raid6: sse2x1   gen()  6035 MB/s <NL> [    0.982893] raid6: sse2x1   xor()  4348 MB/s <NL> [    0.983921] raid6: using algorithm sse2x4 gen() 7807 MB/s <NL> [    0.984912] raid6: .... xor() 4114 MB/s, rmw enabled <NL> [    0.985891] raid6: using intx1 recovery algorithm <NL> [    0.987038] ACPI: Added _OSI(Module Device) <NL> [    0.987968] ACPI: Added _OSI(Processor Device) <NL> [    0.988903] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.989889] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.990892] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.991916] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.992905] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.995588] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.997840] ACPI: Interpreter enabled <NL> [    0.998900] ACPI: (supports S0 S3 S5) <NL> [    0.999889] ACPI: Using IOAPIC for interrupt routing <NL> [    1.000936] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.002260] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.008458] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.008904] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.009920] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.011929] PCI host bridge to bus 0000:00 <NL> [    1.012803] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.012889] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.013887] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.014888] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.015887] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.016886] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.017884] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.018886] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.019968] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.022309] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.024349] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.029891] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.033279] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.033895] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.034898] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.035892] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.038210] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.040374] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.040893] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.042340] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.044955] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.047941] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.058948] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.060684] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.062890] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.065886] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.074643] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.075954] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.078892] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.081891] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.089894] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.091351] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.093892] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.096777] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.103891] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.106042] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.107887] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.110886] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.118895] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.121325] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.123638] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.125632] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.135614] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.137054] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.138067] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.139046] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.139980] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.143970] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.144881] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.144899] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.145895] vgaarb: loaded <NL> [    1.147197] SCSI subsystem initialized <NL> [    1.150987] ACPI: bus type USB registered <NL> [    1.151966] usbcore: registered new interface driver usbfs <NL> [    1.152927] usbcore: registered new interface driver hub"}
{"timestamp_utc": "2024-07-31T08:12:19.519Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    1.153942] usbcore: registered new device driver usb <NL> [    1.155890] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.156646] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.156913] PTP clock support registered <NL> [    1.161579] Bluetooth: Core ver 2.22 <NL> [    1.161909] NET: Registered protocol family 31 <NL> [    1.162890] Bluetooth: HCI device and connection manager initialized <NL> [    1.163900] Bluetooth: HCI socket layer initialized <NL> [    1.164887] Bluetooth: L2CAP socket layer initialized <NL> [    1.165895] Bluetooth: SCO socket layer initialized <NL> [    1.167939] PCI: Using ACPI for IRQ routing <NL> [    1.169306] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.169912] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.170886] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.185532] clocksource: Switched to clocksource kvm-clock <NL> [    1.660268] pnp: PnP ACPI init <NL> [    1.664553] pnp: PnP ACPI: found 7 devices <NL> [    1.678239] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.687485] NET: Registered protocol family 2 <NL> [    1.692000] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    1.700079] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    1.708593] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.714684] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    1.718440] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    1.721916] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.733121] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.736605] NET: Registered protocol family 1 <NL> [    1.756303] RPC: Registered named UNIX socket transport module. <NL> [    1.759726] RPC: Registered udp transport module. <NL> [    1.762272] RPC: Registered tcp transport module. <NL> [    1.764861] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    1.768137] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.772801] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.776261] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.779797] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.783089] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.786241] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.789868] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    1.793405] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.796528] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.799799] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.803305] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.814063] pci 0000:00:02.0: pci_fixup_video+0x0/0xe0 took 10529 usecs <NL> [    1.817167] PCI: CLS 0 bytes, default 64 <NL> [    1.819473] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    1.836682] check: Scanning for low memory corruption every 60 seconds <NL> [    1.841405] Initialise system trusted keyrings <NL> [    1.850984] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    1.870233] NFS: Registering the id_resolver key type <NL> [    1.875238] Key type id_resolver registered <NL> [    1.878521] Key type id_legacy registered <NL> [    1.887281] Key type cifs.idmap registered <NL> [    1.890811] 9p: Installing v9fs 9p2000 file system support <NL> [    1.893632] xor: measuring software checksum speed <NL> [    1.896070]    prefetch64-sse  : 14438 MB/sec <NL> [    1.897372]    generic_sse     : 13598 MB/sec <NL> [    1.897952] xor: using function: prefetch64-sse (14438 MB/sec) <NL> [    1.898737] Key type asymmetric registered <NL> [    1.899301] Asymmetric key parser 'x509' registered <NL> [    1.899987] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    1.923582] io scheduler mq-deadline registered <NL> [    1.924975] io scheduler kyber registered <NL> [    1.929117] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    1.941328] ACPI: Power Button [PWRF] <NL> [    1.958935] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    1.964197] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    1.971331] N_HDLC line discipline registered with maxframe=4096 <NL> [    1.975064] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    1.978512] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    1.982482] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    1.987146] Linux agpgart interface v0.103 <NL> [    1.990046] ACPI: bus type drm_connector registered <NL> [    2.005569] brd: module loaded <NL> [    2.011250] loop: module loaded <NL> [    2.015376] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.023451] vda: detected capacity change from 0 to 2576215040 <NL> [    2.032304] Uniform Multi-Platform E-IDE driver <NL> [    2.036665] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.040742] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.044244] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.044244] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.050836]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.053799]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    3.363221] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    3.992452] hdc: MWDMA2 mode selected <NL> [    3.996707] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.007064] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.017902] ide-gd driver 1.18 <NL> [    4.063813] e100: Intel(R) PRO/100 Network Driver <NL> [    4.069532] e100: Copyright(c) 1999-2006 Intel Corporation"}
{"timestamp_utc": "2024-07-31T08:12:19.520Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    4.076069] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.078824] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.661963] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    4.674838] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    4.682832] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    5.341469] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:09 <NL> [    5.354475] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.372330] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    5.836233] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:0a <NL> [    5.837412] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    5.838625] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    6.242358] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:0b <NL> [    6.246593] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.247332] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    6.247786] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    6.248363] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    6.248873] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    6.249408] PPP generic driver version 2.4.2 <NL> [    6.250072] PPP BSD Compression module registered <NL> [    6.250528] PPP Deflate Compression module registered <NL> [    6.251148] NET: Registered protocol family 24 <NL> [    6.251607] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    6.252514] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    6.253205] SLIP linefill/keepalive option. <NL> [    6.257418] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    6.258057] ehci-pci: EHCI PCI platform driver <NL> [    6.258537] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    6.259171] ohci-pci: OHCI PCI platform driver <NL> [    6.259587] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    6.260279] usbcore: registered new interface driver usb-storage <NL> [    6.260914] usbcore: registered new interface driver usbserial_generic <NL> [    6.261553] usbserial: USB Serial support registered for generic <NL> [    6.271255] usbcore: registered new interface driver ftdi_sio <NL> [    6.271801] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    6.272488] usbcore: registered new interface driver pl2303 <NL> [    6.273013] usbserial: USB Serial support registered for pl2303 <NL> [    6.273697] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    6.322430] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    6.324720] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    6.326921] mousedev: PS/2 mouse device common for all mice <NL> [    6.335995] rtc_cmos 00:00: RTC can wake from S4 <NL> [    6.346556] rtc_cmos 00:00: registered as rtc0 <NL> [    6.361922] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    6.365309] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:11 UTC (1722413531) <NL> [    6.367544] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    6.378918] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    6.383882] intel_pstate: CPU model not supported <NL> [    6.386066] sdhci: Secure Digital Host Controller Interface driver <NL> [    6.388628] sdhci: Copyright(c) Pierre Ossman <NL> [    6.390437] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    6.393191] usbcore: registered new interface driver usbhid <NL> [    6.394317] usbhid: USB HID core driver <NL> [    6.394784] u32 classifier <NL> [    6.395058]     input device check on <NL> [    6.395405]     Actions configured <NL> [    6.396196] xt_time: kernel timezone is -0000 <NL> [    6.396684] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.397409] gre: GRE over IPv4 demultiplexor driver <NL> [    6.405294] ip_gre: GRE over IPv4 tunneling driver <NL> [    6.407820] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    6.411200] NET: Registered protocol family 10 <NL> [    6.423274] Segment Routing with IPv6 <NL> [    6.425796] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.427646] ip6_gre: GRE over IPv6 tunneling driver <NL> [    6.428275] NET: Registered protocol family 17 <NL> [    6.428736] Bridge firewalling registered <NL> [    6.429215] 8021q: 802.1Q VLAN Support v1.8 <NL> [    6.429667] 9pnet: Installing 9P2000 support <NL> [    6.430135] Key type dns_resolver registered <NL> [    6.430632] NET: Registered protocol family 40 <NL> [    6.446667] IPI shorthand broadcast: enabled <NL> [    6.448466] sched_clock: Marking stable (6207601135, 240764203)->(7331534775, -883169437) <NL> [    6.453066] registered taskstats version 1 <NL> [    6.454834] Loading compiled-in X.509 certificates <NL> [    6.479409] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    6.483379] Key type .fscrypt registered <NL> [    6.485491] Key type fscrypt-provisioning registered <NL> [    6.487657] Btrfs loaded, crc32c=crc32c-generic <NL> [    6.500163] Key type encrypted registered <NL> [    6.501350] printk: console [netcon0] enabled <NL> [    6.501756] netconsole: network logging started <NL> [    7.028006] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    7.032716] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    7.052090] 8021q: adding VLAN 0 to HW filter on device eth1"}
{"timestamp_utc": "2024-07-31T08:12:19.521Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    7.081886] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    7.105302] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    7.122994] IP-Config: Failed to open gretap0 <NL> [    7.135786] IP-Config: Failed to open erspan0 <NL> [    7.153051] Sending DHCP requests . <NL> [    9.095986] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.098096] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.107373] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.108808] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [    9.109573] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [    9.110885] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [    9.157539] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.168228] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [    9.383975] ., OK <NL> [    9.393580] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [    9.395143] IP-Config: Complete: <NL> [    9.395878]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [    9.397834]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [    9.406543]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [    9.406547]      nameserver0=10.0.2.3 <NL> [    9.595983] md: Waiting for all devices to be available before autodetect <NL> [    9.608858] md: If you don't use raid, use raid=noautodetect <NL> [    9.629980] md: Autodetecting RAID arrays. <NL> [    9.633405] md: autorun ... <NL> [    9.635581] md: ... autorun DONE. <NL> [    9.645014] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [    9.765497] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [    9.766307] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [    9.773222] devtmpfs: mounted <NL> [    9.777485] Freeing unused kernel image (initmem) memory: 1964K <NL> [    9.779458] Write protecting the kernel read-only data: 22528k <NL> [    9.783337] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [    9.795946] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [    9.797522] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   10.478305] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   10.490980] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   10.730096] #####FSS INIT: Running on host <NL> [   10.851417] #####FSS INIT: FSS system init pre startup script <NL> [   10.971217] random: python3: uninitialized urandom read (24 bytes read) <NL> [   13.787229] random: crng init done <NL> (process:711): GLib-WARNING **: 03:12:01.538: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved"}
{"timestamp_utc": "2024-07-31T08:12:19.522Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 47854001, primary cpu clock <NL> [    0.000000] kvm-clock: using sched offset of 6106394345 cycles <NL> [    0.000006] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000015] tsc: Detected 2793.436 MHz processor <NL> [    0.001322] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.001392] x86/PAT: PAT not supported by the CPU. <NL> [    0.001400] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.001410] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.047633] found SMP MP-table at [mem 0x000f6380-0x000f638f] <NL> [    0.047730] check: Scanning 1 areas for low memory corruption <NL> [    0.062912] ACPI: Early table checksum verification disabled <NL> [    0.062938] ACPI: RSDP 0x00000000000F61D0 000014 (v00 BOCHS ) <NL> [    0.062952] ACPI: RSDT 0x00000000BFFFFBC1 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.062965] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.062974] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.062980] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.062985] ACPI: SSDT 0x00000000BFFFF234 0008DD (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.062991] ACPI: APIC 0x00000000BFFFFB11 000078 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.062997] ACPI: HPET 0x00000000BFFFFB89 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.063002] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.063004] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.063006] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.063007] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffb10] <NL> [    0.063009] ACPI: Reserving APIC table memory at [mem 0xbffffb11-0xbffffb88] <NL> [    0.063011] ACPI: Reserving HPET table memory at [mem 0xbffffb89-0xbffffbc0] <NL> [    0.063092] Zone ranges: <NL> [    0.063094]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.063096]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.063099]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.063101] Movable zone start for each node <NL> [    0.063102] Early memory node ranges <NL> [    0.063104]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.063106]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.063108]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.063111] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.063649] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.063676] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.182826] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.183407] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.183438] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.183482] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.183486] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.183489] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.183491] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.183499] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.183501] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.183511] Using ACPI (MADT) for SMP configuration information <NL> [    0.183514] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.183521] smpboot: Allowing 1 CPUs, 0 hotplug CPUs <NL> [    0.183554] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.183556] Booting paravirtualized kernel on KVM <NL> [    0.183561] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.183573] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:1 nr_node_ids:1 <NL> [    0.184246] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u2097152 <NL> [    0.184281] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.184288] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.184291] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.203895] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.204510] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.204553] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.371946] Memory: 4026940K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 166696K reserved, 0K cma-reserved) <NL> [    0.372002] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1 <NL> [    0.372012] Kernel/User page tables isolation: enabled <NL> [    0.372043] ftrace: allocating 47967 entries in 188 pages <NL> [    0.555947] ftrace: allocated 188 pages with 5 groups <NL> [    0.572634] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.572639] rcu: \tRCU event tracing is enabled. <NL> [    0.572641] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=1. <NL> [    0.572643] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.572644] \tRude variant of Tasks RCU enabled. <NL> [    0.572645] \tTracing variant of Tasks RCU enabled. <NL> [    0.572648] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.572649] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1 <NL> [    0.588659] NR_IRQS: 4352, nr_irqs: 256, preallocated irqs: 16 <NL> [    0.610761] Console: colour VGA+ 80x25 <NL> [    1.045019] printk: console [ttyS0] enabled <NL> [    1.057538] ACPI: Core revision 20200925 <NL> [    1.058111] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    1.059114] APIC: Switch to symmetric I/O mode setup <NL> [    1.059878] x2apic enabled <NL> [    1.060460] Switched APIC routing to physical x2apic. <NL> [    1.079369] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1"}
{"timestamp_utc": "2024-07-31T08:12:19.523Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    1.084021] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    1.085027] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    1.085950] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    1.086025] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    1.086025] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    1.086025] Spectre V2 : Mitigation: Retpolines <NL> [    1.086025] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    1.086037] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    1.086708] Speculative Store Bypass: Vulnerable <NL> [    1.087025] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    1.087025] MMIO Stale Data: Unknown: No mitigations <NL> [    1.087025] x86/fpu: x87 FPU will use FXSAVE <NL> [    1.110775] Freeing SMP alternatives memory: 48K <NL> [    1.111046] pid_max: default: 32768 minimum: 301 <NL> [    1.112061] LSM: Security Framework initializing <NL> [    1.114035] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.115054] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.180025] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    1.180343] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    1.183272] rcu: Hierarchical SRCU implementation. <NL> [    1.184444] smp: Bringing up secondary CPUs ... <NL> [    1.185030] smp: Brought up 1 node, 1 CPU <NL> [    1.186032] smpboot: Max logical packages: 1 <NL> [    1.187028] smpboot: Total of 1 processors activated (5586.87 BogoMIPS) <NL> [    1.188516] devtmpfs: initialized <NL> [    1.189367] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.190036] futex hash table entries: 256 (order: 2, 16384 bytes, linear) <NL> [    1.191079] pinctrl core: initialized pinctrl subsystem <NL> [    1.192359] NET: Registered protocol family 16 <NL> [    1.193296] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.193297] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.194107] cpuidle: using governor menu <NL> [    1.196089] ACPI: bus type PCI registered <NL> [    1.197149] PCI: Using configuration type 1 for base access <NL> [    1.201421] Kprobes globally optimized <NL> [    1.318292] raid6: sse2x4   gen()  2749 MB/s <NL> [    1.338077] raid6: sse2x4   xor()  1620 MB/s <NL> [    1.356036] raid6: sse2x2   gen()  5916 MB/s <NL> [    1.374034] raid6: sse2x2   xor()  4341 MB/s <NL> [    1.392037] raid6: sse2x1   gen()  4882 MB/s <NL> [    1.410036] raid6: sse2x1   xor()  3205 MB/s <NL> [    1.411038] raid6: using algorithm sse2x2 gen() 5916 MB/s <NL> [    1.412035] raid6: .... xor() 4341 MB/s, rmw enabled <NL> [    1.413048] raid6: using intx1 recovery algorithm <NL> [    1.413891] ACPI: Added _OSI(Module Device) <NL> [    1.414031] ACPI: Added _OSI(Processor Device) <NL> [    1.415028] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.415469] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.415957] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.416029] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.416498] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.418728] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.420142] ACPI: Interpreter enabled <NL> [    1.420509] ACPI: (supports S0 S3 S5) <NL> [    1.420858] ACPI: Using IOAPIC for interrupt routing <NL> [    1.421091] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.422243] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.426073] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.426702] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.427054] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.428131] PCI host bridge to bus 0000:00 <NL> [    1.429034] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.430031] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.430643] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.431030] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.432031] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.433028] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.434028] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    1.434750] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.435098] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.436588] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.438093] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.442386] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    1.444462] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.445033] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.446028] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.446722] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.447325] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.448461] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.449038] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.450376] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.453108] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.457093] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    1.468101] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    1.470391] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.473780] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff]"}
{"timestamp_utc": "2024-07-31T08:12:19.524Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    1.476029] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.483701] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    1.486207] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.489037] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    1.492035] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.500719] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    1.501391] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.504044] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.507035] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.515724] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    1.516401] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.518704] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.520689] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.528041] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    1.530145] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    1.533038] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.535610] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    1.543039] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.544404] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    1.546037] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> # 03:12:18 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46487; retry every 5 seconds, waiting forever <NL> # 03:12:18 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46487 <NL> [    1.548034] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    1.555720] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.556387] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    1.558036] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    1.560743] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    1.568036] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.569426] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.572035] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    1.574037] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    1.583543] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.585124] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.586152] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.587132] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.589054] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.591060] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.592025] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.592043] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.593031] vgaarb: loaded <NL> [    1.594294] SCSI subsystem initialized <NL> [    1.596075] ACPI: bus type USB registered <NL> [    1.597121] usbcore: registered new interface driver usbfs <NL> [    1.598043] usbcore: registered new interface driver hub <NL> [    1.598720] usbcore: registered new device driver usb <NL> [    1.599078] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.600026] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.601032] PTP clock support registered <NL> [    1.602630] Bluetooth: Core ver 2.22 <NL> [    1.603051] NET: Registered protocol family 31 <NL> [    1.604029] Bluetooth: HCI device and connection manager initialized <NL> [    1.605042] Bluetooth: HCI socket layer initialized <NL> [    1.606045] Bluetooth: L2CAP socket layer initialized <NL> [    1.607040] Bluetooth: SCO socket layer initialized <NL> [    1.608156] PCI: Using ACPI for IRQ routing <NL> [    1.609423] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.610053] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.611028] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.618102] clocksource: Switched to clocksource kvm-clock <NL> [    1.804407] pnp: PnP ACPI init <NL> [    1.805792] pnp: PnP ACPI: found 7 devices <NL> [    1.812213] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.813159] NET: Registered protocol family 2 <NL> [    1.813853] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    1.818838] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    1.820542] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    1.822491] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    1.823714] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    1.824522] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    1.825186] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    1.825959] NET: Registered protocol family 1 <NL> [    1.827096] RPC: Registered named UNIX socket transport module. <NL> [    1.828415] RPC: Registered udp transport module. <NL> [    1.829049] RPC: Registered tcp transport module. <NL> [    1.829703] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    1.830504] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.831108] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.831862] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.832514] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.833109] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.833738] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.834409] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    1.835172] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.835754] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.836313] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.836933] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.837814] PCI: CLS 0 bytes, default 64 <NL> [    1.838313] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    1.838938] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    1.839806] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns"}
{"timestamp_utc": "2024-07-31T08:12:19.525Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    1.840923] check: Scanning for low memory corruption every 60 seconds <NL> [    1.841960] Initialise system trusted keyrings <NL> [    1.842501] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    1.844994] NFS: Registering the id_resolver key type <NL> [    1.845569] Key type id_resolver registered <NL> [    1.845969] Key type id_legacy registered <NL> [    1.846597] Key type cifs.idmap registered <NL> [    1.847042] 9p: Installing v9fs 9p2000 file system support <NL> [    1.847675] xor: measuring software checksum speed <NL> [    1.848870]    prefetch64-sse  : 14177 MB/sec <NL> [    1.850382]    generic_sse     : 12121 MB/sec <NL> [    1.850956] xor: using function: prefetch64-sse (14177 MB/sec) <NL> [    1.851949] Key type asymmetric registered <NL> [    1.852523] Asymmetric key parser 'x509' registered <NL> [    1.853308] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    1.858322] io scheduler mq-deadline registered <NL> [    1.858759] io scheduler kyber registered <NL> [    1.860047] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    1.872345] ACPI: Power Button [PWRF] <NL> [    1.873834] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    1.874384] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    1.882042] N_HDLC line discipline registered with maxframe=4096 <NL> [    1.882644] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    1.883456] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    1.884464] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    1.885658] Linux agpgart interface v0.103 <NL> [    1.886161] ACPI: bus type drm_connector registered <NL> [    1.900213] brd: module loaded <NL> [    1.920373] loop: module loaded <NL> [    1.922045] virtio_blk virtio0: [vda] 5016568 512-byte logical blocks (2.57 GB/2.39 GiB) <NL> [    1.933414] vda: detected capacity change from 0 to 2568482816 <NL> [    1.939205] Uniform Multi-Platform E-IDE driver <NL> [    1.940044] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    1.941352] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    1.942007] legacy IDE will be removed in 2021, please switch to libata <NL> [    1.942007] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    1.944477]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    1.951731]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    3.172493] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    3.803357] hdc: MWDMA2 mode selected <NL> [    3.803918] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    3.804438] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    3.805053] ide-gd driver 1.18 <NL> [    3.805894] e100: Intel(R) PRO/100 Network Driver <NL> [    3.806365] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    3.806903] e1000: Intel(R) PRO/1000 Network Driver <NL> [    3.807356] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    3.814330] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    4.623159] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    4.623853] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    4.624944] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    5.268865] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:27 <NL> [    5.269539] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.277745] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    5.716105] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:26 <NL> [    5.716792] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.459113] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:24 <NL> [    6.460397] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.963349] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:25 <NL> [    6.970402] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    7.633974] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:23 <NL> [    7.650980] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    8.676369] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:28 <NL> [    8.686667] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    8.723554] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    8.738205] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    8.749277] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    8.768285] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    8.790538] PPP generic driver version 2.4.2 <NL> [    8.808011] PPP BSD Compression module registered <NL> [    8.815878] PPP Deflate Compression module registered <NL> [    8.816597] NET: Registered protocol family 24 <NL> [    8.817230] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    8.821338] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    8.844395] SLIP linefill/keepalive option. <NL> [    8.845007] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    8.868976] ehci-pci: EHCI PCI platform driver <NL> [    8.869683] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    8.870576] ohci-pci: OHCI PCI platform driver <NL> [    8.889355] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    8.890068] usbcore: registered new interface driver usb-storage"}
{"timestamp_utc": "2024-07-31T08:12:19.526Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    8.890702] usbcore: registered new interface driver usbserial_generic <NL> [    8.891343] usbserial: USB Serial support registered for generic <NL> [    8.891924] usbcore: registered new interface driver ftdi_sio <NL> [    8.914634] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    8.915411] usbcore: registered new interface driver pl2303 <NL> [    8.915953] usbserial: USB Serial support registered for pl2303 <NL> [    8.916686] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    8.934859] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    8.949191] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    8.949935] mousedev: PS/2 mouse device common for all mice <NL> [    8.950878] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    8.965855] rtc_cmos 00:00: RTC can wake from S4 <NL> [    8.979214] rtc_cmos 00:00: registered as rtc0 <NL> [    8.984181] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:16 UTC (1722413536) <NL> [    8.985344] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    8.986418] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    8.993947] intel_pstate: CPU model not supported <NL> [    8.994514] sdhci: Secure Digital Host Controller Interface driver <NL> [    9.003961] sdhci: Copyright(c) Pierre Ossman <NL> [    9.004501] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    9.005239] usbcore: registered new interface driver usbhid <NL> [    9.005781] usbhid: USB HID core driver <NL> [    9.006204] u32 classifier <NL> [    9.006469]     input device check on <NL> [    9.006808]     Actions configured <NL> [    9.016461] xt_time: kernel timezone is -0000 <NL> [    9.016996] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.017752] gre: GRE over IPv4 demultiplexor driver <NL> [    9.018273] ip_gre: GRE over IPv4 tunneling driver <NL> [    9.023989] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    9.024843] NET: Registered protocol family 10 <NL> [    9.025919] Segment Routing with IPv6 <NL> [    9.026402] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.032661] ip6_gre: GRE over IPv6 tunneling driver <NL> [    9.033272] NET: Registered protocol family 17 <NL> [    9.033741] Bridge firewalling registered <NL> [    9.034187] 8021q: 802.1Q VLAN Support v1.8 <NL> [    9.034655] 9pnet: Installing 9P2000 support <NL> [    9.035102] Key type dns_resolver registered <NL> [    9.035587] NET: Registered protocol family 40 <NL> [    9.046446] IPI shorthand broadcast: enabled <NL> [    9.046935] sched_clock: Marking stable (8559007405, 487314012)->(9766593822, -720272405) <NL> [    9.047829] registered taskstats version 1 <NL> [    9.048251] Loading compiled-in X.509 certificates <NL> [    9.050168] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    9.061276] Key type .fscrypt registered <NL> [    9.061655] Key type fscrypt-provisioning registered <NL> [    9.062634] Btrfs loaded, crc32c=crc32c-generic <NL> [    9.063641] Key type encrypted registered <NL> [    9.068591] printk: console [netcon0] enabled <NL> [    9.069053] netconsole: network logging started <NL> [    9.599934] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    9.614055] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    9.630048] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    9.654234] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    9.682350] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    9.724526] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [    9.744397] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [    9.752630] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [    9.757107] IP-Config: Failed to open gretap0 <NL> [    9.760324] IP-Config: Failed to open erspan0 <NL> # 03:12:19 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46503; retry every 5 seconds, waiting forever <NL> # 03:12:19 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46503 <NL> (process:684): GLib-WARNING **: 03:12:01.026: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)..."}
{"timestamp_utc": "2024-07-31T08:12:19.527Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80 <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr ae254001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 2931221626 cycles <NL> [    0.000007] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000017] tsc: Detected 2793.436 MHz processor <NL> [    0.001140] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.001208] x86/PAT: PAT not supported by the CPU. <NL> [    0.001216] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.001229] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.009684] found SMP MP-table at [mem 0x000f6380-0x000f638f] <NL> [    0.009787] check: Scanning 1 areas for low memory corruption <NL> [    0.011073] ACPI: Early table checksum verification disabled <NL> [    0.011101] ACPI: RSDP 0x00000000000F61D0 000014 (v00 BOCHS ) <NL> [    0.011111] ACPI: RSDT 0x00000000BFFFFBC1 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.011126] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.011134] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.011140] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.011145] ACPI: SSDT 0x00000000BFFFF234 0008DD (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.011150] ACPI: APIC 0x00000000BFFFFB11 000078 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.011156] ACPI: HPET 0x00000000BFFFFB89 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.011161] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.011163] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.011164] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.011166] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffb10] <NL> [    0.011168] ACPI: Reserving APIC table memory at [mem 0xbffffb11-0xbffffb88] <NL> [    0.011169] ACPI: Reserving HPET table memory at [mem 0xbffffb89-0xbffffbc0] <NL> [    0.011246] Zone ranges: <NL> [    0.011248]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.011251]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.011253]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.011256] Movable zone start for each node <NL> [    0.011257] Early memory node ranges <NL> [    0.011259]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.011261]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.011263]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.011266] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.012190] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.012214] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.060434] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.060969] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.060989] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.061032] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.061036] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.061039] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.061041] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.061051] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.061053] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.061063] Using ACPI (MADT) for SMP configuration information <NL> [    0.061066] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.061087] smpboot: Allowing 1 CPUs, 0 hotplug CPUs <NL> [    0.061124] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.061127] Booting paravirtualized kernel on KVM <NL> [    0.061132] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.061146] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:1 nr_node_ids:1 <NL> [    0.062249] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u2097152 <NL> [    0.062288] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.062297] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.062300] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.064473] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.065468] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.065515] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.254881] Memory: 4026940K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 166696K reserved, 0K cma-reserved) <NL> [    0.254953] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1"}
{"timestamp_utc": "2024-07-31T08:12:19.528Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    0.254965] Kernel/User page tables isolation: enabled <NL> [    0.255004] ftrace: allocating 47967 entries in 188 pages <NL> [    0.299339] ftrace: allocated 188 pages with 5 groups <NL> [    0.300360] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.300362] rcu: \tRCU event tracing is enabled. <NL> [    0.300365] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=1. <NL> [    0.300367] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.300369] \tRude variant of Tasks RCU enabled. <NL> [    0.300370] \tTracing variant of Tasks RCU enabled. <NL> [    0.300373] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.300375] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1 <NL> [    0.305878] NR_IRQS: 4352, nr_irqs: 256, preallocated irqs: 16 <NL> [    0.311547] Console: colour VGA+ 80x25 <NL> [    0.376176] printk: console [ttyS0] enabled <NL> [    0.376579] ACPI: Core revision 20200925 <NL> [    0.377123] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.378206] APIC: Switch to symmetric I/O mode setup <NL> [    0.378963] x2apic enabled <NL> [    0.379590] Switched APIC routing to physical x2apic. <NL> [    0.381504] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.382148] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    0.383174] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    0.384184] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.384692] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.385177] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.385983] Spectre V2 : Mitigation: Retpolines <NL> [    0.386174] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.387174] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.387808] Speculative Store Bypass: Vulnerable <NL> [    0.388176] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.389174] MMIO Stale Data: Unknown: No mitigations <NL> [    0.389654] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.411449] Freeing SMP alternatives memory: 48K <NL> [    0.412051] pid_max: default: 32768 minimum: 301 <NL> [    0.412225] LSM: Security Framework initializing <NL> [    0.413185] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.414190] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.455241] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.457227] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.459353] rcu: Hierarchical SRCU implementation. <NL> [    0.460540] smp: Bringing up secondary CPUs ... <NL> [    0.461190] smp: Brought up 1 node, 1 CPU <NL> [    0.462189] smpboot: Max logical packages: 1 <NL> [    0.463190] smpboot: Total of 1 processors activated (5586.87 BogoMIPS) <NL> [    0.464691] devtmpfs: initialized <NL> [    0.466326] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.467202] futex hash table entries: 256 (order: 2, 16384 bytes, linear) <NL> [    0.468274] pinctrl core: initialized pinctrl subsystem <NL> [    0.470205] NET: Registered protocol family 16 <NL> [    0.471510] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.471512] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.472327] cpuidle: using governor menu <NL> [    0.474294] ACPI: bus type PCI registered <NL> [    0.475364] PCI: Using configuration type 1 for base access <NL> [    0.478458] Kprobes globally optimized <NL> [    0.575222] raid6: sse2x4   gen()  5875 MB/s <NL> [    0.593204] raid6: sse2x4   xor()  2764 MB/s <NL> [    0.610207] raid6: sse2x2   gen()  6184 MB/s <NL> [    0.628182] raid6: sse2x2   xor()  4816 MB/s <NL> [    0.645183] raid6: sse2x1   gen()  5428 MB/s <NL> [    0.662183] raid6: sse2x1   xor()  3791 MB/s <NL> [    0.662810] raid6: using algorithm sse2x2 gen() 6184 MB/s <NL> [    0.663174] raid6: .... xor() 4816 MB/s, rmw enabled <NL> [    0.664175] raid6: using intx1 recovery algorithm <NL> [    0.665324] ACPI: Added _OSI(Module Device) <NL> [    0.666193] ACPI: Added _OSI(Processor Device) <NL> [    0.667203] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.668190] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.669197] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.670196] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.672187] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.673992] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.676115] ACPI: Interpreter enabled <NL> [    0.676191] ACPI: (supports S0 S3 S5) <NL> [    0.677175] ACPI: Using IOAPIC for interrupt routing <NL> [    0.677892] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.678463] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    0.683876] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    0.684184] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    0.685183] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    0.686368] PCI host bridge to bus 0000:00 <NL> [    0.687194] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    0.688195] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    0.689196] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    0.690199] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    0.691197] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    0.692197] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    0.693198] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    0.694198] pci_bus 0000:00: root bus resource [bus 00-ff]"}
{"timestamp_utc": "2024-07-31T08:12:19.529Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    0.695274] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    0.696873] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    0.699178] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    0.704508] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    0.707560] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    0.708192] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    0.709176] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    0.710175] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    0.711106] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    0.714422] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    0.715142] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    0.715530] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    0.718249] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    0.721244] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    0.734264] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    0.737195] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    0.740182] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    0.743184] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    0.751194] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    0.752529] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    0.754875] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    0.757194] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    0.764786] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    0.766364] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    0.768181] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    0.770187] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    0.777186] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    0.778528] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    0.781187] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    0.784186] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    0.793190] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    0.795527] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    0.797801] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    0.799815] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    0.806793] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    0.807529] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    0.810185] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    0.812806] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    0.819827] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    0.820519] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    0.822813] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    0.825186] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    0.833189] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    0.835563] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    0.838192] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    0.841192] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    0.852302] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    0.853358] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    0.854367] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    0.855359] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    0.857297] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    0.859283] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    0.860172] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    0.860195] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    0.861180] vgaarb: loaded <NL> [    0.863310] SCSI subsystem initialized <NL> [    0.864435] ACPI: bus type USB registered <NL> [    0.865266] usbcore: registered new interface driver usbfs <NL> [    0.866243] usbcore: registered new interface driver hub <NL> [    0.867214] usbcore: registered new device driver usb <NL> [    0.868282] pps_core: LinuxPPS API ver. 1 registered <NL> [    0.869180] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    0.870219] PTP clock support registered <NL> [    0.872192] Bluetooth: Core ver 2.22 <NL> [    0.873204] NET: Registered protocol family 31 <NL> [    0.874177] Bluetooth: HCI device and connection manager initialized <NL> [    0.875214] Bluetooth: HCI socket layer initialized <NL> [    0.876182] Bluetooth: L2CAP socket layer initialized <NL> [    0.877202] Bluetooth: SCO socket layer initialized <NL> [    0.878328] PCI: Using ACPI for IRQ routing <NL> [    0.879530] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    0.880203] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    0.881176] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    0.885210] clocksource: Switched to clocksource kvm-clock <NL> [    1.544415] pnp: PnP ACPI init <NL> [    1.551729] pnp: PnP ACPI: found 7 devices <NL> [    1.571027] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.578070] NET: Registered protocol family 2 <NL> [    1.582190] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    1.589441] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    1.597011] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    1.603662] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    1.611711] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    1.612628] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    1.613355] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    1.614289] NET: Registered protocol family 1 <NL> [    1.615091] RPC: Registered named UNIX socket transport module. <NL> [    1.615778] RPC: Registered udp transport module. <NL> [    1.616306] RPC: Registered tcp transport module. <NL> [    1.616847] RPC: Registered tcp NFSv4.1 backchannel transport module."}
{"timestamp_utc": "2024-07-31T08:12:19.530Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    1.617634] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.618333] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.619047] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.619742] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.620428] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.621136] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.638171] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    1.641315] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.644156] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.646674] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.649564] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.653005] PCI: CLS 0 bytes, default 64 <NL> [    1.654789] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    1.657664] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    1.661332] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    1.667101] check: Scanning for low memory corruption every 60 seconds <NL> [    1.679525] Initialise system trusted keyrings <NL> [    1.682324] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    1.687254] NFS: Registering the id_resolver key type <NL> [    1.691870] Key type id_resolver registered <NL> [    1.694075] Key type id_legacy registered <NL> [    1.696276] Key type cifs.idmap registered <NL> [    1.698357] 9p: Installing v9fs 9p2000 file system support <NL> [    1.710053] xor: measuring software checksum speed <NL> [    1.713127]    prefetch64-sse  : 13698 MB/sec <NL> [    1.716741]    generic_sse     : 12264 MB/sec <NL> [    1.719823] xor: using function: prefetch64-sse (13698 MB/sec) <NL> [    1.721219] Key type asymmetric registered <NL> [    1.721672] Asymmetric key parser 'x509' registered <NL> [    1.722237] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    1.723136] io scheduler mq-deadline registered <NL> [    1.723629] io scheduler kyber registered <NL> [    1.725022] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    1.750019] ACPI: Power Button [PWRF] <NL> [    1.754182] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    1.758749] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    1.765011] N_HDLC line discipline registered with maxframe=4096 <NL> [    1.768489] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    1.775848] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    1.779730] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    1.783554] Linux agpgart interface v0.103 <NL> [    1.795389] ACPI: bus type drm_connector registered <NL> [    1.803086] brd: module loaded <NL> [    1.807751] loop: module loaded <NL> [    1.817912] virtio_blk virtio0: [vda] 5016568 512-byte logical blocks (2.57 GB/2.39 GiB) <NL> [    1.822120] vda: detected capacity change from 0 to 2568482816 <NL> [    1.826962] Uniform Multi-Platform E-IDE driver <NL> [    1.828138] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    1.828958] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    1.829720] legacy IDE will be removed in 2021, please switch to libata <NL> [    1.829720] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    1.839819]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    1.841202]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    3.135737] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    3.771769] hdc: MWDMA2 mode selected <NL> [    3.775030] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    3.788020] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    3.798882] ide-gd driver 1.18 <NL> [    3.806779] e100: Intel(R) PRO/100 Network Driver <NL> [    3.807841] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    3.810035] e1000: Intel(R) PRO/1000 Network Driver <NL> [    3.815889] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    3.816912] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    4.431819] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    4.438708] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    4.445444] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    4.835180] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:1c <NL> [    4.845881] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    4.847202] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    5.207885] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:1b <NL> [    5.217589] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    5.590725] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:19 <NL> [    5.596578] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.144385] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:1a <NL> [    6.150006] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    6.830921] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:18 <NL> [    6.837322] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    7.636511] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:1d <NL> [    7.650828] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    7.661574] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    7.665232] e1000e: Copyright(c) 1999 - 2015 Intel Corporation."}
{"timestamp_utc": "2024-07-31T08:12:19.531Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    7.678049] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    7.690340] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    7.694475] PPP generic driver version 2.4.2 <NL> [    7.704989] PPP BSD Compression module registered <NL> [    7.707005] PPP Deflate Compression module registered <NL> [    7.708893] NET: Registered protocol family 24 <NL> [    7.710566] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    7.719990] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    7.720686] SLIP linefill/keepalive option. <NL> [    7.721131] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    7.721752] ehci-pci: EHCI PCI platform driver <NL> [    7.722250] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    7.722850] ohci-pci: OHCI PCI platform driver <NL> [    7.723296] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    7.723999] usbcore: registered new interface driver usb-storage <NL> [    7.724607] usbcore: registered new interface driver usbserial_generic <NL> [    7.725239] usbserial: USB Serial support registered for generic <NL> [    7.725820] usbcore: registered new interface driver ftdi_sio <NL> [    7.726369] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    7.731154] usbcore: registered new interface driver pl2303 <NL> [    7.731697] usbserial: USB Serial support registered for pl2303 <NL> [    7.732371] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    7.733865] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    7.734404] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    7.735007] mousedev: PS/2 mouse device common for all mice <NL> [    7.735831] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    7.743616] rtc_cmos 00:00: RTC can wake from S4 <NL> [    7.744852] rtc_cmos 00:00: registered as rtc0 <NL> [    7.745390] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:13 UTC (1722413533) <NL> [    7.746283] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    7.754508] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    7.755438] intel_pstate: CPU model not supported <NL> [    7.755944] sdhci: Secure Digital Host Controller Interface driver <NL> [    7.756560] sdhci: Copyright(c) Pierre Ossman <NL> [    7.757052] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    7.757779] usbcore: registered new interface driver usbhid <NL> [    7.758353] usbhid: USB HID core driver <NL> [    7.761448] u32 classifier <NL> [    7.762088]     input device check on <NL> [    7.763565]     Actions configured <NL> [    7.773326] xt_time: kernel timezone is -0000 <NL> [    7.774443] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.775957] gre: GRE over IPv4 demultiplexor driver <NL> [    7.776749] ip_gre: GRE over IPv4 tunneling driver <NL> [    7.786038] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    7.787147] NET: Registered protocol family 10 <NL> [    7.788958] Segment Routing with IPv6 <NL> [    7.789513] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.792375] ip6_gre: GRE over IPv6 tunneling driver <NL> [    7.793065] NET: Registered protocol family 17 <NL> [    7.793552] Bridge firewalling registered <NL> [    7.794023] 8021q: 802.1Q VLAN Support v1.8 <NL> [    7.794501] 9pnet: Installing 9P2000 support <NL> [    7.794953] Key type dns_resolver registered <NL> [    7.795439] NET: Registered protocol family 40 <NL> [    7.805257] IPI shorthand broadcast: enabled <NL> [    7.805730] sched_clock: Marking stable (7732003613, 72963863)->(9913821604, -2108854128) <NL> [    7.806619] registered taskstats version 1 <NL> [    7.807038] Loading compiled-in X.509 certificates <NL> [    7.808870] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    7.816978] Key type .fscrypt registered <NL> [    7.817360] Key type fscrypt-provisioning registered <NL> [    7.818324] Btrfs loaded, crc32c=crc32c-generic <NL> [    7.819338] Key type encrypted registered <NL> [    7.819944] printk: console [netcon0] enabled <NL> [    7.820377] netconsole: network logging started <NL> [    8.398367] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    8.424928] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    8.448025] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    8.479223] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    8.523057] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    8.557981] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [    8.581939] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [    8.591794] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [    8.598560] IP-Config: Failed to open gretap0 <NL> [    8.601911] IP-Config: Failed to open erspan0 <NL> [    8.620541] Sending DHCP requests . <NL> [   10.460505] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.462557] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.463735] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   10.465393] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   10.524530] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.526210] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.527358] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   10.528045] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   10.593014] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.595785] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> # 03:12:19 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46489; retry every 5 seconds, waiting forever <NL> # 03:12:19 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46489 <NL> # 03:12:19 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46505; retry every 5 seconds, waiting forever"}
{"timestamp_utc": "2024-07-31T08:12:19.532Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "# 03:12:19 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46505 <NL> (process:696): GLib-WARNING **: 03:12:01.374: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr e654001, primary cpu clock <NL> [    0.000000] kvm-clock: using sched offset of 5163392482 cycles <NL> [    0.000007] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000018] tsc: Detected 2793.436 MHz processor <NL> [    0.001881] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.001958] x86/PAT: PAT not supported by the CPU. <NL> [    0.001968] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.010789] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.010912] check: Scanning 1 areas for low memory corruption <NL> [    0.011152] ACPI: Early table checksum verification disabled <NL> [    0.011183] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.011195] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.011212] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.011221] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.011228] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.011233] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.011239] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.011244] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.011250] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.011252] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.011253] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.011255] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.011257] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.011259] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.011343] Zone ranges: <NL> [    0.011345]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.011348]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.011350]   Normal   empty <NL> [    0.011352] Movable zone start for each node <NL> [    0.011354] Early memory node ranges <NL> [    0.011355]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.011357]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.011360] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.012004] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.012027] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.020527] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.021009] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.021034] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.021080] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.021085] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.021089] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.021090] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.021101] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.021103] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.021113] Using ACPI (MADT) for SMP configuration information <NL> [    0.021116] ACPI: HPET id: 0x8086a201 base: 0xfed00000"}
{"timestamp_utc": "2024-07-31T08:12:19.533Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    0.021127] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.021173] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.021176] Booting paravirtualized kernel on KVM <NL> [    0.021182] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.021200] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.022403] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.022451] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.022462] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.022465] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.023015] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.023189] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.023283] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.027662] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.027740] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.027752] Kernel/User page tables isolation: enabled <NL> [    0.027791] ftrace: allocating 47967 entries in 188 pages <NL> [    0.072424] ftrace: allocated 188 pages with 5 groups <NL> [    0.073532] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.073536] rcu: \tRCU event tracing is enabled. <NL> [    0.073539] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.073541] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.073542] \tRude variant of Tasks RCU enabled. <NL> [    0.073543] \tTracing variant of Tasks RCU enabled. <NL> [    0.073546] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.073548] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.078864] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.084596] Console: colour VGA+ 80x25 <NL> [    0.149176] printk: console [ttyS0] enabled <NL> [    0.149601] ACPI: Core revision 20200925 <NL> [    0.150165] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.151279] APIC: Switch to symmetric I/O mode setup <NL> [    0.152022] x2apic enabled <NL> [    0.152647] Switched APIC routing to physical x2apic. <NL> [    0.154462] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.155075] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    0.156097] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    0.157223] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.158099] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.158633] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.159102] Spectre V2 : Mitigation: Retpolines <NL> [    0.160098] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.160863] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.161099] Speculative Store Bypass: Vulnerable <NL> [    0.162100] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.162706] MMIO Stale Data: Unknown: No mitigations <NL> [    0.163102] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.189907] Freeing SMP alternatives memory: 48K <NL> [    0.190114] pid_max: default: 32768 minimum: 301 <NL> [    0.190538] LSM: Security Framework initializing <NL> [    0.192104] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.192710] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.295990] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.296440] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.300345] rcu: Hierarchical SRCU implementation. <NL> [    0.302169] smp: Bringing up secondary CPUs ... <NL> [    0.303339] x86: Booting SMP configuration: <NL> [    0.304104] .... node  #0, CPUs:      #1 <NL> [    0.074900] kvm-clock: cpu 1, msr e654041, secondary cpu clock <NL> [    0.074900] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.315202] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.316369]  #2 <NL> [    0.074900] kvm-clock: cpu 2, msr e654081, secondary cpu clock <NL> [    0.074900] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.325184] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    0.326366]  #3 <NL> [    0.074900] kvm-clock: cpu 3, msr e6540c1, secondary cpu clock <NL> [    0.074900] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.330186] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    0.331111] smp: Brought up 1 node, 4 CPUs <NL> [    0.332123] smpboot: Max logical packages: 4 <NL> [    0.333108] smpboot: Total of 4 processors activated (22347.48 BogoMIPS) <NL> [    0.341127] devtmpfs: initialized <NL> [    0.343274] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.344121] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.345253] pinctrl core: initialized pinctrl subsystem <NL> [    0.346684] NET: Registered protocol family 16 <NL> [    0.348155] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.348157] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.350149] cpuidle: using governor menu <NL> [    0.352215] ACPI: bus type PCI registered <NL> [    0.353216] PCI: Using configuration type 1 for base access <NL> [    0.357650] Kprobes globally optimized <NL> [    0.485108] raid6: sse2x4   gen()  5312 MB/s <NL> [    0.503107] raid6: sse2x4   xor()  3811 MB/s <NL> [    0.521108] raid6: sse2x2   gen()  6571 MB/s <NL> [    0.539106] raid6: sse2x2   xor()  4677 MB/s <NL> [    0.557105] raid6: sse2x1   gen()  5403 MB/s <NL> [    0.575105] raid6: sse2x1   xor()  4299 MB/s <NL> [    0.576131] raid6: using algorithm sse2x2 gen() 6571 MB/s <NL> [    0.577105] raid6: .... xor() 4677 MB/s, rmw enabled <NL> [    0.578105] raid6: using intx1 recovery algorithm"}
{"timestamp_utc": "2024-07-31T08:12:19.534Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    0.579256] ACPI: Added _OSI(Module Device) <NL> [    0.580144] ACPI: Added _OSI(Processor Device) <NL> [    0.581116] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.582115] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.583115] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.584147] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.585119] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.587858] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.590034] ACPI: Interpreter enabled <NL> [    0.590130] ACPI: (supports S0 S3 S5) <NL> [    0.591106] ACPI: Using IOAPIC for interrupt routing <NL> [    0.592157] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.594277] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    0.597911] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    0.598133] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    0.599148] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    0.600295] PCI host bridge to bus 0000:00 <NL> [    0.601111] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    0.602104] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    0.603098] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    0.604098] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    0.604756] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    0.605099] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    0.605752] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    0.606103] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    0.607168] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    0.609552] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    0.611761] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    0.617450] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    0.619740] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    0.620103] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    0.620678] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    0.621115] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    0.622388] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    0.623505] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    0.624116] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    0.625482] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    0.628159] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    0.631163] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    0.640158] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    0.643341] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    0.645113] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    0.647734] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    0.655726] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    0.656461] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    0.658113] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    0.660735] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    0.668745] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    0.669465] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    0.672108] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    0.674108] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    0.681108] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    0.682470] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    0.685107] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    0.687740] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    0.694107] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    0.696440] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    0.698104] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    0.701105] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    0.709462] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    0.711177] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    0.712224] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    0.713202] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    0.714145] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    0.715556] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    0.716072] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    0.716109] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    0.717101] vgaarb: loaded <NL> [    0.718354] SCSI subsystem initialized <NL> [    0.720253] ACPI: bus type USB registered <NL> [    0.721193] usbcore: registered new interface driver usbfs <NL> [    0.722143] usbcore: registered new interface driver hub <NL> [    0.723178] usbcore: registered new device driver usb <NL> [    0.724160] pps_core: LinuxPPS API ver. 1 registered <NL> [    0.725099] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    0.726137] PTP clock support registered <NL> [    0.728785] Bluetooth: Core ver 2.22 <NL> [    0.729130] NET: Registered protocol family 31 <NL> [    0.730099] Bluetooth: HCI device and connection manager initialized <NL> [    0.731117] Bluetooth: HCI socket layer initialized <NL> [    0.732102] Bluetooth: L2CAP socket layer initialized <NL> [    0.733119] Bluetooth: SCO socket layer initialized <NL> [    0.735142] PCI: Using ACPI for IRQ routing <NL> [    0.736465] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    0.737131] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    0.738100] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    0.757988] clocksource: Switched to clocksource kvm-clock <NL> [    1.005900] pnp: PnP ACPI init <NL> [    1.013841] pnp: PnP ACPI: found 7 devices"}
{"timestamp_utc": "2024-07-31T08:12:19.535Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    1.036830] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.038189] NET: Registered protocol family 2 <NL> [    1.038861] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    1.045458] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    1.046732] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.047705] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    1.048624] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    1.054067] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.055862] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.057985] NET: Registered protocol family 1 <NL> [    1.081380] RPC: Registered named UNIX socket transport module. <NL> [    1.086893] RPC: Registered udp transport module. <NL> [    1.090206] RPC: Registered tcp transport module. <NL> [    1.090722] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    1.091478] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.092156] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.092757] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.093420] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.094450] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.095133] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.095883] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    1.096715] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.097366] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.104300] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.109631] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.114172] PCI: CLS 0 bytes, default 64 <NL> [    1.115580] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    1.136622] check: Scanning for low memory corruption every 60 seconds <NL> [    1.146042] Initialise system trusted keyrings <NL> [    1.148662] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    1.168212] NFS: Registering the id_resolver key type <NL> [    1.168812] Key type id_resolver registered <NL> [    1.169309] Key type id_legacy registered <NL> [    1.174834] Key type cifs.idmap registered <NL> [    1.178928] 9p: Installing v9fs 9p2000 file system support <NL> [    1.182432] xor: measuring software checksum speed <NL> [    1.183725]    prefetch64-sse  : 13773 MB/sec <NL> [    1.185146]    generic_sse     : 13590 MB/sec <NL> [    1.185729] xor: using function: prefetch64-sse (13773 MB/sec) <NL> [    1.186469] Key type asymmetric registered <NL> [    1.186990] Asymmetric key parser 'x509' registered <NL> [    1.187615] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    1.201083] io scheduler mq-deadline registered <NL> [    1.203292] io scheduler kyber registered <NL> [    1.206537] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    1.230048] ACPI: Power Button [PWRF] <NL> [    1.252647] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    1.254259] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    1.262211] N_HDLC line discipline registered with maxframe=4096 <NL> [    1.264919] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    1.267980] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    1.271735] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    1.275574] Linux agpgart interface v0.103 <NL> [    1.278032] ACPI: bus type drm_connector registered <NL> [    1.290712] brd: module loaded <NL> [    1.294868] loop: module loaded <NL> [    1.298153] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    1.304150] vda: detected capacity change from 0 to 2576215040 <NL> [    1.328428] Uniform Multi-Platform E-IDE driver <NL> [    1.332958] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    1.336668] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    1.340628] legacy IDE will be removed in 2021, please switch to libata <NL> [    1.340628] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    1.355743]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    1.359104]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    2.667389] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    3.304270] hdc: MWDMA2 mode selected <NL> [    3.305125] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    3.305646] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    3.306358] ide-gd driver 1.18 <NL> [    3.323354] e100: Intel(R) PRO/100 Network Driver <NL> [    3.323856] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    3.324442] e1000: Intel(R) PRO/1000 Network Driver <NL> [    3.324942] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    3.809237] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    3.810003] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    3.815276] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    4.386930] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:1f <NL> [    4.392502] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    4.398212] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    5.095985] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:20 <NL> [    5.096674] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection"}
{"timestamp_utc": "2024-07-31T08:12:19.536Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    5.097794] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    5.745688] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:21 <NL> [    5.755607] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    5.757270] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    5.758454] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    5.759872] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    5.768103] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    5.768741] PPP generic driver version 2.4.2 <NL> [    5.769332] PPP BSD Compression module registered <NL> [    5.769809] PPP Deflate Compression module registered <NL> [    5.770334] NET: Registered protocol family 24 <NL> [    5.770788] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    5.779782] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    5.780495] SLIP linefill/keepalive option. <NL> [    5.780935] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    5.781563] ehci-pci: EHCI PCI platform driver <NL> [    5.782045] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    5.782673] ohci-pci: OHCI PCI platform driver <NL> [    5.789367] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    5.790067] usbcore: registered new interface driver usb-storage <NL> [    5.790680] usbcore: registered new interface driver usbserial_generic <NL> [    5.799002] usbserial: USB Serial support registered for generic <NL> [    5.801361] usbcore: registered new interface driver ftdi_sio <NL> [    5.803434] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    5.805764] usbcore: registered new interface driver pl2303 <NL> [    5.808204] usbserial: USB Serial support registered for pl2303 <NL> [    5.810180] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    5.813879] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    5.814450] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    5.815059] mousedev: PS/2 mouse device common for all mice <NL> [    5.854122] rtc_cmos 00:00: RTC can wake from S4 <NL> [    5.855264] rtc_cmos 00:00: registered as rtc0 <NL> [    5.855897] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:13 UTC (1722413533) <NL> [    5.858154] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    5.876487] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    5.880967] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    5.911048] intel_pstate: CPU model not supported <NL> [    5.912283] sdhci: Secure Digital Host Controller Interface driver <NL> [    5.912952] sdhci: Copyright(c) Pierre Ossman <NL> [    5.913461] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    5.914256] usbcore: registered new interface driver usbhid <NL> [    5.914811] usbhid: USB HID core driver <NL> [    5.920209] u32 classifier <NL> [    5.921489]     input device check on <NL> [    5.922915]     Actions configured <NL> [    5.929074] xt_time: kernel timezone is -0000 <NL> [    5.931452] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    5.933845] gre: GRE over IPv4 demultiplexor driver <NL> [    5.941273] ip_gre: GRE over IPv4 tunneling driver <NL> [    5.942250] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    5.944099] NET: Registered protocol family 10 <NL> [    5.978984] Segment Routing with IPv6 <NL> [    5.979548] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    5.980450] ip6_gre: GRE over IPv6 tunneling driver <NL> [    5.981080] NET: Registered protocol family 17 <NL> [    5.981539] Bridge firewalling registered <NL> [    5.982014] 8021q: 802.1Q VLAN Support v1.8 <NL> [    5.982484] 9pnet: Installing 9P2000 support <NL> [    5.983052] Key type dns_resolver registered <NL> [    5.983536] NET: Registered protocol family 40 <NL> [    5.984550] IPI shorthand broadcast: enabled <NL> [    5.985028] sched_clock: Marking stable (5911093587, 73900886)->(7024455065, -1039460592) <NL> [    5.985859] registered taskstats version 1 <NL> [    5.986316] Loading compiled-in X.509 certificates <NL> [    6.036009] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    6.037890] Key type .fscrypt registered <NL> [    6.038293] Key type fscrypt-provisioning registered <NL> [    6.039326] Btrfs loaded, crc32c=crc32c-generic <NL> [    6.083033] Key type encrypted registered <NL> [    6.084354] printk: console [netcon0] enabled <NL> [    6.084789] netconsole: network logging started <NL> [    6.513864] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    6.526816] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    6.538769] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    6.555325] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    6.574648] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    6.606234] IP-Config: Failed to open gretap0 <NL> [    6.610467] IP-Config: Failed to open erspan0 <NL> [    6.626053] Sending DHCP requests . <NL> [    8.569548] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    8.572405] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    8.579720] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    8.605448] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [    8.618850] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [    8.619910] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [    8.644149] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> # 03:12:19 socket_monitor INFO: trying to connect to socket on host 'rtxoialp85.fnc.net.local', port 46473; retry every 5 seconds, waiting forever <NL> [    8.659485] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [    8.930942] ., OK"}
{"timestamp_utc": "2024-07-31T08:12:19.537Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    8.934578] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [    8.935300] IP-Config: Complete: <NL> [    8.935628]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [    8.941699]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [    8.954330]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [    8.954332]      nameserver0=10.0.2.3 <NL> [    9.260020] md: Waiting for all devices to be available before autodetect <NL> [    9.267722] md: If you don't use raid, use raid=noautodetect <NL> [    9.277286] md: Autodetecting RAID arrays. <NL> [    9.280860] md: autorun ... <NL> [    9.281567] md: ... autorun DONE. <NL> [    9.290283] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [    9.313677] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [    9.316645] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [    9.319151] devtmpfs: mounted <NL> [    9.327404] Freeing unused kernel image (initmem) memory: 1964K <NL> [    9.332248] Write protecting the kernel read-only data: 22528k <NL> [    9.341829] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [    9.350634] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [    9.353651] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [    9.617993] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [    9.631705] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   10.397521] #####FSS INIT: Running on host <NL> [   10.543788] #####FSS INIT: FSS system init pre startup script <NL> [   10.644719] random: python3: uninitialized urandom read (24 bytes read) <NL> (process:703): GLib-WARNING **: 03:12:01.448: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 1c654001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 6236058851 cycles <NL> [    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000020] tsc: Detected 2793.436 MHz processor <NL> [    0.011163] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.011247] x86/PAT: PAT not supported by the CPU. <NL> [    0.011256] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.028167] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.028287] check: Scanning 1 areas for low memory corruption <NL> [    0.028509] ACPI: Early table checksum verification disabled <NL> [    0.028540] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.028552] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.028570] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.028580] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.028587] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.028593] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.028599] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.028605] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.028619] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.028621] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.028623] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.028625] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.028627] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3]"}
{"timestamp_utc": "2024-07-31T08:12:19.538Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    0.028629] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.028714] Zone ranges: <NL> [    0.028716]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.028719]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.028721]   Normal   empty <NL> [    0.028724] Movable zone start for each node <NL> [    0.028725] Early memory node ranges <NL> [    0.028727]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.028729]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.028733] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.029636] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.029663] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.073811] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.074288] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.074310] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.074359] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.074364] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.074368] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.074370] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.074380] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.074382] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.074392] Using ACPI (MADT) for SMP configuration information <NL> [    0.074396] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.074407] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.074449] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.074452] Booting paravirtualized kernel on KVM <NL> [    0.074459] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.074476] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.086748] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.086807] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.086822] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.086827] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.087336] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.087505] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.087620] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.092350] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.092428] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.092441] Kernel/User page tables isolation: enabled <NL> [    0.092495] ftrace: allocating 47967 entries in 188 pages <NL> [    0.253052] ftrace: allocated 188 pages with 5 groups <NL> [    0.254112] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.254115] rcu: \tRCU event tracing is enabled. <NL> [    0.254117] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.254119] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.254120] \tRude variant of Tasks RCU enabled. <NL> [    0.254121] \tTracing variant of Tasks RCU enabled. <NL> [    0.254123] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.254125] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.259586] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.279049] Console: colour VGA+ 80x25 <NL> [    0.459911] printk: console [ttyS0] enabled <NL> [    0.460381] ACPI: Core revision 20200925 <NL> [    0.478581] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.480531] APIC: Switch to symmetric I/O mode setup <NL> [    0.482248] x2apic enabled <NL> [    0.483363] Switched APIC routing to physical x2apic. <NL> [    0.486212] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.487982] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    0.490247] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    0.491394] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.492249] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.493253] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.494258] Spectre V2 : Mitigation: Retpolines <NL> [    0.495249] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.496251] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.496919] Speculative Store Bypass: Vulnerable <NL> [    0.497251] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.498251] MMIO Stale Data: Unknown: No mitigations <NL> [    0.498737] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.531176] Freeing SMP alternatives memory: 48K <NL> [    0.531275] pid_max: default: 32768 minimum: 301 <NL> [    0.532300] LSM: Security Framework initializing <NL> [    0.534254] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.535268] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.591285] APIC calibration not consistent with PM-Timer: 106ms instead of 100ms <NL> [    0.592245] APIC delta adjusted to PM-Timer: 6249413 (6634727) <NL> [    0.592305] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.593599] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.595414] rcu: Hierarchical SRCU implementation. <NL> [    0.597531] smp: Bringing up secondary CPUs ... <NL> [    0.599499] x86: Booting SMP configuration: <NL> [    0.600264] .... node  #0, CPUs:      #1 <NL> [    0.212848] kvm-clock: cpu 1, msr 1c654041, secondary cpu clock <NL> [    0.212848] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.605298] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.607384]  #2 <NL> [    0.212848] kvm-clock: cpu 2, msr 1c654081, secondary cpu clock <NL> [    0.212848] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.613297] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    0.614503]  #3"}
{"timestamp_utc": "2024-07-31T08:12:19.539Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    0.212848] kvm-clock: cpu 3, msr 1c6540c1, secondary cpu clock <NL> [    0.212848] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.623328] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    0.624261] smp: Brought up 1 node, 4 CPUs <NL> [    0.625268] smpboot: Max logical packages: 4 <NL> [    0.626253] smpboot: Total of 4 processors activated (22347.48 BogoMIPS) <NL> [    0.635559] devtmpfs: initialized <NL> [    0.638263] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.639294] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.640350] pinctrl core: initialized pinctrl subsystem <NL> [    0.641821] NET: Registered protocol family 16 <NL> [    0.642563] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.642564] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.644279] cpuidle: using governor menu <NL> [    0.647409] ACPI: bus type PCI registered <NL> [    0.649303] PCI: Using configuration type 1 for base access <NL> [    0.654362] Kprobes globally optimized <NL> [    0.764253] raid6: sse2x4   gen()  6048 MB/s <NL> [    0.782255] raid6: sse2x4   xor()  3547 MB/s <NL> [    0.800254] raid6: sse2x2   gen()  6166 MB/s <NL> [    0.818253] raid6: sse2x2   xor()  4465 MB/s <NL> [    0.836257] raid6: sse2x1   gen()  5135 MB/s <NL> [    0.854258] raid6: sse2x1   xor()  3715 MB/s <NL> [    0.856277] raid6: using algorithm sse2x2 gen() 6166 MB/s <NL> [    0.857260] raid6: .... xor() 4465 MB/s, rmw enabled <NL> [    0.858256] raid6: using intx1 recovery algorithm <NL> [    0.859386] ACPI: Added _OSI(Module Device) <NL> [    0.860347] ACPI: Added _OSI(Processor Device) <NL> [    0.861311] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.862254] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.863256] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.864281] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.864955] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.867934] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.879064] ACPI: Interpreter enabled <NL> [    0.879279] ACPI: (supports S0 S3 S5) <NL> [    0.880254] ACPI: Using IOAPIC for interrupt routing <NL> [    0.881301] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.883553] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    0.889066] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    0.889270] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    0.890277] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    0.891438] PCI host bridge to bus 0000:00 <NL> [    0.892257] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    0.893250] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    0.894251] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    0.895251] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    0.896255] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    0.897252] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    0.898250] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    0.899258] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    0.901327] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    0.903837] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    0.905566] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    0.911256] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    0.914008] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    0.914259] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    0.915256] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    0.916250] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    0.917597] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    0.920663] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    0.921267] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    0.922694] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    0.926327] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    0.929309] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    0.940326] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    0.942610] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    0.945256] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    0.948255] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    0.956256] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    0.958524] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000"}
{"timestamp_utc": "2024-07-31T08:12:19.798Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    0.961252] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    0.963758] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    0.971257] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    0.972670] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    0.974907] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    0.977250] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    0.984868] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    0.986478] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    0.989255] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    0.991252] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    0.999309] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.001721] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.003913] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.005781] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.014873] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.015406] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.016393] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.017384] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.018338] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.020617] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.021245] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.021268] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.022252] vgaarb: loaded <NL> [    1.023546] SCSI subsystem initialized <NL> [    1.027351] ACPI: bus type USB registered <NL> [    1.028328] usbcore: registered new interface driver usbfs <NL> [    1.030284] usbcore: registered new interface driver hub <NL> [    1.032259] usbcore: registered new device driver usb <NL> [    1.033298] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.034251] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.035263] PTP clock support registered <NL> [    1.038851] Bluetooth: Core ver 2.22 <NL> [    1.039281] NET: Registered protocol family 31 <NL> [    1.040250] Bluetooth: HCI device and connection manager initialized <NL> [    1.041265] Bluetooth: HCI socket layer initialized <NL> [    1.042252] Bluetooth: L2CAP socket layer initialized <NL> [    1.042920] Bluetooth: SCO socket layer initialized <NL> [    1.045297] PCI: Using ACPI for IRQ routing <NL> [    1.047251] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.048048] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.048250] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.055510] clocksource: Switched to clocksource kvm-clock <NL> [    1.505913] pnp: PnP ACPI init <NL> [    1.509162] pnp: PnP ACPI: found 7 devices <NL> [    1.520796] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.522765] NET: Registered protocol family 2 <NL> [    1.523353] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    1.524984] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    1.525776] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.526646] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    1.530934] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    1.536495] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.541974] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.547023] NET: Registered protocol family 1 <NL> [    1.569434] RPC: Registered named UNIX socket transport module. <NL> [    1.572549] RPC: Registered udp transport module. <NL> [    1.574802] RPC: Registered tcp transport module. <NL> [    1.576962] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    1.580318] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.583384] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.586413] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.589297] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.592254] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.595049] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.598112] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    1.601622] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.604380] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.607262] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.610191] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.613684] PCI: CLS 0 bytes, default 64 <NL> [    1.614468] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    1.650618] check: Scanning for low memory corruption every 60 seconds <NL> [    1.655677] Initialise system trusted keyrings <NL> [    1.663354] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    1.671815] NFS: Registering the id_resolver key type <NL> [    1.676334] Key type id_resolver registered <NL> [    1.679211] Key type id_legacy registered <NL> [    1.696091] Key type cifs.idmap registered <NL> [    1.698540] 9p: Installing v9fs 9p2000 file system support <NL> [    1.701281] xor: measuring software checksum speed <NL> [    1.704535]    prefetch64-sse  : 15351 MB/sec <NL> [    1.708571]    generic_sse     : 11920 MB/sec <NL> [    1.711502] xor: using function: prefetch64-sse (15351 MB/sec) <NL> [    1.713840] Key type asymmetric registered <NL> [    1.714389] Asymmetric key parser 'x509' registered <NL> [    1.715033] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    1.729466] io scheduler mq-deadline registered <NL> [    1.731499] io scheduler kyber registered <NL> [    1.734663] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    1.748922] ACPI: Power Button [PWRF] <NL> [    1.760089] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    1.760639] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    1.767505] N_HDLC line discipline registered with maxframe=4096 <NL> [    1.769175] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    1.769946] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    1.771226] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    1.776395] Linux agpgart interface v0.103 <NL> [    1.777557] ACPI: bus type drm_connector registered <NL> [    1.810330] brd: module loaded <NL> [    1.816475] loop: module loaded <NL> [    1.820687] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    1.829135] vda: detected capacity change from 0 to 2576215040"}
{"timestamp_utc": "2024-07-31T08:12:19.799Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    1.847547] Uniform Multi-Platform E-IDE driver <NL> [    1.853051] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    1.859801] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    1.866306] legacy IDE will be removed in 2021, please switch to libata <NL> [    1.866306] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    1.878024]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    1.881762]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    3.141047] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    3.777116] hdc: MWDMA2 mode selected <NL> [    3.777667] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    3.778193] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    3.778860] ide-gd driver 1.18 <NL> [    3.781777] e100: Intel(R) PRO/100 Network Driver <NL> [    3.782457] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    3.783267] e1000: Intel(R) PRO/1000 Network Driver <NL> [    3.783903] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.391238] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    4.401223] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    4.419680] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    4.825185] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:14 <NL> [    4.842306] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    4.843944] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    5.686957] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:15 <NL> [    5.687625] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    5.688723] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    6.090406] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:16 <NL> [    6.099653] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.108056] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    6.111794] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    6.114643] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    6.118089] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    6.118969] PPP generic driver version 2.4.2 <NL> [    6.119558] PPP BSD Compression module registered <NL> [    6.121965] PPP Deflate Compression module registered <NL> [    6.122456] NET: Registered protocol family 24 <NL> [    6.122916] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    6.123824] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    6.124515] SLIP linefill/keepalive option. <NL> [    6.124950] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    6.125568] ehci-pci: EHCI PCI platform driver <NL> [    6.130141] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    6.130777] ohci-pci: OHCI PCI platform driver <NL> [    6.131260] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    6.131949] usbcore: registered new interface driver usb-storage <NL> [    6.132547] usbcore: registered new interface driver usbserial_generic <NL> [    6.137580] usbserial: USB Serial support registered for generic <NL> [    6.138531] usbcore: registered new interface driver ftdi_sio <NL> [    6.139423] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    6.140513] usbcore: registered new interface driver pl2303 <NL> [    6.148997] usbserial: USB Serial support registered for pl2303 <NL> [    6.150018] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    6.155155] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    6.155729] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    6.157046] mousedev: PS/2 mouse device common for all mice <NL> [    6.157845] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    6.181636] rtc_cmos 00:00: RTC can wake from S4 <NL> [    6.183906] rtc_cmos 00:00: registered as rtc0 <NL> [    6.184825] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:14 UTC (1722413534) <NL> [    6.185626] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    6.188062] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    6.198708] intel_pstate: CPU model not supported <NL> [    6.199366] sdhci: Secure Digital Host Controller Interface driver <NL> [    6.199966] sdhci: Copyright(c) Pierre Ossman <NL> [    6.200437] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    6.201164] usbcore: registered new interface driver usbhid <NL> [    6.201700] usbhid: USB HID core driver <NL> [    6.202166] u32 classifier <NL> [    6.202432]     input device check on <NL> [    6.202784]     Actions configured <NL> [    6.203560] xt_time: kernel timezone is -0000 <NL> [    6.204060] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.204741] gre: GRE over IPv4 demultiplexor driver <NL> [    6.205240] ip_gre: GRE over IPv4 tunneling driver <NL> [    6.206127] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    6.211756] NET: Registered protocol family 10 <NL> [    6.224417] Segment Routing with IPv6 <NL> [    6.226372] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.231581] ip6_gre: GRE over IPv6 tunneling driver <NL> [    6.233383] NET: Registered protocol family 17 <NL> [    6.235138] Bridge firewalling registered <NL> [    6.237214] 8021q: 802.1Q VLAN Support v1.8 <NL> [    6.239822] 9pnet: Installing 9P2000 support <NL> [    6.241446] Key type dns_resolver registered <NL> [    6.244444] NET: Registered protocol family 40 <NL> [    6.247756] IPI shorthand broadcast: enabled <NL> [    6.250128] sched_clock: Marking stable (6038224741, 211848113)->(7067780339, -817707485) <NL> [    6.257650] registered taskstats version 1 <NL> [    6.259362] Loading compiled-in X.509 certificates <NL> [    6.278270] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    6.283736] Key type .fscrypt registered <NL> [    6.284252] Key type fscrypt-provisioning registered <NL> [    6.285350] Btrfs loaded, crc32c=crc32c-generic <NL> [    6.296729] Key type encrypted registered <NL> [    6.300137] printk: console [netcon0] enabled <NL> [    6.309531] netconsole: network logging started <NL> [    6.912732] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    6.938468] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    6.978067] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    7.020988] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    7.025680] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    7.027776] IP-Config: Failed to open gretap0 <NL> [    7.032118] IP-Config: Failed to open erspan0 <NL> [    7.052895] Sending DHCP requests . <NL> [    8.966395] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    8.968730] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready"}
{"timestamp_utc": "2024-07-31T08:12:19.800Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    9.030401] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.041659] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [    9.052961] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.072466] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.083470] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [    9.091497] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [    9.485818] ., OK <NL> [    9.494444] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [    9.495680] IP-Config: Complete: <NL> [    9.502251]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [    9.512578]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [    9.513122]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [    9.513124]      nameserver0=10.0.2.3 <NL> [    9.743821] md: Waiting for all devices to be available before autodetect <NL> [    9.746130] md: If you don't use raid, use raid=noautodetect <NL> [    9.749732] md: Autodetecting RAID arrays. <NL> [    9.750141] md: autorun ... <NL> [    9.750422] md: ... autorun DONE. <NL> [    9.787922] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [    9.813074] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [    9.814148] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [    9.825111] devtmpfs: mounted <NL> [    9.842965] Freeing unused kernel image (initmem) memory: 1964K <NL> [    9.848809] Write protecting the kernel read-only data: 22528k <NL> [    9.866557] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [    9.895315] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [    9.915971] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   10.130012] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   10.137655] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   10.256063] #####FSS INIT: Running on host <NL> [   10.467708] #####FSS INIT: FSS system init pre startup script <NL> [   10.496830] random: python3: uninitialized urandom read (24 bytes read) <NL> # 03:12:19 socket_monitor INFO: connected to socket on host 'rtxoialp85.fnc.net.local', port 46473 <NL> (process:707): GLib-WARNING **: 03:12:01.472: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 3ec54001, primary cpu clock <NL> [    0.000000] kvm-clock: using sched offset of 2062066598 cycles <NL> [    0.000006] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000017] tsc: Detected 2793.436 MHz processor <NL> [    0.001801] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.001870] x86/PAT: PAT not supported by the CPU. <NL> [    0.001878] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.015255] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.015371] check: Scanning 1 areas for low memory corruption <NL> [    0.015858] ACPI: Early table checksum verification disabled <NL> [    0.015886] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.015898] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.015913] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.015922] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.015928] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.015932] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.015938] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.015943] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.015948] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.015950] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.015952] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.015953] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.015955] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.015956] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.016046] Zone ranges: <NL> [    0.016048]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.016051]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.016053]   Normal   empty <NL> [    0.016055] Movable zone start for each node <NL> [    0.016056] Early memory node ranges <NL> [    0.016058]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.016060]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.016062] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.017411] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.017439] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.030479] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.030929] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.030947] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.030987] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23"}
{"timestamp_utc": "2024-07-31T08:12:19.801Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    0.030991] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.030994] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.030995] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.031003] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.031005] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.031014] Using ACPI (MADT) for SMP configuration information <NL> [    0.031016] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.031025] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.031058] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.031060] Booting paravirtualized kernel on KVM <NL> [    0.031065] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.031079] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.032522] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.032564] kvm-guest: stealtime: cpu 0, msr 3fc1b600 <NL> [    0.032573] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.032576] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.033040] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.033134] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.033770] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.048462] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.048532] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.048542] Kernel/User page tables isolation: enabled <NL> [    0.048574] ftrace: allocating 47967 entries in 188 pages <NL> [    0.205773] ftrace: allocated 188 pages with 5 groups <NL> [    0.206745] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.206746] rcu: \tRCU event tracing is enabled. <NL> [    0.206748] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.206750] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.206751] \tRude variant of Tasks RCU enabled. <NL> [    0.206752] \tTracing variant of Tasks RCU enabled. <NL> [    0.206754] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.206756] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.214036] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.239666] Console: colour VGA+ 80x25 <NL> [    0.504428] printk: console [ttyS0] enabled <NL> [    0.504861] ACPI: Core revision 20200925 <NL> [    0.505407] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.506439] APIC: Switch to symmetric I/O mode setup <NL> [    0.514414] x2apic enabled <NL> [    0.514987] Switched APIC routing to physical x2apic. <NL> [    0.516819] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.520718] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    0.521738] Calibrating delay loop (skipped) preset value.. 5586.87 BogoMIPS (lpj=2793436) <NL> [    0.522653] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.522751] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.523350] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.523737] Spectre V2 : Mitigation: Retpolines <NL> [    0.523737] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.523742] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.524740] Speculative Store Bypass: Vulnerable <NL> [    0.525740] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.526393] MMIO Stale Data: Unknown: No mitigations <NL> [    0.526742] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.556861] Freeing SMP alternatives memory: 48K <NL> [    0.557354] pid_max: default: 32768 minimum: 301 <NL> [    0.557771] LSM: Security Framework initializing <NL> [    0.558749] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.559745] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.579913] APIC calibration not consistent with PM-Timer: 102ms instead of 100ms <NL> [    0.580591] APIC delta adjusted to PM-Timer: 6250571 (6416565) <NL> [    0.580737] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.581035] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.582873] rcu: Hierarchical SRCU implementation. <NL> [    0.584842] smp: Bringing up secondary CPUs ... <NL> [    0.586075] x86: Booting SMP configuration: <NL> [    0.586745] .... node  #0, CPUs:      #1 <NL> [    0.305400] kvm-clock: cpu 1, msr 3ec54041, secondary cpu clock <NL> [    0.305400] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.593802] kvm-guest: stealtime: cpu 1, msr 3fc9b600 <NL> [    0.594979]  #2 <NL> [    0.305400] kvm-clock: cpu 2, msr 3ec54081, secondary cpu clock <NL> [    0.305400] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.599788] kvm-guest: stealtime: cpu 2, msr 3fd1b600 <NL> [    0.602978]  #3 <NL> [    0.305400] kvm-clock: cpu 3, msr 3ec540c1, secondary cpu clock <NL> [    0.305400] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.606782] kvm-guest: stealtime: cpu 3, msr 3fd9b600"}
{"timestamp_utc": "2024-07-31T08:12:19.802Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    0.607770] smp: Brought up 1 node, 4 CPUs <NL> [    0.608858] smpboot: Max logical packages: 4 <NL> [    0.609766] smpboot: Total of 4 processors activated (22347.48 BogoMIPS) <NL> [    0.617747] devtmpfs: initialized <NL> [    0.619966] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.620749] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.621835] pinctrl core: initialized pinctrl subsystem <NL> [    0.624759] NET: Registered protocol family 16 <NL> [    0.625794] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.625797] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.626761] cpuidle: using governor menu <NL> [    0.627809] ACPI: bus type PCI registered <NL> [    0.628882] PCI: Using configuration type 1 for base access <NL> [    0.637434] Kprobes globally optimized <NL> [    0.815746] raid6: sse2x4   gen()  5471 MB/s <NL> [    0.834747] raid6: sse2x4   xor()  2823 MB/s <NL> [    0.852747] raid6: sse2x2   gen()  5898 MB/s <NL> [    0.870749] raid6: sse2x2   xor()  4163 MB/s <NL> [    0.888746] raid6: sse2x1   gen()  4592 MB/s <NL> [    0.906752] raid6: sse2x1   xor()  3240 MB/s <NL> [    0.908754] raid6: using algorithm sse2x2 gen() 5898 MB/s <NL> [    0.909752] raid6: .... xor() 4163 MB/s, rmw enabled <NL> [    0.910747] raid6: using intx1 recovery algorithm <NL> [    0.911841] ACPI: Added _OSI(Module Device) <NL> [    0.912748] ACPI: Added _OSI(Processor Device) <NL> [    0.913751] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.914750] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.915751] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.916753] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.917756] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.920263] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.922961] ACPI: Interpreter enabled <NL> [    0.923886] ACPI: (supports S0 S3 S5) <NL> [    0.924744] ACPI: Using IOAPIC for interrupt routing <NL> [    0.925783] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.926983] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    0.932129] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    0.932763] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    0.933773] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    0.934883] PCI host bridge to bus 0000:00 <NL> [    0.935279] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    0.935743] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    0.936741] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    0.937752] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    0.938740] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    0.939740] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    0.940457] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    0.940743] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    0.942756] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    0.943847] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    0.944975] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    0.950746] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    0.953089] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    0.953752] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    0.954743] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    0.955752] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    0.956986] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    0.958170] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    0.958759] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    0.961961] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    0.964603] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    0.966798] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    0.976809] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    0.978997] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    0.981746] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    0.985750] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    0.994749] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    0.996063] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    0.998382] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    0.999748] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.007753] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.008893] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.010753] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.013746] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.021365] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.022051] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.023745] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.026749] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.035403] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.036091] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.038410] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.040750] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.054002] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.055820] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.056924] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.057900] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.058848] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.061835] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.062478] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.062746] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.063740] vgaarb: loaded <NL> [    1.066892] SCSI subsystem initialized <NL> [    1.070820] ACPI: bus type USB registered <NL> [    1.071789] usbcore: registered new interface driver usbfs <NL> [    1.072340] usbcore: registered new interface driver hub <NL> [    1.072755] usbcore: registered new device driver usb <NL> [    1.073803] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.074739] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.075746] PTP clock support registered <NL> [    1.077982] Bluetooth: Core ver 2.22 <NL> [    1.078400] NET: Registered protocol family 31 <NL> [    1.078741] Bluetooth: HCI device and connection manager initialized"}
{"timestamp_utc": "2024-07-31T08:12:19.803Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    1.079761] Bluetooth: HCI socket layer initialized <NL> [    1.080741] Bluetooth: L2CAP socket layer initialized <NL> [    1.081769] Bluetooth: SCO socket layer initialized <NL> [    1.086793] PCI: Using ACPI for IRQ routing <NL> [    1.088046] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.088764] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.089742] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.103342] clocksource: Switched to clocksource kvm-clock <NL> [    1.728109] pnp: PnP ACPI init <NL> [    1.730689] pnp: PnP ACPI: found 7 devices <NL> [    1.767775] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.779774] NET: Registered protocol family 2 <NL> [    1.790802] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    1.812575] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    1.815162] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.866444] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    1.867780] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    1.868961] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.880962] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.889561] NET: Registered protocol family 1 <NL> [    1.933798] RPC: Registered named UNIX socket transport module. <NL> [    1.934437] RPC: Registered udp transport module. <NL> [    1.934894] RPC: Registered tcp transport module. <NL> [    1.935372] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    1.936090] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.946919] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.947525] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.948118] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.948713] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.949310] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.949971] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    1.963410] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.973671] pci 0000:00:00.0: quirk_passive_release+0x0/0x80 took 10027 usecs <NL> [    1.974356] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.974939] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.975601] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.976468] PCI: CLS 0 bytes, default 64 <NL> [    1.977038] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x284407e0e7a, max_idle_ns: 440795310592 ns <NL> [    2.040177] check: Scanning for low memory corruption every 60 seconds <NL> [    2.051966] Initialise system trusted keyrings <NL> [    2.062545] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.096528] NFS: Registering the id_resolver key type <NL> [    2.111654] Key type id_resolver registered <NL> [    2.120420] Key type id_legacy registered <NL> [    2.154360] Key type cifs.idmap registered <NL> [    2.156026] 9p: Installing v9fs 9p2000 file system support <NL> [    2.166559] xor: measuring software checksum speed <NL> [    2.168887]    prefetch64-sse  : 20047 MB/sec <NL> [    2.180078]    generic_sse     : 11884 MB/sec <NL> [    2.191323] xor: using function: prefetch64-sse (20047 MB/sec) <NL> [    2.193513] Key type asymmetric registered <NL> [    2.204257] Asymmetric key parser 'x509' registered <NL> [    2.205955] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.227232] io scheduler mq-deadline registered <NL> [    2.228530] io scheduler kyber registered <NL> [    2.230082] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.240469] ACPI: Power Button [PWRF] <NL> [    2.267149] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.271109] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.275708] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.285506] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.286568] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.299039] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.301942] Linux agpgart interface v0.103 <NL> [    2.303311] ACPI: bus type drm_connector registered <NL> [    2.308076] brd: module loaded <NL> [    2.317162] loop: module loaded <NL> [    2.323761] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.332476] vda: detected capacity change from 0 to 2576215040 <NL> [    2.352703] Uniform Multi-Platform E-IDE driver <NL> [    2.353455] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.354499] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.356020] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.356020] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.364346]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.365069]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    3.655480] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.298563] hdc: MWDMA2 mode selected <NL> [    4.301247] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.308142] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.310314] ide-gd driver 1.18 <NL> [    4.363432] e100: Intel(R) PRO/100 Network Driver <NL> [    4.364693] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.365326] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.365848] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.850662] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    4.852613] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    4.853781] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    5.447039] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:2a <NL> [    5.448113] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.453785] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    5.871942] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:2b <NL> [    5.872630] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    5.873724] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    6.259170] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:2c <NL> [    6.259844] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.260557] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    6.261038] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    6.261693] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    6.267278] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    6.267862] PPP generic driver version 2.4.2 <NL> [    6.268371] PPP BSD Compression module registered <NL> [    6.268836] PPP Deflate Compression module registered <NL> [    6.269336] NET: Registered protocol family 24 <NL> [    6.269794] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    6.270723] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    6.271622] SLIP linefill/keepalive option."}
{"timestamp_utc": "2024-07-31T08:12:19.804Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    6.272055] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    6.272682] ehci-pci: EHCI PCI platform driver <NL> [    6.273163] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    6.273785] ohci-pci: OHCI PCI platform driver <NL> [    6.274240] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    6.274912] usbcore: registered new interface driver usb-storage <NL> [    6.275678] usbcore: registered new interface driver usbserial_generic <NL> [    6.276322] usbserial: USB Serial support registered for generic <NL> [    6.276901] usbcore: registered new interface driver ftdi_sio <NL> [    6.277441] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    6.278117] usbcore: registered new interface driver pl2303 <NL> [    6.278668] usbserial: USB Serial support registered for pl2303 <NL> [    6.286429] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    6.291560] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    6.292120] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    6.292730] mousedev: PS/2 mouse device common for all mice <NL> [    6.293689] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    6.295769] rtc_cmos 00:00: RTC can wake from S4 <NL> [    6.296808] rtc_cmos 00:00: registered as rtc0 <NL> [    6.324361] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:11 UTC (1722413531) <NL> [    6.340642] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    6.347603] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    6.348682] intel_pstate: CPU model not supported <NL> [    6.349170] sdhci: Secure Digital Host Controller Interface driver <NL> [    6.349782] sdhci: Copyright(c) Pierre Ossman <NL> [    6.350270] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    6.350956] usbcore: registered new interface driver usbhid <NL> [    6.351488] usbhid: USB HID core driver <NL> [    6.352813] u32 classifier <NL> [    6.353080]     input device check on <NL> [    6.353867]     Actions configured <NL> [    6.354790] xt_time: kernel timezone is -0000 <NL> [    6.355296] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.355995] gre: GRE over IPv4 demultiplexor driver <NL> [    6.356471] ip_gre: GRE over IPv4 tunneling driver <NL> [    6.360181] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    6.383526] NET: Registered protocol family 10 <NL> [    6.399555] Segment Routing with IPv6 <NL> [    6.400129] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.401069] ip6_gre: GRE over IPv6 tunneling driver <NL> [    6.404688] NET: Registered protocol family 17 <NL> [    6.405209] Bridge firewalling registered <NL> [    6.405683] 8021q: 802.1Q VLAN Support v1.8 <NL> [    6.406149] 9pnet: Installing 9P2000 support <NL> [    6.406624] Key type dns_resolver registered <NL> [    6.407122] NET: Registered protocol family 40 <NL> [    6.408165] IPI shorthand broadcast: enabled <NL> [    6.408653] sched_clock: Marking stable (6104210405, 304400731)->(7993905575, -1585294439) <NL> [    6.409561] registered taskstats version 1 <NL> [    6.409985] Loading compiled-in X.509 certificates <NL> [    6.442288] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    6.443367] Key type .fscrypt registered <NL> [    6.443841] Key type fscrypt-provisioning registered <NL> [    6.444988] Btrfs loaded, crc32c=crc32c-generic <NL> [    6.468747] Key type encrypted registered <NL> [    6.469650] printk: console [netcon0] enabled <NL> [    6.470442] netconsole: network logging started <NL> [    7.002195] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    7.034686] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    7.043547] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    7.048437] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    7.081877] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    7.088192] IP-Config: Failed to open gretap0 <NL> [    7.094104] IP-Config: Failed to open erspan0 <NL> [    7.109684] Sending DHCP requests . <NL> [    9.064713] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.067529] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.068689] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [    9.069390] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [    9.128040] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.134642] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.142766] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [    9.145907] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [    9.983204] ., OK <NL> [    9.985271] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [    9.986500] IP-Config: Complete: <NL> [    9.987048]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [    9.988521]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [    9.989368]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [    9.989369]      nameserver0=10.0.2.3 <NL> [   10.308203] md: Waiting for all devices to be available before autodetect <NL> [   10.313741] md: If you don't use raid, use raid=noautodetect <NL> [   10.322694] md: Autodetecting RAID arrays. <NL> [   10.325069] md: autorun ... <NL> [   10.329051] md: ... autorun DONE. <NL> [   10.334359] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   10.410976] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   10.416370] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   10.420003] devtmpfs: mounted <NL> [   10.426946] Freeing unused kernel image (initmem) memory: 1964K <NL> [   10.435530] Write protecting the kernel read-only data: 22528k <NL> [   10.444473] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   10.451870] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   10.456381] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   10.889873] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   10.895346] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   11.036836] #####FSS INIT: Running on host <NL> [   11.197653] #####FSS INIT: FSS system init pre startup script <NL> [   11.254966] random: python3: uninitialized urandom read (24 bytes read) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:19 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46534, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46534, username 'fujitsu', password '1finity', key_filename None <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6."}
{"timestamp_utc": "2024-07-31T08:12:19.805Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "from cryptography.hazmat.backends import default_backend <NL> # 03:12:19 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46502, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:19 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46488, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46488, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46488\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:19 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46486, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:12:20.060Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s01.NE2-main-debug-ssh", "step_id": "s01.NE2-main-debug-ssh", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:19 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46518, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46518, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:19 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46518\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:20.061Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p04.NE2-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p04", "keyword_name": "NE2-trib1-debug-ssh", "step_id": "NE2-trib1-debug-ssh", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:20 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46504, with username 'fujitsu', password '1finity', key_filename None <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:20 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46472, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46504, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:20 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46504\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46472, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:20 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46472\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:20.316Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p02.NE1-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p02", "keyword_name": "NE1-trib1-debug-ssh", "step_id": "NE1-trib1-debug-ssh", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:20 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46520, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46520, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:20 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46520\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:21.244Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   13.245154] random: crng init done <NL> [   14.254196] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   14.263291] #####FSS INIT: FSS no slotRole found <NL> [   14.271042] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   14.285510] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   14.338305] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   14.350583] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   14.376950] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   14.382939] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> sh: -d: unknown operand <NL> [   14.412490] #####FSS INIT:systemd will take it from here! <NL> [   14.523512] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   14.526753] systemd[1]: Detected virtualization kvm. <NL> [   14.536375] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   14.569343] systemd[1]: Hostname set to <fujitsu>. <NL> [   14.582765] systemd[1]: Initializing machine ID from random generator. <NL> [   14.756670] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   14.864869] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   15.255930] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.293129] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.336230] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.380290] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.394795] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.430620] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.436965] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.487250] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.492687] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.570953] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.594529] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.624801] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.629236] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.638297] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.656371] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.659058] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.682662] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.684894] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.699300] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.705564] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.726365] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.748622] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   15.757737] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   15.787523] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:21.822Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   15.790496] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:21.823Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   15.803186] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.818574] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.866303] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.869901] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.897695] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.907898] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.947274] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.951160] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.976150] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.979501] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.984272] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.987565] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.014678] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.018200] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.091501] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.126258] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.129856] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.146044] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.167396] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.175019] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.190177] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.196742] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.213477] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.215677] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.228989] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.234187] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.246215] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.248353] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.263333] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.265479] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.307734] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   16.342433] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details."}
{"timestamp_utc": "2024-07-31T08:12:23.194Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   16.393160] systemd[1]: Created slice Slice /system/getty."}
{"timestamp_utc": "2024-07-31T08:12:23.195Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   16.406240] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   16.415276] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   16.427842] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   16.436223] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   16.444136] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   16.454391] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   16.487049] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   16.507701] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   16.514422] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   16.522721] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   16.525206] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   16.607329] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   16.611220] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   16.623782] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   16.651021] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   16.658244] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   16.659608] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   16.712462] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   16.716227] systemd[1]: Listening on udev Control Socket. <NL> [   16.722514] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   16.752594] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   16.767201] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   16.834835] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   16.887561] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   16.927349] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   16.969013] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   16.989153] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   17.027003] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   17.067799] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   17.096519] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   17.120121] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   17.159856] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   17.202865] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   17.229709] fuse: init (API version 7.32) <NL> [   17.236078] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   17.263535] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   17.294925] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   17.350717] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   17.355982] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;[   17.368803] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> 1;39mRPC Bind\u001b[0m. <NL> [   17.395425] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   17.407343] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   17.428964] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   17.456724] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   17.470566] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   17.473432] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   17.481484] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   17.485112] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   17.490060] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   17.497030] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   17.501831] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   17.518353] dcn_phantom_drv: VIF Support v1.0 <NL> [   17.521197] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   17.530844] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   17.544734] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   17.559336] packet_injector_class: driver registered correctly with major number 246 <NL> [   17.560871] Packet_injector 257949696: minor device creation 246:0 <NL> [   17.561712] Packet_injector 257949697: minor device creation 246:1 <NL> [   17.562381] Packet_injector 257949698: minor device creation 246:2 <NL> [   17.563269] Packet_injector 257949699: minor device creation 246:3 <NL> [   17.563307] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   17.567446] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   17.568503] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   17.610616] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   17.640024] systemd[1]: Finished Load Kernel Modules."}
{"timestamp_utc": "2024-07-31T08:12:23.758Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   16.026373] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   16.072112] #####FSS INIT: FSS no slotRole found <NL> [   16.098573] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   16.102695] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   16.124942] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   16.158027] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   16.179512] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   16.190166] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   16.219929] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   16.310231] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   16.386068] systemd[1]: Detected virtualization kvm. <NL> [   16.391273] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   16.440861] systemd[1]: Hostname set to <fujitsu>. <NL> [   16.452706] systemd[1]: Initializing machine ID from random generator. <NL> [   16.617295] systemd-sysv-generator[342]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   16.694554] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   17.668852] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.671148] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.677887] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.723050] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.774950] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.793063] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.795296] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.827961] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.844212] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.978350] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.981766] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.016085] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.092634] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:23.759Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   18.105815] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.146756] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.168595] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.227689] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.239326] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.268019] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.282408] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.363280] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.366135] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   18.368299] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   18.412850] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:24.691Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   12.359274] random: crng init done <NL> [   14.366270] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   14.382696] #####FSS INIT: FSS no slotRole found <NL> [   14.383260] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   14.383973] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   14.416861] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   14.427240] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   14.437057] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   14.452595] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   14.480296] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   14.588889] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   14.622740] systemd[1]: Detected virtualization kvm. <NL> [   14.623270] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   14.684093] systemd[1]: Hostname set to <fujitsu>. <NL> [   14.695608] systemd[1]: Initializing machine ID from random generator. <NL> [   14.813203] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   14.853525] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   15.053494] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.077433] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.122217] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.138652] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.166426] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.184576] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.198071] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.222301] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.230628] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.270507] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.273772] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.312973] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.353382] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.376498] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.426589] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.436381] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.483142] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.486302] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.520322] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.531643] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.554705] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.574727] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   15.577965] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   15.586635] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.594331] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> # 03:12:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:12:24.692Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:12:24 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46488, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:24 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46488\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:24.947Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   18.425571] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.485033] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.487354] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.542746] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.550075] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.597186] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.606982] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.696672] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.710460] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:24.948Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   18.717497] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.729897] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.779053] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.808066] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.871469] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.897290] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.030835] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.183078] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.184915] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.245854] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.270258] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.310241] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.322670] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.324846] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.332663] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.343019] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.363702] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.366212] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.372739] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.381872] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.414746] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.416857] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.440444] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   19.518095] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   19.544988] systemd[1]: Created slice Slice /system/getty. <NL> # 03:12:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46518, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:24 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46518\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:25.231Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p04.NE2-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p04", "keyword_name": "NE2-trib1-debug-ssh", "step_id": "NE2-trib1-debug-ssh", "message_content": "# 03:12:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46504, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:25 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46504\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46472, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:25 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46472\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46520, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:25 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46520\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:25.491Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   14.256425] random: crng init done <NL> [   16.418524] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   16.440039] #####FSS INIT: FSS no slotRole found <NL> [   16.440591] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   16.441332] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   16.501985] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   16.516157] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   16.535295] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   16.536220] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   16.554616] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   16.614733] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   16.641565] systemd[1]: Detected virtualization kvm. <NL> [   16.642063] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   16.652313] systemd[1]: Hostname set to <fujitsu>. <NL> [   16.653788] systemd[1]: Initializing machine ID from random generator. <NL> [   16.705486] systemd-sysv-generator[341]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   16.753305] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   17.082578] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.119289] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.146202] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.165166] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.193916] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.213850] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.227254] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.241435] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.259860] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.274309] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.289605] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.319970] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.335531] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.343648] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.354797] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.377807] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.396537] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.420914] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.443701] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.449805] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.465966] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.484527] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.493227] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.517128] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:25.753Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   15.606415] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.613221] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.651186] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.658548] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.682577] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.692392] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.724274] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.727708] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.752126] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.755565] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.762916] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.770828] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.792029] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.795774] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.923461] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.003469] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.010002] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.067695] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.091715] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.112008] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:25.754Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   16.174475] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.184556] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.225501] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.228710] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.267481] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.279441] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.307179] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.311133] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.325781] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.338361] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.384841] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   16.433939] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   16.458046] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:26.012Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   17.529824] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.542665] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.553594] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.583077] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.603866] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.642434] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.654156] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.660069] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.662248] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.689506] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.691666] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.707053] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.712350] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.740591] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.749974] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.779813] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.812882] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.837117] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.881348] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.931631] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.962819] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.991382] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.002286] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.018423] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.028684] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.042127] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.054339] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.075044] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.077323] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.088438] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.098282] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:26.013Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   18.124550] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -."}
{"timestamp_utc": "2024-07-31T08:12:26.580Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   19.564267] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   19.566807] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   19.577439] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   19.642175] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   19.677314] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   19.691670] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   19.714062] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   19.717490] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   19.733614] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   19.737509] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   19.770093] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   19.813905] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   19.848105] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   19.859921] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   19.879526] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   19.888931] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   19.893976] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   19.901540] systemd[1]: Starting Journal Socket... <NL> [   19.902285] systemd[348]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   19.937720] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   19.947202] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   19.956398] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   19.973520] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   19.999523] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   20.021230] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   20.076916] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:12:26.581Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   20.094229] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   20.125356] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   20.153654] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   20.180848] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   20.203754] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   20.244135] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   20.319286] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   20.372263] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   20.400583] fuse: init (API version 7.32) <NL> [   20.411731] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   20.472159] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   20.513584] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   20.611415] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   20.646512] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   20.658532] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   20.668193] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   20.729363] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   20.749343] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   20.751306] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   20.783650] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   20.795428] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   20.812636] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   20.815822] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   20.828126] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   20.832108] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   20.840147] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   20.867653] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   20.894226] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   20.896673] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore)."}
{"timestamp_utc": "2024-07-31T08:12:26.582Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   20.914685] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   20.924483] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   20.940303] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   20.954034] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   20.957211] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   21.036196] dcn_phantom_drv: VIF Support v1.0 <NL> [   21.160981] packet_injector_class: driver registered correctly with major number 246 <NL> [   21.164174] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [   21.165180] Packet_injector 257949696: minor device creation 246:0 <NL> [   21.165244] Packet_injector 257949697: minor device creation 246:1 <NL> # 03:12:26 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:26.839Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:12:26 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46534\" SSHException('Error reading SSH protocol banner',) <NL> [   10.596984] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   10.597679] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   10.626004] ., OK <NL> [   10.634206] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   10.635966] IP-Config: Complete: <NL> [   10.636395]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   10.637643]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   10.642074]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   10.642076]      nameserver0=10.0.2.3 <NL> [   10.654450] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.057756] md: Waiting for all devices to be available before autodetect <NL> [   11.085841] md: If you don't use raid, use raid=noautodetect <NL> [   11.105566] md: Autodetecting RAID arrays. <NL> [   11.118610] md: autorun ... <NL> [   11.139220] md: ... autorun DONE. <NL> [   11.142743] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   11.241064] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   11.242379] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   11.243959] devtmpfs: mounted <NL> [   11.250096] Freeing unused kernel image (initmem) memory: 1964K <NL> [   11.258663] Write protecting the kernel read-only data: 22528k <NL> [   11.266872] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   11.275123] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   11.283325] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   11.589962] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   11.599125] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   11.875390] #####FSS INIT: Running on host <NL> [   11.993189] #####FSS INIT: FSS system init pre startup script <NL> [   12.099142] random: python3: uninitialized urandom read (24 bytes read) <NL> [   16.677602] random: crng init done <NL> [   17.946633] #####FSS INIT: UnitCode:c200  ShelfRole:MAIN <NL> [   17.951122] #####FSS INIT: FSS no slotRole found <NL> [   17.966936] #####FSS INIT: FSS system init get inputs from PSI c200 : MAIN <NL> [   17.979760] #####FSS INIT:PI data: unitCode=c200 Role=MAIN <NL> [   18.067552] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   18.084876] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-C200-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   18.117615] #####FSS INIT:Specific Target File found : /lib/systemd/system/FSS-C200-MAIN.target <NL> [   18.131338] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-C200-MAIN.target <NL> sh: -d: unknown operand <NL> [   18.168235] #####FSS INIT:systemd will take it from here! <NL> [   18.269909] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   18.366726] systemd[1]: Detected virtualization kvm. <NL> [   18.376668] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   18.407731] systemd[1]: Hostname set to <fujitsu>. <NL> [   18.426437] systemd[1]: Initializing machine ID from random generator. <NL> [   18.809875] systemd-sysv-generator[310]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   19.126491] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   19.680514] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.699440] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.802034] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.839124] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.865857] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.909011] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.040390] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.132539] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.134923] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.179492] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.196795] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.260868] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.271373] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.295275] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.304575] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.311619] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:27.404Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   12.388633] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.390204] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   12.455465] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.457751] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   12.515933] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.518779] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.548356] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.578743] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.583241] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.590521] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   12.595484] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   12.598687] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   12.601391] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   12.604737] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   12.997939] ., OK <NL> [   12.998721] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   12.999452] IP-Config: Complete: <NL> [   12.999773]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   13.000713]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   13.001250]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   13.001251]      nameserver0=10.0.2.3 <NL> [   13.605035] md: Waiting for all devices to be available before autodetect <NL> [   13.625949] md: If you don't use raid, use raid=noautodetect <NL> [   13.627490] md: Autodetecting RAID arrays. <NL> [   13.630419] md: autorun ... <NL> [   13.630700] md: ... autorun DONE. <NL> [   13.644089] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   13.737324] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   13.738133] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   13.739594] devtmpfs: mounted <NL> [   13.743607] Freeing unused kernel image (initmem) memory: 1964K <NL> [   13.744437] Write protecting the kernel read-only data: 22528k <NL> [   13.751372] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   13.762197] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   13.766593] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   14.348515] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   14.364100] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   14.548971] #####FSS INIT: Running on host <NL> [   14.720166] #####FSS INIT: FSS system init pre startup script <NL> [   14.779238] random: python3: uninitialized urandom read (24 bytes read) <NL> [   17.126011] random: crng init done <NL> [   19.658383] #####FSS INIT: UnitCode:f9fc  ShelfRole:MAIN <NL> [   19.661842] #####FSS INIT: FSS no slotRole found <NL> [   19.662355] #####FSS INIT: FSS system init get inputs from PSI f9fc : MAIN <NL> [   19.663051] #####FSS INIT:PI data: unitCode=f9fc Role=MAIN <NL> [   19.722846] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   19.754158] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   19.828386] #####FSS INIT:FSS MAIN Target File found : /lib/systemd/system/FSS-MAIN.target <NL> [   19.855052] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-MAIN.target <NL> sh: -d: unknown operand <NL> [   19.898016] #####FSS INIT:systemd will take it from here! <NL> [   19.967014] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   20.000112] systemd[1]: Detected virtualization kvm. <NL> [   20.000651] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   20.069115] systemd[1]: Hostname set to <fujitsu>. <NL> [   20.077438] systemd[1]: Initializing machine ID from random generator."}
{"timestamp_utc": "2024-07-31T08:12:27.405Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   20.238936] systemd-sysv-generator[344]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   20.334470] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   20.952830] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.030609] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.072872] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.117559] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.173019] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.180354] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.185921] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.231480] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.250197] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.312879] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.318486] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.348151] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.391742] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:27.661Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   16.513569] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   16.588447] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   16.663796] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   16.722195] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   16.753570] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   16.771533] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   16.790421] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   16.810999] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   16.826955] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:27.662Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   16.839693] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   16.851396] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   16.951452] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   16.952997] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   16.968494] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   16.969985] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   17.011630] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   17.012944] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   17.021058] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   17.031510] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   17.066235] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   17.077022] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   17.103181] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   17.126007] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   17.131849] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   17.199850] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   17.227557] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   17.256409] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   17.294959] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   17.349892] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   17.410562] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   17.460459] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   17.558156] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   17.698729] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   17.720135] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   17.772364] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   17.878183] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   17.921147] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   18.000159] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   18.033063] systemd[1]: Mounted POSIX Message Queue File System. <NL> [   18.033724] fuse: init (API version 7.32) <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   18.059133] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   18.090220] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   18.155293] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   18.186334] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   18.206273] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   18.242642] systemd[1]: modprobe@drm.service: Deactivated successfully."}
{"timestamp_utc": "2024-07-31T08:12:27.663Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   18.268900] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   18.305381] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   18.333076] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   18.347414] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   18.372819] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   18.417533] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   18.462083] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   18.465524] systemd[1]: Mounting Kernel Configuration File System... <NL> [   18.477590] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   18.574026] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   18.578495] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   18.591302] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   18.615239] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   18.653260] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   18.767131] dcn_phantom_drv: VIF Support v1.0 <NL> [   18.797879] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   18.802564] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   18.812278] systemd[1]: Mounting /var/ftp..."}
{"timestamp_utc": "2024-07-31T08:12:27.938Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   20.319509] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.376917] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:27.939Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   20.436226] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.465368] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.537094] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.558503] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   20.594382] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   20.647458] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.658743] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.693468] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.695505] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.724425] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.731012] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.798698] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.811633] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.865266] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.898838] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.930240] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.958642] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.010624] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.020770] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.067944] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.107616] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.228793] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.266094] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.292791] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.321668] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.377923] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.394293] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.412181] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.417663] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.437073] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   21.468098] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   21.490880] systemd[1]: Created slice Slice /system/getty."}
{"timestamp_utc": "2024-07-31T08:12:28.209Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   18.150406] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   18.176002] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   18.179052] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   18.182000] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   18.186242] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   18.191075] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   18.194694] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   18.198969] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   18.204111] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   18.206431] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   18.209928] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   18.212136] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   18.216404] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   18.245002] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   18.250172] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   18.267438] systemd[1]: Listening on Process Core Dump Socket."}
{"timestamp_utc": "2024-07-31T08:12:28.210Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   18.274273] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   18.298560] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   18.300124] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   18.319745] systemd[1]: Starting Journal Socket... <NL> [   18.321628] systemd[347]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   18.331993] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   18.338087] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   18.351360] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   18.376956] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   18.409555] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   18.424750] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   18.472626] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   18.545172] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   18.602981] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   18.615478] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   18.670359] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   18.705710] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   18.741723] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   18.793348] fuse: init (API version 7.32) <NL> [   18.843476] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   18.915313] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   18.967125] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   19.558352] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   19.615749] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   19.903639] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   19.913128] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   19.963485] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   19.972887] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   19.975646] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   19.985820] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   19.994379] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   19.996426] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   19.998172] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   20.001557] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   20.004037] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   20.008510] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   20.009614] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   20.014479] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   20.020444] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   20.028300] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   20.047185] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   20.059120] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   20.091106] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   20.101487] dcn_phantom_drv: VIF Support v1.0 <NL> [   20.130965] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   20.186716] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   20.238497] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   20.292349] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   21.424260] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.440884] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.500313] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.502616] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.549624] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.588627] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.747268] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.783892] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.838718] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.880660] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:28.211Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   21.883007] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.891851] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.898264] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   21.908424] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   21.962354] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.968289] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.036271] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.041973] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.084047] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.089575] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.120112] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.131085] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.176406] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.185181] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.216261] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.232689] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.255916] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.259823] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.291597] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.294066] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.366274] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.391953] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:29.574Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   22.441476] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.443691] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.460657] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.462880] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.467108] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.469575] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.473195] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.486153] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.544496] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.547546] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.580390] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   22.694739] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   22.738321] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   22.775250] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   22.789797] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   22.805387] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   22.840720] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   22.842238] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   22.873108] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   22.882122] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   22.904119] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   22.913054] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   22.934950] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   23.021027] systemd[1]: Listening on RPCbind Server Activation Socket."}
{"timestamp_utc": "2024-07-31T08:12:29.575Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   23.036433] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   23.059801] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   23.104177] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   23.139648] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   23.141061] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   23.152222] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   23.154875] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   23.158017] systemd[350]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   23.193999] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   23.205671] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   23.231596] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   23.238092] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   23.287180] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   23.309698] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   23.324162] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   23.330175] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   23.347337] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   23.380149] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   23.398662] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   23.439529] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   23.505571] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   23.579796] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   23.638158] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   23.717430] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   23.744103] fuse: init (API version 7.32) <NL> [   23.754081] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   23.807587] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   23.850893] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   23.908719] systemd[1]: Mounted Kernel Debug File System."}
{"timestamp_utc": "2024-07-31T08:12:29.835Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:12:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:29 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46488, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:29 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46488\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:30.096Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s01.NE2-main-debug-ssh", "step_id": "s01.NE2-main-debug-ssh", "message_content": "# 03:12:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46518, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:29 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46518\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46504, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46472, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:30 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46504\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:30.352Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p02.NE1-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p02", "keyword_name": "NE1-trib1-debug-ssh", "step_id": "NE1-trib1-debug-ssh", "message_content": "# 03:12:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46520, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:30 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46520\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:30.609Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    9.780251] Sending DHCP requests . <NL> [   11.677582] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.695775] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.697638] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.708853] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.723335] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   11.725416] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   11.735929] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   11.737850] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   11.749468] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.765693] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   11.807569] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.828671] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.842276] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   11.849212] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   12.261028] ., OK <NL> [   12.263563] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   12.285868] IP-Config: Complete: <NL> [   12.292334]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   12.308556]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   12.310889]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   12.310891]      nameserver0=10.0.2.3 <NL> [   12.944261] md: Waiting for all devices to be available before autodetect <NL> [   12.944940] md: If you don't use raid, use raid=noautodetect <NL> [   12.945502] md: Autodetecting RAID arrays. <NL> [   12.945895] md: autorun ... <NL> [   12.946175] md: ... autorun DONE. <NL> [   12.969110] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   13.003490] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null)"}
{"timestamp_utc": "2024-07-31T08:12:30.610Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   13.014355] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   13.016489] devtmpfs: mounted <NL> [   13.023494] Freeing unused kernel image (initmem) memory: 1964K <NL> [   13.026981] Write protecting the kernel read-only data: 22528k <NL> [   13.033555] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   13.034663] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   13.043322] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   13.464565] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   13.468063] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   13.644358] #####FSS INIT: Running on host <NL> [   13.887773] #####FSS INIT: FSS system init pre startup script <NL> [   13.963553] random: python3: uninitialized urandom read (24 bytes read) <NL> [   17.605335] random: crng init done <NL> [   19.126689] #####FSS INIT: UnitCode:c200  ShelfRole:MAIN <NL> [   19.135487] #####FSS INIT: FSS no slotRole found <NL> [   19.141614] #####FSS INIT: FSS system init get inputs from PSI c200 : MAIN <NL> [   19.150055] #####FSS INIT:PI data: unitCode=c200 Role=MAIN <NL> [   19.163585] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   19.177197] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-C200-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   19.179683] #####FSS INIT:Specific Target File found : /lib/systemd/system/FSS-C200-MAIN.target <NL> [   19.187792] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-C200-MAIN.target <NL> sh: -d: unknown operand <NL> [   19.203122] #####FSS INIT:systemd will take it from here! <NL> [   19.223242] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   19.251534] systemd[1]: Detected virtualization kvm. <NL> [   19.255956] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   19.266798] systemd[1]: Hostname set to <fujitsu>."}
{"timestamp_utc": "2024-07-31T08:12:30.611Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   19.271974] systemd[1]: Initializing machine ID from random generator. <NL> [   19.492336] systemd-sysv-generator[309]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   19.651706] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   20.958579] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.027476] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.134179] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.136620] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.195577] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.426040] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.504441] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.596580] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.613580] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.635443] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.656757] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.714908] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.740540] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:31.175Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   11.908190] IP-Config: Failed to open gretap0 <NL> [   11.912313] IP-Config: Failed to open erspan0 <NL> [   11.931374] Sending DHCP requests . <NL> [   13.873480] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.917005] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.947225] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.970818] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.972888] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   13.973850] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   13.990724] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   13.991437] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   13.992593] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.003234] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.014743] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.026837] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   14.027779] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   14.061147] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   14.391964] ., OK <NL> [   14.402210] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   14.402886] IP-Config: Complete: <NL> [   14.403220]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   14.404153]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   14.404706]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   14.404707]      nameserver0=10.0.2.3 <NL> [   15.057595] md: Waiting for all devices to be available before autodetect <NL> [   15.086067] md: If you don't use raid, use raid=noautodetect <NL> [   15.105691] md: Autodetecting RAID arrays. <NL> [   15.122979] md: autorun ... <NL> [   15.133149] md: ... autorun DONE. <NL> [   15.166194] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   15.285484] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   15.287407] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   15.306343] devtmpfs: mounted <NL> [   15.320833] Freeing unused kernel image (initmem) memory: 1964K <NL> [   15.335342] Write protecting the kernel read-only data: 22528k <NL> [   15.350150] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   15.361667] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   15.363341] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   15.737386] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   15.749445] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   15.820313] #####FSS INIT: Running on host <NL> [   16.069523] #####FSS INIT: FSS system init pre startup script <NL> [   16.164930] random: python3: uninitialized urandom read (24 bytes read) <NL> [   19.790301] random: crng init done <NL> [   23.113723] #####FSS INIT: UnitCode:f9fc  ShelfRole:MAIN <NL> [   23.125316] #####FSS INIT: FSS no slotRole found <NL> [   23.142133] #####FSS INIT: FSS system init get inputs from PSI f9fc : MAIN <NL> [   23.160246] #####FSS INIT:PI data: unitCode=f9fc Role=MAIN <NL> [   23.204319] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   23.246116] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   23.274463] #####FSS INIT:FSS MAIN Target File found : /lib/systemd/system/FSS-MAIN.target <NL> [   23.289722] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-MAIN.target <NL> sh: -d: unknown operand <NL> [   23.338624] #####FSS INIT:systemd will take it from here!"}
{"timestamp_utc": "2024-07-31T08:12:31.176Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   23.449442] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   23.470140] systemd[1]: Detected virtualization kvm. <NL> [   23.470743] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   23.487034] systemd[1]: Hostname set to <fujitsu>. <NL> [   23.526923] systemd[1]: Initializing machine ID from random generator. <NL> [   23.717452] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   23.763250] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   23.907085] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.929816] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.960284] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.999191] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.020046] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.131080] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.158417] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.178170] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.180586] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.220036] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.231815] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.266933] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.283337] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:31.737Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:12:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46534, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:31 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46534\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:31 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',) <NL> [   21.775399] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.806843] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.834679] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.883366] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.905896] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.933466] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.949696] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.966646] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.984370] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   21.995019] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   22.006613] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.029530] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.046456] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:31.738Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   22.058186] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.068498] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.081561] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.114879] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.139140] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.172478] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.182976] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.220264] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.229432] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.267082] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.312511] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.433594] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.574544] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.659448] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.718803] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.803463] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.874401] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.956461] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   17.651575] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   17.674699] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   17.688272] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   17.691693] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   17.704119] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   17.719396] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   17.736645] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   17.793228] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   17.825580] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   17.878687] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   17.892314] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   17.916836] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   17.989302] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   17.992607] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:31.739Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   18.148159] systemd-journald[359]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   19.463855] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   19.476924] Floppy drive(s): fd0 is 1.44M <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [   19.530621] FDC 0 is a S82078B <NL> [   19.555211] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   19.566144] Console: switching to colour dummy device 80x25 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   19.631274] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   19.653431] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   19.699884] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   19.699986] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   19.716436] Console: switching to colour frame buffer device 128x48 <NL> [   19.837640] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:31.740Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [   26.182421] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:32.773Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   24.290101] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.295336] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.346451] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.349788] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.405533] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.407698] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.469794] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.472048] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.544202] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.609723] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.619424] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.700338] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.726490] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   24.789282] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   24.845037] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.860326] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.889255] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.917621] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.974704] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.977682] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.014663] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.025044] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.038958] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:32.774Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   25.050896] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.087952] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.090122] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.164733] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.166893] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.219339] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.234783] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.432718] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.468548] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:12:33.096Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   22.966311] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.020982] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.103619] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.166713] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   23.222589] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   23.270444] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   23.282954] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   23.295222] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   23.308844] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   23.320156] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   23.333395] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   23.346346] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   23.356782] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   23.365551] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   23.369101] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   23.369990] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   23.443443] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   23.457087] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   23.475402] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   23.488177] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   23.493746] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   23.501047] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   23.516421] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   23.546787] systemd[315]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   23.584055] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   23.613611] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   23.655633] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   23.692954] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   23.701731] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   23.712368] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   23.717942] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   23.723162] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   23.732181] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   23.747222] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   23.773493] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   23.795002] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   23.830630] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   23.858228] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   23.890661] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   23.916279] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   23.956021] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> [   23.967793] fuse: init (API version 7.32) <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   23.986592] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   24.012212] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   24.020505] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:33.097Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   24.036222] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   24.053647] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   24.075359] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   24.096894] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   24.110387] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   24.132313] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   24.144449] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   24.163232] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   24.168373] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   24.175357] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   24.197468] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   24.226454] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   24.248493] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   24.269264] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   24.279471] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   24.307889] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   24.316643] systemd[1]: Starting Create Static Device Nodes in /dev..."}
{"timestamp_utc": "2024-07-31T08:12:33.353Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   21.507316] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   21.521764] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   21.542525] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   21.556803] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   21.566542] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   21.573507] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   21.580620] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   21.585290] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   21.589156] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   21.592372] systemd[1]: Reached target Swaps."}
{"timestamp_utc": "2024-07-31T08:12:33.354Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   21.680712] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   21.728346] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   21.776610] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   21.790846] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   21.825459] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   21.853810] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   21.914204] systemd[1]: Starting Journal Socket... <NL> [   21.931763] systemd[316]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   21.950626] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   21.954602] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   21.955925] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   21.969215] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   21.978222] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   21.990104] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   22.004907] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   22.032242] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   22.077792] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   22.133763] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   22.270094] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   22.434179] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   22.764584] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   23.157567] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   23.293739] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   23.537532] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   24.012556] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   24.144017] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   24.255221] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   24.337779] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m.[   24.393944] fuse: init (API version 7.32) <NL> [   24.418865] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   24.489216] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   24.610858] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   24.741116] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   24.781934] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   24.884711] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   24.943510] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   25.029432] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   25.064958] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   25.205645] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   25.322673] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   25.448808] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   25.605261] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   25.749420] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   25.808196] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   25.942573] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   26.112349] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m.[   26.149283] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   26.174590] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   26.283077] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   26.445238] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m.[   26.607054] dcn_phantom_drv: VIF Support v1.0 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:12:34.280Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   25.508341] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.510417] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.525456] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.527572] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.554890] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.557877] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.574822] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.584164] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.615428] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.617524] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.636366] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   25.677630] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   25.679899] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   25.682136] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   25.688182] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   25.693779] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   25.706919] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   25.724247] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   25.732435] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   25.736271] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   25.739650] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   25.743088] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   25.744168] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   25.775907] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   25.784385] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   25.791169] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   25.804818] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   25.812428] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   25.816875] systemd[1]: Listening on Journal Socket (/dev/log)."}
{"timestamp_utc": "2024-07-31T08:12:34.281Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   25.861364] systemd[1]: Starting Journal Socket... <NL> [   25.863171] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   25.946951] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   25.994462] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   26.010915] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   26.085242] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   26.133048] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   26.158323] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   26.200994] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   26.222249] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   26.272237] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   26.315661] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   26.430615] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   26.453082] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   26.605595] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   26.649031] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   26.727094] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   26.751187] fuse: init (API version 7.32) <NL> [   26.759572] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   26.867079] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   26.945217] systemd[1]: Starting Coldplug All udev Devices... <NL> [   26.992533] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   27.022468] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   27.061977] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   27.098401] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:34.840Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:12:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:34 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46488, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:34 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46488\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:35.095Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s01.NE2-main-debug-ssh", "step_id": "s01.NE2-main-debug-ssh", "message_content": "# 03:12:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46518, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:34 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46518\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46504, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:12:35.351Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p02.NE1-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p02", "keyword_name": "NE1-trib1-debug-ssh", "step_id": "NE1-trib1-debug-ssh", "message_content": "# 03:12:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46520, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:35 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46520\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:35.606Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p08.NE4-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p08", "keyword_name": "NE4-trib1-debug-ssh", "step_id": "NE4-trib1-debug-ssh", "message_content": "# 03:12:35 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:12:35 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:12:35 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:12:35 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:12:35 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\": process 3367 terminated with exitcode 0 <NL> # 03:12:35 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:12:35 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #7 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:12:35 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 7 children running (n01.p09.s01.startup (p)) <NL> # 03:12:35 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", exit_code 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   23.944796] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   23.962453] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   23.974606] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   23.975646] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   23.986491] systemd[1]: Finished Load Kernel Module configfs. <NL> [   24.046170] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   24.074949] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   24.076211] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   24.092138] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   24.115615] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   24.220598] dcn_phantom_drv: VIF Support v1.0 <NL> [   24.223502] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   24.238647] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   24.267719] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   24.326463] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   24.392140] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   24.394654] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   24.418404] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   24.447281] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:35.607Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   24.528699] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   24.617353] packet_injector_class: driver registered correctly with major number 246 <NL> [   24.643248] Packet_injector 257949696: minor device creation 246:0 <NL> [   24.661868] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   24.680816] Packet_injector 257949697: minor device creation 246:1 <NL> [   24.705025] systemd[1]: Reached target Preparation for Local File Systems. <NL> [   24.770629] Packet_injector 257949698: minor device creation 246:2 <NL> [   24.770653] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   24.858048] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   24.896163] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   24.906816] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   24.957881] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   25.024891] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   25.107321] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   25.202217] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   25.254869] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   25.321711] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   25.379491] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   25.438198] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   25.454766] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   25.474632] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   25.523848] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   25.577057] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   25.688496] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   25.756950] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   25.771723] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   25.793989] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   25.800988] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   25.802394] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   25.868786] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   25.896974] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   25.957936] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   25.991889] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   26.019778] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   26.195397] systemd-journald[360]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   29.093988] Floppy drive(s): fd0 is 1.44M <NL> [   29.106597] FDC 0 is a S82078B <NL> [   29.113203] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   29.114372] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   29.114458] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   29.115788] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   29.559024] Console: switching to colour dummy device 80x25 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   29.610634] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   29.681526] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   29.876800] Console: switching to colour frame buffer device 128x48"}
{"timestamp_utc": "2024-07-31T08:12:35.864Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   20.321977] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   20.351294] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   20.404342] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   20.568551] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   20.586419] packet_injector_class: driver registered correctly with major number 246 <NL> [   20.598117] Packet_injector 257949696: minor device creation 246:0 <NL> [   20.607516] Packet_injector 257949697: minor device creation 246:1 <NL> [   20.652047] Packet_injector 257949698: minor device creation 246:2 <NL> [   20.652771] Packet_injector 257949699: minor device creation 246:3 <NL> [   20.671949] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   20.682111] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   20.713710] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   20.787108] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   20.854095] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   21.013778] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   21.067659] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   21.074373] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   21.085156] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   21.124712] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   21.131354] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   21.184179] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   21.207123] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   21.239382] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   21.282543] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   21.303104] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   21.391323] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   21.439727] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   21.489242] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   21.513923] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   21.550569] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   21.613791] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   21.649302] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   21.803644] systemd-journald[357]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6Information startup (6s / 5min 3s) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   25.427617] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   25.454411] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   25.454560] Floppy drive(s): fd0 is 1.44M <NL> [   25.507194] FDC 0 is a S82078B <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   25.566557] Console: switching to colour dummy device 80x25 <NL> [   25.604053] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   25.628525] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   25.672118] Console: switching to colour frame buffer device 128x48 <NL> [   25.712371] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [   25.750930] parport_pc 00:04: reported by Plug and Play ACPI"}
{"timestamp_utc": "2024-07-31T08:12:35.865Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   25.751851] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:12:36.426Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   18.826401] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   18.834881] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   18.891830] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   18.936393] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   18.961104] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   18.974988] packet_injector_class: driver registered correctly with major number 246 <NL> [   18.977291] Packet_injector 257949696: minor device creation 246:0 <NL> [   18.980391] Packet_injector 257949697: minor device creation 246:1 <NL> [   18.985347] Packet_injector 257949698: minor device creation 246:2 <NL> [   18.996352] Packet_injector 257949699: minor device creation 246:3 <NL> [   19.011451] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   19.029359] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   19.088998] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   19.124070] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   19.145758] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   19.176798] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   19.191397] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   19.200988] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   19.235125] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   19.310357] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   19.327503] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   19.337734] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   19.365617] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:12:36.427Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   19.410104] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   19.425452] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   19.440673] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   19.501241] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   19.532864] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   19.591153] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   19.698015] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   19.973112] systemd-journald[359]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   21.702995] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   22.058880] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   22.067550] Console: switching to colour dummy device 80x25 <NL> [   22.145577] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   22.160375] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   22.399262] Console: switching to colour frame buffer device 128x48 <NL> [   22.497408] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [   23.264339] Floppy drive(s): fd0 is 1.44M <NL> [   23.391347] FDC 0 is a S82078B <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   23.584342] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   23.594954] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:36.682Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:12:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46534, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:36 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46534\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:36 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:38.089Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p04.NE2-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p04", "keyword_name": "NE2-trib1-debug-ssh", "step_id": "NE2-trib1-debug-ssh", "message_content": "# 03:12:37 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:12:37 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:12:37 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:12:37 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:12:37 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\": process 3363 terminated with exitcode 0 <NL> # 03:12:37 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p04.NE2-trib1-debug-ssh)"}
{"timestamp_utc": "2024-07-31T08:12:38.090Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:37 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #3 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:12:37 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 6 children running (n01.p09.s01.startup (p)) <NL> # 03:12:37 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:12:39.977Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:12:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> [   21.165270] Packet_injector 257949698: minor device creation 246:2 <NL> [   21.165312] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   21.200888] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   21.913077] systemd-journald[358]: Received client request to flush runtime journal."}
{"timestamp_utc": "2024-07-31T08:12:39.978Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   23.285398] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   23.885134] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   23.889508] Console: switching to colour dummy device 80x25 <NL> [   23.953302] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   23.957469] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   24.022077] Console: switching to colour frame buffer device 128x48 <NL> [   24.087229] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [   24.437233] Floppy drive(s): fd0 is 1.44M <NL> [   24.491883] FDC 0 is a S82078B <NL> [   24.864508] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   24.871483] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6namic Linker Cache (7s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6namic Linker Cache (8s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6namic Linker Cache (8s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6namic Linker Cache (9s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   34.198458] pktHandler[572]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> # 03:12:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46488, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:39 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46518, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:12:40.234Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p02.NE1-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p02", "keyword_name": "NE1-trib1-debug-ssh", "step_id": "NE1-trib1-debug-ssh", "message_content": "# 03:12:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46520, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:12:41.160Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   27.134729] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   27.171417] systemd[1]: Mounted Kernel Trace File System. <NL> [   27.179195] dcn_phantom_drv: VIF Support v1.0 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   27.210226] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   27.250250] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   27.279871] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   27.304532] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   27.347973] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   27.397560] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   27.414466] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   27.431955] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   27.444970] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   27.497841] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   27.558043] packet_injector_class: driver registered correctly with major number 246 <NL> [   27.559184] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   27.621523] Packet_injector 257949696: minor device creation 246:0 <NL> [   27.634406] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   27.637815] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   27.662795] Packet_injector 257949697: minor device creation 246:1 <NL> [   27.666784] Packet_injector 257949698: minor device creation 246:2 <NL> [   27.702229] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> [   27.704172] Packet_injector 257949699: minor device creation 246:3 <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   27.787594] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   27.818572] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   27.847399] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   27.912853] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   27.968688] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   28.272069] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   29.062098] systemd-journald[359]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [   29.755096] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   30.663519] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   30.828345] Console: switching to colour dummy device 80x25 <NL> [   30.907305] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   31.045525] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   31.293686] Console: switching to colour frame buffer device 128x48 <NL> [   31.565368] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   31.938101] Floppy drive(s): fd0 is 1.44M <NL> [   32.019879] FDC 0 is a S82078B <NL> [   32.050149] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   32.050819] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:41.161Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:41.722Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:57574)\u001b[0m. <NL> [   28.607660] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [   29.104982] hrtimer: interrupt took 9103154 ns <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m... <NL> [   30.645645] pktHandler[592]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   30.690660] pktHandler[592]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   30.695295] pktHandler[592]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   30.696867] pktHandler[592]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   30.708993] pktHandler[592]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   30.714989] pktHandler[592]: Init PktClient init complete <NL> [   30.731055] pktHandler[592]: EsalConfig::EsalConfig main 0 <NL> [   30.770072] pktHandler[592]: EsalConfig::EsalConfig trib 1 <NL> [   30.790190] pktHandler[592]: EsalConfig::EsalConfig ciRole 0 <NL> [   30.803479] pktHandler[592]: EsalConfig is not running inside container. <NL> [   30.862935] pktHandler[592]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   30.901550] pktHandler[592]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   30.918978] pktHandler[592]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   30.935431] pktHandler[592]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   30.947034] pktHandler[592]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   30.967327] pktHandler[592]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   30.975463] pktHandler[592]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   30.986971] pktHandler[592]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   31.020413] pktHandler[592]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   31.029176] pktHandler[592]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   31.068988] pktHandler[592]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   31.098550] pktHandler[592]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   31.112940] pktHandler[592]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   31.113811] pktHandler[592]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   31.114633] pktHandler[592]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   31.115423] pktHandler[592]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   31.126970] pktHandler[592]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   31.144786] pktHandler[592]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Database Manager\u001b[0m. <NL> [   31.494636] commsdriver[610]: DllUtil::symbolInit() <NL> [   31.545853] commsdriver[610]: int DllInit() <NL> [   31.574325] commsdriver[610]: DllUtil::DllInit DllInit() return is null <NL> [   31.598033] commsdriver[610]: Could not resolve symbol name get_late_config_file_path <NL> [   31.638782] commsdriver[610]: Could not resolve symbol name create_l3_interface <NL> [   31.674227] commsdriver[610]: Could not resolve symbol name create_l2_interface <NL> [   31.720420] commsdriver[610]: Could not resolve symbol name delete_interface <NL> [   31.725013] commsdriver[610]: Could not resolve symbol name pre_setup_interfaces <NL> [   31.728951] commsdriver[610]: Could not resolve symbol name setup_interfaces <NL> [   31.732984] commsdriver[610]: Could not resolve symbol name post_setup_interfaces <NL> [   31.762035] commsdriver[610]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   31.812101] commsdriver[610]: Could not resolve symbol name setup_late_interfaces"}
{"timestamp_utc": "2024-07-31T08:12:41.723Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   31.812934] commsdriver[610]: Could not resolve symbol name post_setup_late_interfaces <NL> [   31.813692] commsdriver[610]: Could not resolve symbol name pre_init <NL> [   31.814349] commsdriver[610]: Could not resolve symbol name post_init <NL> [   31.814944] commsdriver[610]: Could not resolve symbol name pre_handle_link_state_change <NL> [   31.821896] commsdriver[610]: Could not resolve symbol name handle_link_state_change <NL> [   31.822688] commsdriver[610]: Could not resolve symbol name post_handle_link_state_change <NL> [   31.830895] commsdriver[610]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   31.831728] commsdriver[610]: Could not resolve symbol name handle_link_state_notify <NL> [   31.832561] commsdriver[610]: Could not resolve symbol name post_handle_link_state_notify <NL> [   31.840902] commsdriver[610]: Could not resolve symbol name handle_rate_duplex_change <NL> [   31.841838] commsdriver[610]: Could not resolve symbol name delete_mac_address <NL> [   31.842632] commsdriver[610]: Could not resolve symbol name set_vlan_prio <NL> [   31.853912] commsdriver[610]: Could not resolve symbol name replay_mac <NL> [   31.854934] commsdriver[610]: Could not resolve symbol name set_red_state <NL> [   31.856050] commsdriver[610]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   31.875991] commsdriver[610]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   31.884963] commsdriver[610]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   31.892750] commsdriver[610]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   31.904423] commsdriver[610]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   31.905499] commsdriver[610]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   31.906241] commsdriver[610]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   31.907232] commsdriver[610]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   31.961169] commsdriver[610]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   31.962384] commsdriver[610]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   31.963094] commsdriver[610]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   31.974861] commsdriver[610]: SharedMemory::getShmSegment creating new segment <NL> [   31.975649] commsdriver[610]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser Slice of UID 3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Manager for UID 3000\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Manager for UID 3000\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSession c1 of User fujitsu\u001b[0m. <NL> # 03:12:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46534, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:41 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:42.648Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p06", "keyword_name": "NE3-trib1-debug-ssh", "step_id": "NE3-trib1-debug-ssh", "message_content": "# 03:12:42 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:12:42 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:12:42 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:12:42 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:12:42 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\": process 3365 terminated with exitcode 0 <NL> # 03:12:42 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:12:42 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #5 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:12:42 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 5 children running (n01.p09.s01.startup (p)) <NL> # 03:12:42 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", exit_code 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:39100)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   27.988303] pktHandler[583]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   27.990968] pktHandler[583]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   27.997833] pktHandler[583]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   28.002169] pktHandler[583]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   28.018194] pktHandler[583]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   28.054944] pktHandler[583]: Init PktClient init complete <NL> [   28.067174] pktHandler[583]: EsalConfig::EsalConfig main 0 <NL> [   28.073675] pktHandler[583]: EsalConfig::EsalConfig trib 1 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   28.170025] pktHandler[583]: EsalConfig::EsalConfig ciRole 0 <NL> [   28.182921] pktHandler[583]: EsalConfig is not running inside container. <NL> [   28.193189] pktHandler[583]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   28.213717] pktHandler[583]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   28.219290] pktHandler[583]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   28.238743] pktHandler[583]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   28.253825] pktHandler[583]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   28.290278] pktHandler[583]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   28.321054] pktHandler[583]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   28.355789] pktHandler[583]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   28.367939] pktHandler[583]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   28.368870] pktHandler[583]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   28.369754] pktHandler[583]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   28.370467] pktHandler[583]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   28.399371] pktHandler[583]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   28.404850] pktHandler[583]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   28.411822] pktHandler[583]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   28.412476] pktHandler[583]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   28.413198] pktHandler[583]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   28.413846] pktHandler[583]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   28.884385] commsdriver[606]: DllUtil::symbolInit() <NL> [   28.919591] commsdriver[606]: int DllInit() <NL> [   28.921125] commsdriver[606]: DllUtil::DllInit DllInit() return is null <NL> [   28.927351] commsdriver[606]: Could not resolve symbol name get_late_config_file_path <NL> [   28.938694] commsdriver[606]: Could not resolve symbol name create_l3_interface <NL> [   28.967989] commsdriver[606]: Could not resolve symbol name create_l2_interface <NL> [   28.981857] commsdriver[606]: Could not resolve symbol name delete_interface <NL> [   29.007365] commsdriver[606]: Could not resolve symbol name pre_setup_interfaces <NL> [   29.015169] commsdriver[606]: Could not resolve symbol name setup_interfaces <NL> [   29.026326] commsdriver[606]: Could not resolve symbol name post_setup_interfaces <NL> [   29.034195] commsdriver[606]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   29.052186] commsdriver[606]: Could not resolve symbol name setup_late_interfaces <NL> [   29.057307] commsdriver[606]: Could not resolve symbol name post_setup_late_interfaces <NL> [   29.117314] commsdriver[606]: Could not resolve symbol name pre_init <NL> [   29.119583] commsdriver[606]: Could not resolve symbol name post_init <NL> [   29.161082] commsdriver[606]: Could not resolve symbol name pre_handle_link_state_change <NL> [   29.176323] commsdriver[606]: Could not resolve symbol name handle_link_state_change"}
{"timestamp_utc": "2024-07-31T08:12:42.649Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   29.186036] commsdriver[606]: Could not resolve symbol name post_handle_link_state_change <NL> [   29.200296] commsdriver[606]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   29.206119] commsdriver[606]: Could not resolve symbol name handle_link_state_notify <NL> [   29.206193] commsdriver[606]: Could not resolve symbol name post_handle_link_state_notify <NL> [   29.206261] commsdriver[606]: Could not resolve symbol name handle_rate_duplex_change <NL> [   29.206320] commsdriver[606]: Could not resolve symbol name delete_mac_address <NL> [   29.206375] commsdriver[606]: Could not resolve symbol name set_vlan_prio <NL> [   29.206429] commsdriver[606]: Could not resolve symbol name replay_mac <NL> [   29.206492] commsdriver[606]: Could not resolve symbol name set_red_state <NL> [   29.206774] commsdriver[606]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   29.206837] commsdriver[606]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   29.206922] commsdriver[606]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   29.206984] commsdriver[606]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   29.207060] commsdriver[606]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   29.207117] commsdriver[606]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   29.207173] commsdriver[606]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   29.207228] commsdriver[606]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   29.207282] commsdriver[606]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   29.207339] commsdriver[606]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   29.207393] commsdriver[606]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   29.207444] commsdriver[606]: SharedMemory::getShmSegment creating new segment <NL> [   29.207510] commsdriver[606]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   32.543931] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   32.337474] commsdriver[640]: SUCCESS <NL> [   34.680207] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   34.682092] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   34.911392] commsdriver[606]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   35.264049] device eth1 entered promiscuous mode <NL> [   34.973941] commsdriver[606]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   35.705690] commsdriver[606]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   35.791574] commsdriver[690]: Actual changes: <NL> [   35.791775] commsdriver[690]: tx-checksum-ip-generic: off <NL> [   35.791853] commsdriver[690]: tx-tcp-segmentation: off [not requested] <NL> [   35.791911] commsdriver[690]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   35.791968] commsdriver[690]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   35.792041] commsdriver[690]: tx-tcp6-segmentation: off [not requested] <NL> [   36.381074] commsdriver[606]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   36.460995] commsdriver[702]: Actual changes: <NL> [   36.461203] commsdriver[702]: tx-checksum-ip-generic: off <NL> [   36.461276] commsdriver[702]: tx-tcp-segmentation: off [not requested] <NL> [   36.461330] commsdriver[702]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   36.461400] commsdriver[702]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   36.461454] commsdriver[702]: tx-tcp6-segmentation: off [not requested] <NL> [   37.064833] br-odcc1: port 1(eth2) entered blocking state <NL> # 03:12:42 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:12:42 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:12:43.109Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:42 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:12:42 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:12:42 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\": process 3361 terminated with exitcode 0 <NL> # 03:12:42 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:12:42 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #1 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:12:42 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 4 children running (n01.p09.s01.startup (p)) <NL> # 03:12:42 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:12:43.366Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s01.NE2-main-debug-ssh", "step_id": "s01.NE2-main-debug-ssh", "message_content": "# 03:12:43 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:12:43 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:12:43.622Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:43 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:12:43 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:12:43 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\": process 3362 terminated with exitcode 0 <NL> # 03:12:43 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:12:43 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:12:43 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46517', '--delay', '5'] (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:12:43 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p03.s02.NE2-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46517', '--delay', '5'] <NL> # 03:12:43 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:12:43 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"command\" <NL> # 03:12:43 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:12:43.877Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:43 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46517, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:43 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:44.802Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:12:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:44 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:45.362Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   29.887643] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [   34.882229] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:53114)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   38.100325] pktHandler[605]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   38.136781] pktHandler[605]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   38.170698] pktHandler[605]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   38.235787] pktHandler[605]: GetRxFilters:83 rawdata= <NL> [   38.286661] pktHandler[605]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   38.300480] pktHandler[605]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   38.325564] pktHandler[605]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   38.356081] pktHandler[605]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   38.425119] pktHandler[605]: GetRxFilters:83 rawdata= <NL> [   38.510848] pktHandler[605]: Init PktClient init complete <NL> [   38.550548] pktHandler[605]: EsalConfig::EsalConfig main 1 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   38.572529] pktHandler[605]: EsalConfig::EsalConfig trib 0 <NL> [   38.626636] pktHandler[605]: EsalConfig::EsalConfig ciRole 0 <NL> [   38.683013] pktHandler[605]: EsalConfig is not running inside container. <NL> [   38.718526] pktHandler[605]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   38.719680] pktHandler[605]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   38.721691] pktHandler[605]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   38.732811] pktHandler[605]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   38.766532] pktHandler[605]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   38.804489] pktHandler[605]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   38.848243] pktHandler[605]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   38.909714] pktHandler[605]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   38.936497] pktHandler[605]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   38.950676] pktHandler[605]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   39.003610] pktHandler[605]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   39.020612] pktHandler[605]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   39.020772] pktHandler[605]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   39.134067] pktHandler[605]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   39.297942] pktHandler[605]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   39.347609] pktHandler[605]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf"}
{"timestamp_utc": "2024-07-31T08:12:45.363Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   39.361553] pktHandler[605]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   39.364936] pktHandler[605]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:12:45.619Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [   29.684074] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [   31.926476] pktHandler[578]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   31.946236] pktHandler[578]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   31.965193] pktHandler[578]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   31.981077] pktHandler[578]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   32.007243] pktHandler[578]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   32.017502] pktHandler[578]: Init PktClient init complete <NL> [   32.024497] pktHandler[578]: EsalConfig::EsalConfig main 0 <NL> [   32.033512] pktHandler[578]: EsalConfig::EsalConfig trib 1 <NL> [   32.047332] pktHandler[578]: EsalConfig::EsalConfig ciRole 0 <NL> [   32.063756] pktHandler[578]: EsalConfig is not running inside container. <NL> [   32.074487] pktHandler[578]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.083043] pktHandler[578]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.088669] pktHandler[578]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.095225] pktHandler[578]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.111345] pktHandler[578]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   32.151051] pktHandler[578]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   32.155329] pktHandler[578]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   32.170637] pktHandler[578]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   32.179059] pktHandler[578]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   32.217346] pktHandler[578]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   32.241020] pktHandler[578]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   32.245047] pktHandler[578]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   32.255294] pktHandler[578]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   32.258157] pktHandler[578]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   32.260320] pktHandler[578]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   32.267118] pktHandler[578]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   32.267986] pktHandler[578]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   32.268806] pktHandler[578]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:49094)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   32.695230] commsdriver[593]: DllUtil::symbolInit() <NL> [   32.704098] commsdriver[593]: int DllInit() <NL> [   32.709514] commsdriver[593]: DllUtil::DllInit DllInit() return is null <NL> [   32.727671] commsdriver[593]: Could not resolve symbol name get_late_config_file_path <NL> [   32.760470] commsdriver[593]: Could not resolve symbol name create_l3_interface <NL> [   32.781474] commsdriver[593]: Could not resolve symbol name create_l2_interface <NL> [   32.791103] commsdriver[593]: Could not resolve symbol name delete_interface <NL> [   32.800634] commsdriver[593]: Could not resolve symbol name pre_setup_interfaces <NL> [   32.814656] commsdriver[593]: Could not resolve symbol name setup_interfaces <NL> [   32.826721] commsdriver[593]: Could not resolve symbol name post_setup_interfaces <NL> [   32.831250] commsdriver[593]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   32.841223] commsdriver[593]: Could not resolve symbol name setup_late_interfaces"}
{"timestamp_utc": "2024-07-31T08:12:45.620Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   32.849466] commsdriver[593]: Could not resolve symbol name post_setup_late_interfaces <NL> [   32.867153] commsdriver[593]: Could not resolve symbol name pre_init <NL> [   32.875302] commsdriver[593]: Could not resolve symbol name post_init <NL> [   32.883936] commsdriver[593]: Could not resolve symbol name pre_handle_link_state_change <NL> [   32.899121] commsdriver[593]: Could not resolve symbol name handle_link_state_change <NL> [   32.920798] commsdriver[593]: Could not resolve symbol name post_handle_link_state_change <NL> [   32.950285] commsdriver[593]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   32.970052] commsdriver[593]: Could not resolve symbol name handle_link_state_notify <NL> [   32.991527] commsdriver[593]: Could not resolve symbol name post_handle_link_state_notify <NL> [   33.020887] commsdriver[593]: Could not resolve symbol name handle_rate_duplex_change <NL> [   33.035517] commsdriver[593]: Could not resolve symbol name delete_mac_address <NL> [   33.048969] commsdriver[593]: Could not resolve symbol name set_vlan_prio <NL> [   33.076234] commsdriver[593]: Could not resolve symbol name replay_mac <NL> [   33.106345] commsdriver[593]: Could not resolve symbol name set_red_state <NL> [   33.154440] commsdriver[593]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   33.203239] commsdriver[593]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   33.252696] commsdriver[593]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   33.299915] commsdriver[593]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   33.321349] commsdriver[593]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.361930] commsdriver[593]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   33.388141] commsdriver[593]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.415943] commsdriver[593]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.438952] commsdriver[593]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   33.459490] commsdriver[593]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   33.460238] commsdriver[593]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.461266] commsdriver[593]: SharedMemory::getShmSegment creating new segment <NL> [   33.471578] commsdriver[593]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   36.223801] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   36.232275] commsdriver[638]: SUCCESS"}
{"timestamp_utc": "2024-07-31T08:12:46.180Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:12:45 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:12:45 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:12:45 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:12:45 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:12:45 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\": process 3360 terminated with exitcode 0 <NL> # 03:12:45 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:12:45 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:12:45 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46533', '--delay', '5'] (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:12:45 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p01.s02.NE1-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46533', '--delay', '5'] <NL> # 03:12:46 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:12:46 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"command\" <NL> # 03:12:46 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:12:46.436Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:12:46 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46533, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:46 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:46.691Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:12:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:46 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:48.580Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [   36.739983] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:43536)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   38.975137] pktHandler[607]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   39.105513] pktHandler[607]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.130020] pktHandler[607]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   39.205267] pktHandler[607]: GetRxFilters:83 rawdata= <NL> [   39.213504] pktHandler[607]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   39.289504] pktHandler[607]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.290542] pktHandler[607]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.314648] pktHandler[607]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   39.362761] pktHandler[607]: GetRxFilters:83 rawdata= <NL> [   39.382886] pktHandler[607]: Init PktClient init complete <NL> [   39.405154] pktHandler[607]: EsalConfig::EsalConfig main 1 <NL> [   39.422788] pktHandler[607]: EsalConfig::EsalConfig trib 0 <NL> [   39.454620] pktHandler[607]: EsalConfig::EsalConfig ciRole 0 <NL> [   39.515036] pktHandler[607]: EsalConfig is not running inside container. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   39.553498] pktHandler[607]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.699564] pktHandler[607]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.732280] pktHandler[607]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.746209] pktHandler[607]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.772815] pktHandler[607]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   39.786324] pktHandler[607]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   39.827386] pktHandler[607]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   39.839143] pktHandler[607]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   39.851859] pktHandler[607]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   39.879392] pktHandler[607]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   39.895048] pktHandler[607]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   39.904979] pktHandler[607]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   39.930699] pktHandler[607]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   39.946417] pktHandler[607]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   39.989280] pktHandler[607]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   39.991179] pktHandler[607]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   39.993274] pktHandler[607]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   40.000014] pktHandler[607]: pkt-handler: sd_notify ready <NL> [   40.006316] commsdriver[624]: DllUtil::symbolInit() <NL> [   40.007666] commsdriver[624]: int DllInit() <NL> [   40.027709] commsdriver[624]: DllUtil::DllInit DllInit() return is null <NL> [   40.033456] commsdriver[624]: Could not resolve symbol name get_late_config_file_path <NL> [   40.036715] commsdriver[624]: Could not resolve symbol name create_l3_interface <NL> [   40.043371] commsdriver[624]: Could not resolve symbol name create_l2_interface <NL> [   40.047993] commsdriver[624]: Could not resolve symbol name delete_interface <NL> [   40.050568] commsdriver[624]: Could not resolve symbol name pre_setup_interfaces <NL> [   40.052528] commsdriver[624]: Could not resolve symbol name setup_interfaces <NL> [   40.057175] commsdriver[624]: Could not resolve symbol name post_setup_interfaces <NL> [   40.068619] commsdriver[624]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   40.079628] commsdriver[624]: Could not resolve symbol name setup_late_interfaces <NL> [   40.091762] commsdriver[624]: Could not resolve symbol name post_setup_late_interfaces <NL> [   40.100235] commsdriver[624]: Could not resolve symbol name pre_init <NL> [   40.130516] commsdriver[624]: Could not resolve symbol name post_init <NL> [   40.149612] commsdriver[624]: Could not resolve symbol name pre_handle_link_state_change <NL> [   40.199580] commsdriver[624]: Could not resolve symbol name handle_link_state_change <NL> [   40.221296] commsdriver[624]: Could not resolve symbol name post_handle_link_state_change <NL> [   40.243853] commsdriver[624]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   40.278769] commsdriver[624]: Could not resolve symbol name handle_link_state_notify <NL> [   40.287962] commsdriver[624]: Could not resolve symbol name post_handle_link_state_notify <NL> [   40.298373] commsdriver[624]: Could not resolve symbol name handle_rate_duplex_change <NL> [   40.312022] commsdriver[624]: Could not resolve symbol name delete_mac_address"}
{"timestamp_utc": "2024-07-31T08:12:48.581Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   40.320772] commsdriver[624]: Could not resolve symbol name set_vlan_prio <NL> [   40.339513] commsdriver[624]: Could not resolve symbol name replay_mac <NL> [   34.213361] pktHandler[572]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.235816] pktHandler[572]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.245064] pktHandler[572]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.246653] pktHandler[572]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.255780] pktHandler[572]: Init PktClient init complete <NL> [   34.256572] pktHandler[572]: EsalConfig::EsalConfig main 0 <NL> [   34.258260] pktHandler[572]: EsalConfig::EsalConfig trib 1 <NL> [   34.261282] pktHandler[572]: EsalConfig::EsalConfig ciRole 0 <NL> [   34.293112] pktHandler[572]: EsalConfig is not running inside container. <NL> [   34.352685] pktHandler[572]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   34.358646] pktHandler[572]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   34.442695] pktHandler[572]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   34.454227] pktHandler[572]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   34.455589] pktHandler[572]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   34.463378] pktHandler[572]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   34.473989] pktHandler[572]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   34.513191] pktHandler[572]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   34.514841] pktHandler[572]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   34.516717] pktHandler[572]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   34.534705] pktHandler[572]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   34.633220] pktHandler[572]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   34.674477] pktHandler[572]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   34.688153] pktHandler[572]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   34.758152] pktHandler[572]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   34.793598] pktHandler[572]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   34.822649] pktHandler[572]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   34.873527] pktHandler[572]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:36494)\u001b[0m. <NL> [   35.198759] commsdriver[583]: DllUtil::symbolInit() <NL> [   35.204022] commsdriver[583]: int DllInit() <NL> [   35.215436] commsdriver[583]: DllUtil::DllInit DllInit() return is null <NL> [   35.222434] commsdriver[583]: Could not resolve symbol name get_late_config_file_path <NL> [   35.240190] commsdriver[583]: Could not resolve symbol name create_l3_interface <NL> [   35.250183] commsdriver[583]: Could not resolve symbol name create_l2_interface <NL> [   35.254714] commsdriver[583]: Could not resolve symbol name delete_interface <NL> [   35.267582] commsdriver[583]: Could not resolve symbol name pre_setup_interfaces <NL> [   35.282790] commsdriver[583]: Could not resolve symbol name setup_interfaces <NL> [   35.291957] commsdriver[583]: Could not resolve symbol name post_setup_interfaces <NL> [   35.292774] commsdriver[583]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   35.316498] commsdriver[583]: Could not resolve symbol name setup_late_interfaces <NL> [   35.340393] commsdriver[583]: Could not resolve symbol name post_setup_late_interfaces <NL> [   35.341926] commsdriver[583]: Could not resolve symbol name pre_init <NL> [   35.355600] commsdriver[583]: Could not resolve symbol name post_init <NL> [   35.366490] commsdriver[583]: Could not resolve symbol name pre_handle_link_state_change <NL> [   35.385375] commsdriver[583]: Could not resolve symbol name handle_link_state_change <NL> [   35.397274] commsdriver[583]: Could not resolve symbol name post_handle_link_state_change <NL> [   35.417461] commsdriver[583]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   35.435333] commsdriver[583]: Could not resolve symbol name handle_link_state_notify <NL> [   35.450904] commsdriver[583]: Could not resolve symbol name post_handle_link_state_notify <NL> [   35.452878] commsdriver[583]: Could not resolve symbol name handle_rate_duplex_change <NL> [   35.479624] commsdriver[583]: Could not resolve symbol name delete_mac_address <NL> [   35.485715] commsdriver[583]: Could not resolve symbol name set_vlan_prio <NL> [   35.492565] commsdriver[583]: Could not resolve symbol name replay_mac <NL> [   35.493233] commsdriver[583]: Could not resolve symbol name set_red_state <NL> [   35.499607] commsdriver[583]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   35.506552] commsdriver[583]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   35.512484] commsdriver[583]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   35.519547] commsdriver[583]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   35.525446] commsdriver[583]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.536583] commsdriver[583]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   35.538815] commsdriver[583]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.544592] commsdriver[583]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.578715] commsdriver[583]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   35.579599] commsdriver[583]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   35.591723] commsdriver[583]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.592780] commsdriver[583]: SharedMemory::getShmSegment creating new segment <NL> [   35.593552] commsdriver[583]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   38.485059] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   38.421710] commsdriver[631]: SUCCESS <NL> fujitsu login: [   40.453815] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   40.508245] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   41.270958] device eth1 entered promiscuous mode <NL> [   41.011670] commsdriver[583]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   41.064255] commsdriver[583]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   41.895108] commsdriver[583]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   42.062945] commsdriver[683]: Actual changes: <NL> [   42.085319] commsdriver[683]: tx-checksum-ip-generic: off <NL> [   42.114879] commsdriver[683]: tx-tcp-segmentation: off [not requested] <NL> [   42.151909] commsdriver[683]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   42.153994] commsdriver[683]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   42.177605] commsdriver[683]: tx-tcp6-segmentation: off [not requested] <NL> [   42.618879] commsdriver[583]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   42.711485] commsdriver[695]: Actual changes: <NL> [   42.721587] commsdriver[695]: tx-checksum-ip-generic: off <NL> [   42.744421] commsdriver[695]: tx-tcp-segmentation: off [not requested] <NL> [   42.767827] commsdriver[695]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   42.792595] commsdriver[695]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   42.813443] commsdriver[695]: tx-tcp6-segmentation: off [not requested] <NL> [   43.370930] br-odcc1: port 1(eth2) entered blocking state <NL> [   43.399073] br-odcc1: port 1(eth2) entered disabled state"}
{"timestamp_utc": "2024-07-31T08:12:48.897Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:12:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:48 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:49.845Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:12:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:49 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:51.730Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:12:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:51 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:12:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:51 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:54.241Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:12:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:53 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:54.840Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:12:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:12:55.117Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   24.362663] systemd[1]: Started Journal Service. <NL> [   24.369702] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m.[   24.435937] dcn_phantom_drv: VIF Support v1.0 <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   24.477965] packet_injector_class: driver registered correctly with major number 246 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   24.523622] Packet_injector 257949696: minor device creation 246:0 <NL> [   24.524461] Packet_injector 257949697: minor device creation 246:1 <NL> [   24.546443] Packet_injector 257949698: minor device creation 246:2 <NL> [   24.557224] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   26.773867] systemd-journald[324]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [   27.407171] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6Information startup (7s / 5min 3s) <NL> [   30.734749] Floppy drive(s): fd0 is 1.44M <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6Information startup (7s / 5min 3s) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6Information startup (8s / 5min 3s) <NL> [   31.717282] FDC 0 is a S82078B <NL> [   32.247598] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (9s / no limit) <NL> [   32.449794] parport_pc 00:04: reported by Plug and Play ACPI <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (9s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> [   34.827422] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (10s / 5min 3s) <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (11s / 5min 3s) <NL> [   35.103158] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   35.130482] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (12s / 5min 3s) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> [   36.119002] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   37.495604] Console: switching to colour frame buffer device 128x48 <NL> [   39.875907] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically restarts sync-log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m...[   45.306575] sched: RT throttling activated <NL> [   39.529313] commsdriver[624]: DllUtil::symbolInit() <NL> [   39.529498] commsdriver[624]: int DllInit() <NL> [   39.529564] commsdriver[624]: DllUtil::DllInit DllInit() return is null <NL> [   39.529643] commsdriver[624]: Could not resolve symbol name get_late_config_file_path"}
{"timestamp_utc": "2024-07-31T08:12:55.118Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   39.529698] commsdriver[624]: Could not resolve symbol name create_l3_interface <NL> [   39.529760] commsdriver[624]: Could not resolve symbol name create_l2_interface <NL> [   39.529822] commsdriver[624]: Could not resolve symbol name delete_interface <NL> [   39.529876] commsdriver[624]: Could not resolve symbol name pre_setup_interfaces <NL> [   39.532361] commsdriver[624]: Could not resolve symbol name setup_interfaces <NL> [   39.532447] commsdriver[624]: Could not resolve symbol name post_setup_interfaces <NL> [   39.532507] commsdriver[624]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   39.532572] commsdriver[624]: Could not resolve symbol name setup_late_interfaces <NL> [   39.532629] commsdriver[624]: Could not resolve symbol name post_setup_late_interfaces <NL> [   39.532710] commsdriver[624]: Could not resolve symbol name pre_init <NL> [   39.532779] commsdriver[624]: Could not resolve symbol name post_init <NL> [   39.532836] commsdriver[624]: Could not resolve symbol name pre_handle_link_state_change <NL> [   39.533198] commsdriver[624]: Could not resolve symbol name handle_link_state_change <NL> [   39.533333] commsdriver[624]: Could not resolve symbol name post_handle_link_state_change <NL> [   39.533396] commsdriver[624]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   39.533454] commsdriver[624]: Could not resolve symbol name handle_link_state_notify <NL> [   39.533528] commsdriver[624]: Could not resolve symbol name post_handle_link_state_notify <NL> [   39.533584] commsdriver[624]: Could not resolve symbol name handle_rate_duplex_change <NL> [   39.533638] commsdriver[624]: Could not resolve symbol name delete_mac_address <NL> [   39.533693] commsdriver[624]: Could not resolve symbol name set_vlan_prio <NL> [   39.587992] commsdriver[624]: Could not resolve symbol name replay_mac <NL> [   39.591905] commsdriver[624]: Could not resolve symbol name set_red_state <NL> [   39.607813] commsdriver[624]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   39.608046] commsdriver[624]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   39.656498] commsdriver[624]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   39.656751] commsdriver[624]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   39.656895] commsdriver[624]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   39.694516] commsdriver[624]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   39.727657] commsdriver[624]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   39.727737] commsdriver[624]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   39.728058] commsdriver[624]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   39.728119] commsdriver[624]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   39.728176] commsdriver[624]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   39.728242] commsdriver[624]: SharedMemory::getShmSegment creating new segment <NL> [   39.728299] commsdriver[624]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   42.515851] br-lcn00: port 1(eth3) entered blocking state <NL> [   42.534646] br-lcn00: port 1(eth3) entered disabled state <NL> [   42.554712] device eth3 entered promiscuous mode <NL> [   42.577857] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   42.610606] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   42.629926] device lcn00-peer entered promiscuous mode <NL> [   42.718886] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   42.615740] commsdriver[624]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   43.450786] br-lcn01: port 1(eth4) entered blocking state <NL> [   43.471775] br-lcn01: port 1(eth4) entered disabled state <NL> [   43.499862] device eth4 entered promiscuous mode <NL> [   43.557203] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   43.575746] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   43.604661] device lcn01-peer entered promiscuous mode <NL> [   43.670157] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   43.546581] commsdriver[624]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   44.125739] br-lmp00: port 1(eth2) entered blocking state <NL> [   44.146331] br-lmp00: port 1(eth2) entered disabled state <NL> [   44.149560] device eth2 entered promiscuous mode <NL> [   44.189582] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   44.192102] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   44.192860] device lmp00-peer entered promiscuous mode <NL> [   44.276770] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   44.308424] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   44.331797] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   44.392200] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   44.208715] commsdriver[624]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   44.268319] commsdriver[624]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   44.524665] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   44.548529] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   44.565953] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   45.095028] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   45.096224] br-lcn00: port 1(eth3) entered blocking state <NL> [   45.105258] br-lcn00: port 1(eth3) entered forwarding state <NL> [   45.862747] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   45.924487] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   45.970347] br-lcn01: port 1(eth4) entered blocking state <NL> [   45.978560] br-lcn01: port 1(eth4) entered forwarding state <NL> [   45.782784] commsdriver[747]: SUCCESS <NL> [   46.311557] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.450163] br-lmp00: port 1(eth2) entered blocking state <NL> [   46.473223] br-lmp00: port 1(eth2) entered forwarding state <NL> [   47.314835] commsdriver[624]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   47.623991] device eth5 entered promiscuous mode <NL> [   47.417626] commsdriver[624]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   47.907971] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   47.909207] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   48.027329] commsdriver[624]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   48.274609] device erstp-peer entered promiscuous mode <NL> [   48.501538] br-odcc1: port 1(eth1) entered blocking state <NL> [   48.509159] br-odcc1: port 1(eth1) entered disabled state <NL> [   48.523655] device eth1 entered promiscuous mode <NL> [   48.534994] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   48.560599] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   48.583032] device odcc1-peer entered promiscuous mode <NL> [   48.687031] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   48.722629] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   48.729241] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   48.748135] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   48.566512] commsdriver[624]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   48.579571] commsdriver[624]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   49.139888] br-odcc2: port 1(eth6) entered blocking state <NL> [   49.167164] br-odcc2: port 1(eth6) entered disabled state <NL> [   49.197177] device eth6 entered promiscuous mode <NL> [   49.255517] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   49.259026] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   49.270671] device odcc2-peer entered promiscuous mode <NL> [   49.338438] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   49.367090] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   49.401511] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   49.421221] br-odcc2: port 2(odcc2-peer) entered disabled state"}
{"timestamp_utc": "2024-07-31T08:12:56.480Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:12:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:56 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:12:56.736Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:12:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:12:59.249Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:12:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:12:58 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:00.672Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   40.401490] commsdriver[624]: Could not resolve symbol name set_red_state <NL> [   40.421686] commsdriver[624]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   40.436269] commsdriver[624]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   40.509671] commsdriver[624]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   40.511231] commsdriver[624]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   40.512611] commsdriver[624]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.524862] commsdriver[624]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   40.555530] commsdriver[624]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.581527] commsdriver[624]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.642417] commsdriver[624]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   40.676377] commsdriver[624]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   40.731133] commsdriver[624]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.791647] commsdriver[624]: SharedMemory::getShmSegment creating new segment <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m... <NL> [   40.841271] commsdriver[624]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   43.072674] br-lcn00: port 1(eth3) entered blocking state <NL> [   43.075501] br-lcn00: port 1(eth3) entered disabled state <NL> [   43.082378] device eth3 entered promiscuous mode <NL> [   43.105200] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   43.105846] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   43.116488] device lcn00-peer entered promiscuous mode <NL> [   43.204151] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   42.850842] commsdriver[624]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   43.928796] br-lcn01: port 1(eth4) entered blocking state <NL> [   43.948724] br-lcn01: port 1(eth4) entered disabled state <NL> [   43.967559] device eth4 entered promiscuous mode <NL> [   43.986064] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   43.986709] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   43.987404] device lcn01-peer entered promiscuous mode <NL> [   44.129928] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   43.786810] commsdriver[624]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   44.781736] br-lmp00: port 1(eth2) entered blocking state <NL> [   44.795432] br-lmp00: port 1(eth2) entered disabled state <NL> [   44.808295] device eth2 entered promiscuous mode <NL> [   44.822135] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   44.861508] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   44.886050] device lmp00-peer entered promiscuous mode <NL> [   44.923593] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   44.958402] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   44.959037] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   44.982153] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   44.501793] commsdriver[624]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   44.587082] commsdriver[624]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   45.119924] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   45.129449] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   45.131085] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   45.622178] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   45.623479] br-lcn00: port 1(eth3) entered blocking state <NL> [   45.623996] br-lcn00: port 1(eth3) entered forwarding state <NL> [   46.553773] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   46.576896] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.585048] br-lcn01: port 1(eth4) entered blocking state <NL> [   46.590984] br-lcn01: port 1(eth4) entered forwarding state <NL> [   46.207567] commsdriver[754]: SUCCESS"}
{"timestamp_utc": "2024-07-31T08:13:00.673Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   46.976319] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.977558] br-lmp00: port 1(eth2) entered blocking state <NL> [   46.978096] br-lmp00: port 1(eth2) entered forwarding state <NL> [   48.662437] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   48.759137] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   49.178434] device eth5 entered promiscuous mode <NL> [   48.652699] commsdriver[624]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   48.726587] commsdriver[624]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   49.303620] commsdriver[624]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   49.849332] device erstp-peer entered promiscuous mode <NL> [   50.305417] br-odcc1: port 1(eth1) entered blocking state <NL> [   50.334554] br-odcc1: port 1(eth1) entered disabled state <NL> [   50.345087] device eth1 entered promiscuous mode <NL> [   50.375873] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   50.376538] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   50.380689] device odcc1-peer entered promiscuous mode <NL> [   50.411931] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   50.460848] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   50.475746] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   50.478192] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   50.031434] commsdriver[624]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   50.036927] commsdriver[624]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   50.881464] br-odcc2: port 1(eth6) entered blocking state <NL> [   50.882030] br-odcc2: port 1(eth6) entered disabled state <NL> [   50.882677] device eth6 entered promiscuous mode <NL> [   50.885431] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   50.886058] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   50.902040] device odcc2-peer entered promiscuous mode <NL> [   51.017679] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   51.052193] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   51.057339] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   51.062821] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   50.630942] commsdriver[624]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   50.640134] commsdriver[624]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   51.943406] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   51.980975] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   52.013074] device eth1.3800 entered promiscuous mode <NL> [   52.065604] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   52.085116] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   52.114948] device gcc0-peer entered promiscuous mode <NL> [   52.224342] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   52.229193] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   52.234558] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   51.775018] commsdriver[624]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   51.821379] commsdriver[624]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   52.720812] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   52.839788] br-odcc1: port 1(eth1) entered blocking state <NL> [   52.847969] br-odcc1: port 1(eth1) entered forwarding state <NL> [   52.862841] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   52.876000] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   52.894498] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.3801: link becomes ready <NL> [   53.246044] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   53.292621] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   53.335621] device eth1.3801 entered promiscuous mode <NL> [   53.364885] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   53.380636] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   53.411621] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   53.430375] device gcc1-peer entered promiscuous mode <NL> [   53.456163] br-odcc2: port 1(eth6) entered blocking state <NL> [   53.465110] br-odcc2: port 1(eth6) entered forwarding state <NL> [   53.677082] br-gcc1: port 1(eth1.3801) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:13:01.236Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   33.496634] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   33.419633] commsdriver[651]: SUCCESS <NL> fujitsu login: [   35.526081] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   35.527743] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   36.378407] commsdriver[610]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   36.645745] device eth1 entered promiscuous mode <NL> [   36.456919] commsdriver[610]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   36.748175] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   37.317894] commsdriver[610]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   37.400505] commsdriver[690]: Actual changes: <NL> [   37.400782] commsdriver[690]: tx-checksum-ip-generic: off <NL> [   37.400860] commsdriver[690]: tx-tcp-segmentation: off [not requested] <NL> [   37.400943] commsdriver[690]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   37.401045] commsdriver[690]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   37.401127] commsdriver[690]: tx-tcp6-segmentation: off [not requested] <NL> [   37.951182] commsdriver[610]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   38.107407] commsdriver[702]: Actual changes: <NL> [   38.107594] commsdriver[702]: tx-checksum-ip-generic: off <NL> [   38.107662] commsdriver[702]: tx-tcp-segmentation: off [not requested] <NL> [   38.108675] commsdriver[702]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   38.109134] commsdriver[702]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   38.109213] commsdriver[702]: tx-tcp6-segmentation: off [not requested] <NL> [   38.657376] br-odcc1: port 1(eth2) entered blocking state <NL> [   38.698083] br-odcc1: port 1(eth2) entered disabled state <NL> [   38.738221] device eth2 entered promiscuous mode <NL> [   38.778003] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   38.811406] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   38.846218] device odcc1-peer entered promiscuous mode <NL> [   38.938432] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   38.819130] commsdriver[610]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   38.826070] commsdriver[610]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   39.673516] br-odcc2: port 1(eth3) entered blocking state <NL> [   39.674066] br-odcc2: port 1(eth3) entered disabled state <NL> [   39.697692] device eth3 entered promiscuous mode <NL> [   39.730690] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   39.753969] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   39.755576] device odcc2-peer entered promiscuous mode <NL> [   39.765289] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   39.776442] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   39.908411] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   39.740851] commsdriver[610]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   39.756097] commsdriver[610]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   40.629550] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   40.646805] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   40.681018] device eth2.3800 entered promiscuous mode <NL> [   40.732446] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   40.762259] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   40.791938] device gcc0-peer entered promiscuous mode <NL> [   40.873511] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   40.887055] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   40.902122] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   40.722719] commsdriver[610]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   40.740324] commsdriver[610]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   41.354278] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   41.452657] br-odcc1: port 1(eth2) entered blocking state <NL> [   41.480148] br-odcc1: port 1(eth2) entered forwarding state <NL> [   41.503055] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   41.518681] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   41.837665] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   41.874263] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   41.909731] device eth2.3801 entered promiscuous mode <NL> [   41.934679] IPv6: ADDRCONF(NETDEV_CHANGE): eth2.3801: link becomes ready <NL> [   42.013518] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   42.014151] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   42.038403] device gcc1-peer entered promiscuous mode <NL> [   42.122681] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   42.142217] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   42.190513] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   42.220283] br-odcc2: port 1(eth3) entered blocking state <NL> [   42.251065] br-odcc2: port 1(eth3) entered forwarding state <NL> [   42.111176] commsdriver[610]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   42.115340] commsdriver[610]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   43.091450] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   43.119432] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   43.181955] device eth3.3802 entered promiscuous mode <NL> [   43.220786] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   43.237293] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   43.317003] device lwap-peer entered promiscuous mode <NL> [   43.513345] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   43.549513] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   43.594128] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   43.612549] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   43.437811] commsdriver[610]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   43.458028] commsdriver[610]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   43.979255] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   44.261209] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   44.281919] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   44.405751] device eth3.3803 entered promiscuous mode <NL> [   44.580977] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   44.668954] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   44.719119] device illdp-peer entered promiscuous mode <NL> [   44.948119] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   44.949816] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   44.963238] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   44.968156] br-illdp: port 2(illdp-peer) entered forwarding state <NL> [   45.018726] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   44.824260] commsdriver[610]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   44.955258] commsready[876]: callback: Entry PID=0x36C signo(15) <NL> [   44.955472] commsready[876]: DipLog_pimpl destructor called <NL> [   44.955548] commsready[876]: DipVerbosity Listener ZMQ error <NL> [   44.955603] commsready[876]:     ret='Context was terminated <NL> [   44.955699] commsready[876]: deleting subscriber_ socket <NL> [   44.955750] commsready[876]: Exiting verb listener <NL> [   45.025254] change_esal_priority.sh[882]: Comms check for and selectively change esal priorities <NL> [   45.733941] change_esal_priority.sh[882]: Comms did not change any esal thread priorities"}
{"timestamp_utc": "2024-07-31T08:13:01.237Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   46.016614] python[926]: running intRstpEnable file creation SCRIPT <NL> [   46.082614] python[926]: Already set to  TRUE <NL> [   46.104563] python[926]:  , NO CHANGE! <NL> [   46.564103] serialportMon[943]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   46.580895] sh[973]: In startMstpInt <NL> [   48.067358] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   48.139671] NFSD: Using legacy client tracking operations. <NL> [   48.240905] NFSD: starting 90-second grace period (net f0000098) <NL> [   48.512022] sh[973]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   50.639565] br.rstp_int: port 1(istp1) entered blocking state <NL> [   50.640182] br.rstp_int: port 1(istp1) entered disabled state <NL> [   50.640816] device istp1 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:13:01.493Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:01 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:02.140Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   26.835290] packet_injector_class: driver registered correctly with major number 246 <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m...[   26.915696] Packet_injector 257949696: minor device creation 246:0 <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   26.976883] Packet_injector 257949697: minor device creation 246:1 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m.[   26.990729] Packet_injector 257949698: minor device creation 246:2 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m.[   27.019505] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m...[   27.379700] systemd-journald[325]: Received client request to flush runtime journal. <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:02.141Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> [   29.985539] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (12s / no limit)[   34.390733] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   34.825905] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (13s / no limit)[   35.680022] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (14s / 5min 6s) <NL> [   36.187255] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   36.379564] Floppy drive(s): fd0 is 1.44M <NL> [   36.439909] FDC 0 is a S82078B <NL> [   38.427922] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   38.445774] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   39.147600] Console: switching to colour frame buffer device 128x48 <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (14s / 5min 6s)[   43.340223] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically restarts sync-log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> [   51.472426] sched: RT throttling activated <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:04.033Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:03 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:04.959Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   37.739920] commsdriver[593]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   37.838371] device eth1 entered promiscuous mode <NL> [   37.783870] commsdriver[593]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   38.285362] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   38.317681] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   38.422565] commsdriver[593]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   38.483619] commsdriver[689]: Actual changes: <NL> [   38.483799] commsdriver[689]: tx-checksum-ip-generic: off <NL> [   38.483868] commsdriver[689]: tx-tcp-segmentation: off [not requested] <NL> [   38.483920] commsdriver[689]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   38.483973] commsdriver[689]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   38.484048] commsdriver[689]: tx-tcp6-segmentation: off [not requested] <NL> [   39.175752] commsdriver[593]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   39.289645] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1000: link becomes ready <NL> [   39.318562] commsdriver[702]: Actual changes: <NL> [   39.318738] commsdriver[702]: tx-checksum-ip-generic: off <NL> [   39.318803] commsdriver[702]: tx-tcp-segmentation: off [not requested] <NL> [   39.318858] commsdriver[702]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   39.318915] commsdriver[702]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   39.318982] commsdriver[702]: tx-tcp6-segmentation: off [not requested] <NL> [   39.805418] br-odcc1: port 1(eth2) entered blocking state <NL> [   39.835715] br-odcc1: port 1(eth2) entered disabled state <NL> [   39.884173] device eth2 entered promiscuous mode <NL> [   39.914255] br-odcc1: port 2(odcc1-peer) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:13:04.960Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   39.951014] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   39.958675] device odcc1-peer entered promiscuous mode <NL> [   40.045804] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   40.111860] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   40.133999] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   40.159726] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   40.136927] commsdriver[593]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   40.144310] commsdriver[593]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   40.904589] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   40.906329] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   41.118407] br-odcc2: port 1(eth3) entered blocking state <NL> [   41.180574] br-odcc2: port 1(eth3) entered disabled state <NL> [   41.212215] device eth3 entered promiscuous mode <NL> [   41.264832] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   41.282692] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   41.283470] device odcc2-peer entered promiscuous mode <NL> [   41.409953] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   41.430026] commsdriver[593]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   41.470395] commsdriver[593]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   42.503078] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   42.573776] br-odcc1: port 1(eth2) entered blocking state <NL> [   42.612165] br-odcc1: port 1(eth2) entered forwarding state <NL> [   42.637883] IPv6: ADDRCONF(NETDEV_CHANGE): eth2.3800: link becomes ready <NL> [   42.653779] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   42.654387] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   42.667935] device eth2.3800 entered promiscuous mode <NL> [   42.700571] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   42.701981] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   42.712709] device gcc0-peer entered promiscuous mode <NL> [   42.790898] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   42.812527] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   42.850286] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   42.850805] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   42.828704] commsdriver[593]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   42.850137] commsdriver[593]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   43.450339] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   43.685577] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   43.686164] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   43.698113] device eth2.3801 entered promiscuous mode <NL> [   43.764706] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   43.765335] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   43.778098] device gcc1-peer entered promiscuous mode <NL> [   43.900042] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   43.998000] br-odcc2: port 1(eth3) entered blocking state <NL> [   44.024380] br-odcc2: port 1(eth3) entered forwarding state <NL> [   44.089133] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   44.091325] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   44.104850] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   44.111603] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   44.091730] commsdriver[593]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   44.103753] commsdriver[593]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   44.440397] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   45.001481] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   45.019134] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   45.079618] device eth3.3802 entered promiscuous mode <NL> [   45.106583] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   45.124591] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   45.141440] device lwap-peer entered promiscuous mode <NL> [   45.330541] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   45.367328] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   45.478698] commsdriver[593]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   45.487756] commsdriver[593]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   46.674781] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   46.685451] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   46.717522] device eth3.3803 entered promiscuous mode <NL> [   46.762804] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   46.786475] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   46.823379] device illdp-peer entered promiscuous mode <NL> [   46.999065] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   46.999703] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   47.050891] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   47.112547] br-illdp: port 2(illdp-peer) entered forwarding state <NL> [   47.104672] commsdriver[593]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   47.398441] commsready[875]: callback: Entry PID=0x36B signo(15) <NL> [   47.426205] change_esal_priority.sh[879]: Comms check for and selectively change esal priorities <NL> [   47.527539] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   48.545768] change_esal_priority.sh[879]: Comms did not change any esal thread priorities <NL> [   48.945982] python[941]: running intRstpEnable file creation SCRIPT <NL> [   48.971321] python[941]: Already set to  TRUE <NL> [   48.989552] python[941]:  , NO CHANGE! <NL> [   49.597390] serialportMon[955]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   49.820053] sh[978]: In startMstpInt <NL> [   50.255855] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   50.349874] NFSD: Using legacy client tracking operations. <NL> [   50.350480] NFSD: starting 90-second grace period (net f0000098) <NL> [   51.515048] sh[978]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   54.060531] br.rstp_int: port 1(istp1) entered blocking state <NL> [   54.061153] br.rstp_int: port 1(istp1) entered disabled state <NL> [   54.061822] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:02,091 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml"}
{"timestamp_utc": "2024-07-31T08:13:06.851Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:06 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:09.371Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:08 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:09.932Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:09 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:10.493Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [   49.817805] pktHandler[484]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [   50.255686] pktHandler[484]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   50.765438] pktHandler[484]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   51.909859] pktHandler[484]: GetRxFilters:83 rawdata= <NL> [   52.419400] pktHandler[484]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   52.714292] pktHandler[484]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   53.239083] pktHandler[484]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   53.843253] pktHandler[484]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [   54.693647] pktHandler[484]: GetRxFilters:83 rawdata= <NL> [   55.643403] pktHandler[484]: Init PktClient init complete <NL> [   55.645185] pktHandler[484]: EsalConfig::EsalConfig main 1 <NL> [   55.829075] pktHandler[484]: EsalConfig::EsalConfig trib 0 <NL> [   55.877154] pktHandler[484]: EsalConfig::EsalConfig ciRole 0"}
{"timestamp_utc": "2024-07-31T08:13:10.494Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   56.139231] pktHandler[484]: EsalConfig is not running inside container. <NL> [   56.333173] pktHandler[484]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   57.127622] pktHandler[484]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> fujitsu[   57.520479] pktHandler[484]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> login: [   57.913440] pktHandler[484]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   58.376806] pktHandler[484]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   58.532867] pktHandler[484]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   58.667045] pktHandler[484]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   58.804793] pktHandler[484]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   58.805807] pktHandler[484]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   58.959295] pktHandler[484]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   59.034120] pktHandler[484]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   59.110613] pktHandler[484]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   59.164262] pktHandler[484]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   59.218823] pktHandler[484]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   59.265534] pktHandler[484]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   59.325374] pktHandler[484]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   59.416595] pktHandler[484]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   59.513710] pktHandler[484]: pkt-handler: sd_notify ready <NL> [   59.714439] commsdriver[531]: DllUtil::symbolInit() <NL> [   59.833594] commsdriver[531]: int DllInit() <NL> [   59.839052] commsdriver[531]: DllUtil::DllInit DllInit() return is null <NL> [   59.896228] commsdriver[531]: Could not resolve symbol name get_late_config_file_path <NL> [   60.047394] commsdriver[531]: Could not resolve symbol name create_l3_interface[   60.588896] br-lcn00: port 1(eth3) entered blocking state <NL> [   60.213565] commsdriver[531]: Could not resolve symbol name create_l2_interface <NL> [   60.232917] commsdriver[531]: Could not resolve symbol name delete_interface <NL> [   60.233630] commsdriver[531]: Could not resolve symbol name pre_setup_interfaces <NL> [   60.234301] commsdriver[531]: Could not resolve symbol name setup_interfaces <NL> [   60.234921] commsdriver[531]: Could not resolve symbol name post_setup_interfaces <NL> [   60.235612] commsdriver[531]: Could not resolve symbol name pre_setup_late_interfaces[   60.754216] br-lcn00: port 1(eth3) entered disabled state <NL> [   60.756758] device eth3 entered promiscuous mode <NL> [   60.374496] commsdriver[531]: Could not resolve symbol name setup_late_interfaces[   60.890767] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   60.442345] commsdriver[531]: Could not resolve symbol name post_setup_late_interfaces <NL> [   60.443102] commsdriver[531]: Could not resolve symbol name pre_init <NL> [   60.443701] commsdriver[531]: Could not resolve symbol name post_init <NL> [   60.444423] commsdriver[531]: Could not resolve symbol name pre_handle_link_state_change <NL> [   60.460565] commsdriver[531]: Could not resolve symbol name handle_link_state_change[   60.964017] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   60.978882] device lcn00-peer entered promiscuous mode <NL> [   60.511849] commsdriver[531]: Could not resolve symbol name post_handle_link_state_change <NL> [   60.512662] commsdriver[531]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   60.513452] commsdriver[531]: Could not resolve symbol name handle_link_state_notify <NL> [   60.559668] commsdriver[531]: Could not resolve symbol name post_handle_link_state_notify <NL> [   60.638282] commsdriver[531]: Could not resolve symbol name handle_rate_duplex_change <NL> [   60.711136] commsdriver[531]: Could not resolve symbol name delete_mac_address <NL> [   60.763616] commsdriver[531]: Could not resolve symbol name set_vlan_prio <NL> [   60.824932] commsdriver[531]: Could not resolve symbol name replay_mac <NL> [   61.376151] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   60.909205] commsdriver[531]: Could not resolve symbol name set_red_state <NL> [   60.922913] commsdriver[531]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   60.958125] commsdriver[531]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   60.958984] commsdriver[531]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   60.964137] commsdriver[531]: unitcode=02_00_00_00, uc=02_00_00_00"}
{"timestamp_utc": "2024-07-31T08:13:11.420Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:11 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:11.982Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:13:11 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:13.410Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   56.737737] pktHandler[517]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   57.135054] pktHandler[517]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   57.145326] pktHandler[517]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   57.146319] pktHandler[517]: GetRxFilters:83 rawdata= <NL> [   57.203207] pktHandler[517]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   57.204046] pktHandler[517]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   57.479618] pktHandler[517]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   58.456754] pktHandler[517]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   59.358470] pktHandler[517]: GetRxFilters:83 rawdata= <NL> [   59.912414] pktHandler[517]: Init PktClient init complete <NL> [   60.024569] pktHandler[517]: EsalConfig::EsalConfig main 1 <NL> [   60.159652] pktHandler[517]: EsalConfig::EsalConfig trib 0 <NL> [   60.352294] pktHandler[517]: EsalConfig::EsalConfig ciRole 0 <NL> [   60.797655] pktHandler[517]: EsalConfig is not running inside container. <NL> [   61.065408] pktHandler[517]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   61.201512] pktHandler[517]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   61.472153] pktHandler[517]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   61.908246] pktHandler[517]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   62.150677] pktHandler[517]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> fujitsu login: [   62.506516] pktHandler[517]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   62.670737] pktHandler[517]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   62.830216] pktHandler[517]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   63.309684] pktHandler[517]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   63.310383] pktHandler[517]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   63.599254] pktHandler[517]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   64.082369] pktHandler[517]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   64.083172] pktHandler[517]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   64.083841] pktHandler[517]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   64.124454] pktHandler[517]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   64.335613] pktHandler[517]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   64.451309] pktHandler[517]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   64.453176] pktHandler[517]: pkt-handler: sd_notify ready <NL> [   64.837358] commsdriver[544]: DllUtil::symbolInit() <NL> [   64.945287] commsdriver[544]: int DllInit() <NL> [   64.975282] commsdriver[544]: DllUtil::DllInit DllInit() return is null <NL> [   64.991652] commsdriver[544]: Could not resolve symbol name get_late_config_file_path <NL> [   65.042710] commsdriver[544]: Could not resolve symbol name create_l3_interface <NL> [   65.103501] commsdriver[544]: Could not resolve symbol name create_l2_interface <NL> [   65.171653] commsdriver[544]: Could not resolve symbol name delete_interface <NL> [   65.181941] commsdriver[544]: Could not resolve symbol name pre_setup_interfaces <NL> [   65.182731] commsdriver[544]: Could not resolve symbol name setup_interfaces <NL> [   65.183387] commsdriver[544]: Could not resolve symbol name post_setup_interfaces <NL> [   65.184071] commsdriver[544]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   65.184738] commsdriver[544]: Could not resolve symbol name setup_late_interfaces <NL> [   65.225129] commsdriver[544]: Could not resolve symbol name post_setup_late_interfaces <NL> [   65.256875] commsdriver[544]: Could not resolve symbol name pre_init <NL> [   65.293143] commsdriver[544]: Could not resolve symbol name post_init <NL> [   65.314438] commsdriver[544]: Could not resolve symbol name pre_handle_link_state_change <NL> [   65.343620] commsdriver[544]: Could not resolve symbol name handle_link_state_change <NL> [   65.365988] commsdriver[544]: Could not resolve symbol name post_handle_link_state_change <NL> [   65.378302] commsdriver[544]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   65.385694] commsdriver[544]: Could not resolve symbol name handle_link_state_notify <NL> [   65.386416] commsdriver[544]: Could not resolve symbol name post_handle_link_state_notify <NL> [   65.387111] commsdriver[544]: Could not resolve symbol name handle_rate_duplex_change <NL> [   65.388348] commsdriver[544]: Could not resolve symbol name delete_mac_address <NL> [   65.389066] commsdriver[544]: Could not resolve symbol name set_vlan_prio <NL> [   65.389691] commsdriver[544]: Could not resolve symbol name replay_mac <NL> [   65.390321] commsdriver[544]: Could not resolve symbol name set_red_state <NL> [   65.392654] commsdriver[544]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   65.393434] commsdriver[544]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   65.394267] commsdriver[544]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   65.395301] commsdriver[544]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   65.396159] commsdriver[544]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   65.397384] commsdriver[544]: late config file=unitcode=02_00_00_00, uc=02_00_00_00"}
{"timestamp_utc": "2024-07-31T08:13:13.411Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   65.398196] commsdriver[544]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   65.399170] commsdriver[544]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   65.399843] commsdriver[544]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   65.400520] commsdriver[544]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   65.401099] commsdriver[544]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   65.402451] commsdriver[544]: SharedMemory::getShmSegment creating new segment <NL> [   65.406412] commsdriver[544]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   66.045757] br-lcn00: port 1(eth3) entered blocking state <NL> [   66.070008] br-lcn00: port 1(eth3) entered disabled state <NL> [   66.132494] device eth3 entered promiscuous mode <NL> [   66.163846] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   66.217101] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   66.261448] device lcn00-peer entered promiscuous mode <NL> [   66.335094] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   66.349504] commsdriver[544]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   66.694238] br-lcn01: port 1(eth4) entered blocking state <NL> [   66.705991] br-lcn01: port 1(eth4) entered disabled state <NL> [   66.719115] device eth4 entered promiscuous mode <NL> [   66.732835] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   66.741559] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   66.750561] device lcn01-peer entered promiscuous mode <NL> [   66.820672] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   66.853685] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   66.879265] br-lcn01: port 2(lcn01-peer) entered forwarding state <NL> [   66.900125] br-lcn01: port 2(lcn01-peer) entered disabled state"}
{"timestamp_utc": "2024-07-31T08:13:13.971Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:13 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:14.897Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:16.783Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:16 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:19.296Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:18 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:21.813Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:21 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:24.327Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:23 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:26.837Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:26 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:29.348Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:28 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:29.911Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:29 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:30.471Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   60.965689] commsdriver[531]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.068340] commsdriver[531]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   61.070542] commsdriver[531]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.110772] commsdriver[531]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.113140] commsdriver[531]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   61.113837] commsdriver[531]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   61.114451] commsdriver[531]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.193619] commsdriver[531]: SharedMemory::getShmSegment creating new segment <NL> [   61.287457] commsdriver[531]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   61.502072] commsdriver[531]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   62.515042] br-lcn01: port 1(eth4) entered blocking state <NL> [   62.515628] br-lcn01: port 1(eth4) entered disabled state <NL> [   62.516720] device eth4 entered promiscuous mode <NL> [   62.536069] br-lcn01: port 2(lcn01-peer) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:13:30.472Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   62.597277] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   62.678220] device lcn01-peer entered promiscuous mode <NL> [   62.960060] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   62.572692] commsdriver[531]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   63.270087] br-lmp00: port 1(eth2) entered blocking state <NL> [   63.281375] br-lmp00: port 1(eth2) entered disabled state <NL> [   63.294831] device eth2 entered promiscuous mode <NL> [   63.315542] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   63.327261] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   63.335752] device lmp00-peer entered promiscuous mode <NL> [   63.356543] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   63.370304] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   63.378447] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   63.386531] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   62.917415] commsdriver[531]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   62.943220] commsdriver[531]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   63.442045] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   63.449785] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   64.224878] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   64.251308] br-lcn00: port 1(eth3) entered blocking state <NL> [   64.300064] br-lcn00: port 1(eth3) entered forwarding state <NL> [   65.081750] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   65.255679] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   65.285439] br-lcn01: port 1(eth4) entered blocking state <NL> [   65.325132] br-lcn01: port 1(eth4) entered forwarding state <NL> [   64.903300] commsdriver[679]: SUCCESS[   65.443968] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   65.532544] br-lmp00: port 1(eth2) entered blocking state <NL> [   65.560160] br-lmp00: port 1(eth2) entered forwarding state <NL> [   67.114680] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   67.157443] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   68.485698] commsdriver[531]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   69.100145] device eth5 entered promiscuous mode <NL> [   68.658832] commsdriver[531]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   69.369143] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   69.867134] commsdriver[531]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   70.432507] device erstp-peer entered promiscuous mode <NL> [   70.958958] br-odcc1: port 1(eth1) entered blocking state <NL> [   71.066741] br-odcc1: port 1(eth1) entered disabled state <NL> [   71.137810] device eth1 entered promiscuous mode <NL> [   71.190117] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   71.190790] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   71.245855] device odcc1-peer entered promiscuous mode <NL> [   71.710286] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   71.451922] commsdriver[531]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   71.613312] commsdriver[531]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   72.932720] br-odcc2: port 1(eth6) entered blocking state <NL> [   73.017483] br-odcc2: port 1(eth6) entered disabled state <NL> [   73.121807] device eth6 entered promiscuous mode <NL> [   73.161761] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   73.233650] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   73.280793] device odcc2-peer entered promiscuous mode <NL> [   73.463218] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   73.093455] commsdriver[531]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   73.180259] commsdriver[531]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   74.467633] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   74.531567] br-odcc1: port 1(eth1) entered blocking state <NL> [   74.559059] br-odcc1: port 1(eth1) entered forwarding state <NL> [   74.637557] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.3800: link becomes ready <NL> [   74.732706] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   74.754865] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   74.807610] device eth1.3800 entered promiscuous mode <NL> [   74.869032] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   74.893473] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   74.921416] device gcc0-peer entered promiscuous mode <NL> [   75.060520] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   75.074316] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   74.707789] commsdriver[531]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   74.858261] commsdriver[531]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   75.836029] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   75.910915] br-odcc2: port 1(eth6) entered blocking state <NL> [   75.941944] br-odcc2: port 1(eth6) entered forwarding state <NL> [   76.699712] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   76.800797] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   76.813878] device eth1.3801 entered promiscuous mode <NL> [   77.079025] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   77.122432] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   77.133283] device gcc1-peer entered promiscuous mode <NL> [   77.449986] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   77.488698] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   77.112630] commsdriver[531]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   77.162877] commsdriver[531]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   78.506014] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   78.580789] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   78.649363] device eth6.3802 entered promiscuous mode <NL> [   78.935370] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   79.027659] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   79.051587] device lwap-peer entered promiscuous mode <NL> [   79.232274] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   79.280136] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   78.969493] commsdriver[531]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   79.069719] commsdriver[531]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   79.845564] commsdriver[531]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   79.918165] commsdriver[868]: Actual changes: <NL> [   79.937147] commsdriver[868]: tx-checksum-ip-generic: off <NL> [   79.948972] commsdriver[868]: tx-tcp-segmentation: off [not requested] <NL> [   79.978478] commsdriver[868]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   80.003380] commsdriver[868]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   80.106622] commsdriver[868]: tx-tcp6-segmentation: off [not requested] <NL> [   80.741474] commsdriver[531]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   80.904997] commsdriver[880]: Actual changes: <NL> [   81.007140] commsdriver[880]: tx-checksum-ip-generic: off"}
{"timestamp_utc": "2024-07-31T08:13:31.834Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:31 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:31 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:34.345Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:33 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:34.905Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:35.831Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   66.869239] commsdriver[544]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   67.363071] br-lmp00: port 1(eth2) entered blocking state <NL> [   67.401331] br-lmp00: port 1(eth2) entered disabled state <NL> [   67.431130] device eth2 entered promiscuous mode <NL> [   67.444247] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   67.456677] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   67.469473] device lmp00-peer entered promiscuous mode <NL> [   67.495406] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   67.512408] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   67.523365] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   67.532440] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   67.481530] commsdriver[544]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   67.508123] commsdriver[544]: DEBUG: set_ip Marking lmp00 down for 2[   67.594928] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   67.605673] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   68.653246] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   68.654531] br-lcn00: port 1(eth3) entered blocking state <NL> [   68.680189] br-lcn00: port 1(eth3) entered forwarding state <NL> [   69.094274] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   69.167562] br-lcn01: port 1(eth4) entered blocking state <NL> [   69.204141] br-lcn01: port 1(eth4) entered forwarding state <NL> [   69.409849] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   69.398551] commsdriver[688]: SUCCESS <NL> [   69.544318] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   69.573294] br-lmp00: port 1(eth2) entered blocking state <NL> [   69.591832] br-lmp00: port 1(eth2) entered forwarding state <NL> [   71.051212] commsdriver[544]: DEBUG: change_linkstate Marking eth5.2003 down for 44[   71.170298] device eth5 entered promiscuous mode <NL> [   71.120551] commsdriver[544]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   71.467414] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   71.550527] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   71.641161] commsdriver[544]: DEBUG: change_linkstate Marking erstp down for 46[   71.789776] device erstp-peer entered promiscuous mode <NL> [   72.364673] br-odcc1: port 1(eth1) entered blocking state <NL> [   72.472159] br-odcc1: port 1(eth1) entered disabled state <NL> [   72.575565] device eth1 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:13:35.832Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   72.680387] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   72.739433] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   72.778186] device odcc1-peer entered promiscuous mode <NL> [   72.861797] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   72.913976] commsdriver[544]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   73.019799] commsdriver[544]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   73.747773] br-odcc2: port 1(eth6) entered blocking state <NL> [   73.776847] br-odcc2: port 1(eth6) entered disabled state <NL> [   73.778070] device eth6 entered promiscuous mode <NL> [   73.822839] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   73.892147] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   73.926212] device odcc2-peer entered promiscuous mode <NL> [   74.213378] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   74.208272] commsdriver[544]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   74.304284] commsdriver[544]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   75.431384] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   75.466012] br-odcc1: port 1(eth1) entered blocking state <NL> [   75.466603] br-odcc1: port 1(eth1) entered forwarding state <NL> [   75.467239] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.3800: link becomes ready <NL> [   75.684847] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   75.745610] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   75.790330] device eth1.3800 entered promiscuous mode <NL> [   75.839529] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   75.863227] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   75.886771] device gcc0-peer entered promiscuous mode <NL> [   76.008709] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   76.009325] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   75.980795] commsdriver[544]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   76.004414] commsdriver[544]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   76.576291] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   76.634562] br-odcc2: port 1(eth6) entered blocking state <NL> [   76.663734] br-odcc2: port 1(eth6) entered forwarding state <NL> [   76.958759] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   76.968115] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   77.000954] device eth1.3801 entered promiscuous mode <NL> [   77.073242] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   77.134528] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   77.274947] device gcc1-peer entered promiscuous mode <NL> [   77.432002] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   77.455698] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   77.479236] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   77.479854] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   77.500514] commsdriver[544]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   77.563776] commsdriver[544]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   77.852646] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   78.180895] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   78.222231] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   78.252881] device eth6.3802 entered promiscuous mode <NL> [   78.312367] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   78.421572] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   78.500259] device lwap-peer entered promiscuous mode <NL> [   78.665082] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   78.702539] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   78.737151] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   78.740832] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   78.794592] commsdriver[544]: DEBUG: change_linkstate Marking lwap down for 15[   78.889145] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   78.907041] commsdriver[544]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   79.932812] commsdriver[544]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   80.031997] commsdriver[872]: Actual changes: <NL> [   80.032582] commsdriver[872]: tx-checksum-ip-generic: off <NL> [   80.033099] commsdriver[872]: tx-tcp-segmentation: off [not requested] <NL> [   80.033664] commsdriver[872]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   80.055046] commsdriver[872]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   80.055818] commsdriver[872]: tx-tcp6-segmentation: off [not requested] <NL> [   80.210163] e1000 0000:00:08.0 eth5: Reset adapter <NL> [   80.666426] commsdriver[544]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   80.916051] commsdriver[884]: Actual changes: <NL> [   80.972090] commsdriver[884]: tx-checksum-ip-generic: off <NL> [   81.029331] commsdriver[884]: tx-tcp-segmentation: off [not requested] <NL> [   81.183343] commsdriver[884]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   81.305721] commsdriver[884]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   81.388258] commsdriver[884]: tx-tcp6-segmentation: off [not requested] <NL> [   81.645767] commsready[887]: callback: Entry PID=0x377 signo(15) <NL> [   81.730748] change_esal_priority.sh[891]: Comms check for and selectively change esal priorities <NL> [   82.341227] change_esal_priority.sh[891]: Comms did not change any esal thread priorities[   82.460905] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   82.539291] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   84.756323] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   89.242698] NFSD: Using legacy client tracking operations."}
{"timestamp_utc": "2024-07-31T08:13:36.760Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:36 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:37.015Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:13:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:39.527Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:39 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:42.040Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:41 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:44.551Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:44 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:47.060Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:46 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:49.573Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:49 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:49.830Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:49 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:51.716Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:51 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:51.971Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:13:51 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:54.480Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:54 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:55.039Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:56.924Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:56 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:57.848Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   37.078993] br-odcc1: port 1(eth2) entered disabled state <NL> [   37.087427] device eth2 entered promiscuous mode <NL> [   37.160851] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   37.172872] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   37.179477] device odcc1-peer entered promiscuous mode <NL> [   37.220977] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   37.249405] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   37.260679] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   37.279012] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   36.999532] commsdriver[606]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   36.999713] commsdriver[606]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   37.614949] br-odcc2: port 1(eth3) entered blocking state <NL> [   37.630659] br-odcc2: port 1(eth3) entered disabled state <NL> [   37.649314] device eth3 entered promiscuous mode <NL> [   37.686034] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   37.758110] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   37.827098] device odcc2-peer entered promiscuous mode <NL> [   38.033221] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   37.901692] commsdriver[606]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   38.313804] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   38.315750] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   38.023739] commsdriver[606]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   39.384530] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   39.416820] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   39.454678] device eth2.3800 entered promiscuous mode <NL> [   39.508305] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   39.556960] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   39.565545] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   39.580904] device gcc0-peer entered promiscuous mode <NL> [   39.607638] br-odcc1: port 1(eth2) entered blocking state <NL> [   39.641903] br-odcc1: port 1(eth2) entered forwarding state <NL> [   39.671883] IPv6: ADDRCONF(NETDEV_CHANGE): eth2.3800: link becomes ready <NL> [   39.890963] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   39.891598] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   39.922641] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   39.930314] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   39.970552] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   39.663509] commsdriver[606]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   39.718535] commsdriver[606]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   40.654704] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   40.657909] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   40.691985] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   40.725925] device eth2.3801 entered promiscuous mode <NL> [   40.749242] br-gcc1: port 2(gcc1-peer) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:13:57.849Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   40.749245] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   40.749348] device gcc1-peer entered promiscuous mode <NL> [   40.761013] br-odcc2: port 1(eth3) entered blocking state <NL> [   40.774120] br-odcc2: port 1(eth3) entered forwarding state <NL> [   41.019666] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   41.025992] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   40.869212] commsdriver[606]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   40.901251] commsdriver[606]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   42.245975] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   42.299177] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   42.349768] device eth3.3802 entered promiscuous mode <NL> [   42.402006] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   42.416934] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   42.435133] device lwap-peer entered promiscuous mode <NL> [   42.589478] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   42.610292] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   42.689816] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   42.717523] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   42.506419] commsdriver[606]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   42.535237] commsdriver[606]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   43.078082] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   43.450310] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   43.450940] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   43.470517] device eth3.3803 entered promiscuous mode <NL> [   43.514648] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   43.515266] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   43.515970] device illdp-peer entered promiscuous mode <NL> [   43.607285] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   43.607958] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   43.622399] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   43.630005] br-illdp: port 2(illdp-peer) entered forwarding state <NL> [   43.351492] commsdriver[606]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   43.593060] commsready[877]: callback: Entry PID=0x36D signo(15) <NL> [   43.634334] change_esal_priority.sh[881]: Comms check for and selectively change esal priorities <NL> [   44.107764] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   44.442753] change_esal_priority.sh[881]: Comms did not change any esal thread priorities <NL> [   44.930432] serialportMon[939]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   45.035472] python[926]: running intRstpEnable file creation SCRIPT <NL> [   45.035660] python[926]: Already set to  TRUE <NL> [   45.035739] python[926]:  , NO CHANGE! <NL> [   45.537112] sh[976]: In startMstpInt <NL> [   46.382761] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   46.534755] NFSD: Using legacy client tracking operations. <NL> [   46.633978] NFSD: starting 90-second grace period (net f0000098) <NL> [   47.768244] sh[976]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> 2024-07-31 08:12:55,222 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> [   50.179332] br.rstp_int: port 1(istp1) entered blocking state <NL> [   50.194845] br.rstp_int: port 1(istp1) entered disabled state <NL> [   50.210660] device istp1 entered promiscuous mode <NL> 2024-07-31 08:12:55,778 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:12:55,778 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:12:55,778 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   59.857840] vsftpd_listen_address[943]: listen_address=127.1.1.1 <NL> [   61.544072] br.rstp_int: port 2(istp2) entered blocking state <NL> [   61.579305] br.rstp_int: port 2(istp2) entered disabled state <NL> [   61.599777] device istp2 entered promiscuous mode <NL> [   81.030490] hrtimer: interrupt took 10051969 ns <NL> [  111.903064] ntputils[1739]: int ntputils_main(int, char**)Starting ntputils <NL> [  111.983212] ntputils[1739]: Running as a daemon <NL> [  112.010549] ntputils[1739]: shelf role is: TRIB <NL> [  112.018576] ntputils[1739]: slot number is: 0 <NL> [  112.037692] ntputils[1739]: slot role is: UNKNOWN <NL> [  112.083010] ntputils[1739]: redundancy_mode: UNKNOWN <NL> [  112.092699] ntputils[1739]: Executing on a work blade <NL> 2024-07-31 08:13:57,572 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 61 seconds <NL> [  112.114145] ntputils[1739]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  112.151951] ntputils[1739]: ================================"}
{"timestamp_utc": "2024-07-31T08:13:59.216Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:59 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:02.425Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:01 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:04.109Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:04.110Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:04 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:06.627Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  112.152076] ntputils[1739]: shelf_role is: TRIB"}
{"timestamp_utc": "2024-07-31T08:14:06.628Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  112.152148] ntputils[1739]: redundancy_mode: UNKNOWN <NL> [  112.152201] ntputils[1739]: active_status: active <NL> [  112.152275] ntputils[1739]: ntp_role: trib <NL> [  112.152335] ntputils[1739]: ================================ <NL> [  112.152446] ntputils[1739]: NTPUtilsConfig::do_default_config <NL> [  112.152513] ntputils[1739]: shelf_num/is_client: 1 <NL> [  112.152572] ntputils[1739]: server_ip: 0x557f05aa0fc0 <NL> [  112.152632] ntputils[1739]: ip_addr(ilan): 0x557f05aa0f80 <NL> [  112.152699] ntputils[1739]: ntp_role trib <NL> [  112.152761] ntputils[1739]: shelf_num aka is_client > 0 <NL> [  112.152821] ntputils[1739]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.152880] ntputils[1739]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.152941] ntputils[1739]: NTPServer::execute_cmd spawning: <NL> [  112.153012] ntputils[1739]: systemctl --no-block stop ntpd <NL> [  112.202987] ntputils[1739]: child pid is 1753 <NL> [  112.234518] ntputils[1739]: exited, status is 0 <NL> [  112.235048] ntputils[1739]: NTPServer::execute_cmd spawning: <NL> [  112.258438] ntputils[1739]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.258523] ntputils[1739]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.258589] ntputils[1739]: child pid is 1759 <NL> [  112.260051] ntputils[1771]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:13:57,862 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:13:57,862 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> 2024-07-31 08:13:58,062 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:13:58,118 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  112.619924] ntputils[1783]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:13:58,229 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:13:58,230 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:13:58,230 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:13:58,230 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:13:58,230 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:13:58,230 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:13:58,232 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:13:58,232 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:13:58,232 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:13:58,265 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  112.788538] ntputils[1739]: exited, status is 0 <NL> [  112.788713] ntputils[1739]: NTPServer::execute_cmd spawning: <NL> [  112.788780] ntputils[1739]: /bin/systemctl reset-failed ntpd <NL> [  112.819049] ntputils[1739]: child pid is 1811 <NL> [  112.872755] ntputils[1739]: exited, status is 0 <NL> [  112.872935] ntputils[1739]: NTPServer::execute_cmd spawning: <NL> [  112.872993] ntputils[1739]: systemctl --no-block start ntpd <NL> [  112.946011] ntputils[1739]: child pid is 1812 <NL> [  113.102217] ntputils[1739]: exited, status is 0 <NL> [  113.102345] ntputils[1739]: client role with Python client, systemD starts it <NL> [  114.600576] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  114.600759] ntputils_client.py[1740]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  114.600852] ntputils_client.py[1740]: b'31 Jul 08:14:00 ntpdate[1854]: the NTP socket is in use, exiting\\n' <NL> 2024-07-31 08:14:02,453 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:02,476 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:02,481 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:02,493 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent"}
{"timestamp_utc": "2024-07-31T08:14:06.629Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "2024-07-31 08:14:02,532 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:02,534 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:02,584 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:02,552 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:02,620 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:02,621 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> [  117.225207] fujitsu-check-ssh-host-key.pl[1899]: Checking system account status... <NL> [  117.244597] fujitsu-check-ssh-host-key.pl[1899]: System account found... <NL> [  117.312761] fujitsu-check-ssh-host-key.pl[1899]: 3004 <NL> [  117.323707] fujitsu-check-ssh-host-key.pl[1899]: /bin/bash <NL> [  117.323901] fujitsu-check-ssh-host-key.pl[1899]: /home/system exists <NL> [  117.323967] fujitsu-check-ssh-host-key.pl[1899]: Checking for trib... <NL> [  117.358497] fujitsu-check-ssh-host-key.pl[1899]: Creating factory user for trib.. <NL> 2024-07-31 08:14:03,674 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:03,676 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:03,676 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:03,677 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:03,738 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:03,881 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:14:03,882 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:14:03,882 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  119.073595] fujitsu-check-ssh-host-key.pl[1927]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  119.073792] fujitsu-check-ssh-host-key.pl[1927]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  119.108540] fujitsu-check-ssh-host-key.pl[1933]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  119.108691] fujitsu-check-ssh-host-key.pl[1933]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  119.368214] fujitsu-check-ssh-host-key.pl[1949]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  119.370595] fujitsu-check-ssh-host-key.pl[1949]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  119.677835] fujitsu-check-ssh-host-key.pl[1957]: useradd: user 'fujitsu' already exists <NL> [  120.683097] fujitsu-check-ssh-host-key.pl[1913]: DDS Peristency is enabled"}
{"timestamp_utc": "2024-07-31T08:14:06.884Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:06 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:07.443Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   43.407079] device eth2 entered promiscuous mode <NL> [   43.412687] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   43.419733] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   43.420489] device odcc1-peer entered promiscuous mode <NL> [   43.486681] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   43.507045] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   43.526280] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   43.533663] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   43.351240] commsdriver[583]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   43.389245] commsdriver[583]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   44.337659] br-odcc2: port 1(eth3) entered blocking state <NL> [   44.350787] br-odcc2: port 1(eth3) entered disabled state <NL> [   44.370326] device eth3 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:07.444Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   44.383800] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   44.397546] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   44.411553] device odcc2-peer entered promiscuous mode <NL> [   44.470419] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   44.510238] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   44.526532] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   44.539415] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   44.547207] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   44.562555] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   44.362628] commsdriver[583]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   44.393765] commsdriver[583]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   45.644241] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   45.682450] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   45.698716] device eth2.3800 entered promiscuous mode <NL> [   45.725398] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   45.739547] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   45.761730] device gcc0-peer entered promiscuous mode <NL> [   45.814788] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   45.826478] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   45.829923] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   45.877010] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   45.894910] br-odcc1: port 1(eth2) entered blocking state <NL> [   45.906852] br-odcc1: port 1(eth2) entered forwarding state <NL> [   45.920565] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   45.927030] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   45.704131] commsdriver[583]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   45.711158] commsdriver[583]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   46.451291] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   46.484891] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   46.508701] device eth2.3801 entered promiscuous mode <NL> [   46.556635] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   46.585247] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   46.618464] device gcc1-peer entered promiscuous mode <NL> [   46.836820] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   46.854139] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   46.854980] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.916525] br-odcc2: port 1(eth3) entered blocking state <NL> [   46.922677] br-odcc2: port 1(eth3) entered forwarding state <NL> [   46.776216] commsdriver[583]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   46.779079] commsdriver[583]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   47.846435] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   47.890741] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   47.931522] device eth3.3802 entered promiscuous mode <NL> [   48.027331] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   48.028378] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   48.049726] device lwap-peer entered promiscuous mode <NL> [   48.283615] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   48.284227] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   48.112173] commsdriver[583]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   48.124950] commsdriver[583]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   48.867736] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   48.868712] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   48.873707] device eth3.3803 entered promiscuous mode <NL> [   48.921659] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   48.924506] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   48.925694] device illdp-peer entered promiscuous mode <NL> [   49.048411] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   49.063314] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   48.881463] commsdriver[583]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   50.189701] commsready[869]: callback: Entry PID=0x365 signo(15) <NL> [   50.206654] commsready[869]: DipLog_pimpl destructor called <NL> [   50.225861] commsready[869]: DipVerbosity Listener ZMQ error <NL> [   50.226510] commsready[869]:     ret='Context was terminated <NL> [   50.227238] commsready[869]: deleting subscriber_ socket <NL> [   50.237958] commsready[869]: Exiting verb listener <NL> [   50.256122] change_esal_priority.sh[875]: Comms check for and selectively change esal priorities <NL> [   51.560929] change_esal_priority.sh[875]: Comms did not change any esal thread priorities <NL> [   51.882915] python[935]: running intRstpEnable file creation SCRIPT <NL> [   51.884291] python[935]: Already set to  TRUE <NL> [   51.884783] python[935]:  , NO CHANGE! <NL> [   52.213046] serialportMon[947]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   52.394437] sh[968]: In startMstpInt <NL> [   53.863955] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   53.881944] NFSD: Using legacy client tracking operations. <NL> [   53.882553] NFSD: starting 90-second grace period (net f0000098) <NL> [   53.734690] sh[968]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   57.639667] br.rstp_int: port 1(istp1) entered blocking state <NL> [   57.664204] br.rstp_int: port 1(istp1) entered disabled state <NL> [   57.700389] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:04,064 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:05,516 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:13:05,540 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:05,546 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   67.263120] vsftpd_listen_address[951]: listen_address=127.1.1.2 <NL> [   70.004434] br.rstp_int: port 2(istp2) entered blocking state <NL> [   70.072784] br.rstp_int: port 2(istp2) entered disabled state <NL> [   70.081950] device istp2 entered promiscuous mode <NL> [  111.018608] hrtimer: interrupt took 125774546 ns <NL> [  121.703217] ntputils[1723]: int ntputils_main(int, char**)Starting ntputils <NL> [  121.727925] ntputils[1723]: Running as a daemon <NL> [  121.728168] ntputils[1723]: shelf role is: TRIB <NL> [  121.728238] ntputils[1723]: slot number is: 0 <NL> [  121.728297] ntputils[1723]: slot role is: UNKNOWN <NL> [  121.728364] ntputils[1723]: redundancy_mode: UNKNOWN <NL> [  121.728453] ntputils[1723]: Executing on a work blade <NL> [  121.728510] ntputils[1723]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  121.728566] ntputils[1723]: ================================ <NL> [  121.728623] ntputils[1723]: shelf_role is: TRIB <NL> [  121.728691] ntputils[1723]: redundancy_mode: UNKNOWN <NL> [  121.728751] ntputils[1723]: active_status: active"}
{"timestamp_utc": "2024-07-31T08:14:09.327Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:09 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:09.886Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:09 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:10.445Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:13:00,688 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:02,366 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:13:02,473 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:02,473 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   61.299774] vsftpd_listen_address[958]: listen_address=127.1.1.2 <NL> [   62.905671] br.rstp_int: port 2(istp2) entered blocking state <NL> [   62.913219] br.rstp_int: port 2(istp2) entered disabled state <NL> [   62.921384] device istp2 entered promiscuous mode <NL> [  112.363754] ntputils[1721]: int ntputils_main(int, char**)Starting ntputils <NL> [  112.363954] ntputils[1721]: Running as a daemon <NL> [  112.364078] ntputils[1721]: shelf role is: TRIB <NL> [  112.364135] ntputils[1721]: slot number is: 0 <NL> [  112.364189] ntputils[1721]: slot role is: UNKNOWN <NL> [  112.364243] ntputils[1721]: redundancy_mode: UNKNOWN <NL> [  112.364329] ntputils[1721]: Executing on a work blade <NL> [  112.364383] ntputils[1721]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  112.364445] ntputils[1721]: ================================ <NL> [  112.364500] ntputils[1721]: shelf_role is: TRIB <NL> [  112.364570] ntputils[1721]: redundancy_mode: UNKNOWN <NL> [  112.364625] ntputils[1721]: active_status: active <NL> [  112.364679] ntputils[1721]: ntp_role: trib <NL> [  112.364735] ntputils[1721]: ================================ <NL> [  112.364828] ntputils[1721]: NTPUtilsConfig::do_default_config <NL> [  112.364884] ntputils[1721]: shelf_num/is_client: 1 <NL> [  112.364942] ntputils[1721]: server_ip: 0x55ed5b201fc0 <NL> [  112.364996] ntputils[1721]: ip_addr(ilan): 0x55ed5b201f80 <NL> [  112.365066] ntputils[1721]: ntp_role trib <NL> [  112.365121] ntputils[1721]: shelf_num aka is_client > 0 <NL> [  112.365176] ntputils[1721]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.365240] ntputils[1721]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.365296] ntputils[1721]: NTPServer::execute_cmd spawning: <NL> [  112.365350] ntputils[1721]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:14:01,008 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 58 seconds <NL> [  112.470759] ntputils[1721]: child pid is 1743 <NL> [  112.780951] ntputils[1721]: exited, status is 0 <NL> [  112.781034] ntputils[1721]: NTPServer::execute_cmd spawning: <NL> [  112.781093] ntputils[1721]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.781151] ntputils[1721]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.781206] ntputils[1721]: child pid is 1755 <NL> 2024-07-31 08:14:01,384 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:01,387 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  112.882571] ntputils[1759]: Changing Stratum and adding restrictions <NL> [  113.463899] ntputils[1785]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:02,162 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:02,266 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  113.903074] ntputils[1721]: exited, status is 0 <NL> [  113.903217] ntputils[1721]: NTPServer::execute_cmd spawning: <NL> [  113.903268] ntputils[1721]: /bin/systemctl reset-failed ntpd <NL> [  113.961061] ntputils[1721]: child pid is 1807 <NL> [  114.108347] ntputils[1721]: exited, status is 0 <NL> [  114.108415] ntputils[1721]: NTPServer::execute_cmd spawning: <NL> [  114.108469] ntputils[1721]: systemctl --no-block start ntpd <NL> [  114.108535] ntputils[1721]: child pid is 1810 <NL> [  114.441068] ntputils[1721]: exited, status is 0 <NL> [  114.441249] ntputils[1721]: client role with Python client, systemD starts it"}
{"timestamp_utc": "2024-07-31T08:14:10.446Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:14:03,150 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:03,150 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:03,254 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:03,254 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:03,302 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:03,736 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:03,738 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:03,738 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:03,739 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:03,804 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  119.911733] fujitsu-check-ssh-host-key.pl[1903]: Checking system account status... <NL> [  119.919628] fujitsu-check-ssh-host-key.pl[1903]: System account found... <NL> [  120.026890] fujitsu-check-ssh-host-key.pl[1903]: 3004 <NL> [  120.060847] fujitsu-check-ssh-host-key.pl[1903]: /bin/bash <NL> [  120.061167] fujitsu-check-ssh-host-key.pl[1903]: /home/system exists <NL> [  120.061330] fujitsu-check-ssh-host-key.pl[1903]: Checking for trib... <NL> [  120.113117] fujitsu-check-ssh-host-key.pl[1903]: Creating factory user for trib.. <NL> 2024-07-31 08:14:08,643 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:14:08,643 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:08,643 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:08,644 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:08,659 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:08,780 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:08,781 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:08,808 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:08,808 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:08,809 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> 2024-07-31 08:14:09,809 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:09,810 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665')"}
{"timestamp_utc": "2024-07-31T08:14:11.874Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:11 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:12.130Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:14:11 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:14.640Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:14 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:14.895Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:16.256Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   49.280307] commsdriver[624]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   49.334654] commsdriver[624]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   50.276165] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   50.277043] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   50.317773] device eth1.3800 entered promiscuous mode <NL> [   50.360369] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   50.397151] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   50.415571] device gcc0-peer entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:16.257Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   50.573462] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   50.601684] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   50.691492] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   50.538663] commsdriver[624]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   50.584805] commsdriver[624]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   50.920927] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   50.922645] br-odcc1: port 1(eth1) entered blocking state <NL> [   50.943406] br-odcc1: port 1(eth1) entered forwarding state <NL> [   50.975190] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   51.001691] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   51.709125] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   51.793521] br-odcc2: port 1(eth6) entered blocking state <NL> [   51.794052] br-odcc2: port 1(eth6) entered forwarding state <NL> [   51.893157] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   51.894085] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   51.911156] device eth1.3801 entered promiscuous mode <NL> [   51.976591] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   51.978292] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   52.054636] device gcc1-peer entered promiscuous mode <NL> [   52.160157] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   52.179087] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   52.037695] commsdriver[624]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   52.125584] commsdriver[624]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   53.137058] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   53.178545] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   53.213595] device eth6.3802 entered promiscuous mode <NL> [   53.257587] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   53.290921] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   53.302919] device lwap-peer entered promiscuous mode <NL> [   53.496516] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   53.497119] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   53.342278] commsdriver[624]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   53.361190] commsdriver[624]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   53.743359] commsdriver[624]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   53.810126] commsdriver[933]: Actual changes: <NL> [   53.810287] commsdriver[933]: tx-checksum-ip-generic: off <NL> [   53.810352] commsdriver[933]: tx-tcp-segmentation: off [not requested] <NL> [   53.810406] commsdriver[933]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   53.810474] commsdriver[933]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   53.810530] commsdriver[933]: tx-tcp6-segmentation: off [not requested] <NL> [   54.414214] commsdriver[624]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   54.460195] commsdriver[945]: Actual changes: <NL> [   54.460359] commsdriver[945]: tx-checksum-ip-generic: off <NL> [   54.460424] commsdriver[945]: tx-tcp-segmentation: off [not requested] <NL> [   54.460507] commsdriver[945]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   54.460563] commsdriver[945]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   54.460616] commsdriver[945]: tx-tcp6-segmentation: off [not requested] <NL> [   54.564955] commsready[948]: callback: Entry PID=0x3B4 signo(15) <NL> [   54.584930] change_esal_priority.sh[951]: Comms check for and selectively change esal priorities <NL> [   55.676585] change_esal_priority.sh[951]: Comms did not change any esal thread priorities <NL> [   56.262992] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   56.347131] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   56.682739] python[1017]: running intRstpEnable file creation SCRIPT <NL> [   56.682949] python[1017]: Already set to  TRUE <NL> [   56.683096] python[1017]:  , NO CHANGE! <NL> [   56.968583] serialportMon[1032]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   57.097561] sh[1058]: In startMstpInt <NL> [   57.550534] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   57.655829] NFSD: Using legacy client tracking operations. <NL> [   57.810072] NFSD: starting 90-second grace period (net f0000098) <NL> [   59.013113] sh[1058]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   62.553675] br.rstp_int: port 1(istp1) entered blocking state <NL> [   62.554541] br.rstp_int: port 1(istp1) entered disabled state <NL> [   62.555552] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:09,519 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:10,977 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:10,977 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:10,978 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> 2024-07-31 08:13:11,054 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:11,054 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:11,055 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> [   71.698870] vsftpd_listen_address[1035]: listen_address=127.1.254.254 <NL> [   74.804953] br.rstp_int: port 2(istp2) entered blocking state <NL> [   74.805728] br.rstp_int: port 2(istp2) entered disabled state <NL> [   74.819275] device istp2 entered promiscuous mode <NL> [  125.951908] dcn_dns_controller[1592]:  WaitForActive <NL> [  127.711666] dcn_ka[1594]:  WaitForActive <NL> [  129.842778] ntputils[1963]: int ntputils_main(int, char**)Starting ntputils <NL> [  129.842938] ntputils[1963]: Running as a daemon <NL> [  130.016129] ntputils[1963]: shelf role is: MAIN <NL> [  130.016291] ntputils[1963]: slot number is: 0 <NL> [  130.016369] ntputils[1963]: slot role is: UNKNOWN <NL> [  130.016428] ntputils[1963]: redundancy_mode: UNKNOWN <NL> [  130.016523] ntputils[1963]: Executing on a work blade <NL> [  130.016580] ntputils[1963]: ================================ <NL> [  130.016639] ntputils[1963]: shelf_role is: MAIN <NL> [  130.016697] ntputils[1963]: redundancy_mode: UNKNOWN <NL> [  130.016754] ntputils[1963]: active_status: active <NL> [  130.016810] ntputils[1963]: ntp_role: act <NL> [  130.016873] ntputils[1963]: ================================ <NL> [  130.017289] ntputils[1963]: NTPUtilsConfig::do_default_config <NL> [  130.017393] ntputils[1963]: shelf_num/is_client: 0 <NL> [  130.017449] ntputils[1963]: server_ip: 0x55b0f1873fc0 <NL> [  130.017505] ntputils[1963]: ip_addr(ilan): 0x55b0f1873f80 <NL> [  130.017560] ntputils[1963]: ntp_role act <NL> [  130.017614] ntputils[1963]: shelf_num aka is_client == 0 <NL> [  130.017669] ntputils[1963]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  130.017729] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  130.017788] ntputils[1963]: systemctl --no-block stop ntpd"}
{"timestamp_utc": "2024-07-31T08:14:16.818Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "2024-07-31 08:13:04,648 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:04,648 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:04,648 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   64.488354] vsftpd_listen_address[958]: listen_address=127.1.1.1 <NL> [   66.390731] br.rstp_int: port 2(istp2) entered blocking state <NL> [   66.400580] br.rstp_int: port 2(istp2) entered disabled state <NL> [   66.402066] device istp2 entered promiscuous mode <NL> [   80.761967] hrtimer: interrupt took 12980550 ns <NL> [  120.918310] ntputils[1760]: int ntputils_main(int, char**)Starting ntputils <NL> [  120.951719] ntputils[1760]: Running as a daemon <NL> [  120.952245] ntputils[1760]: shelf role is: TRIB <NL> [  120.952711] ntputils[1760]: slot number is: 0 <NL> [  120.953136] ntputils[1760]: slot role is: UNKNOWN <NL> [  120.978184] ntputils[1760]: redundancy_mode: UNKNOWN <NL> [  120.978761] ntputils[1760]: Executing on a work blade <NL> [  120.979302] ntputils[1760]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  120.980132] ntputils[1760]: ================================ <NL> [  121.017947] ntputils[1760]: shelf_role is: TRIB <NL> [  121.018529] ntputils[1760]: redundancy_mode: UNKNOWN <NL> [  121.019078] ntputils[1760]: active_status: active <NL> [  121.019614] ntputils[1760]: ntp_role: trib <NL> [  121.050505] ntputils[1760]: ================================ <NL> [  121.051971] ntputils[1760]: NTPUtilsConfig::do_default_config <NL> [  121.083241] ntputils[1760]: shelf_num/is_client: 1 <NL> [  121.091250] ntputils[1760]: server_ip: 0x559e8a97bfc0 <NL> [  121.100185] ntputils[1760]: ip_addr(ilan): 0x559e8a97bf80 <NL> [  121.101008] ntputils[1760]: ntp_role trib <NL> [  121.102109] ntputils[1760]: shelf_num aka is_client > 0 <NL> [  121.103550] ntputils[1760]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  121.106403] ntputils[1760]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  121.147274] ntputils[1760]: NTPServer::execute_cmd spawning: <NL> [  121.148812] ntputils[1760]: systemctl --no-block stop ntpd <NL> [  121.150239] ntputils[1760]: child pid is 1784"}
{"timestamp_utc": "2024-07-31T08:14:16.819Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  121.377820] ntputils[1760]: exited, status is 0 <NL> [  121.378029] ntputils[1760]: NTPServer::execute_cmd spawning: <NL> [  121.378098] ntputils[1760]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  121.378162] ntputils[1760]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  121.429334] ntputils[1760]: child pid is 1800 <NL> [  121.432612] ntputils[1802]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:09,329 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 64 seconds <NL> 2024-07-31 08:14:09,595 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:09,596 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  122.017629] ntputils[1820]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:10,178 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:10,179 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  122.623789] ntputils[1760]: exited, status is 0 <NL> [  122.623963] ntputils[1760]: NTPServer::execute_cmd spawning: <NL> [  122.624043] ntputils[1760]: /bin/systemctl reset-failed ntpd <NL> [  122.624108] ntputils[1760]: child pid is 1858 <NL> [  122.770896] ntputils[1760]: exited, status is 0 <NL> [  122.771085] ntputils[1760]: NTPServer::execute_cmd spawning: <NL> [  122.799944] ntputils[1760]: systemctl --no-block start ntpd <NL> [  122.827990] ntputils[1760]: child pid is 1863 <NL> 2024-07-31 08:14:10,594 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:10,595 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:10,595 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:10,595 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:10,697 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:10,697 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> [  122.976233] ntputils[1760]: exited, status is 0 <NL> [  123.026988] ntputils[1760]: client role with Python client, systemD starts it <NL> 2024-07-31 08:14:10,867 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:10,867 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:10,867 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:10,869 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  127.104496] fujitsu-check-ssh-host-key.pl[1909]: Checking system account status... <NL> [  127.134885] fujitsu-check-ssh-host-key.pl[1909]: System account found... <NL> [  127.270636] fujitsu-check-ssh-host-key.pl[1909]: 3004 <NL> 2024-07-31 08:14:15,051 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:15,051 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:15,051 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:15,113 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:15,187 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:15,188 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:15,189 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> [  127.554424] fujitsu-check-ssh-host-key.pl[1909]: /bin/bash <NL> [  127.554604] fujitsu-check-ssh-host-key.pl[1909]: /home/system exists <NL> [  127.554679] fujitsu-check-ssh-host-key.pl[1909]: Checking for trib... <NL> [  127.554783] fujitsu-check-ssh-host-key.pl[1909]: Creating factory user for trib.. <NL> 2024-07-31 08:14:15,358 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:15,358 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:15,358 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> 2024-07-31 08:14:16,366 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:16,367 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:16,367 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:16,368 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:07,177 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 61 seconds <NL> [  121.768146] ntputils[1723]: ntp_role: trib <NL> [  121.850210] ntputils[1723]: ================================ <NL> [  121.850354] ntputils[1723]: NTPUtilsConfig::do_default_config <NL> [  121.850411] ntputils[1723]: shelf_num/is_client: 1 <NL> [  121.850476] ntputils[1723]: server_ip: 0x558215c07fc0 <NL> [  121.850530] ntputils[1723]: ip_addr(ilan): 0x558215c07f80 <NL> [  121.850583] ntputils[1723]: ntp_role trib <NL> [  121.850649] ntputils[1723]: shelf_num aka is_client > 0 <NL> [  121.850704] ntputils[1723]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  121.850760] ntputils[1723]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  121.850811] ntputils[1723]: NTPServer::execute_cmd spawning: <NL> [  121.850866] ntputils[1723]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:14:07,269 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:07,345 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  122.037969] ntputils[1723]: child pid is 1762 <NL> [  122.309950] ntputils[1723]: exited, status is 0 <NL> [  122.310167] ntputils[1723]: NTPServer::execute_cmd spawning: <NL> [  122.310238] ntputils[1723]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  122.310298] ntputils[1723]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  122.373152] ntputils[1723]: child pid is 1771 <NL> 2024-07-31 08:14:07,823 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:07,824 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  122.533051] ntputils[1781]: Changing Stratum and adding restrictions <NL> [  123.052167] ntputils[1801]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:08,564 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:08,564 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:08,564 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:08,564 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:08,564 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:08,565 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:08,648 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:08,703 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:08,703 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:08,723 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  123.575480] ntputils[1723]: exited, status is 0 <NL> [  123.575649] ntputils[1723]: NTPServer::execute_cmd spawning: <NL> [  123.575706] ntputils[1723]: /bin/systemctl reset-failed ntpd <NL> [  123.619290] ntputils[1723]: child pid is 1833 <NL> [  123.874134] ntputils[1723]: exited, status is 0 <NL> [  123.874283] ntputils[1723]: NTPServer::execute_cmd spawning: <NL> [  123.874344] ntputils[1723]: systemctl --no-block start ntpd <NL> [  123.929628] ntputils[1723]: child pid is 1837 <NL> [  124.114339] ntputils[1723]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:14:16.820Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  124.114465] ntputils[1723]: client role with Python client, systemD starts it <NL> [  128.942693] fujitsu-check-ssh-host-key.pl[1942]: Checking system account status... <NL> [  129.132829] fujitsu-check-ssh-host-key.pl[1942]: System account found... <NL> 2024-07-31 08:14:14,718 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:14:14,771 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:14,771 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:14,772 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:14,773 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:14,853 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:14,872 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> [  129.485869] fujitsu-check-ssh-host-key.pl[1942]: 3004 <NL> [  129.486026] fujitsu-check-ssh-host-key.pl[1942]: /bin/bash <NL> [  129.486085] fujitsu-check-ssh-host-key.pl[1942]: /home/system exists <NL> [  129.486140] fujitsu-check-ssh-host-key.pl[1942]: Checking for trib... <NL> [  129.510916] fujitsu-check-ssh-host-key.pl[1942]: Creating factory user for trib.. <NL> 2024-07-31 08:14:14,991 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:14,992 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:14,992 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> 2024-07-31 08:14:16,025 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:16,026 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:16,027 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:16,027 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:16,027 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:16,028 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:14:16,028 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:14:16,028 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  130.708894] fujitsu-check-ssh-host-key.pl[1995]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  130.756784] fujitsu-check-ssh-host-key.pl[1995]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  130.757800] fujitsu-check-ssh-host-key.pl[1996]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  130.858613] fujitsu-check-ssh-host-key.pl[1996]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  130.913586] fujitsu-check-ssh-host-key.pl[1998]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  130.958043] fujitsu-check-ssh-host-key.pl[1998]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  130.969678] fujitsu-check-ssh-host-key.pl[2001]: useradd: user 'fujitsu' already exists <NL> [  131.068292] fujitsu-check-ssh-host-key.pl[1975]: DDS Peristency is enabled <NL> [  131.077652] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  131.097283] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  131.107189] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> # 03:14:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:16 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:17.129Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:14:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:19.675Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:19.676Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:19 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:21.561Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  130.373063] ntputils[1963]: child pid is 1971 <NL> 2024-07-31 08:14:15,976 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 64 seconds <NL> [  130.680382] ntputils[1963]: exited, status is 0 <NL> [  130.680500] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  130.680558] ntputils[1963]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  130.680615] ntputils[1963]: child pid is 1990 <NL> 2024-07-31 08:14:16,336 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:16,614 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  130.948465] ntputils[1997]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:16,565 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 65 seconds <NL> [  131.401536] rdm[1970]: RdmConfig: file_exist 0 <NL> [  131.401736] rdm[1970]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  131.401836] rdm[1970]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  131.404219] ntputils[1963]: exited, status is 0 <NL> [  131.404352] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  131.404417] ntputils[1963]: /bin/systemctl reset-failed ntpd <NL> [  131.404489] ntputils[1963]: child pid is 2016 <NL> [  131.404548] ntputils[1963]: exited, status is 0 <NL> [  131.404603] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  131.404658] ntputils[1963]: systemctl --no-block start ntpd <NL> [  131.404724] ntputils[1963]: child pid is 2036 <NL> [  131.505958] rdm[1970]: start rdm msg hdlr thd <NL> [  131.764099] ntputils[1963]: exited, status is 0 <NL> [  131.764179] ntputils[1963]: server role, server_ip is set to: 127.0.0.1 <NL> [  131.764237] ntputils[1963]: Running in production mode <NL> [  131.764292] ntputils[1963]: InitDaemon redundancy_mode: UNKNOWN <NL> [  131.764363] ntputils[1963]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  131.764443] ntputils[1963]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  131.764503] ntputils[1963]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  131.764560] ntputils[1963]: registration socket.send OK <NL> 2024-07-31 08:14:17,026 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:17,272 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> 2024-07-31 08:14:17,142 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:17,560 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:17,587 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:14:18,179 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:18,179 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:18,179 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:18,179 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:18,180 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:18,180 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:18,181 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:18,181 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:18,181 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:18,288 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:14:18,289 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:18,289 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:18,289 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:18,289 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> 2024-07-31 08:14:18,401 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> 2024-07-31 08:14:18,401 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> 2024-07-31 08:14:18,404 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:18,404 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:14:18,531 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:14:18,682 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:14:18,846 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:14:18,846 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:14:18,846 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:14:18,846 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:14:18,847 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> [  133.313508] ntputils[1963]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  133.869509] ntputils[1963]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> 2024-07-31 08:14:19,032 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> 2024-07-31 08:14:19,545 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:19,546 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:19,255 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:19,593 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  134.036553] ntputils[1963]:  topic reg for: <NL> [  134.388229] ntputils[1963]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  134.432731] ntputils[1963]: registration socket.send OK <NL> [  134.879710] ntputils[1963]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  135.124719] ntputils[1963]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  135.137814] ntputils[1963]:  topic reg for: <NL> [  135.141121] ntputils[1963]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  135.271103] ntputils[1963]: registration socket.send OK <NL> [  135.319069] ntputils[1963]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  135.458285] ntputils[1963]: void NTPServer::check_ntp_enabled() <NL> [  135.501527] ntputils[1963]: check_ntp_enabled not empty <NL> [  135.505533] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.510083] ntputils[1963]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf"}
{"timestamp_utc": "2024-07-31T08:14:21.816Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:21 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:24.327Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:24 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:25.251Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   53.711674] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   53.762136] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   53.823079] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   53.865479] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   53.453065] commsdriver[624]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   53.494147] commsdriver[624]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   54.812641] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   54.813241] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   54.822116] device eth6.3802 entered promiscuous mode <NL> [   54.882104] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   54.912647] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   54.943405] device lwap-peer entered promiscuous mode <NL> [   55.191405] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   55.223653] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   54.824618] commsdriver[624]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   54.879259] commsdriver[624]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   55.529793] commsdriver[624]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   55.641259] commsdriver[939]: Actual changes: <NL> [   55.690324] commsdriver[939]: tx-checksum-ip-generic: off <NL> [   55.690427] commsdriver[939]: tx-tcp-segmentation: off [not requested] <NL> [   55.690489] commsdriver[939]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   55.690547] commsdriver[939]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   55.690612] commsdriver[939]: tx-tcp6-segmentation: off [not requested] <NL> [   56.301373] commsdriver[624]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   56.383529] commsdriver[951]: Actual changes: <NL> [   56.383689] commsdriver[951]: tx-checksum-ip-generic: off <NL> [   56.383752] commsdriver[951]: tx-tcp-segmentation: off [not requested] <NL> [   56.383807] commsdriver[951]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   56.383862] commsdriver[951]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   56.383912] commsdriver[951]: tx-tcp6-segmentation: off [not requested] <NL> [   56.640922] commsready[954]: callback: Entry PID=0x3BA signo(15) <NL> [   56.676490] change_esal_priority.sh[959]: Comms check for and selectively change esal priorities <NL> [   57.840632] change_esal_priority.sh[959]: Comms did not change any esal thread priorities <NL> [   58.355280] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   58.356869] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   58.421802] python[1010]: running intRstpEnable file creation SCRIPT <NL> [   58.421971] python[1010]: Already set to  TRUE <NL> [   58.422107] python[1010]:  , NO CHANGE! <NL> [   58.918179] sh[1056]: In startMstpInt <NL> [   59.060364] serialportMon[1036]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   60.621918] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   60.706311] NFSD: Using legacy client tracking operations. <NL> [   60.216725] sh[1056]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   60.739392] NFSD: starting 90-second grace period (net f0000098) <NL> [   65.253252] br.rstp_int: port 1(istp1) entered blocking state <NL> [   65.258353] br.rstp_int: port 1(istp1) entered disabled state"}
{"timestamp_utc": "2024-07-31T08:14:25.252Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   65.259102] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:11,957 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:13,974 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:13,974 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:13,974 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> 2024-07-31 08:13:14,041 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:14,113 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:14,116 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> [   73.668540] vsftpd_listen_address[1039]: listen_address=127.1.254.254 <NL> [   77.575339] br.rstp_int: port 2(istp2) entered blocking state <NL> [   77.583658] br.rstp_int: port 2(istp2) entered disabled state <NL> [   77.595753] device istp2 entered promiscuous mode <NL> [  131.594080] dcn_dns_controller[1599]:  WaitForActive <NL> [  134.099667] dcn_ka[1601]:  WaitForActive <NL> 2024-07-31 08:14:21,667 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 67 seconds <NL> 2024-07-31 08:14:21,715 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 67 seconds <NL> 2024-07-31 08:14:21,755 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:21,805 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:22,072 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> 2024-07-31 08:14:21,877 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  136.022835] ntputils[1958]: int ntputils_main(int, char**)Starting ntputils <NL> [  136.181481] ntputils[1958]: Running as a daemon <NL> [  136.182209] ntputils[1958]: shelf role is: MAIN <NL> [  136.182676] ntputils[1958]: slot number is: 0 <NL> [  136.290529] ntputils[1958]: slot role is: UNKNOWN <NL> [  136.290609] ntputils[1958]: redundancy_mode: UNKNOWN <NL> [  136.290720] ntputils[1958]: Executing on a work blade <NL> [  136.290780] ntputils[1958]: ================================ <NL> [  136.290836] ntputils[1958]: shelf_role is: MAIN <NL> [  136.290894] ntputils[1958]: redundancy_mode: UNKNOWN <NL> 2024-07-31 08:14:22,833 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> [  136.335037] ntputils[1958]: active_status: active <NL> [  136.683522] ntputils[1958]: ntp_role: act <NL> [  136.683594] ntputils[1958]: ================================ <NL> [  136.683649] ntputils[1958]: NTPUtilsConfig::do_default_config <NL> [  136.683755] ntputils[1958]: shelf_num/is_client: 0 <NL> [  136.683813] ntputils[1958]: server_ip: 0x55e4f6ac6fc0 <NL> [  136.683869] ntputils[1958]: ip_addr(ilan): 0x55e4f6ac6f80 <NL> [  136.683923] ntputils[1958]: ntp_role act <NL> [  136.683994] ntputils[1958]: shelf_num aka is_client == 0 <NL> [  136.684065] ntputils[1958]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  136.684120] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  136.684175] ntputils[1958]: systemctl --no-block stop ntpd <NL> [  136.684235] ntputils[1958]: child pid is 1978 <NL> 2024-07-31 08:14:23,704 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:23,714 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:23,920 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:14:23,920 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE"}
{"timestamp_utc": "2024-07-31T08:14:27.140Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:26 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> [  135.597424] ntputils[1963]: child pid is 2160 <NL> [  135.612802] ntputils[1963]: exited, status is 0 <NL> [  135.686246] ntputils[1963]: check_ntp_enabled skip system script_start <NL> [  135.691836] ntputils[1963]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  135.705052] ntputils[1963]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  135.705946] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.706549] ntputils[1963]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  135.707254] ntputils[1963]: child pid is 2164 <NL> [  135.707720] ntputils[1963]: exited, status is 0 <NL> [  135.806448] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.899242] ntputils[1963]: systemctl --no-block stop ntpd <NL> [  135.903265] ntputils[1963]: child pid is 2178 <NL> [  135.909426] ntputils[1963]: exited, status is 0 <NL> [  135.969364] ntputils[1963]: call delete_all_external_servers <NL> [  135.969453] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.969518] ntputils[1963]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  135.969577] ntputils[1963]: child pid is 2185 <NL> [  135.970652] ntputils[2185]: remove_all_ext_src <NL> [  135.970725] ntputils[2185]: delete: <NL> [  135.971541] ntputils[1963]: exited, status is 0 <NL> [  135.971611] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.971667] ntputils[1963]: /bin/systemctl reset-failed ntpd <NL> [  135.971737] ntputils[1963]: child pid is 2188 <NL> [  135.971798] ntputils[1963]: exited, status is 0 <NL> [  135.971854] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.971910] ntputils[1963]: systemctl --no-block start ntpd <NL> [  135.971991] ntputils[1963]: child pid is 2189 <NL> [  135.972067] ntputils[1963]: exited, status is 0 <NL> [  135.972131] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.972187] ntputils[1963]: /bin/systemctl reset-failed init_state_check.timer <NL> [  135.972248] ntputils[1963]: child pid is 2192 <NL> [  135.972318] ntputils[1963]: exited, status is 0 <NL> [  135.972375] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  135.972431] ntputils[1963]: /bin/systemctl --no-block start init_state_check.timer <NL> [  135.972493] ntputils[1963]: child pid is 2195 <NL> [  136.026589] ntputils[1963]: exited, status is 0 <NL> [  136.053390] ntputils[1963]: server.InitDaemon <NL> [  136.053477] ntputils[1963]: int NTPServer::platformdds_listen() <NL> [  136.053549] ntputils[1963]: void NTPServer::poller() <NL> [  136.053603] ntputils[1963]: void NTPServer::late_joiner() <NL> [  136.939524] ntputils[1963]: bool NTPServer::handle_command(const string&) <NL> [  136.943532] ntputils[1963]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  137.065842] ntputils[1963]: got Platform::RedundancyMode: UNKNOWN <NL> [  137.070819] ntputils[1963]: got Platform::RedundancyStatus: STANDALONE <NL> [  137.075390] ntputils[1963]: my current red mode is: UNKNOWN <NL> [  137.089527] ntputils[1963]: new red mode is: UNKNOWN <NL> [  137.101083] ntputils[1963]: my current red status is: active <NL> [  137.101787] ntputils[1963]: new red status is: STANDALONE <NL> [  137.102337] ntputils[1963]: received unknown! <NL> [  137.102775] ntputils[1963]: new red mode is: UNKNOWN <NL> [  137.176683] ntputils[1963]: new red status is: STANDALONE <NL> [  137.188588] ntputils[1963]: red status change, update active => STANDALONE <NL> [  137.194808] ntputils[1963]: no active/not-active status change: 0 <NL> 2024-07-31 08:14:23,127 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0"}
{"timestamp_utc": "2024-07-31T08:14:27.141Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "2024-07-31 08:14:23,127 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  137.871770] ntputils[1963]: bool NTPServer::handle_command(const string&) <NL> [  137.871938] ntputils[1963]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  137.872033] ntputils[1963]: got Platform::RedundancyMode: UNKNOWN <NL> [  137.872110] ntputils[1963]: got Platform::RedundancyStatus: STANDALONE <NL> [  137.872175] ntputils[1963]: my current red mode is: UNKNOWN <NL> [  137.872234] ntputils[1963]: new red mode is: UNKNOWN <NL> [  137.872305] ntputils[1963]: my current red status is: STANDALONE <NL> [  137.872365] ntputils[1963]: new red status is: STANDALONE <NL> [  137.872417] ntputils[1963]: received unknown! <NL> [  137.872499] ntputils[1963]: new red mode is: UNKNOWN <NL> [  137.872551] ntputils[1963]: new red status is: STANDALONE <NL> [  137.872617] ntputils[1963]: no active/not-active status change: 0 <NL> 2024-07-31 08:14:23,121 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:23,404 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  139.015536] ntp_oper_data.py[1965]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  139.015735] ntp_oper_data.py[1965]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  139.097219] ntp_oper_data.py[1965]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  139.097389] ntp_oper_data.py[1965]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  139.603244] usb_script_handler.py[1983]: usb: INFO - usb_base.disable_if_not_ha_mode[323] Disabling USB SSW: ha_mode != USB. <NL> [  139.603448] usb_script_handler.py[1983]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  139.603513] usb_script_handler.py[1983]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> [  139.770696] ntp_oper_data.py[1965]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  139.770922] ntp_oper_data.py[1965]: INFO:root:redundancy status now set to standalone <NL> [  139.771051] ntp_oper_data.py[1965]: INFO:root:Received redundancy topic <NL> [  139.771115] ntp_oper_data.py[1965]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:14:26,013 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:26,013 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:26,013 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:26,014 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:26,014 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:26,039 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:26,133 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:26,133 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:26,041 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:26,178 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:26,219 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:26,219 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:14:26,220 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:26,220 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:14:26,267 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  141.325307] fujitsu-check-ssh-host-key.pl[2271]: Checking system account status... <NL> [  141.337558] fujitsu-check-ssh-host-key.pl[2271]: System account found..."}
{"timestamp_utc": "2024-07-31T08:14:29.652Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:29 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:29.907Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:29 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:31.269Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:14:24,032 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:24,468 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:24,468 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  137.158660] ntputils[1958]: exited, status is 0 <NL> [  137.801924] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  137.900042] ntputils[1958]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  137.900116] ntputils[1958]: child pid is 2016 <NL> [  138.019748] ntputils[2018]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:24,760 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:25,166 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> [  138.407752] rdm[1963]: RdmConfig: file_exist 0 <NL> 2024-07-31 08:14:25,266 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> [  138.549652] rdm[1963]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  138.755309] rdm[1963]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> 2024-07-31 08:14:25,302 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE"}
{"timestamp_utc": "2024-07-31T08:14:31.270Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:14:25,928 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:25,928 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:25,928 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:25,928 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:26,011 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:26,011 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:26,011 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:26,012 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:14:24,912 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> 2024-07-31 08:14:26,090 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> [  138.916799] rdm[1963]: start rdm msg hdlr thd <NL> 2024-07-31 08:14:25,838 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> [  139.381662] ntputils[1958]: exited, status is 0 <NL> [  139.466928] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:14:26,273 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  139.517276] ntputils[1958]: /bin/systemctl reset-failed ntpd <NL> [  139.551714] ntputils[1958]: child pid is 2074 <NL> 2024-07-31 08:14:26,385 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  139.694439] ntputils[1958]: exited, status is 0 <NL> 2024-07-31 08:14:26,540 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:14:26,563 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  139.777520] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  140.127162] ntputils[1958]: systemctl --no-block start ntpd <NL> 2024-07-31 08:14:26,708 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:27,049 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:26,934 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> 2024-07-31 08:14:27,146 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:27,147 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:27,187 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  140.213092] ntputils[1958]: child pid is 2101 <NL> [  140.396231] ntputils[1958]: exited, status is 0 <NL> [  140.463495] ntputils[1958]: server role, server_ip is set to: 127.0.0.1 <NL> [  140.471479] ntputils[1958]: Running in production mode <NL> [  140.481857] ntputils[1958]: InitDaemon redundancy_mode: UNKNOWN <NL> [  140.581510] ntputils[1958]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  140.600532] ntputils[1958]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  140.671321] ntputils[1958]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  140.799374] ntputils[1958]: registration socket.send OK <NL> [  141.391056] ntputils[1958]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  141.843289] ntputils[1958]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  142.017588] ntputils[1958]:  topic reg for: <NL> [  142.260360] ntputils[1958]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  142.260440] ntputils[1958]: registration socket.send OK <NL> [  142.260500] ntputils[1958]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  142.260558] ntputils[1958]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  142.260631] ntputils[1958]:  topic reg for: <NL> [  142.260688] ntputils[1958]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  142.260746] ntputils[1958]: registration socket.send OK <NL> [  142.260798] ntputils[1958]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  142.260849] ntputils[1958]: void NTPServer::check_ntp_enabled() <NL> [  142.260919] ntputils[1958]: check_ntp_enabled not empty <NL> [  142.260977] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  142.261045] ntputils[1958]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  142.261103] ntputils[1958]: child pid is 2148 <NL> [  142.261184] ntputils[1958]: exited, status is 0 <NL> [  142.261241] ntputils[1958]: check_ntp_enabled skip system script_start <NL> [  142.261296] ntputils[1958]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  142.261354] ntputils[1958]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  142.261413] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  142.261475] ntputils[1958]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  142.261533] ntputils[1958]: child pid is 2152 <NL> [  142.261592] ntputils[1958]: exited, status is 0 <NL> [  142.261659] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  142.261713] ntputils[1958]: systemctl --no-block stop ntpd <NL> [  142.261770] ntputils[1958]: child pid is 2169 <NL> [  142.261824] ntputils[1958]: exited, status is 0 <NL> [  142.295555] ntputils[1958]: call delete_all_external_servers <NL> [  142.954287] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  142.954418] ntputils[1958]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  142.954471] ntputils[1958]: child pid is 2171 <NL> [  143.033112] ntputils[2171]: remove_all_ext_src <NL> [  143.033274] ntputils[2171]: delete: <NL> [  143.149726] ntputils[1958]: exited, status is 0 <NL> [  143.149857] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  143.149925] ntputils[1958]: /bin/systemctl reset-failed ntpd <NL> [  143.149981] ntputils[1958]: child pid is 2173 <NL> [  143.150065] ntputils[1958]: exited, status is 0 <NL> [  143.150118] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  143.150170] ntputils[1958]: systemctl --no-block start ntpd <NL> [  143.150225] ntputils[1958]: child pid is 2185 <NL> [  143.150280] ntputils[1958]: exited, status is 0 <NL> [  141.423813] fujitsu-check-ssh-host-key.pl[2271]: 3004 <NL> [  141.455451] fujitsu-check-ssh-host-key.pl[2271]: /bin/bash <NL> [  141.469069] fujitsu-check-ssh-host-key.pl[2271]: /home/system exists <NL> [  141.482218] fujitsu-check-ssh-host-key.pl[2271]: Checking for trib... <NL> [  141.533355] fujitsu-check-ssh-host-key.pl[2271]: Checking for PIU ... <NL> [  141.639021] fujitsu-check-ssh-host-key.pl[2271]: slot number (0) is not a PIU. <NL> [  141.696726] fujitsu-check-ssh-host-key.pl[2271]: Trib check done. <NL> 2024-07-31 08:14:27,228 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:27,236 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:27,267 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:14:27,344 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:27,401 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:27,454 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:14:27,482 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:14:27,524 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:14:27,552 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:27,573 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:27,613 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:27,796 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY"}
{"timestamp_utc": "2024-07-31T08:14:31.271Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "2024-07-31 08:14:27,646 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:27,989 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:14:27,884 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:14:28,528 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> [  143.059754] startup[2300]: Startup, World! <NL> [  143.301419] startup[2300]: Cmd arg set to loop 1 <NL> 2024-07-31 08:14:28,810 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:14:28,811 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:28,874 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:14:28,874 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:14:28,875 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:14:28,875 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:14:28,875 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:14:28,875 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:28,965 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:14:29,141 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:29,142 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:29,143 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:14:29,143 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> 2024-07-31 08:14:29,093 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:29,284 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:29,284 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:14:29,284 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:14:29,285 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:29,285 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:29,096 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:29,406 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:29,517 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> 2024-07-31 08:14:29,518 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:14:29,518 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:14:29,518 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:14:29,538 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> 2024-07-31 08:14:29,765 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:14:29,555 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:14:29,768 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:14:29,769 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:14:29,769 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:14:29,770 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:14:29,770 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:14:29,770 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:14:29,801 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:14:29,945 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:14:29,946 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0,"}
{"timestamp_utc": "2024-07-31T08:14:32.197Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:31 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:31 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:34.710Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:34 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:34.966Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:35.892Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:14:09,811 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version:"}
{"timestamp_utc": "2024-07-31T08:14:35.893Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:14:09,811 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:09,811 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:09,812 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:14:09,817 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:14:09,818 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  121.544696] fujitsu-check-ssh-host-key.pl[1940]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  121.544853] fujitsu-check-ssh-host-key.pl[1940]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  121.553431] fujitsu-check-ssh-host-key.pl[1945]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  121.553573] fujitsu-check-ssh-host-key.pl[1945]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  121.586824] fujitsu-check-ssh-host-key.pl[1948]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  121.586991] fujitsu-check-ssh-host-key.pl[1948]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  121.928759] fujitsu-check-ssh-host-key.pl[1965]: useradd: user 'fujitsu' already exists <NL> [  123.935055] fujitsu-check-ssh-host-key.pl[1917]: DDS Peristency is enabled <NL> [  123.935337] fujitsu-check-ssh-host-key.pl[1917]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  123.935439] fujitsu-check-ssh-host-key.pl[1917]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  123.935504] fujitsu-check-ssh-host-key.pl[1917]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  123.935563] fujitsu-check-ssh-host-key.pl[1917]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  123.935619] fujitsu-check-ssh-host-key.pl[1917]: Factory user shell set to /bin/bash <NL> [  124.342057] fujitsu-check-ssh-host-key.pl[1903]: Converting fujitsu user to bash shell... <NL> [  124.448262] fujitsu-check-ssh-host-key.pl[2019]: usermod: no changes <NL> [  124.467475] fujitsu-check-ssh-host-key.pl[1903]: Lock Root account in TRIB... <NL> [  124.501686] fujitsu-check-ssh-host-key.pl[2020]: Running lock on root account... <NL> [  124.937125] fujitsu-check-ssh-host-key.pl[2021]: passwd: password changed. <NL> [  124.966325] fujitsu-check-ssh-host-key.pl[1903]: Trib check done. <NL> [  125.076304] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  125.076525] ntputils_client.py[1727]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  125.076614] ntputils_client.py[1727]: b'31 Jul 08:14:13 ntpdate[1863]: no server suitable for synchronization found\\n' <NL> [  125.778568] startup[2037]: Startup, World! <NL> [  125.778765] startup[2037]: Cmd arg set to loop 1 <NL> [  126.275844] confd_mgr_action_server[2039]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 2 <NL> [  127.507081] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  127.711066] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  127.548165] sh[2067]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  127.620837] sh[2067]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  128.499701] startup_finished.py[2031]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  129.668997] ains_manager[2032]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  130.312330] startup_finished.py[2031]: Startup Finished: systemd state is non-Production mode and running <NL> [  130.312461] startup_finished.py[2031]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  130.940073] startup_finished.py[2031]: *****Startup Finished: stopping EOW timer***** <NL> 2024-07-31 08:14:19,574 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  132.414071] startup_finished.py[2031]: systemctl stop startup_finished_limit.timer <NL> [  132.464184] zebra[2064]: 2024/07/31 08:14:20 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  139.118081] layer1_control_layer[2053]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  142.147465] ains_manager[2314]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  145.214661] layer1_control_layer[2053]: DIP entity prov dump <NL> [  145.401713] layer1_control_layer[2053]: EsalConfig::EsalConfig main 0 <NL> [  145.401966] layer1_control_layer[2053]: EsalConfig::EsalConfig trib 1 <NL> [  145.402079] layer1_control_layer[2053]: EsalConfig::EsalConfig ciRole 0 <NL> [  145.424540] layer1_control_layer[2053]: EsalConfig is not running inside container. <NL> [  145.424844] layer1_control_layer[2053]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.424929] layer1_control_layer[2053]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.425036] layer1_control_layer[2053]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.425127] layer1_control_layer[2053]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.425219] layer1_control_layer[2053]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  145.425314] layer1_control_layer[2053]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  145.425415] layer1_control_layer[2053]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  145.425504] layer1_control_layer[2053]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  145.425597] layer1_control_layer[2053]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  145.425703] layer1_control_layer[2053]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  145.425826] layer1_control_layer[2053]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  145.425898] layer1_control_layer[2053]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  145.426008] layer1_control_layer[2053]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  145.426099] layer1_control_layer[2053]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  145.426188] layer1_control_layer[2053]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  145.426261] layer1_control_layer[2053]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  145.426332] layer1_control_layer[2053]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> 2024-07-31 08:14:34,975 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:14:34,975 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:35,110 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:14:35,111 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True"}
{"timestamp_utc": "2024-07-31T08:14:35.894Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:14:35,120 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":2} <NL> 2024-07-31 08:14:35,120 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:14:35,120 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:14:35,121 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:14:35,122 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:35,132 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:14:35,207 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True"}
{"timestamp_utc": "2024-07-31T08:14:37.258Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:36 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> [  143.150332] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  143.150383] ntputils[1958]: /bin/systemctl reset-failed init_state_check.timer <NL> [  143.150453] ntputils[1958]: child pid is 2189 <NL> [  143.150508] ntputils[1958]: exited, status is 0 <NL> [  143.150559] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  143.150613] ntputils[1958]: /bin/systemctl --no-block start init_state_check.timer <NL> [  143.150668] ntputils[1958]: child pid is 2191 <NL> [  143.150723] ntputils[1958]: exited, status is 0 <NL> [  143.150774] ntputils[1958]: server.InitDaemon <NL> [  143.150830] ntputils[1958]: int NTPServer::platformdds_listen() <NL> [  143.189951] ntputils[1958]: void NTPServer::poller() <NL> [  143.346449] ntputils[1958]: void NTPServer::late_joiner() <NL> [  143.346522] ntputils[1958]: bool NTPServer::handle_command(const string&) <NL> [  143.346588] ntputils[1958]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  143.346645] ntputils[1958]: got Platform::RedundancyMode: UNKNOWN <NL> [  143.346702] ntputils[1958]: got Platform::RedundancyStatus: STANDALONE <NL> [  143.346758] ntputils[1958]: my current red mode is: UNKNOWN <NL> [  143.346814] ntputils[1958]: new red mode is: UNKNOWN <NL> [  143.346879] ntputils[1958]: my current red status is: active <NL> [  143.346943] ntputils[1958]: new red status is: STANDALONE <NL> [  143.347011] ntputils[1958]: received unknown! <NL> [  143.347068] ntputils[1958]: new red mode is: UNKNOWN <NL> [  143.347123] ntputils[1958]: new red status is: STANDALONE <NL> [  143.347178] ntputils[1958]: red status change, update active => STANDALONE <NL> [  143.347235] ntputils[1958]: no active/not-active status change: 0 <NL> 2024-07-31 08:14:31,709 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:31,709 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:31,735 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:31,735 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  145.908642] ntputils[1958]: bool NTPServer::handle_command(const string&) <NL> [  145.942753] ntputils[1958]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  145.942859] ntputils[1958]: got Platform::RedundancyMode: UNKNOWN <NL> [  145.943254] ntputils[1958]: got Platform::RedundancyStatus: STANDALONE <NL> [  145.943322] ntputils[1958]: my current red mode is: UNKNOWN <NL> [  145.943383] ntputils[1958]: new red mode is: UNKNOWN <NL> [  145.943460] ntputils[1958]: my current red status is: STANDALONE <NL> [  145.943531] ntputils[1958]: new red status is: STANDALONE <NL> [  145.943583] ntputils[1958]: received unknown! <NL> [  145.943670] ntputils[1958]: new red mode is: UNKNOWN <NL> [  145.943729] ntputils[1958]: new red status is: STANDALONE"}
{"timestamp_utc": "2024-07-31T08:14:37.259Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  145.943786] ntputils[1958]: no active/not-active status change: 0 <NL> [  146.450033] usb_script_handler.py[1968]: usb: INFO - usb_base.disable_if_not_ha_mode[323] Disabling USB SSW: ha_mode != USB. <NL> [  146.450230] usb_script_handler.py[1968]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  146.520532] ntp_oper_data.py[1959]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  146.520687] ntp_oper_data.py[1959]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  146.520769] ntp_oper_data.py[1959]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  146.557342] ntp_oper_data.py[1959]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  146.613474] usb_script_handler.py[1968]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> [  147.034512] ntp_oper_data.py[1959]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  147.034708] ntp_oper_data.py[1959]: INFO:root:redundancy status now set to standalone <NL> [  147.034801] ntp_oper_data.py[1959]: INFO:root:Received redundancy topic <NL> [  147.034894] ntp_oper_data.py[1959]: INFO:root:Redundancy status is standalone <NL> [  148.054863] fujitsu-check-ssh-host-key.pl[2275]: Checking system account status... <NL> [  148.089636] fujitsu-check-ssh-host-key.pl[2275]: System account found... <NL> 2024-07-31 08:14:34,975 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:35,020 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:35,020 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:35,021 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:35,021 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:35,073 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:35,239 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:35,031 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  148.326426] fujitsu-check-ssh-host-key.pl[2275]: 3004 <NL> 2024-07-31 08:14:35,240 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:35,240 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:35,245 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:35,256 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  148.500719] fujitsu-check-ssh-host-key.pl[2275]: /bin/bash <NL> 2024-07-31 08:14:35,308 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:35,355 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  148.501246] fujitsu-check-ssh-host-key.pl[2275]: /home/system exists <NL> [  148.560635] fujitsu-check-ssh-host-key.pl[2275]: Checking for trib... <NL> [  148.560827] fujitsu-check-ssh-host-key.pl[2275]: Checking for PIU ... <NL> 2024-07-31 08:14:35,384 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  148.685732] fujitsu-check-ssh-host-key.pl[2275]: slot number (0) is not a PIU. <NL> [  148.685926] fujitsu-check-ssh-host-key.pl[2275]: Trib check done. <NL> [  149.399756] startup[2305]: Startup, World! <NL> [  149.399983] startup[2305]: Cmd arg set to loop 1 <NL> 2024-07-31 08:14:36,389 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:36,390 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:36,391 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:14:36,391 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:14:36,391 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:36,391 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:36,392 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:14:36,597 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect"}
{"timestamp_utc": "2024-07-31T08:14:39.773Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:39 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:40.336Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:14:36,605 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:14:36,628 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:36,681 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:14:36,703 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:36,716 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:36,738 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:14:36,750 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:14:36,762 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> 2024-07-31 08:14:36,970 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:14:37,006 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:37,100 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:14:37,229 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:14:37,191 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:37,282 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:14:37,343 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:14:37,344 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:14:37,344 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:14:40.337Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:14:37,323 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  150.611693] ains_manager[2302]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:14:37,486 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:14:37,607 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:37,608 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:37,608 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:14:37,609 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> 2024-07-31 08:14:37,609 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> 2024-07-31 08:14:37,609 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:14:37,495 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:37,725 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:14:37,760 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:14:37,783 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> 2024-07-31 08:14:37,788 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:14:37,783 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:14:37,817 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:14:37,817 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:14:37,818 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:14:37,818 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:14:37,818 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:14:37,819 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:14:37,819 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:14:37,819 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:14:37,819 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> 2024-07-31 08:14:37,834 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:37,834 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:14:37,874 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:38,056 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:38,056 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:14:38,056 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: RESET -> READY_STATE -> reset_fn -> WAIT_STATE <NL> 2024-07-31 08:14:37,877 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:14:38,095 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:38,095 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:37,929 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:14:38,139 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount  --script  --base /mnt/secondary/var/shared --algorithm longest-match L1-OTSG2.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  152.064266] startup_finished.py[2301]: *****Startup Finished Monitor:Starting the event loop***** <NL> 2024-07-31 08:14:39,019 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:39,020 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:39,063 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect"}
{"timestamp_utc": "2024-07-31T08:14:42.222Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:41 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:44.735Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:44.736Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:44 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:44.992Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  131.143139] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  131.176126] fujitsu-check-ssh-host-key.pl[1975]: Factory user shell set to /bin/bash <NL> [  131.435965] fujitsu-check-ssh-host-key.pl[1942]: Converting fujitsu user to bash shell... <NL> [  131.445271] fujitsu-check-ssh-host-key.pl[2009]: usermod: no changes <NL> [  131.491314] fujitsu-check-ssh-host-key.pl[1942]: Lock Root account in TRIB... <NL> [  131.491758] fujitsu-check-ssh-host-key.pl[2010]: Running lock on root account... <NL> [  131.883557] fujitsu-check-ssh-host-key.pl[2011]: passwd: password changed. <NL> [  131.923731] fujitsu-check-ssh-host-key.pl[1942]: Trib check done. <NL> [  132.495180] startup[2027]: Startup, World! <NL> [  132.495368] startup[2027]: Cmd arg set to loop 1 <NL> [  133.480811] ains_manager[2024]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  133.856209] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  133.856420] ntputils_client.py[1726]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  133.856515] ntputils_client.py[1726]: b'31 Jul 08:14:19 ntpdate[1864]: no server suitable for synchronization found\\n' <NL> [  134.316945] startup_finished.py[2023]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  134.707717] dhal_sim_startup.sh[2070]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  135.434772] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  135.435736] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  135.244921] sh[2092]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  135.603414] sh[2092]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  135.786403] confd_mgr_action_server[2064]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 2 <NL> [  137.885091] zebra[2091]: 2024/07/31 08:14:23 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  139.039286] startup_finished.py[2023]: Startup Finished: systemd state is non-Production mode and running <NL> [  139.136432] startup_finished.py[2023]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  139.733698] startup_finished.py[2023]: *****Startup Finished: stopping EOW timer***** <NL> [  140.696815] startup_finished.py[2023]: systemctl stop startup_finished_limit.timer <NL> 2024-07-31 08:14:27,817 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  148.083458] layer1_control_layer[2082]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  151.330566] ains_manager[2281]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  156.651764] layer1_control_layer[2082]: DIP entity prov dump <NL> [  156.954463] layer1_control_layer[2082]: EsalConfig::EsalConfig main 0 <NL> [  156.954658] layer1_control_layer[2082]: EsalConfig::EsalConfig trib 1 <NL> [  156.954712] layer1_control_layer[2082]: EsalConfig::EsalConfig ciRole 0 <NL> [  157.087548] layer1_control_layer[2082]: EsalConfig is not running inside container. <NL> [  157.087710] layer1_control_layer[2082]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  157.087766] layer1_control_layer[2082]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  157.087818] layer1_control_layer[2082]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  157.087880] layer1_control_layer[2082]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  157.087936] layer1_control_layer[2082]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  157.088025] layer1_control_layer[2082]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  157.088078] layer1_control_layer[2082]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  157.088130] layer1_control_layer[2082]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  157.088203] layer1_control_layer[2082]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  157.088261] layer1_control_layer[2082]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  157.088313] layer1_control_layer[2082]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  157.088365] layer1_control_layer[2082]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  157.088417] layer1_control_layer[2082]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  157.088468] layer1_control_layer[2082]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  157.088520] layer1_control_layer[2082]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  157.088575] layer1_control_layer[2082]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  157.088628] layer1_control_layer[2082]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> 2024-07-31 08:14:43,399 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:14:43,451 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:43,517 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:14:43,518 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:14:43,518 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":2} <NL> 2024-07-31 08:14:43,519 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:14:43,519 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:14:43,520 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:14:43,566 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:43,650 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:14:43,641 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:43,709 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:43,723 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:14:43,791 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":2} <NL> 2024-07-31 08:14:43,791 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:14:43,797 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:14:43,813 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:14:44,287 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:44,288 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version:"}
{"timestamp_utc": "2024-07-31T08:14:44.993Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "2024-07-31 08:14:44,288 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:44,301 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:14:44,468 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:14:44,469 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> 2024-07-31 08:14:29,946 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:29,946 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:29,946 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:14:29,946 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: RESET -> READY_STATE -> reset_fn -> WAIT_STATE <NL> 2024-07-31 08:14:30,240 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:14:30,240 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:30,240 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:30,241 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount  --script  --base /mnt/secondary/var/shared --algorithm longest-match L1-OTSG2.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  145.106222] ains_manager[2297]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:14:30,949 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:30,949 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:14:30,950 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:30,950 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:14:30,951 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:30,951 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:30,951 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:14:30,951 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:14:31,426 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:14:31,429 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:14:31,433 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:14:31,550 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  146.055554] startup_finished.py[2296]: *****Startup Finished Monitor:Starting the event loop***** <NL> 2024-07-31 08:14:31,693 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:14:31,720 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:31,721 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:31,963 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:31,964 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:32,203 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:32,203 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> ERROR:root:empty repository <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> 2024-07-31 08:14:35,373 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:14:35,373 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:14:35,435 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:14:35,436 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:14:35,436 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:14:35,436 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:14:35,436 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:14:35,461 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  151.323482] dhal_sim_startup.sh[2388]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  152.280509] confd_mgr_action_server[2372]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  153.795525] confd_phase_sentry[2419]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  153.856981] confd_phase_sentry[2419]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  153.886968] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  155.043525] temp_acct_cleanup_app[2435]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  155.079857] temp_acct_cleanup_app[2435]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  155.213917] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 1 <NL> [  156.340304] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  156.411114] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  158.301426] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 2 <NL> [  158.706653] ains_manager[2544]: Failed to get unit file state for rdm-chassis.service: No such file or directory"}
{"timestamp_utc": "2024-07-31T08:14:47.507Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:46 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:49.395Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:49 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:49.956Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:49 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:52.468Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:51 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:51 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:54.977Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:54 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:54.978Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:57.487Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:57 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:58.047Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  159.003432] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  159.003528] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  160.218031] sncp_app[2369]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:14:46,256 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:14:46,376 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:14:46,378 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:14:46,889 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:14:46,889 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:14:46,890 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:14:46,890 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:46,524 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:14:46,891 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  161.271904] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 3 <NL> [  162.114876] ypg_app[2370]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:14:47,411 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:47,541 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:48,581 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:48,660 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:48,660 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:48,661 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:14:48,661 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:14:48,718 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> [  163.852374] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  164.037545] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  164.271214] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 4 <NL> 2024-07-31 08:14:49,785 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> 2024-07-31 08:14:50,018 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:14:50,484 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:14:50,485 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:14:50,485 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:14:50,486 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:50,486 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:14:50,709 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========="}
{"timestamp_utc": "2024-07-31T08:14:58.048Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "Executing confd_mgr_rdm_status.sh STANDALONE <NL> 2024-07-31 08:14:51,336 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  167.296179] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 5 <NL> [  169.047433] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  169.585052] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  169.962207] common_alarm_handler[2365]: gen_util: DDS_P2MP not available <NL> [  170.553972] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 6 <NL> [  170.904385] python3[2405]: [.440] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  170.904537] python3[2405]: [.440] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  170.904623] python3[2405]: [.440] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  170.904680] python3[2405]: [.441] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  170.904743] python3[2405]: [.441] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  170.904801] python3[2405]: [.441] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  170.904886] python3[2405]: [.441] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  170.904947] python3[2405]: [.441] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  170.905021] python3[2405]: [.441] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  170.905079] python3[2405]: [.441] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  170.905149] python3[2405]: [.442] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  170.905209] python3[2405]: [.442] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  170.905266] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  170.905322] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  170.905404] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  170.905476] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  170.905534] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  170.905606] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  170.905666] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  170.905726] python3[2405]: [.488] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  170.906263] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'}"}
{"timestamp_utc": "2024-07-31T08:14:58.973Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:14:39,160 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:14:39,161 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:39,161 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:14:39,161 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:39,298 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:39,298 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:14:39,298 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:14:39,298 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:14:39,299 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:14:39,299 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:14:39,299 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:39,645 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:14:39,645 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:39,645 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:40,036 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:14:40,036 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:14:40,076 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:40,094 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  157.313141] dhal_sim_startup.sh[2389]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  158.615994] confd_phase_sentry[2422]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  158.863732] confd_phase_sentry[2422]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  158.988410] confd_mgr_action_server[2382]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  159.935850] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  160.430468] temp_acct_cleanup_app[2443]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  160.430650] temp_acct_cleanup_app[2443]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  161.625312] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 1 <NL> [  163.521055] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  163.732312] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> ERROR:root:empty repository"}
{"timestamp_utc": "2024-07-31T08:14:58.974Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  164.872241] sncp_app[2377]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  164.872921] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 2 <NL> [  165.021255] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  165.021414] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> [  165.753654] ypg_app[2380]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:14:52,597 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:14:53,395 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> 2024-07-31 08:14:54,373 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:14:54,374 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  167.610729] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 3 <NL> 2024-07-31 08:14:54,643 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:14:55,337 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:14:55,338 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:14:55,338 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  169.215642] ains_manager[2585]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  169.949347] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  169.949942] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  170.571739] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 4 <NL> 2024-07-31 08:14:58,094 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:14:58,224 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:14:58,225 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:14:58,225 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version:"}
{"timestamp_utc": "2024-07-31T08:14:59.535Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:59 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:00.464Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  170.906328] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  170.906384] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  171.525052] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  171.525233] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  171.525297] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  171.525356] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  171.525432] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'}"}
{"timestamp_utc": "2024-07-31T08:15:00.465Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  171.525491] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  171.525551] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  171.525610] python3[2405]: [.539] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  171.525670] python3[2405]: [.539] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  171.525729] python3[2405]: [.539] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  171.525786] python3[2405]: [.590] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  171.525844] python3[2405]: [.590] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  171.525906] python3[2405]: [.627] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  171.526006] python3[2405]: [.627] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  171.526067] python3[2405]: [.627] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  171.526126] python3[2405]: [.627] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  171.600109] common_alarm_handler[2365]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  171.965524] common_alarm_handler[2365]: topic = SystemProv; id = 1 <NL> [  171.965598] common_alarm_handler[2365]: topic = WdmcfgProv; id = 2 <NL> [  171.965659] common_alarm_handler[2365]: topic = LicenseStatusTopic; id = 3 <NL> [  171.965722] common_alarm_handler[2365]: topic = ShelfProv; id = 5 <NL> [  171.965810] common_alarm_handler[2365]: topic = SlotProv; id = 6 <NL> [  171.965876] common_alarm_handler[2365]: topic = PortProv; id = 7 <NL> [  171.965938] common_alarm_handler[2365]: topic = SubportProv; id = 8 <NL> [  171.965997] common_alarm_handler[2365]: topic = FconProv; id = 9 <NL> [  171.966067] common_alarm_handler[2365]: topic = XconProv; id = 10 <NL> [  171.966134] common_alarm_handler[2365]: topic = OchProv; id = 11 <NL> [  171.966189] common_alarm_handler[2365]: topic = OmsProv; id = 12 <NL> [  171.966244] common_alarm_handler[2365]: topic = OtsProv; id = 13 <NL> [  171.966336] common_alarm_handler[2365]: topic = EthernetProv; id = 14 <NL> [  171.966392] common_alarm_handler[2365]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  171.966457] common_alarm_handler[2365]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  171.966515] common_alarm_handler[2365]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  171.966571] common_alarm_handler[2365]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  171.966626] common_alarm_handler[2365]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  171.966688] common_alarm_handler[2365]: topic = DcnStaticRoute_DcnStaticRoute; id = 21"}
{"timestamp_utc": "2024-07-31T08:15:00.466Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  171.966749] common_alarm_handler[2365]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  171.966806] common_alarm_handler[2365]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  171.966862] common_alarm_handler[2365]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  171.966919] common_alarm_handler[2365]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  171.966975] common_alarm_handler[2365]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  171.967044] common_alarm_handler[2365]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  171.967101] common_alarm_handler[2365]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  171.967162] common_alarm_handler[2365]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  171.967219] common_alarm_handler[2365]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  171.967276] common_alarm_handler[2365]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  171.967332] common_alarm_handler[2365]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> [  171.967390] common_alarm_handler[2365]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  171.992190] common_alarm_handler[2365]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  172.505103] common_alarm_handler[2365]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  172.505313] common_alarm_handler[2365]: topic = AlarmNotification; id = 40 <NL> [  172.505392] common_alarm_handler[2365]: topic = GenericOperInfoReq; id = 41 <NL> [  172.505460] common_alarm_handler[2365]: topic = PmRtrvReq; id = 42 <NL> [  172.505516] common_alarm_handler[2365]: topic = PmRtrvResp; id = 43 <NL> [  172.505570] common_alarm_handler[2365]: topic = PmInitReq; id = 44 <NL> [  172.505665] common_alarm_handler[2365]: topic = PmOperData; id = 45 <NL> [  173.040722] common_alarm_handler[2365]: topic = StateChange; id = 46 <NL> [  173.040802] common_alarm_handler[2365]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  173.040860] common_alarm_handler[2365]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  173.040916] common_alarm_handler[2365]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> [  173.040971] common_alarm_handler[2365]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  173.041038] common_alarm_handler[2365]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  173.041100] common_alarm_handler[2365]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  173.041156] common_alarm_handler[2365]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  173.041655] python3[2405]: [.627] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  173.041756] python3[2405]: [.627] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  173.041821] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  173.041888] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  173.041945] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  173.113552] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  173.831817] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  173.831903] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  173.831964] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'}"}
{"timestamp_utc": "2024-07-31T08:15:00.467Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  173.832035] python3[2405]: [.737] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  173.832103] python3[2405]: [.738] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  173.832161] python3[2405]: [.738] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'}"}
{"timestamp_utc": "2024-07-31T08:15:02.354Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:02 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:04.866Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> [  173.832221] python3[2405]: [.775] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  173.832280] python3[2405]: [.775] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  173.832338] python3[2405]: [.775] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  173.832414] python3[2405]: [.775] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  173.832473] python3[2405]: [.775] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  173.832531] python3[2405]: [.776] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  173.832590] python3[2405]: [.776] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  173.832650] python3[2405]: [.776] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  173.834973] common_alarm_handler[2365]: topic = EthIfProv; id = 56 <NL> [  173.877378] common_alarm_handler[2365]: topic = DcnNat64Attributes; id = 57 <NL> [  174.898750] common_alarm_handler[2365]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  174.898882] common_alarm_handler[2365]: topic = LldpGlobalCfgProv; id = 59 <NL> [  174.952219] common_alarm_handler[2365]: topic = LldpPortCfgProv; id = 60 <NL> [  174.952299] common_alarm_handler[2365]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  174.952358] common_alarm_handler[2365]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  174.952431] common_alarm_handler[2365]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  175.328757] common_alarm_handler[2365]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  175.328979] common_alarm_handler[2365]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  175.329075] common_alarm_handler[2365]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  175.329135] common_alarm_handler[2365]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  175.329192] common_alarm_handler[2365]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  175.329250] common_alarm_handler[2365]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  175.329307] common_alarm_handler[2365]: topic = DcnPppAttributesProv; id = 70 <NL> [  175.619598] common_alarm_handler[2365]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  175.713438] common_alarm_handler[2365]: topic = LldpBladeCfgProv; id = 72 <NL> [  175.759302] common_alarm_handler[2365]: topic = LldpPortInstCfgProv; id = 73 <NL> [  175.759384] common_alarm_handler[2365]: topic = DcnGreTunnelProv; id = 74 <NL> [  175.759444] common_alarm_handler[2365]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  175.759503] common_alarm_handler[2365]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  175.759571] common_alarm_handler[2365]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  175.759629] common_alarm_handler[2365]: topic = SysGnmiCertProv; id = 78 <NL> [  175.759687] common_alarm_handler[2365]: topic = IetfInterfaceProv; id = 79 <NL> [  175.759796] common_alarm_handler[2365]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  175.759854] common_alarm_handler[2365]: topic = SystemAutoLogoffProv; id = 81 <NL> [  175.759914] common_alarm_handler[2365]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  175.759977] common_alarm_handler[2365]: topic = SystemPortsProv; id = 83 <NL> [  175.760049] common_alarm_handler[2365]: topic = OspfProvisioningModeProv; id = 84 <NL> [  175.760106] common_alarm_handler[2365]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  175.760165] common_alarm_handler[2365]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  175.760223] common_alarm_handler[2365]: topic = BasicGroupProv; id = 87 <NL> [  175.760280] common_alarm_handler[2365]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  175.760337] common_alarm_handler[2365]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  176.045242] common_alarm_handler[2365]: topic = SystemFipsProv; id = 90 <NL> [  177.020881] common_alarm_handler[2365]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  177.020970] common_alarm_handler[2365]: topic = SecuritySystemwideProv; id = 92 <NL> [  177.021055] common_alarm_handler[2365]: topic = DataEncryptionProv; id = 93 <NL> [  177.021113] common_alarm_handler[2365]: topic = SystemServicesProv; id = 94 <NL> [  177.021171] common_alarm_handler[2365]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  177.021233] common_alarm_handler[2365]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  177.021293] common_alarm_handler[2365]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  177.021363] common_alarm_handler[2365]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  177.021445] common_alarm_handler[2365]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  177.021507] common_alarm_handler[2365]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  177.021565] common_alarm_handler[2365]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  177.021621] common_alarm_handler[2365]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  177.021690] common_alarm_handler[2365]: topic = FscProv; id = 111 <NL> [  177.021748] common_alarm_handler[2365]: topic = XconProv_v2Prov; id = 112 <NL> [  177.021802] common_alarm_handler[2365]: topic = OchIfProv; id = 113 <NL> [  177.045229] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 7 <NL> [  177.045383] txid_tracker[2436]: ::::create_confd_subscription_connection() try number 8 <NL> [  177.045846] python3[2405]: [.776] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  177.045921] python3[2405]: [.776] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  177.045981] python3[2405]: [.776] hookhdlr 140013762971456 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  177.046054] python3[2405]: [.776] hookhdlr 140013762971456 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  177.046113] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  177.046170] python3[2405]: [.938] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  177.356219] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  177.383945] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  177.384269] common_alarm_handler[2365]: topic = AclProfileProv; id = 114 <NL> [  177.384499] common_alarm_handler[2365]: topic = OtuProv; id = 115 <NL> [  177.384735] common_alarm_handler[2365]: topic = GeProv; id = 116 <NL> [  177.405507] common_alarm_handler[2365]: topic = OduProv; id = 117 <NL> [  177.405681] common_alarm_handler[2365]: topic = TcmProv; id = 118 <NL> [  177.405755] common_alarm_handler[2365]: topic = OCnProv; id = 119 <NL> [  177.405818] common_alarm_handler[2365]: topic = OnDemandDM; id = 120 <NL> [  177.405883] common_alarm_handler[2365]: topic = OducnProv; id = 121 <NL> [  177.405947] common_alarm_handler[2365]: topic = OtsiProv; id = 122 <NL> [  177.406402] common_alarm_handler[2365]: topic = OtsigProv; id = 123 <NL> [  177.406468] common_alarm_handler[2365]: topic = OtucnProv; id = 124 <NL> [  177.406525] common_alarm_handler[2365]: topic = YpgProv; id = 125 <NL> [  177.406590] common_alarm_handler[2365]: topic = EpgProv; id = 126 <NL> [  177.406654] common_alarm_handler[2365]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  177.406716] common_alarm_handler[2365]: topic = DataEncryptionOperReq; id = 128 <NL> [  177.406778] common_alarm_handler[2365]: topic = RoutePolicyTableProv; id = 129 <NL> [  177.406838] common_alarm_handler[2365]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  177.406904] common_alarm_handler[2365]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  177.407042] common_alarm_handler[2365]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  177.407121] common_alarm_handler[2365]: topic = ShapingProfileProv; id = 133 <NL> [  177.407190] common_alarm_handler[2365]: topic = TaildropProfileProv; id = 134"}
{"timestamp_utc": "2024-07-31T08:15:04.867Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:04 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:06.754Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:14:58,225 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:14:58,225 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:14:58,226 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:14:58,227 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:14:58,531 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:14:58,774 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:59,061 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:00,196 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:00,206 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:00,206 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:00,227 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:15:00,791 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> [  173.584766] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 5 <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> 2024-07-31 08:15:00,901 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  175.067426] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  175.232438] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:15:02,260 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:15:02,301 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:02,360 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:02,360 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:02,361 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:02,361 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:02,527 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:02,540 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:02,541 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> [  176.587273] hrtimer: interrupt took 2294924 ns <NL> [  176.647473] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 6 <NL> [  178.133551] common_alarm_handler[2374]: gen_util: DDS_P2MP not available <NL> [  178.340698] common_alarm_handler[2374]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  178.394746] common_alarm_handler[2374]: topic = SystemProv; id = 1 <NL> [  178.394929] common_alarm_handler[2374]: topic = WdmcfgProv; id = 2 <NL> [  178.394992] common_alarm_handler[2374]: topic = LicenseStatusTopic; id = 3 <NL> [  178.395063] common_alarm_handler[2374]: topic = ShelfProv; id = 5 <NL> [  178.395150] common_alarm_handler[2374]: topic = SlotProv; id = 6 <NL> [  178.395205] common_alarm_handler[2374]: topic = PortProv; id = 7 <NL> [  178.395260] common_alarm_handler[2374]: topic = SubportProv; id = 8 <NL> [  178.395320] common_alarm_handler[2374]: topic = FconProv; id = 9 <NL> [  178.395390] common_alarm_handler[2374]: topic = XconProv; id = 10 <NL> [  178.395449] common_alarm_handler[2374]: topic = OchProv; id = 11 <NL> [  178.395506] common_alarm_handler[2374]: topic = OmsProv; id = 12 <NL> [  178.395563] common_alarm_handler[2374]: topic = OtsProv; id = 13 <NL> [  178.395665] common_alarm_handler[2374]: topic = EthernetProv; id = 14 <NL> [  178.395723] common_alarm_handler[2374]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  178.395779] common_alarm_handler[2374]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  178.395836] common_alarm_handler[2374]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  178.395896] common_alarm_handler[2374]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  178.395953] common_alarm_handler[2374]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  178.396022] common_alarm_handler[2374]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  178.396084] common_alarm_handler[2374]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  178.396141] common_alarm_handler[2374]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  178.396197] common_alarm_handler[2374]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24"}
{"timestamp_utc": "2024-07-31T08:15:06.755Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  178.396261] common_alarm_handler[2374]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  178.396327] common_alarm_handler[2374]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  178.396395] common_alarm_handler[2374]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  178.396467] common_alarm_handler[2374]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  178.396528] common_alarm_handler[2374]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  178.396594] common_alarm_handler[2374]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  178.396651] common_alarm_handler[2374]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  178.396708] common_alarm_handler[2374]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> [  178.396764] common_alarm_handler[2374]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  178.396821] common_alarm_handler[2374]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  178.396877] common_alarm_handler[2374]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  178.396937] common_alarm_handler[2374]: topic = AlarmNotification; id = 40 <NL> [  178.396995] common_alarm_handler[2374]: topic = GenericOperInfoReq; id = 41 <NL> [  178.397068] common_alarm_handler[2374]: topic = PmRtrvReq; id = 42 <NL> [  178.397124] common_alarm_handler[2374]: topic = PmRtrvResp; id = 43 <NL> [  178.397182] common_alarm_handler[2374]: topic = PmInitReq; id = 44 <NL> [  178.397272] common_alarm_handler[2374]: topic = PmOperData; id = 45 <NL> [  178.397330] common_alarm_handler[2374]: topic = StateChange; id = 46 <NL> [  178.584375] common_alarm_handler[2374]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  178.735752] common_alarm_handler[2374]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  178.735825] common_alarm_handler[2374]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> [  178.735883] common_alarm_handler[2374]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  178.735959] common_alarm_handler[2374]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  178.736029] common_alarm_handler[2374]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  178.736092] common_alarm_handler[2374]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  178.736149] common_alarm_handler[2374]: topic = EthIfProv; id = 56 <NL> [  178.736211] common_alarm_handler[2374]: topic = DcnNat64Attributes; id = 57 <NL> [  178.736277] common_alarm_handler[2374]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  178.736339] common_alarm_handler[2374]: topic = LldpGlobalCfgProv; id = 59"}
{"timestamp_utc": "2024-07-31T08:15:07.908Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:07 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:09.909Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:09 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:10.172Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:15:10 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:11.556Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  178.736408] common_alarm_handler[2374]: topic = LldpPortCfgProv; id = 60 <NL> [  178.736464] common_alarm_handler[2374]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  178.736518] common_alarm_handler[2374]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  178.736573] common_alarm_handler[2374]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  178.736625] common_alarm_handler[2374]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  178.736676] common_alarm_handler[2374]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  178.736739] common_alarm_handler[2374]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  178.736791] common_alarm_handler[2374]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  178.736848] common_alarm_handler[2374]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  178.736905] common_alarm_handler[2374]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  178.736964] common_alarm_handler[2374]: topic = DcnPppAttributesProv; id = 70 <NL> [  178.737034] common_alarm_handler[2374]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  178.737092] common_alarm_handler[2374]: topic = LldpBladeCfgProv; id = 72 <NL> [  178.737147] common_alarm_handler[2374]: topic = LldpPortInstCfgProv; id = 73 <NL> [  178.737217] common_alarm_handler[2374]: topic = DcnGreTunnelProv; id = 74 <NL> [  178.737274] common_alarm_handler[2374]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  178.737329] common_alarm_handler[2374]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  178.737402] common_alarm_handler[2374]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  178.737464] common_alarm_handler[2374]: topic = SysGnmiCertProv; id = 78 <NL> [  178.737523] common_alarm_handler[2374]: topic = IetfInterfaceProv; id = 79 <NL> [  178.737584] common_alarm_handler[2374]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  178.737639] common_alarm_handler[2374]: topic = SystemAutoLogoffProv; id = 81 <NL> [  178.737703] common_alarm_handler[2374]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  178.737776] common_alarm_handler[2374]: topic = SystemPortsProv; id = 83 <NL> [  178.737835] common_alarm_handler[2374]: topic = OspfProvisioningModeProv; id = 84 <NL> [  178.737893] common_alarm_handler[2374]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  178.737950] common_alarm_handler[2374]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  178.738029] common_alarm_handler[2374]: topic = BasicGroupProv; id = 87 <NL> [  178.738089] common_alarm_handler[2374]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  178.738159] common_alarm_handler[2374]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  178.738221] common_alarm_handler[2374]: topic = SystemFipsProv; id = 90 <NL> [  178.738284] common_alarm_handler[2374]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  178.738341] common_alarm_handler[2374]: topic = SecuritySystemwideProv; id = 92 <NL> [  178.796956] common_alarm_handler[2374]: topic = DataEncryptionProv; id = 93 <NL> [  179.732297] common_alarm_handler[2374]: topic = SystemServicesProv; id = 94 <NL> [  179.732499] common_alarm_handler[2374]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  180.301617] common_alarm_handler[2374]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  180.490874] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 7 <NL> [  180.492233] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  180.492320] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  180.651068] common_alarm_handler[2374]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  180.699041] common_alarm_handler[2374]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  180.699138] common_alarm_handler[2374]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  180.699209] common_alarm_handler[2374]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  180.699268] common_alarm_handler[2374]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  180.699324] common_alarm_handler[2374]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  180.699399] common_alarm_handler[2374]: topic = FscProv; id = 111 <NL> [  180.699459] common_alarm_handler[2374]: topic = XconProv_v2Prov; id = 112 <NL> [  180.699515] common_alarm_handler[2374]: topic = OchIfProv; id = 113 <NL> [  180.699573] common_alarm_handler[2374]: topic = AclProfileProv; id = 114 <NL> [  180.699630] common_alarm_handler[2374]: topic = OtuProv; id = 115 <NL> [  180.699695] common_alarm_handler[2374]: topic = GeProv; id = 116 <NL> [  180.699756] common_alarm_handler[2374]: topic = OduProv; id = 117 <NL> [  180.699811] common_alarm_handler[2374]: topic = TcmProv; id = 118 <NL> [  180.699865] common_alarm_handler[2374]: topic = OCnProv; id = 119 <NL> [  180.699929] common_alarm_handler[2374]: topic = OnDemandDM; id = 120 <NL> [  180.699986] common_alarm_handler[2374]: topic = OducnProv; id = 121 <NL> [  180.700055] common_alarm_handler[2374]: topic = OtsiProv; id = 122 <NL> [  180.700117] common_alarm_handler[2374]: topic = OtsigProv; id = 123 <NL> [  180.700171] common_alarm_handler[2374]: topic = OtucnProv; id = 124 <NL> [  180.700229] common_alarm_handler[2374]: topic = YpgProv; id = 125 <NL> [  180.700283] common_alarm_handler[2374]: topic = EpgProv; id = 126 <NL> [  180.700348] common_alarm_handler[2374]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  180.700404] common_alarm_handler[2374]: topic = DataEncryptionOperReq; id = 128 <NL> [  180.700456] common_alarm_handler[2374]: topic = RoutePolicyTableProv; id = 129 <NL> [  181.021193] common_alarm_handler[2374]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  181.021326] common_alarm_handler[2374]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  181.021438] common_alarm_handler[2374]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  181.021513] common_alarm_handler[2374]: topic = ShapingProfileProv; id = 133 <NL> [  181.021583] common_alarm_handler[2374]: topic = TaildropProfileProv; id = 134 <NL> [  181.021641] common_alarm_handler[2374]: topic = PolicingProfileProv; id = 135 <NL> [  181.021700] common_alarm_handler[2374]: topic = CapabilityProfileProv; id = 136 <NL> [  181.021757] common_alarm_handler[2374]: topic = TransportInterfaceRateProv; id = 137 <NL> [  181.021815] common_alarm_handler[2374]: topic = PmRtrvReqSess; id = 138 <NL> [  181.021872] common_alarm_handler[2374]: topic = PmRtrvRespSess; id = 139 <NL> [  181.021931] common_alarm_handler[2374]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  181.022037] common_alarm_handler[2374]: topic = DataEncryptionPskReq; id = 141 <NL> [  181.022096] common_alarm_handler[2374]: topic = SystemWebserverProv; id = 142 <NL> [  181.022159] common_alarm_handler[2374]: NO match: <NL> [  181.022217] common_alarm_handler[2374]: NO match: <NL> [  181.022273] common_alarm_handler[2374]: NO match: <NL> [  182.884580] txid_tracker[2444]: ::::create_confd_subscription_connection() try number 8 <NL> [  183.381344] python3[2409]: [.033] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  183.384953] python3[2409]: [.033] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  183.564458] python3[2409]: [.230] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  183.564584] python3[2409]: [.230] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  183.564645] python3[2409]: [.230] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  183.564703] python3[2409]: [.230] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  183.564784] python3[2409]: [.230] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  183.564846] python3[2409]: [.230] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  183.564916] python3[2409]: [.370] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  183.564980] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'}"}
{"timestamp_utc": "2024-07-31T08:15:12.117Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:12 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:12 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:14.633Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:14 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:15.195Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:15:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:17.085Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  183.652445] python3[2409]: [.459] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  183.896049] python3[2409]: [.459] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  183.896196] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  183.896274] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  183.896379] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  183.896439] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  183.896498] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  183.896566] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  183.896628] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  183.896686] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  183.896742] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  183.896803] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  183.896866] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  183.896925] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  183.896988] python3[2409]: [.593] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  183.897065] python3[2409]: [.594] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  183.897123] python3[2409]: [.594] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  183.897181] python3[2409]: [.594] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  183.897238] python3[2409]: [.594] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  184.339463] python3[2409]: [.594] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  184.341101] python3[2409]: [.951] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  184.368499] python3[2409]: [.952] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  184.369566] python3[2409]: [.952] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  184.590073] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  184.590159] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  184.590239] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  184.590322] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  184.590383] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  184.590442] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  184.590500] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  184.590586] python3[2409]: [.371] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  184.775955] python3[2409]: [.535] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  184.776117] python3[2409]: [.535] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  184.776183] python3[2409]: [.535] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  184.776251] python3[2409]: [.535] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  184.776344] python3[2409]: [.535] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  184.776409] python3[2409]: [.535] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  184.776473] python3[2409]: [.535] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  184.776535] python3[2409]: [.536] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  184.776595] python3[2409]: [.536] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'}"}
{"timestamp_utc": "2024-07-31T08:15:17.086Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  184.776659] python3[2409]: [.536] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  184.984127] python3[2409]: [.707] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  184.984247] python3[2409]: [.707] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  184.984318] python3[2409]: [.707] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  184.984378] python3[2409]: [.707] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  184.984432] python3[2409]: [.707] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  184.984486] python3[2409]: [.708] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  184.984553] python3[2409]: [.708] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  184.984615] python3[2409]: [.708] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  184.984683] python3[2409]: [.708] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  184.984742] python3[2409]: [.708] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  184.984800] python3[2409]: [.708] hookhdlr 140061943105344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  184.984861] python3[2409]: [.708] hookhdlr 140061943105344 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  185.260391] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  185.260648] python3[2409]: [.847] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  185.261168] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  185.261237] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  188.167921] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 1 <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  188.986799] layer1_control_layer[2410]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> # 03:15:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:17.342Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:17.901Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:17 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:19.788Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:19 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:23.102Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> [  177.407255] common_alarm_handler[2365]: topic = PolicingProfileProv; id = 135 <NL> [  177.407323] common_alarm_handler[2365]: topic = CapabilityProfileProv; id = 136 <NL> [  177.407394] common_alarm_handler[2365]: topic = TransportInterfaceRateProv; id = 137 <NL> [  177.407456] common_alarm_handler[2365]: topic = PmRtrvReqSess; id = 138 <NL> [  177.407524] common_alarm_handler[2365]: topic = PmRtrvRespSess; id = 139 <NL> [  177.407590] common_alarm_handler[2365]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  177.407654] common_alarm_handler[2365]: topic = DataEncryptionPskReq; id = 141 <NL> [  177.407721] common_alarm_handler[2365]: topic = SystemWebserverProv; id = 142 <NL> [  177.407784] common_alarm_handler[2365]: NO match: <NL> [  177.407848] common_alarm_handler[2365]: NO match: <NL> [  177.407908] common_alarm_handler[2365]: NO match: <NL> [  179.590007] python3[2547]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  179.590246] python3[2547]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  179.590341] python3[2547]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  179.590400] python3[2547]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  179.590455] python3[2547]: max_slotNumber=5 <NL> [  179.591014] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  179.591095] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  180.597031] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  180.597155] python3[2405]: [.970] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  184.292454] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  185.718190] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  185.898603] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 1 <NL> Exception: Connect failed <NL> [  187.468540] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 2 <NL> Exception: Connect failed <NL> 2024-07-31 08:15:14,018 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:15:14,019 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:14,091 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:15:14,191 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  188.860045] dcn_ka[1594]: KaSessMgr Process Startup <NL> [  188.940150] dcn_dns_controller[1592]: dnsClientStartup() <NL> [  189.229501] dcn_dns_controller[1592]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  189.229606] dcn_dns_controller[1592]: fin_dnsmasq_conf is open <NL> [  189.519998] confd_mgr[2874]: ConfdMgrConf: DB signature is NOT supported <NL> [  189.796682] confd_mgr[2874]: Read reset type failed basic_ios::clear: iostream error <NL> [  189.796943] confd_mgr[2874]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  190.017853] ntp_oper_data.py[1965]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  190.018036] ntp_oper_data.py[1965]: INFO:root:redundancy status now set to standalone <NL> [  190.018098] ntp_oper_data.py[1965]: INFO:root:Received redundancy topic <NL> [  190.018158] ntp_oper_data.py[1965]: INFO:root:Redundancy status is standalone <NL> [  190.018652] ntputils[1963]: bool NTPServer::handle_command(const string&) <NL> [  190.018762] ntputils[1963]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  190.018848] ntputils[1963]: got Platform::RedundancyMode: WORK <NL> [  190.018916] ntputils[1963]: got Platform::RedundancyStatus: STANDALONE <NL> [  190.018971] ntputils[1963]: my current red mode is: UNKNOWN <NL> [  190.019036] ntputils[1963]: new red mode is: WORK <NL> [  190.019094] ntputils[1963]: my current red status is: STANDALONE <NL> [  190.359480] ntputils[1963]: new red status is: STANDALONE"}
{"timestamp_utc": "2024-07-31T08:15:23.103Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  190.359724] ntputils[1963]: red mode change, update: UNKNOWN => WORK <NL> [  190.359791] ntputils[1963]: no active/not-active status change: 0 <NL> [  190.360365] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  190.360447] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> [  190.819727] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  191.206958] python3[2405]: [.981] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  191.208801] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 3 <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  191.496337] startup_finished.py[2296]: Startup Finished: systemd state is non-Production mode and running <NL> [  191.514523] startup_finished.py[2296]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  192.143381] startup_finished.py[2296]: *****Startup Finished: stopping EOW timer***** <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> [  194.465982] hrtimer: interrupt took 1342389 ns <NL> [  194.329961] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  194.330124] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  194.330187] ntputils[1963]: child pid is 2948 <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> [  194.331096] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 4 <NL> [  195.398855] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  195.432411] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  195.492869] startup_finished.py[2296]: systemctl stop startup_finished_limit.timer <NL> [  195.522604] ntputils[1963]: exited, status is 0 <NL> [  195.539113] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  195.539787] ntputils[1963]: poller time change delta is: 1 <NL> [  195.540389] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  195.541313] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  195.541997] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  195.542742] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  195.568260] ntputils[1963]: push_local_changes OK <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  196.236368] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  196.236522] ntputils[1963]: /sbin/hwclock -u --systohc <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  196.912758] ntputils[1963]: child pid is 2988 <NL> [  196.912929] ntputils[1963]: exited, status is 0 <NL> [  196.912991] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  197.184037] ntputils[1963]: poller time change delta is: 1 <NL> [  197.184280] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  197.184344] ntputils[1963]: local_push OK u Platform::Time changedByUser 0"}
{"timestamp_utc": "2024-07-31T08:15:24.028Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:23 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:24.719Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:24 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:29.959Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:28 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:29 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:30.214Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:15:30 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:32.102Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:32 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:34.082Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:33 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:34.642Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:34 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:34.898Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   89.287854] serialportMon[952]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg[   89.544003] NFSD: starting 90-second grace period (net f0000098) <NL> [  101.909925] vsftpd_listen_address[959]: listen_address=127.1.254.254"}
{"timestamp_utc": "2024-07-31T08:15:34.899Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:13:53,945 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:02,525 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:02,528 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:02,618 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:02,665 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:02,670 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> 2024-07-31 08:14:02,678 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  144.773002] dcn_dns_controller[1390]:  WaitForActive <NL> [  155.076459] dcn_ka[1392]:  WaitForActive <NL> 2024-07-31 08:14:50,586 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 47 seconds <NL> 2024-07-31 08:14:51,204 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 47 seconds <NL> [  167.044430] ntputils[1728]: int ntputils_main(int, char**)Starting ntputils <NL> 2024-07-31 08:14:52,727 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:53,235 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  169.886626] ntputils[1728]: Running as a daemon <NL> 2024-07-31 08:14:55,807 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> 2024-07-31 08:14:55,920 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  170.580337] ntputils[1728]: shelf role is: MAIN <NL> [  174.309792] ntputils[1728]: slot number is: 0 <NL> [  174.642197] ntputils[1728]: slot role is: UNKNOWN <NL> [  175.365782] ntputils[1728]: redundancy_mode: UNKNOWN <NL> [  176.207043] ntputils[1728]: Executing on a work blade <NL> 2024-07-31 08:15:02,429 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> [  177.776688] ntputils[1728]: ================================ <NL> 2024-07-31 08:15:04,574 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:04,623 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> [  181.194686] ntputils[1728]: shelf_role is: MAIN <NL> 2024-07-31 08:15:09,686 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> [  184.379704] ntputils[1728]: redundancy_mode: UNKNOWN <NL> 2024-07-31 08:15:10,398 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn <NL> 2024-07-31 08:15:11,225 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  185.472841] ntputils[1728]: active_status: active <NL> [  190.435286] ntputils[1728]: ntp_role: act <NL> [  191.088058] ntputils[1728]: ================================ <NL> 2024-07-31 08:15:17,533 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:18,520 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  192.826917] standby_filesync[1410]: DipLog_pimpl destructor called <NL> 2024-07-31 08:15:20,394 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> [  194.853278] standby_filesync[1410]: DipVerbosity Listener ZMQ error <NL> [  196.957255] standby_filesync[1410]:     ret='Context was terminated <NL> [  197.029616] standby_filesync[1410]: deleting subscriber_ socket <NL> [  197.275920] standby_filesync[1410]: Exiting verb listener <NL> [  197.329917] ntputils[1728]: NTPUtilsConfig::do_default_config <NL> [  197.647070] ntputils[1728]: shelf_num/is_client: 0 <NL> [  197.746995] ntputils[1728]: server_ip: 0x55cf53962fc0 <NL> [  198.374869] ntputils[1728]: ip_addr(ilan): 0x55cf53962f80 <NL> [  199.022355] ntputils[1728]: ntp_role act <NL> [  199.432218] ntputils[1728]: shelf_num aka is_client == 0 <NL> [  200.029312] ntputils[1728]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:20,878 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:22,110 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn <NL> [  201.452351] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:21,173 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> [  202.512801] ntputils[1728]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:28,637 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:28,962 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> [  203.761952] ntputils[1728]: child pid is 1789 <NL> 2024-07-31 08:15:29,862 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:31,347 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:29,126 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> [  205.155590] ntputils[1728]: exited, status is 0 <NL> 2024-07-31 08:15:31,993 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:15:30,855 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  206.830964] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  206.837614] ntputils[1728]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  206.842756] ntputils[1728]: child pid is 1793 <NL> 2024-07-31 08:15:32,669 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:32,667 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  207.010869] ops-redundancy-mgr[1405]: DipLog_pimpl destructor called <NL> 2024-07-31 08:15:33,216 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> [  207.923643] ops-redundancy-mgr[1405]: DipVerbosity Listener ZMQ error <NL> [  207.924310] ops-redundancy-mgr[1405]:     ret='Context was terminated <NL> 2024-07-31 08:15:33,764 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:33,729 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  207.991800] ops-redundancy-mgr[1405]: deleting subscriber_ socket"}
{"timestamp_utc": "2024-07-31T08:15:35.155Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:15:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:37.669Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:38.595Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   81.052161] commsdriver[880]: tx-tcp-segmentation: off [not requested] <NL> [   81.260844] commsdriver[880]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   81.426601] commsdriver[880]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   81.589344] commsdriver[880]: tx-tcp6-segmentation: off [not requested] <NL> [   81.698672] commsready[883]: callback: Entry PID=0x373 signo(15) <NL> [   81.817092] change_esal_priority.sh[887]: Comms check for and selectively change esal priorities <NL> [   82.599430] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   82.719864] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   82.875216] change_esal_priority.sh[887]: Comms did not change any esal thread priorities <NL> [   88.475930] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   88.897179] NFSD: Using legacy client tracking operations. <NL> [   89.236035] NFSD: starting 90-second grace period (net f0000098) <NL> [   90.227930] serialportMon[1185]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [  104.517314] vsftpd_listen_address[1190]: listen_address=127.1.254.254 <NL> 2024-07-31 08:13:57,036 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:03,347 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:03,465 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:03,509 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:03,521 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:03,533 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> 2024-07-31 08:14:03,540 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  141.689278] dcn_ka[1390]:  WaitForActive <NL> [  148.479717] dcn_dns_controller[1388]:  WaitForActive <NL> 2024-07-31 08:14:47,825 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 43 seconds <NL> 2024-07-31 08:14:48,054 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 44 seconds <NL> 2024-07-31 08:14:52,147 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:52,754 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> 2024-07-31 08:14:53,155 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  169.079185] ntputils[1724]: int ntputils_main(int, char**)Starting ntputils <NL> 2024-07-31 08:14:57,365 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  171.217202] ntputils[1724]: Running as a daemon <NL> 2024-07-31 08:15:02,070 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> [  175.368187] ntputils[1724]: shelf role is: MAIN <NL> 2024-07-31 08:15:04,236 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:15:04,575 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  177.569367] ntputils[1724]: slot number is: 0 <NL> 2024-07-31 08:15:06,700 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  180.417414] ntputils[1724]: slot role is: UNKNOWN <NL> [  181.366332] ntputils[1724]: redundancy_mode: UNKNOWN <NL> [  182.188315] ntputils[1724]: Executing on a work blade <NL> 2024-07-31 08:15:10,302 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> [  183.079164] ntputils[1724]: ================================ <NL> 2024-07-31 08:15:12,664 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn <NL> [  185.232569] ntputils[1724]: shelf_role is: MAIN <NL> [  185.811954] ntputils[1724]: redundancy_mode: UNKNOWN <NL> [  186.019384] ntputils[1724]: active_status: active <NL> [  187.351167] ntputils[1724]: ntp_role: act <NL> [  187.351749] ntputils[1724]: ================================ <NL> [  187.352373] ntputils[1724]: NTPUtilsConfig::do_default_config <NL> [  187.353019] ntputils[1724]: shelf_num/is_client: 0 <NL> [  188.292106] ntputils[1724]: server_ip: 0x561ab50dcfc0 <NL> 2024-07-31 08:15:19,161 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> [  191.033197] ntputils[1724]: ip_addr(ilan): 0x561ab50dcf80 <NL> 2024-07-31 08:15:18,987 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  192.361712] ntputils[1724]: ntp_role act <NL> 2024-07-31 08:15:20,426 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn <NL> 2024-07-31 08:15:22,641 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  195.087268] ntputils[1724]: shelf_num aka is_client == 0 <NL> 2024-07-31 08:15:24,116 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  197.061678] ntputils[1724]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  197.216975] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  197.229284] ntputils[1724]: systemctl --no-block stop ntpd <NL> [  197.229790] ntputils[1724]: child pid is 1744 <NL> 2024-07-31 08:15:25,085 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE"}
{"timestamp_utc": "2024-07-31T08:15:38.596Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:15:25,161 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> [  199.065337] standby_filesync[1406]: DipLog_pimpl destructor called <NL> 2024-07-31 08:15:30,537 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:15:31,679 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  204.117346] standby_filesync[1406]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:31,288 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> 2024-07-31 08:15:33,172 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> [  205.949176] standby_filesync[1406]:     ret='Context was terminated <NL> 2024-07-31 08:15:32,586 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> 2024-07-31 08:15:35,167 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> [  208.477282] standby_filesync[1406]: deleting subscriber_ socket <NL> 2024-07-31 08:15:36,507 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  208.553787] standby_filesync[1406]: Exiting verb listener"}
{"timestamp_utc": "2024-07-31T08:15:39.156Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:38 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:39.414Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:14:35,208 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":2} <NL> 2024-07-31 08:14:35,209 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:14:35,355 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:35,402 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:14:35,241 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:14:35,422 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:14:35,641 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:35,641 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:35,642 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:35,691 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:14:35,912 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:14:35,913 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:35,938 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:14:36,080 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:36,081 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:14:36,151 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> REPO_REPL_EVT <NL> 2024-07-31 08:14:36,236 swdllite(agt): ERROR - swdl_agent_repo_repl.replicate[400] error(1): error: missing config <NL> 2024-07-31 08:14:36,272 swdllite(agt): ERROR - swdl_agent_staging.repo_repl_fn[400] non-recoverable error encountered <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> [  148.235963] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  148.236152] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  148.236214] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.059921, delay 0.06223\\n31 Jul 08:14:36 ntpdate[2344]: no server suitable for synchronization found\\n' <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:14:38,390 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:14:38,390 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:14:38,390 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  151.364855] python3[2205]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  151.457434] python3[2205]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  151.457552] python3[2205]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  151.457612] python3[2205]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  151.457670] python3[2205]: max_slotNumber=5 <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:14:44,544 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:14:44,560 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  160.218418] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  160.223583] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:15:39.415Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  160.251069] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.071113, delay 0.02763\\n31 Jul 08:14:48 ntpdate[2499]: no server suitable for synchronization found\\n' <NL> [  160.776036] python3[2497]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  160.776424] python3[2497]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  160.776494] python3[2497]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  160.776551] python3[2497]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  160.776607] python3[2497]: max_slotNumber=5 <NL> [  160.776662] python3[2497]:  prov channel is 127.0.0.1:10000 <NL> [  160.776724] python3[2497]: success: command executed <NL> [  160.976496] layer1_hal[2087]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  161.011901] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2404 <NL> [  172.225971] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  172.265807] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  172.265887] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.075901, delay 0.04982\\n31 Jul 08:15:00 ntpdate[2545]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  184.493010] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  184.493209] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  184.493310] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.075191, delay 0.03882\\n31 Jul 08:15:13 ntpdate[2610]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:15:22,715 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  197.184914] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  197.185116] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  197.185177] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.072247, delay 0.04108\\n31 Jul 08:15:25 ntpdate[2641]: no server suitable for synchronization found\\n' <NL> [  210.234471] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  210.234969] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:15:39.670Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:39 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:40.598Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  197.184403] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  197.184462] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  197.471899] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 5 <NL> [  197.940092] ntputils[1963]: push_local_changes OK <NL> [  198.203939] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  198.424198] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  198.424340] ntputils[1963]: child pid is 3009 <NL> [  198.891875] layer1_control_layer[2411]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  198.893452] dcn_dns_controller[1592]: subscribe_data Enter main loop <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  199.437659] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  199.560795] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  199.572945] ntputils[1963]: exited, status is 0 <NL> [  199.657739] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  199.657802] ntputils[1963]: poller time change delta is: 1 <NL> [  199.657850] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  199.657898] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  200.492702] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 6 <NL> [  201.920949] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  202.054082] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  202.121337] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:15:40.599Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  202.121497] python3[2405]: [.071] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  202.248514] ntputils[1963]: push_local_changes OK <NL> [  203.302308] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 7 <NL> [  203.318943] confd_mgr[2874]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  203.331578] confd_mgr[2874]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  203.332438] confd_mgr[3063]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:15:27 UTC 2024 <NL> [  204.019380] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  204.402787] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  204.592234] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  204.620902] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  204.621530] ntputils[1963]: child pid is 3072 <NL> [  204.621658] ntputils[1963]: exited, status is 0 <NL> [  204.621718] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  204.621869] ntputils[1963]: poller time change delta is: 4 <NL> [  204.621937] ntputils[1963]: push_local_changes user_changed: 0 delta: 4 <NL> [  205.005813] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  206.218886] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  206.219074] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  206.219138] ntputils[1963]: push_local_changes OK <NL> [  206.219239] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  206.219326] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  206.550726] txid_tracker[2790]: ::::create_confd_subscription_connection() try number 8 <NL> [  206.551852] ntputils[1963]: child pid is 3105 <NL> [  206.610723] ntputils[1963]: exited, status is 0 <NL> [  206.670812] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  206.670882] ntputils[1963]: poller time change delta is: 2 <NL> [  206.670955] ntputils[1963]: push_local_changes user_changed: 0 delta: 2 <NL> [  206.671029] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  206.671084] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  207.363564] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  207.363682] ntputils[1963]: push_local_changes OK <NL> [  207.611610] confd_mgr[3134]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  207.994579] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  207.994725] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  207.994790] ntputils[1963]: child pid is 3149 <NL> [  207.994847] ntputils[1963]: exited, status is 0 <NL> [  207.994904] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  207.994974] ntputils[1963]: poller time change delta is: 1 <NL> [  207.995048] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  207.995106] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  208.265423] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  208.265534] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  208.454267] ntputils[1963]: push_local_changes OK <NL> [  208.667970] confd_mgr[3063]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  208.861635] confd_mgr[3169]: /usr/bin/ui_sys_reset.py NONE <NL> [  209.379543] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  209.379660] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  210.810445] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  210.811799] python3[2405]: [.107] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  211.170763] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 1 <NL> [  213.344581] confd_mgr[3212]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  213.344746] confd_mgr[3212]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  213.392318] confd_mgr[3213]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  213.392476] confd_mgr[3213]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  213.392826] confd_mgr[3214]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  213.392942] confd_mgr[3214]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  213.511564] confd_mgr[3170]: DDS Peristency is enabled <NL> [  213.511785] confd_mgr[3170]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  213.511884] confd_mgr[3170]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  213.511948] confd_mgr[3170]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  213.512037] confd_mgr[3170]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  214.118859] confd_mgr[3169]: /usr/bin/dbrestore_no.py <NL> [  214.119170] confd_mgr[3216]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  214.120752] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 2 <NL> [  214.265753] confd_mgr[2874]: main::/run/rdm_status.sh found. Invoking it. <NL> [  214.304520] confd_mgr[2874]: entering: wait_for_alarm_event <NL> [  214.304690] confd_mgr[2874]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  214.304755] confd_mgr[2874]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  214.411209] confd_mgr[2874]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  214.411332] confd_mgr[2874]: ha_sm : wait_for_SWDL_s timer is set <NL> [  214.411392] confd_mgr[2874]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  214.411450] confd_mgr[2874]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  214.411508] confd_mgr[2874]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  214.411576] confd_mgr[2874]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  214.411638] confd_mgr[2874]: entering: at_sm::wait_for_SWDL <NL> [  214.422722] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:15:43.111Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  189.585958] python3[2556]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  189.697982] python3[2556]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  189.698831] python3[2556]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  189.699414] python3[2556]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  189.700073] python3[2556]: max_slotNumber=5 <NL> [  190.078148] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  190.134970] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  191.346703] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 2 <NL> Exception: Connect failed <NL> 2024-07-31 08:15:28,278 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:15:29,201 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  201.574040] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 3 <NL> [  202.679706] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 4 <NL> [  202.696414] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:29,034 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:15:29,553 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  202.778711] ntputils[1958]: /sbin/hwclock -u --systohc <NL> [  203.075040] ntputils[1958]: child pid is 2860 <NL> [  203.075168] ntputils[1958]: exited, status is 0 <NL> [  203.075235] ntputils[1958]: poller time change reason is: local_pub_str.ntp_drift <NL> [  203.075294] ntputils[1958]: poller time change delta is: 1 <NL> [  203.511298] ntputils[1958]: push_local_changes user_changed: 0 delta: 1 <NL> [  203.511415] ntputils[1958]: local_push OK u Platform::Time changedByUser 0 <NL> [  203.511476] ntputils[1958]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  203.511550] ntputils[1958]: local_push OK w Platform::Time 0 0 <NL> [  203.511609] ntputils[1958]: push_local_changes OK <NL> [  203.511682] ntputils[1958]: bool NTPServer::handle_command(const string&) <NL> [  203.511747] ntputils[1958]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  203.511800] ntputils[1958]: got Platform::RedundancyMode: WORK <NL> [  203.511856] ntputils[1958]: got Platform::RedundancyStatus: STANDALONE <NL> [  203.511908] ntputils[1958]: my current red mode is: UNKNOWN <NL> [  203.511960] ntputils[1958]: new red mode is: WORK <NL> [  203.512039] ntputils[1958]: my current red status is: STANDALONE <NL> [  203.512097] ntputils[1958]: new red status is: STANDALONE <NL> [  203.534584] ntputils[1958]: red mode change, update: UNKNOWN => WORK <NL> [  203.534675] ntputils[1958]: no active/not-active status change: 0 <NL> [  205.043830] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  205.043967] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  205.502504] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  205.502622] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE"}
{"timestamp_utc": "2024-07-31T08:15:43.112Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> [  205.936593] dcn_dns_controller[1599]: dnsClientStartup() <NL> [  205.968416] dcn_dns_controller[1599]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  206.001301] dcn_dns_controller[1599]: fin_dnsmasq_conf is open <NL> /run/rdm_status.sh created successfully <NL> [  206.257859] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  206.258399] python3[2409]: [.347] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  206.267666] dcn_ka[1601]: KaSessMgr Process Startup <NL> [  206.312559] ntp_oper_data.py[1959]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  206.312648] ntp_oper_data.py[1959]: INFO:root:redundancy status now set to standalone <NL> [  206.312706] ntp_oper_data.py[1959]: INFO:root:Received redundancy topic <NL> [  206.312768] ntp_oper_data.py[1959]: INFO:root:Redundancy status is standalone <NL> [  206.313267] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 5 <NL> [  206.313334] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 6 <NL> [  206.314639] confd_mgr[2866]: ConfdMgrConf: DB signature is NOT supported <NL> [  206.314752] confd_mgr[2866]: Read reset type failed basic_ios::clear: iostream error <NL> [  206.314907] confd_mgr[2866]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  206.320660] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  206.320791] ntputils[1958]: /sbin/hwclock -u --systohc <NL> [  206.320857] ntputils[1958]: child pid is 2933 <NL> [  206.320916] ntputils[1958]: exited, status is 0 <NL> [  206.320973] ntputils[1958]: poller time change reason is: local_pub_str.ntp_drift <NL> [  206.321177] ntputils[1958]: poller time change delta is: 1 <NL> [  206.321237] ntputils[1958]: push_local_changes user_changed: 0 delta: 1 <NL> [  206.321294] ntputils[1958]: local_push OK u Platform::Time changedByUser 0 <NL> [  206.321350] ntputils[1958]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  206.321406] ntputils[1958]: local_push OK w Platform::Time 0 0 <NL> [  206.321466] ntputils[1958]: push_local_changes OK <NL> [  206.322947] startup_finished.py[2301]: Startup Finished: systemd state is non-Production mode and running <NL> [  206.323050] startup_finished.py[2301]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  207.365608] startup_finished.py[2301]: *****Startup Finished: stopping EOW timer***** <NL> [  208.161920] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 7 <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  208.478274] startup_finished.py[2301]: systemctl stop startup_finished_limit.timer <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  208.676852] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  209.775537] dcn_dns_controller[1599]: subscribe_data Enter main loop <NL> [  209.809796] python3[2409]: [.494] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  210.440309] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  210.440572] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  211.697564] txid_tracker[2765]: ::::create_confd_subscription_connection() try number 8 <NL> [  214.910781] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  214.979033] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:15:44.036Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:44 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:44.968Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:44 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:49.129Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:49 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:49.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:49.944Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:49 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:50.199Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:15:50 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:52.710Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:52 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:52.966Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  214.493856] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  214.667094] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  214.693169] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  214.693253] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  214.693314] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  214.693375] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  214.693434] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  214.708035] confd_mgr[2874]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  214.778562] confd_mgr[2874]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  217.166588] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 3 <NL> [  219.441994] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  219.442189] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  220.320644] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 4 <NL> [  220.766084] confd_mgr[3235]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'NONE', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  220.791214] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  221.521340] python3[2405]: [.238] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  221.685741] confd_mgr[2874]: ConfdMgrConf::reload: DB signature set to false <NL> [  221.870626] confd_mgr[2874]: is_swdl_alarm_0 <NL> [  222.309830] confd_mgr[2874]: sdb_restore_= 0 <NL> [  222.309910] confd_mgr[2874]: swdl_alarm_ = NONE <NL> [  222.309973] confd_mgr[2874]: swdl_alarm_tag_ = <NL> [  222.310069] confd_mgr[2874]: swdl status = SUCCESS <NL> [  222.358498] confd_mgr[2874]: is_swdl_in_swupgrade = 0 <NL> [  222.647965] confd_mgr[2874]: is_swdl_alarm_0 <NL> [  222.648065] confd_mgr[2874]: sdb_restore_= 0 <NL> [  222.648139] confd_mgr[2874]: swdl_alarm_ = NONE <NL> [  222.648205] confd_mgr[2874]: swdl_alarm_tag_ = <NL> [  222.986934] confd_mgr[2874]: swdl status = SUCCESS <NL> [  223.037260] confd_mgr[2874]: is_swdl_in_swupgrade = 0 <NL> [  223.037474] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  223.037542] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  223.037604] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  223.037759] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  223.037832] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  223.037893] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  223.037953] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  223.038023] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  223.038139] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  223.038203] confd_mgr[2874]: is_swdl_alarm_0 <NL> [  223.038258] confd_mgr[2874]: sdb_restore_= 0 <NL> [  223.038311] confd_mgr[2874]: swdl_alarm_ = NONE <NL> [  223.038610] confd_mgr[2874]: swdl_alarm_tag_ = <NL> [  223.038739] confd_mgr[2874]: swdl status = SUCCESS <NL> [  223.038802] confd_mgr[2874]: is_swdl_in_swupgrade = 0 <NL> [  223.038858] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  223.038917] confd_mgr[2874]: is_swdl_alarm_0 <NL> [  223.038971] confd_mgr[2874]: sdb_restore_= 0 <NL> [  223.039036] confd_mgr[2874]: swdl_alarm_ = NONE <NL> [  223.039091] confd_mgr[2874]: swdl_alarm_tag_ = <NL> [  223.039199] confd_mgr[2874]: swdl status = SUCCESS <NL> [  223.039259] confd_mgr[2874]: is_swdl_in_swupgrade = 0 <NL> [  223.039324] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  223.039494] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  223.039570] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  223.266759] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  223.267602] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  223.560987] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  223.583185] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  223.775661] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  223.900108] confd_mgr[2874]: ConfdMgrConf::reload: DB signature set to false <NL> [  224.204528] confd_mgr[2874]: confd_db_init::sConfd_db_init_executed_=false <NL> [  224.230119] confd_mgr[2874]: ConfdMgrConf::reload: DB signature set to false <NL> [  224.733308] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 5 <NL> [  224.749749] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  225.137368] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:15:50,960 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> 2024-07-31 08:15:51,088 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  225.886190] layer1_control_layer[2411]: DIP entity prov dump <NL> [  226.324886] layer1_control_layer[2411]: EsalConfig::EsalConfig main 1 <NL> [  226.325131] layer1_control_layer[2411]: EsalConfig::EsalConfig trib 0 <NL> [  226.325223] layer1_control_layer[2411]: EsalConfig::EsalConfig ciRole 0 <NL> [  226.472180] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 6 <NL> [  226.473037] layer1_control_layer[2411]: EsalConfig is not running inside container. <NL> [  226.473132] layer1_control_layer[2411]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  226.473190] layer1_control_layer[2411]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  226.473245] layer1_control_layer[2411]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:15:52.967Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  226.473426] layer1_control_layer[2411]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  226.473511] layer1_control_layer[2411]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  226.473613] layer1_control_layer[2411]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  226.473897] layer1_control_layer[2411]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  226.473988] layer1_control_layer[2411]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  226.474080] layer1_control_layer[2411]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  226.474137] layer1_control_layer[2411]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  226.474194] layer1_control_layer[2411]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  226.474267] layer1_control_layer[2411]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  226.496552] layer1_control_layer[2411]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  226.611566] layer1_control_layer[2411]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  226.611641] layer1_control_layer[2411]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  226.611873] layer1_control_layer[2411]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf"}
{"timestamp_utc": "2024-07-31T08:15:54.328Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:54 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:54.887Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:55.142Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:54 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:57.652Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:58.213Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:15:33,945 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:34,097 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  208.522278] ops-redundancy-mgr[1405]: Exiting verb listener <NL> 2024-07-31 08:15:34,908 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:35,645 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:35,869 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> 2024-07-31 08:15:36,072 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:36,687 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  211.757846] ntputils[1805]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:15:37,898 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  212.142511] rdm[1734]: RdmConfig: file_exist 0 <NL> [  212.189333] rdm[1734]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> 2024-07-31 08:15:38,128 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  212.494723] rdm[1734]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  212.563048] rdm[1734]: start rdm msg hdlr thd <NL> [  212.658759] ntputils[1728]: exited, status is 0 <NL> [  212.713908] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  212.805415] ntputils[1728]: /bin/systemctl reset-failed ntpd <NL> [  212.917884] ntputils[1728]: child pid is 1830 <NL> [  212.918380] ntputils[1728]: exited, status is 0 <NL> [  212.918836] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  212.919470] ntputils[1728]: systemctl --no-block start ntpd <NL> [  213.115791] ntputils[1728]: child pid is 1832 <NL> [  213.413144] ntputils[1728]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:15:58.214Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  213.515037] ntputils[1728]: server role, server_ip is set to: 127.0.0.1 <NL> [  213.582666] ntputils[1728]: Running in production mode <NL> [  213.642237] ntputils[1728]: InitDaemon redundancy_mode: UNKNOWN <NL> [  213.666514] ntputils[1728]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  213.697133] ntputils[1728]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  213.703654] ntputils[1728]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  213.713269] ntputils[1728]: registration socket.send OK <NL> [  213.984228] ntputils[1728]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  214.146389] ntputils[1728]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  214.222321] ntputils[1728]:  topic reg for: <NL> [  214.344742] ntputils[1728]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  214.455461] ntputils[1728]: registration socket.send OK <NL> [  214.662610] ntputils[1728]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  214.663799] ntputils[1728]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  214.664961] ntputils[1728]:  topic reg for: <NL> [  214.771157] ntputils[1728]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  214.772523] ntputils[1728]: registration socket.send OK <NL> [  214.798543] ntputils[1728]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  214.820934] ntputils[1728]: void NTPServer::check_ntp_enabled() <NL> [  214.920543] ntputils[1728]: check_ntp_enabled not empty <NL> [  214.921279] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  214.921809] ntputils[1728]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  214.922524] ntputils[1728]: child pid is 1923 <NL> [  215.104799] ntputils[1728]: exited, status is 0 <NL> [  215.456288] ntputils[1728]: check_ntp_enabled skip system script_start <NL> [  215.794271] ntputils[1728]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  216.000257] ntputils[1728]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  216.346388] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  216.966210] ntputils[1728]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  217.042267] ntputils[1728]: child pid is 1940 <NL> [  217.101599] ntputils[1728]: exited, status is 0 <NL> [  217.157387] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  217.399307] ntputils[1728]: systemctl --no-block stop ntpd <NL> [  217.671935] ntputils[1728]: child pid is 1954 <NL> [  218.987945] ntputils[1728]: exited, status is 0 <NL> [  218.988511] ntputils[1728]: call delete_all_external_servers <NL> [  218.989055] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  219.249259] ntputils[1728]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  219.612150] ntputils[1728]: child pid is 1960 <NL> [  220.622276] ntp_oper_data.py[1729]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  220.623509] ntp_oper_data.py[1729]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  221.642037] ntp_oper_data.py[1729]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> 2024-07-31 08:15:48,623 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> [  222.861955] ntp_oper_data.py[1729]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> 2024-07-31 08:15:49,075 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> [  223.872324] ntp_oper_data.py[1729]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> 2024-07-31 08:15:50,475 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  225.287957] ntp_oper_data.py[1729]: INFO:root:redundancy status now set to standalone <NL> [  226.157068] ntp_oper_data.py[1729]: INFO:root:Received redundancy topic <NL> [  226.157701] ntp_oper_data.py[1729]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:15:51,928 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> [  226.377552] ntputils[1960]: remove_all_ext_src <NL> 2024-07-31 08:15:52,471 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  226.979993] ntputils[1960]: delete:"}
{"timestamp_utc": "2024-07-31T08:15:58.215Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:15:53,083 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  228.081177] ntputils[1728]: exited, status is 0 <NL> [  229.192375] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:55,079 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:15:55,204 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:55,303 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  229.678190] ntputils[1728]: /bin/systemctl reset-failed ntpd <NL> 2024-07-31 08:15:56,229 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:56,543 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:57,066 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  231.327607] ntputils[1728]: child pid is 1962 <NL> [  231.548634] ntputils[1728]: exited, status is 0 <NL> 2024-07-31 08:15:57,238 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662"}
{"timestamp_utc": "2024-07-31T08:15:59.140Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:59.396Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:59 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:00.321Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:00 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:03.591Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  216.625297] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 1 <NL> 2024-07-31 08:15:45,038 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  218.517188] confd_mgr[2866]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  218.670022] confd_mgr[2866]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  218.721595] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  218.721802] python3[2409]: [.507] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  219.208052] confd_mgr[3116]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:15:45 UTC 2024 <NL> [  219.316740] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 2 <NL> [  220.341435] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  220.409087] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  221.485089] confd_mgr[3148]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  221.638608] confd_mgr[3116]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  221.842637] confd_mgr[3161]: /usr/bin/ui_sys_reset.py NONE <NL> [  222.204039] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 3 <NL> [  224.915604] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  224.915770] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  225.239845] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 4 <NL> [  228.294540] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 5 <NL> [  228.974044] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  229.099134] python3[2409]: [.651] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  229.925980] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  229.926152] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:15:57,677 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  230.946931] confd_mgr[3259]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  231.267274] confd_mgr[3259]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  231.267508] confd_mgr[3261]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  231.267564] confd_mgr[3261]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  231.689827] layer1_control_layer[2410]: DIP entity prov dump <NL> [  231.690094] confd_mgr[3262]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  231.690189] confd_mgr[3262]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  231.690666] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 6 <NL> [  231.926933] layer1_control_layer[2410]: EsalConfig::EsalConfig main 1 <NL> [  231.927167] layer1_control_layer[2410]: EsalConfig::EsalConfig trib 0 <NL> [  231.927254] layer1_control_layer[2410]: EsalConfig::EsalConfig ciRole 0 <NL> [  232.047275] layer1_control_layer[2410]: EsalConfig is not running inside container. <NL> [  232.095224] confd_mgr[3177]: DDS Peristency is enabled <NL> [  232.095458] confd_mgr[3177]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  232.095538] confd_mgr[3177]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  232.096264] confd_mgr[3177]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  232.096338] confd_mgr[3177]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  232.096492] layer1_control_layer[2410]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  232.104830] layer1_control_layer[2410]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  232.146854] layer1_control_layer[2410]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  232.146987] layer1_control_layer[2410]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:16:03.592Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  232.147058] layer1_control_layer[2410]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  232.147152] layer1_control_layer[2410]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  232.147211] layer1_control_layer[2410]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  232.147265] layer1_control_layer[2410]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  232.147328] layer1_control_layer[2410]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  232.147380] layer1_control_layer[2410]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  232.147433] layer1_control_layer[2410]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  232.147486] layer1_control_layer[2410]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  232.147574] layer1_control_layer[2410]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  232.147636] layer1_control_layer[2410]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  232.147956] layer1_control_layer[2410]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  232.148050] layer1_control_layer[2410]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  232.148106] layer1_control_layer[2410]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  233.362041] confd_mgr[3161]: /usr/bin/dbrestore_no.py <NL> [  233.363317] confd_mgr[3291]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  233.625020] confd_mgr[2866]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  233.651682] confd_mgr[2866]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  233.651787] confd_mgr[2866]: ha_sm : wait_for_SWDL_s timer is set <NL> [  233.708780] confd_mgr[2866]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  233.708931] confd_mgr[2866]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  233.802256] confd_mgr[2866]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  233.802421] confd_mgr[2866]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  233.802489] confd_mgr[2866]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  233.802545] confd_mgr[2866]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  233.917276] confd_mgr[2866]: entering: wait_for_alarm_event <NL> [  233.934491] confd_mgr[2866]: entering: at_sm::wait_for_SWDL <NL> [  234.455479] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted <NL> [  234.455646] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  234.455729] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  234.455789] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  234.455848] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  234.455920] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  234.455979] confd_mgr[2866]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  234.456068] confd_mgr[2866]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  234.486719] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 7 <NL> [  235.141478] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:16:04.518Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:05.079Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:04 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:05.335Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:05 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:09.496Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "2024-07-31 08:14:16,368 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:16,478 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:14:16,486 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:14:16,486 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  129.904327] fujitsu-check-ssh-host-key.pl[1996]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  129.973722] fujitsu-check-ssh-host-key.pl[1996]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  129.973963] fujitsu-check-ssh-host-key.pl[1997]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  129.974046] fujitsu-check-ssh-host-key.pl[1997]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  129.999730] fujitsu-check-ssh-host-key.pl[1998]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  130.136782] fujitsu-check-ssh-host-key.pl[1998]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  130.328478] fujitsu-check-ssh-host-key.pl[2003]: useradd: user 'fujitsu' already exists <NL> [  131.094182] fujitsu-check-ssh-host-key.pl[1933]: DDS Peristency is enabled <NL> [  131.094371] fujitsu-check-ssh-host-key.pl[1933]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  131.094447] fujitsu-check-ssh-host-key.pl[1933]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  131.094504] fujitsu-check-ssh-host-key.pl[1933]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  131.094576] fujitsu-check-ssh-host-key.pl[1933]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  131.094640] fujitsu-check-ssh-host-key.pl[1933]: Factory user shell set to /bin/bash <NL> [  131.193043] fujitsu-check-ssh-host-key.pl[1909]: Converting fujitsu user to bash shell... <NL> [  131.216982] fujitsu-check-ssh-host-key.pl[2020]: usermod: no changes <NL> [  131.227719] fujitsu-check-ssh-host-key.pl[1909]: Lock Root account in TRIB... <NL> [  131.230684] fujitsu-check-ssh-host-key.pl[2021]: Running lock on root account... <NL> [  131.269960] fujitsu-check-ssh-host-key.pl[2022]: passwd: password changed. <NL> [  131.298639] fujitsu-check-ssh-host-key.pl[1909]: Trib check done. <NL> [  131.726106] startup[2034]: Startup, World! <NL> [  131.730040] startup[2034]: Cmd arg set to loop 1 <NL> [  132.983876] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  133.057334] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  132.866280] confd_mgr_action_server[2036]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  133.664353] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  133.740612] ntputils_client.py[1761]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  133.740717] ntputils_client.py[1761]: b'31 Jul 08:14:20 ntpdate[1876]: no server suitable for synchronization found\\n' <NL> [  133.742117] sh[2055]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  133.742209] sh[2055]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  134.119025] ains_manager[2031]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  135.259603] startup_finished.py[2030]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  136.088431] zebra[2053]: 2024/07/31 08:14:23 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  136.723468] startup_finished.py[2030]: Startup Finished: systemd state is non-Production mode and running <NL> [  136.723597] startup_finished.py[2030]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  137.600153] startup_finished.py[2030]: *****Startup Finished: stopping EOW timer*****"}
{"timestamp_utc": "2024-07-31T08:16:09.497Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  137.967305] startup_finished.py[2030]: systemctl stop startup_finished_limit.timer <NL> [  145.725946] layer1_control_layer[2046]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  148.665950] ains_manager[2325]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  153.732229] layer1_control_layer[2046]: DIP entity prov dump <NL> [  153.924251] layer1_control_layer[2046]: EsalConfig::EsalConfig main 0 <NL> [  153.940597] layer1_control_layer[2046]: EsalConfig::EsalConfig trib 1 <NL> [  153.947132] layer1_control_layer[2046]: EsalConfig::EsalConfig ciRole 0 <NL> [  154.012536] layer1_control_layer[2046]: EsalConfig is not running inside container. <NL> [  154.013361] layer1_control_layer[2046]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.028701] layer1_control_layer[2046]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.046906] layer1_control_layer[2046]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.052336] layer1_control_layer[2046]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.066481] layer1_control_layer[2046]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  154.099607] layer1_control_layer[2046]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  154.123372] layer1_control_layer[2046]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  154.125663] layer1_control_layer[2046]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  154.142914] layer1_control_layer[2046]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  154.160162] layer1_control_layer[2046]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  154.184209] layer1_control_layer[2046]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  154.194294] layer1_control_layer[2046]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  154.209500] layer1_control_layer[2046]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  154.210358] layer1_control_layer[2046]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  154.211291] layer1_control_layer[2046]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  154.212093] layer1_control_layer[2046]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  154.274760] layer1_control_layer[2046]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  155.798509] python3[2200]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  155.798718] python3[2200]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  155.798816] python3[2200]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  155.798872] python3[2200]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  155.798930] python3[2200]: max_slotNumber=5 <NL> [  166.364924] python3[2437]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  166.365349] python3[2437]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  166.365433] python3[2437]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  166.365628] python3[2437]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  166.365687] python3[2437]: max_slotNumber=5 <NL> [  166.365743] python3[2437]:  prov channel is 127.0.0.1:10000 <NL> [  166.365837] python3[2437]: success: command executed <NL> [  166.710565] layer1_hal[2080]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  166.770871] layer1_control_layer[2046]:    ChalApi Constructor with tid = 2375 <NL> 2024-07-31 08:15:38,893 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=5 <NL> [  217.118481] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  217.148059] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  217.206275] ntputils_client.py[1761]: b'31 Jul 08:15:44 ntpdate[2563]: no server suitable for synchronization found\\n' <NL> [  229.109028] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  229.144770] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  229.198703] ntputils_client.py[1761]: b'31 Jul 08:15:56 ntpdate[2584]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:16:10.056Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:10 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:10.312Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:10 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:10 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> 2024-07-31 08:15:36,863 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:36,897 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:37,068 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  209.112504] ntputils[1724]: exited, status is 0 <NL> [  209.339879] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  209.353298] ntputils[1724]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:37,528 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:37,589 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  209.659701] ntputils[1724]: child pid is 1793 <NL> 2024-07-31 08:15:38,051 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  210.575410] ops-redundancy-mgr[1398]: DipLog_pimpl destructor called <NL> 2024-07-31 08:15:39,099 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  211.153258] ops-redundancy-mgr[1398]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:39,766 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> 2024-07-31 08:15:40,320 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:40,322 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  212.346458] ops-redundancy-mgr[1398]:     ret='Context was terminated <NL> [  212.775599] ops-redundancy-mgr[1398]: deleting subscriber_ socket <NL> 2024-07-31 08:15:41,091 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  213.744583] ops-redundancy-mgr[1398]: Exiting verb listener <NL> [  215.226308] ntputils[1798]: Changing Stratum and adding restrictions <NL> [  215.987456] ntputils[1724]: exited, status is 0 <NL> [  216.599231] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  216.599832] ntputils[1724]: /bin/systemctl reset-failed ntpd <NL> [  216.792429] ntputils[1724]: child pid is 1811 <NL> [  217.701755] ntputils[1724]: exited, status is 0 <NL> [  217.865753] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  218.132467] ntputils[1724]: systemctl --no-block start ntpd <NL> [  218.244217] ntputils[1724]: child pid is 1819 <NL> [  218.352855] ntputils[1724]: exited, status is 0 <NL> [  218.370238] ntputils[1724]: server role, server_ip is set to: 127.0.0.1 <NL> [  218.462323] ntputils[1724]: Running in production mode <NL> [  218.562289] ntputils[1724]: InitDaemon redundancy_mode: UNKNOWN <NL> [  218.595189] ntputils[1724]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  218.647077] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  219.152647] ntputils[1724]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  219.470160] ntputils[1724]: registration socket.send OK <NL> [  220.287567] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  220.433904] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  220.773525] ntputils[1724]:  topic reg for: <NL> [  220.907264] ntputils[1724]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  221.079902] ntputils[1724]: registration socket.send OK <NL> [  221.117564] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  221.349418] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  221.641902] ntputils[1724]:  topic reg for: <NL> [  221.825707] ntputils[1724]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  221.826474] ntputils[1724]: registration socket.send OK <NL> [  221.827037] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  221.880357] ntputils[1724]: void NTPServer::check_ntp_enabled() <NL> [  222.339864] ntputils[1724]: check_ntp_enabled not empty <NL> [  222.579332] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  222.643414] ntputils[1724]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  222.828529] ntputils[1724]: child pid is 1923 <NL> [  222.951234] ntputils[1724]: exited, status is 0 <NL> [  222.951818] ntputils[1724]: check_ntp_enabled skip system script_start <NL> [  222.952456] ntputils[1724]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  222.981699] ntputils[1724]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  223.008584] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  223.180949] ntputils[1724]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  223.213344] ntputils[1724]: child pid is 1960 <NL> [  223.319922] ntputils[1724]: exited, status is 0 <NL> [  223.558655] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  224.364327] ntputils[1724]: systemctl --no-block stop ntpd <NL> [  225.047624] ntputils[1724]: child pid is 1961 <NL> [  225.299880] ntputils[1724]: exited, status is 0 <NL> [  225.339106] ntputils[1724]: call delete_all_external_servers <NL> [  225.564694] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  226.607065] ntputils[1724]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  227.367697] ntputils[1724]: child pid is 1962 <NL> [  227.656687] ntp_oper_data.py[1725]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  227.689760] ntp_oper_data.py[1725]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  228.229294] ntp_oper_data.py[1725]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  229.718786] ntp_oper_data.py[1725]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  230.653863] ntp_oper_data.py[1725]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  231.474846] ntp_oper_data.py[1725]: INFO:root:redundancy status now set to standalone <NL> [  231.509371] ntp_oper_data.py[1725]: INFO:root:Received redundancy topic <NL> [  231.510185] ntp_oper_data.py[1725]: INFO:root:Redundancy status is standalone <NL> [  231.675913] ntputils[1962]: remove_all_ext_src <NL> [  232.662896] ntputils[1962]: delete:"}
{"timestamp_utc": "2024-07-31T08:16:10.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:16:01,266 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:16:02,699 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:16:02,702 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  235.391322] ntputils[1724]: exited, status is 0 <NL> [  235.986096] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:04,160 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> [  236.458846] ntputils[1724]: /bin/systemctl reset-failed ntpd <NL> 2024-07-31 08:16:05,302 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  237.540521] ntputils[1724]: child pid is 1965 <NL> 2024-07-31 08:16:06,047 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:06,100 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  238.764473] ntputils[1724]: exited, status is 0 <NL> [  239.400378] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  239.400936] ntputils[1724]: systemctl --no-block start ntpd <NL> 2024-07-31 08:16:07,501 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  239.577415] ntputils[1724]: child pid is 1966"}
{"timestamp_utc": "2024-07-31T08:16:11.677Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  226.611971] layer1_control_layer[2411]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  227.788854] systemd-journald[360]: Data hash table of /run/log/journal/f8c9085252d349cbaec7cd0908673c96/system.journal has a fill level at 75.0 (13655 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  227.863459] systemd-journald[360]: /run/log/journal/f8c9085252d349cbaec7cd0908673c96/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  229.429522] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  230.184904] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  230.335461] layer1_hal[2448]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  230.500903] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 7 <NL> [  230.501875] python3[3305]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  230.592180] python3[3305]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  230.592277] python3[3305]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  230.592334] python3[3305]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  230.592392] python3[3305]: max_slotNumber=5 <NL> [  230.592456] python3[3305]:  prov channel is 127.0.0.1:10000 <NL> [  230.592524] python3[3305]: success: command executed <NL> [  231.560159] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  231.682028] python3[2405]: [.253] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  232.560835] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 8[  232.869496] systemd-sysv-generator[3412]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  233.628628] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3417 <NL> [  233.684124] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  233.722281] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  233.886091] ntputils[1963]: child pid is 3420 <NL> [  233.886180] ntputils[1963]: exited, status is 0 <NL> [  233.886276] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  233.886340] ntputils[1963]: poller time change delta is: 1 <NL> [  233.886438] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  233.886498] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  234.161599] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  234.564179] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  234.782891] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  234.783034] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  235.074402] healthcheck_agt.py[3433]: /bin/sh: line 1: podman: command not found <NL> [  235.306304] ntputils[1963]: push_local_changes OK <NL> [  235.492982] confd_mgr[3440]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  236.157663] confd_mgr[3308]: build /etc/confd/confd.conf.bank0 NONE <NL> [  236.210038] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  236.210196] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  236.484920] ntputils[1963]: child pid is 3458 <NL> [  236.779125] ntputils[1963]: exited, status is 0 <NL> [  236.779261] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  236.779319] ntputils[1963]: poller time change delta is: 1 <NL> [  236.779374] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  236.779431] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  236.779486] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  236.779599] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  236.779695] confd_mgr[3308]: /etc/confd/default_backup.dbs <NL> [  236.779863] confd_mgr[3308]: Create default DB in bank0 <NL> [  237.030945] ntputils[1963]: push_local_changes OK <NL> [  238.082530] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  238.082704] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  238.083694] ntputils[1963]: child pid is 3486 <NL> [  238.083785] ntputils[1963]: exited, status is 0 <NL> [  238.083867] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  238.083919] ntputils[1963]: poller time change delta is: 1 <NL> [  238.083969] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  238.084031] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  238.084082] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  238.197026] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  238.298887] ntputils[1963]: push_local_changes OK <NL> [  239.724873] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  239.726806] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  241.113928] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  241.189507] python3[2405]: [.398] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  242.020055] tun: Universal TUN/TAP device driver, 1.6 <NL> [  242.369732] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 1 <NL> [  244.784152] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  244.801764] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  245.430481] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 2 <NL> [  245.473172] confd_mgr[2874]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  245.473368] confd_mgr[2874]: confd_db_init::RESET REASON IS NONE <NL> [  245.473610] confd_mgr[2874]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  245.473676] confd_mgr[2874]: ha_sm leaving: wait_for_SWDL_s <NL> [  245.473732] confd_mgr[2874]: ha_sm entering: no_ha_s <NL> [  245.473902] confd_mgr[2874]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  245.474834] confd_mgr[2874]: leaving: at_sm::wait_for_SWDL <NL> [  245.474998] confd_mgr[2874]: entering: at_sm::wait_for_start_bank <NL> [  245.475121] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  245.475289] confd_mgr[2874]: leaving: at_sm::wait_for_start_bank <NL> [  245.480187] confd_mgr[2874]: entering: at_sm_dbready::wait_for_db_status <NL> [  245.481292] confd_mgr[2874]: confd_at_common::check_dbssm: Skipping DB signature check"}
{"timestamp_utc": "2024-07-31T08:16:11.678Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  245.481431] confd_mgr[2874]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  245.524595] confd_mgr[3227]: TRUE <NL> [  245.645071] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  245.645171] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  245.645234] confd_mgr[2874]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  245.720952] confd_mgr[3672]: Executing check_db.sh <NL> [  245.784756] confd_mgr[3672]: check_db.sh: found xml files <NL> [  245.785590] confd_mgr[3672]: 0 <NL> [  245.786906] confd_mgr[2874]: Found no error <NL> [  245.788475] confd_mgr[2874]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  245.789321] confd_mgr[2874]: cur_gdbissue 24-1-1 gdbissue 24-1-1 rc = 1 <NL> [  245.789951] confd_mgr[2874]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  245.790026] confd_mgr[2874]: L1-BLADE is in the list: L1-BLADE <NL> [  245.790395] confd_mgr[2874]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  245.791563] confd_mgr[2874]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  245.791660] confd_mgr[2874]: Start_type: GO_NONE (STANDALONE/WORK)"}
{"timestamp_utc": "2024-07-31T08:16:12.238Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:12 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:14.755Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:15:57,319 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  231.577076] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:57,406 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  231.830800] ntputils[1728]: systemctl --no-block start ntpd <NL> [  231.847754] ntputils[1728]: child pid is 1963 <NL> [  231.848401] ntputils[1728]: exited, status is 0 <NL> [  231.849057] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  231.868943] ntputils[1728]: /bin/systemctl reset-failed init_state_check.timer <NL> [  231.939224] ntputils[1728]: child pid is 1965 <NL> [  231.939995] ntputils[1728]: exited, status is 0 <NL> [  231.957219] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  231.958391] ntputils[1728]: /bin/systemctl --no-block start init_state_check.timer <NL> [  231.959337] ntputils[1728]: child pid is 1967 <NL> [  231.959907] ntputils[1728]: exited, status is 0 <NL> [  232.113555] ntputils[1728]: server.InitDaemon <NL> [  232.114703] ntputils[1728]: int NTPServer::platformdds_listen() <NL> [  232.176186] ntputils[1728]: void NTPServer::poller() <NL> [  232.176735] ntputils[1728]: void NTPServer::late_joiner() <NL> [  232.177378] ntputils[1728]: bool NTPServer::handle_command(const string&) <NL> [  232.178056] ntputils[1728]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  232.474772] ntputils[1728]: got Platform::RedundancyMode: UNKNOWN <NL> [  232.526944] ntputils[1728]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:15:58,516 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:58,516 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  232.833547] ntputils[1728]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:15:58,899 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:59,208 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  233.680523] ntputils[1728]: new red mode is: UNKNOWN <NL> [  233.768949] ntputils[1728]: my current red status is: active <NL> [  233.769903] ntputils[1728]: new red status is: STANDALONE <NL> [  233.772170] ntputils[1728]: received unknown! <NL> 2024-07-31 08:15:59,599 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:59,602 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  233.775310] ntputils[1728]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:00,012 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:16:00,853 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> [  235.255281] ntputils[1728]: new red status is: STANDALONE <NL> 2024-07-31 08:16:01,522 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:02,274 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> [  236.670680] ntputils[1728]: red status change, update active => STANDALONE <NL> 2024-07-31 08:16:02,844 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:16:03,273 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  237.732688] ntputils[1728]: no active/not-active status change: 0 <NL> 2024-07-31 08:16:03,884 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:16:04,786 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  239.140467] ntputils[1728]: bool NTPServer::handle_command(const string&) <NL> 2024-07-31 08:16:05,389 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> [  239.676536] ntputils[1728]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:16:05,966 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> 2024-07-31 08:16:06,142 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  240.657027] ntputils[1728]: got Platform::RedundancyMode: UNKNOWN <NL> 2024-07-31 08:16:07,368 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:16:07,655 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  242.435704] ntputils[1728]: got Platform::RedundancyStatus: STANDALONE <NL> [  242.826981] ntputils[1728]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:16:08,655 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:16:08,883 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:16:08,683 swdllite(mgr): INFO - swdl_state_confdmgr.confdmgr_notify_wait_fn[81] mgr_confdmgr_state: confdmgr notification suppressed, OrderedDict([('mode', 'NORMAL'), ('status', 'SUCCESS'), ('rdm-status', 'STANDALONE')]) <NL> [  242.919725] ntputils[1728]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:09,399 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:09,688 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  243.983339] ntputils[1728]: my current red status is: STANDALONE <NL> 2024-07-31 08:16:10,054 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  245.049879] ntputils[1728]: new red status is: STANDALONE <NL> 2024-07-31 08:16:10,935 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  245.297211] ntputils[1728]: received unknown! <NL> 2024-07-31 08:16:11,127 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:11,263 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:11,265 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:16:11,351 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0"}
{"timestamp_utc": "2024-07-31T08:16:14.756Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:16:11,707 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> [  245.905584] ntputils[1728]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:11,922 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:12,202 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  246.460520] ntputils[1728]: new red status is: STANDALONE <NL> 2024-07-31 08:16:12,469 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  246.854622] ntputils[1728]: no active/not-active status change: 0 <NL> 2024-07-31 08:16:12,775 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:13,064 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:16:15.510Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:15 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:15 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:17.220Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:20.500Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:20 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:20 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:25.797Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:25 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:25 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:26.356Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  235.330025] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  237.476317] txid_tracker[3077]: ::::create_confd_subscription_connection() try number 8"}
{"timestamp_utc": "2024-07-31T08:16:26.357Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  239.040484] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  239.419352] python3[2409]: [.785] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  241.096047] systemd-journald[359]: Data hash table of /run/log/journal/0e8d7ca0912d45e69819aeb1822a793f/system.journal has a fill level at 75.0 (13655 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  241.285008] systemd-journald[359]: /run/log/journal/0e8d7ca0912d45e69819aeb1822a793f/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  240.209354] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  240.353999] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  240.418958] healthcheck_agt.py[3358]: /bin/sh: line 1: podman: command not found <NL> [  242.275206] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 1 <NL> [  243.588847] python3[3325]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  243.589070] python3[3325]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  243.589164] python3[3325]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  243.589213] python3[3325]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  243.589264] python3[3325]: max_slotNumber=5 <NL> [  243.589313] python3[3325]:  prov channel is 127.0.0.1:10000 <NL> [  243.589388] python3[3325]: success: command executed <NL> [  243.830111] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3352 <NL> [  243.830299] layer1_hal[2451]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  244.190764] confd_mgr[3310]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'NONE', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  245.519518] systemd-sysv-generator[3405]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  245.115275] confd_mgr[2866]: ConfdMgrConf::reload: DB signature set to false <NL> [  245.124640] confd_mgr[2866]: is_swdl_alarm_0 <NL> [  245.124825] confd_mgr[2866]: sdb_restore_= 0 <NL> [  245.124888] confd_mgr[2866]: swdl_alarm_ = NONE <NL> [  245.124956] confd_mgr[2866]: swdl_alarm_tag_ = <NL> [  245.125043] confd_mgr[2866]: swdl status = SUCCESS <NL> [  245.125113] confd_mgr[2866]: is_swdl_in_swupgrade = 0 <NL> [  245.125208] confd_mgr[2866]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  245.125264] confd_mgr[2866]: is_swdl_alarm_0 <NL> [  245.125315] confd_mgr[2866]: sdb_restore_= 0 <NL> [  245.125368] confd_mgr[2866]: swdl_alarm_ = NONE <NL> [  245.125425] confd_mgr[2866]: swdl_alarm_tag_ = <NL> [  245.125490] confd_mgr[2866]: swdl status = SUCCESS <NL> [  245.125561] confd_mgr[2866]: is_swdl_in_swupgrade = 0 <NL> [  245.125944] confd_mgr[3308]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  245.126065] confd_mgr[2866]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  245.198127] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  245.198301] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  245.198442] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  245.198528] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  245.278995] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 2 <NL> [  245.994911] confd_mgr[2866]: main::/run/rdm_status.sh found. Invoking it. <NL> [  246.236682] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted <NL> [  246.242635] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  246.242773] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  246.242839] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  246.242900] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  246.242958] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  246.243048] confd_mgr[2866]: ConfdMgrConf::reload: DB signature set to false <NL> [  246.243110] confd_mgr[2866]: confd_db_init::sConfd_db_init_executed_=false <NL> [  246.648367] confd_mgr[2866]: ConfdMgrConf::reload: DB signature set to false <NL> [  248.357102] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 3 <NL> [  249.035378] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  249.085957] python3[2409]: [.864] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  250.191432] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  250.320517] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  251.523862] tun: Universal TUN/TAP device driver, 1.6 <NL> [  251.349680] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 4 <NL> [  252.189411] confd_mgr[3451]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  252.297881] confd_mgr[3413]: build /etc/confd/confd.conf.bank0 NONE <NL> [  252.757073] confd_mgr[3413]: /etc/confd/default_backup.dbs <NL> [  252.757199] confd_mgr[3413]: Create default DB in bank0 <NL> [  254.356509] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 5 <NL> [  255.175419] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  255.200990] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  257.368135] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 6 <NL> [  257.964985] confd_mgr[2866]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  257.965161] confd_mgr[2866]: confd_db_init::RESET REASON IS NONE <NL> [  257.965224] confd_mgr[2866]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  257.965292] confd_mgr[2866]: ha_sm leaving: wait_for_SWDL_s <NL> [  257.965349] confd_mgr[2866]: ha_sm entering: no_ha_s <NL> [  258.041746] confd_mgr[2866]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  258.285360] confd_mgr[2866]: leaving: at_sm::wait_for_SWDL <NL> [  258.285558] confd_mgr[2866]: entering: at_sm::wait_for_start_bank <NL> [  258.285631] confd_mgr[2866]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  258.285770] confd_mgr[2866]: leaving: at_sm::wait_for_start_bank <NL> [  258.285830] confd_mgr[2866]: entering: at_sm_dbready::wait_for_db_status <NL> [  258.285891] confd_mgr[2866]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  258.285948] confd_mgr[2866]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  258.286613] confd_mgr[3411]: TRUE <NL> [  258.286778] confd_mgr[2866]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  258.286839] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  258.286898] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  258.287910] confd_mgr[3659]: Executing check_db.sh <NL> [  258.342935] confd_mgr[3659]: check_db.sh: found xml files"}
{"timestamp_utc": "2024-07-31T08:16:30.532Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:30 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:30 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:30 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:32.427Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:32 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:35.879Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:35 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:35 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:37.241Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:40.501Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:40 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:40 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:45.737Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:45.738Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:45 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:45 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:50.975Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:50 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:50 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:50 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:52.338Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:52 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:54.224Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "2024-07-31 08:14:44,469 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:14:44,469 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:14:44,470 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:14:44,470 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> REPO_REPL_EVT <NL> 2024-07-31 08:14:44,471 swdllite(agt): ERROR - swdl_agent_repo_repl.replicate[400] error(1): error: missing config <NL> 2024-07-31 08:14:44,471 swdllite(agt): ERROR - swdl_agent_staging.repo_repl_fn[400] non-recoverable error encountered <NL> [  159.198052] python3[2200]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  159.198231] python3[2200]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  159.198306] python3[2200]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  159.198362] python3[2200]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  159.198417] python3[2200]: max_slotNumber=5 <NL> [  159.442150] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  159.442298] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  159.442360] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.691444, delay 0.40997\\n31 Jul 08:14:44 ntpdate[2349]: no server suitable for synchronization found\\n' <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:14:48,253 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> 2024-07-31 08:14:48,366 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:14:48,393 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:14:54,440 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:14:54,440 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  169.342931] python3[2483]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py"}
{"timestamp_utc": "2024-07-31T08:16:54.225Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  169.356059] python3[2483]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  169.356156] python3[2483]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  169.356354] python3[2483]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  169.356427] python3[2483]: max_slotNumber=5 <NL> [  169.356490] python3[2483]:  prov channel is 127.0.0.1:10000 <NL> [  169.356556] python3[2483]: success: command executed <NL> [  169.523212] layer1_hal[2101]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  169.653279] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2403 <NL> [  171.147730] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  171.148062] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  171.148135] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.535592, delay 0.05194\\n31 Jul 08:14:56 ntpdate[2485]: no server suitable for synchronization found\\n' <NL> [  183.676600] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  183.683401] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  183.685834] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.457936, delay 0.18750\\n31 Jul 08:15:09 ntpdate[2554]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  197.000534] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  197.000760] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  197.000908] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.365973, delay 0.36029\\n31 Jul 08:15:22 ntpdate[2612]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:15:31,598 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  213.324415] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  213.344919] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  213.364865] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.539930, delay 0.04308\\n31 Jul 08:15:38 ntpdate[2644]: no server suitable for synchronization found\\n' <NL> [  225.925805] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  225.925971] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  225.926050] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.530043, delay 0.03444\\n31 Jul 08:15:51 ntpdate[2680]: no server suitable for synchronization found\\n' <NL> [  238.174803] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  238.175116] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  238.175185] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.524495, delay 0.04309\\n31 Jul 08:16:03 ntpdate[2728]: no server suitable for synchronization found\\n' <NL> [  250.378727] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  250.388526] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  250.441782] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.444808, delay 0.20987\\n31 Jul 08:16:15 ntpdate[2767]: no server suitable for synchronization found\\n' <NL> [  262.318108] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  262.371552] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  262.371627] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.530994, delay 0.03110\\n31 Jul 08:16:27 ntpdate[2794]: no server suitable for synchronization found\\n' <NL> [  274.523261] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  274.525184] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  274.525963] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.532809, delay 0.02625\\n31 Jul 08:16:39 ntpdate[2820]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:16:55.587Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:55 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:55 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:57.472Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:00.732Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:00 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:00 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:04.899Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  258.529924] confd_mgr[3659]: 0 <NL> [  258.530068] confd_mgr[2866]: Found no error <NL> [  258.530134] confd_mgr[2866]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  258.530230] confd_mgr[2866]: cur_gdbissue 24-1-1 gdbissue 24-1-1 rc = 1 <NL> [  258.534298] confd_mgr[2866]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  258.611390] confd_mgr[2866]: L1-BLADE is in the list: L1-BLADE <NL> [  258.611482] confd_mgr[2866]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  258.611562] confd_mgr[2866]: guard at_sm_dbready::is_halting_db_alarm_g"}
{"timestamp_utc": "2024-07-31T08:17:04.900Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  258.611640] confd_mgr[2866]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  258.611703] confd_mgr[2866]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  258.611768] confd_mgr[2866]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  258.611833] confd_mgr[2866]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  258.611898] confd_mgr[2866]: guard is_db_okay_g: The HA mode is NONE <NL> [  258.611963] confd_mgr[2866]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  258.612227] confd_mgr[2866]: entering: sm_startconfd::start_confd_p0 <NL> [  258.612361] confd_mgr[2866]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  258.713727] confd_mgr[3665]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:16:25 UTC 2024 <NL> [  258.884477] confd_mgr[2866]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  259.072891] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  259.073036] python3[2409]: [.879] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  260.244827] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  260.244977] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  260.448322] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 7 <NL> [  263.572404] txid_tracker[3379]: ::::create_confd_subscription_connection() try number 8 <NL> [  265.320841] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  265.320961] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  268.337760] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 1 <NL> [  269.270120] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  269.281585] python3[2409]: [.076] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  270.321561] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  270.321733] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  271.384114] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 2 <NL> [  275.105822] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 3 <NL> [  275.348015] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  275.348167] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  278.106311] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 4 <NL> [  279.299094] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  279.299244] python3[2409]: [.105] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  281.238774] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 5 <NL> [  281.379753] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  281.379894] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  281.437543] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  281.437681] ntputils[1958]: /sbin/hwclock -u --systohc <NL> [  281.437765] ntputils[1958]: child pid is 3742 <NL> [  281.795692] ntputils[1958]: exited, status is 0 <NL> [  281.795905] ntputils[1958]: poller time change reason is: local_pub_str.ntp_drift <NL> [  281.795979] ntputils[1958]: poller time change delta is: 1 <NL> [  281.796102] ntputils[1958]: push_local_changes user_changed: 0 delta: 1 <NL> [  281.796165] ntputils[1958]: local_push OK u Platform::Time changedByUser 0 <NL> [  283.331383] ntputils[1958]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  283.495534] ntputils[1958]: local_push OK w Platform::Time 0 0 <NL> [  283.532427] ntputils[1958]: push_local_changes OK <NL> [  284.294628] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 6 <NL> [  284.891687] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  284.893582] ntputils[1958]: /sbin/hwclock -u --systohc <NL> [  284.918244] ntputils[1958]: child pid is 3756 <NL> [  285.028260] ntputils[1958]: exited, status is 0 <NL> [  285.028421] ntputils[1958]: poller time change reason is: local_pub_str.ntp_drift <NL> [  285.028489] ntputils[1958]: poller time change delta is: 2 <NL> [  285.028546] ntputils[1958]: push_local_changes user_changed: 0 delta: 2 <NL> [  285.028601] ntputils[1958]: local_push OK u Platform::Time changedByUser 0 <NL> [  285.931955] ntputils[1958]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  285.932132] ntputils[1958]: local_push OK w Platform::Time 0 0 <NL> [  287.301491] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 7 <NL> [  287.422730] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  287.422898] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  287.515536] ntputils[1958]: push_local_changes OK <NL> [  288.442675] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  288.442839] ntputils[1958]: /sbin/hwclock -u --systohc <NL> [  288.509271] ntputils[1958]: child pid is 3768 <NL> [  288.544763] ntputils[1958]: exited, status is 0 <NL> [  288.544923] ntputils[1958]: poller time change reason is: local_pub_str.ntp_drift <NL> [  288.576673] ntputils[1958]: poller time change delta is: 3 <NL> [  288.576755] ntputils[1958]: push_local_changes user_changed: 0 delta: 3 <NL> [  288.576816] ntputils[1958]: local_push OK u Platform::Time changedByUser 0 <NL> [  288.889760] ntputils[1958]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  289.024760] ntputils[1958]: local_push OK w Platform::Time 0 0 <NL> [  289.067724] ntputils[1958]: push_local_changes OK <NL> [  289.313070] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  289.313234] python3[2409]: [.119] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1! <NL> [  290.314658] txid_tracker[3713]: ::::create_confd_subscription_connection() try number 8 <NL> [  292.435824] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  292.436052] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  294.747653] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 1 <NL> [  297.429362] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:17:05.461Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:05 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:05 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:08.736Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:16:07,938 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:16:08,035 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:16:07,976 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  241.103589] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:16:09,638 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:16:10,796 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  243.038571] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:11,120 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:16:11,290 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:16:11,297 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  243.413550] ntputils[1724]: /bin/systemctl reset-failed init_state_check.timer <NL> 2024-07-31 08:16:11,573 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  244.803109] ntputils[1724]: child pid is 1967 <NL> 2024-07-31 08:16:12,951 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:16:12,975 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> [  245.310321] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:16:13,399 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:16:13,643 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  245.887923] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:14,404 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:14,926 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  247.065759] ntputils[1724]: /bin/systemctl --no-block start init_state_check.timer <NL> 2024-07-31 08:16:15,654 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:16:15,848 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  248.100208] ntputils[1724]: child pid is 1969 <NL> 2024-07-31 08:16:16,286 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:16:16,521 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  248.697978] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:16:17,077 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion #"}
{"timestamp_utc": "2024-07-31T08:17:08.737Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  249.634756] ntputils[1724]: server.InitDaemon <NL> [  249.670204] ntputils[1724]: int NTPServer::platformdds_listen() <NL> 2024-07-31 08:16:17,760 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  249.893936] ntputils[1724]: void NTPServer::poller() <NL> 2024-07-31 08:16:18,099 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:16:18,326 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  250.334897] ntputils[1724]: void NTPServer::late_joiner() <NL> 2024-07-31 08:16:18,684 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> 2024-07-31 08:16:18,875 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  251.170586] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> 2024-07-31 08:16:19,417 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> [  251.490148] ntputils[1724]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:16:19,507 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:16:19,721 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  252.192465] ntputils[1724]: got Platform::RedundancyMode: UNKNOWN <NL> 2024-07-31 08:16:20,626 swdllite(mgr): INFO - swdl_state_confdmgr.confdmgr_notify_wait_fn[81] mgr_confdmgr_state: confdmgr notification suppressed, OrderedDict([('mode', 'NORMAL'), ('status', 'SUCCESS'), ('rdm-status', 'STANDALONE')]) <NL> 2024-07-31 08:16:20,948 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> [  253.916040] ntputils[1724]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:16:25,333 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:16:25,566 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE[  272.752485] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  274.349637] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  261.953238] ntputils[1724]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:16:38,102 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  275.377135] ntputils[1724]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:43,453 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:45,501 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> [  279.370614] ntputils[1724]: my current red status is: active <NL> 2024-07-31 08:16:49,524 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  282.111878] ntputils[1724]: new red status is: STANDALONE <NL> [  283.915298] ntputils[1724]: received unknown! <NL> [  283.915767] ntputils[1724]: new red mode is: UNKNOWN <NL> [  283.916299] ntputils[1724]: new red status is: STANDALONE <NL> [  283.916708] ntputils[1724]: red status change, update active => STANDALONE <NL> 2024-07-31 08:16:51,944 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:52,004 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> [  284.907631] ntputils[1724]: no active/not-active status change: 0 <NL> 2024-07-31 08:16:53,291 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:54,165 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  287.719997] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> [  289.911526] ntputils[1724]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:16:58,058 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  291.347601] ntputils[1724]: got Platform::RedundancyMode: UNKNOWN <NL> 2024-07-31 08:17:00,159 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  293.654763] ntputils[1724]: got Platform::RedundancyStatus: STANDALONE"}
{"timestamp_utc": "2024-07-31T08:17:10.642Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:10 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:10 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:10 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:10.898Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  245.792889] confd_mgr[2874]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  245.793031] confd_mgr[2874]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  245.793096] confd_mgr[2874]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  245.793782] confd_mgr[2874]: guard is_db_okay_g: The HA mode is NONE"}
{"timestamp_utc": "2024-07-31T08:17:10.899Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  245.793999] confd_mgr[2874]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  245.801987] confd_mgr[2874]: entering: sm_startconfd::start_confd_p0 <NL> [  245.804162] confd_mgr[2874]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  245.915672] confd_mgr[3680]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:16:11 UTC 2024 <NL> [  246.193011] confd_mgr[2874]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  248.475575] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 3 <NL> [  249.796260] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  249.796452] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  250.813309] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  250.813516] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  250.813574] ntputils[1963]: child pid is 3727 <NL> [  250.902548] ntputils[1963]: exited, status is 0 <NL> [  250.902697] ntputils[1963]: poller time change reason is: local_pub_str.ntp_drift <NL> [  250.902752] ntputils[1963]: poller time change delta is: 1 <NL> [  250.902803] ntputils[1963]: push_local_changes user_changed: 0 delta: 1 <NL> [  250.902898] ntputils[1963]: local_push OK u Platform::Time changedByUser 0 <NL> [  250.974426] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  251.080927] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  251.130116] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  251.130294] python3[2405]: [.539] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  251.163516] ntputils[1963]: push_local_changes OK <NL> [  251.475890] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 4 <NL> [  254.485238] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 5 <NL> [  254.793395] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  254.793535] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  257.494677] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 6 <NL> [  259.802507] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  259.802975] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  260.498222] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 7 <NL> [  261.521056] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  261.521228] python3[2405]: [.804] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  263.548512] txid_tracker[3548]: ::::create_confd_subscription_connection() try number 8 <NL> [  264.810410] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  264.825076] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  267.748541] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 1 <NL> [  269.810219] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  269.840740] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  270.761994] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 2 <NL> [  271.426165] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  271.426903] python3[2405]: [.828] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1! <NL> [  273.826853] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 3 <NL> [  274.810397] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  274.810551] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  276.817118] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 4 <NL> [  279.804611] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 5 <NL> [  279.851458] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  279.908795] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  281.456876] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  281.465273] python3[2405]: [.852] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1! <NL> [  282.816624] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 6 <NL> [  284.838625] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  284.854159] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  285.826986] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 7 <NL> [  288.840064] txid_tracker[3759]: ::::create_confd_subscription_connection() try number 8 <NL> [  289.843062] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  289.843219] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  291.479019] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  291.513624] python3[2405]: [.874] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  293.340638] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 1 <NL> [  294.852688] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  294.852840] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  296.347545] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 2 <NL> [  299.357067] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 3 <NL> [  299.877217] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  299.949687] confd_phase_sentry[2419]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f022e36d5c7; Failed to connect to ConfD: Connection refused <NL> [  301.469313] python3[2405]: DEBUG Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:17:10.900Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  301.532892] python3[2405]: [.877] hookhdlr 140013762971456 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  302.369392] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 4"}
{"timestamp_utc": "2024-07-31T08:17:12.263Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:12 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:15.525Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:15 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:15 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:17.617Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:20.713Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:20 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:20 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:26.015Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:25 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:25 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:31.340Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:17:30 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:30 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:30 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:31.596Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  120.683324] fujitsu-check-ssh-host-key.pl[1913]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  120.683413] fujitsu-check-ssh-host-key.pl[1913]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  120.698222] fujitsu-check-ssh-host-key.pl[1913]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  120.802823] fujitsu-check-ssh-host-key.pl[1913]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  120.802899] fujitsu-check-ssh-host-key.pl[1913]: Factory user shell set to /bin/bash <NL> [  121.503975] fujitsu-check-ssh-host-key.pl[1899]: Converting fujitsu user to bash shell... <NL> [  121.543362] fujitsu-check-ssh-host-key.pl[2008]: usermod: no changes <NL> [  121.543559] fujitsu-check-ssh-host-key.pl[1899]: Lock Root account in TRIB... <NL> [  121.684444] fujitsu-check-ssh-host-key.pl[2009]: Running lock on root account... <NL> [  121.881538] fujitsu-check-ssh-host-key.pl[2012]: passwd: password changed. <NL> [  121.881689] fujitsu-check-ssh-host-key.pl[1899]: Trib check done. <NL> [  122.293590] startup[2028]: Startup, World! <NL> [  122.300294] startup[2028]: Cmd arg set to loop 1 <NL> [  124.054043] startup_finished.py[2023]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  124.276236] ains_manager[2025]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  125.025429] dhal_sim_startup.sh[2078]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  126.044273] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  126.115526] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  125.962544] confd_mgr_action_server[2073]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  125.962803] sh[2105]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  126.385542] sh[2105]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  129.276568] startup_finished.py[2023]: Startup Finished: systemd state is non-Production mode and running <NL> [  129.276723] startup_finished.py[2023]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  129.799316] zebra[2102]: 2024/07/31 08:14:15 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  130.449052] startup_finished.py[2023]: *****Startup Finished: stopping EOW timer***** <NL> [  131.199659] startup_finished.py[2023]: systemctl stop startup_finished_limit.timer <NL> [  139.614626] ains_manager[2270]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  141.500740] layer1_control_layer[2089]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  146.929249] layer1_control_layer[2089]: DIP entity prov dump <NL> [  147.268234] layer1_control_layer[2089]: EsalConfig::EsalConfig main 0 <NL> [  147.268445] layer1_control_layer[2089]: EsalConfig::EsalConfig trib 1 <NL> [  147.268514] layer1_control_layer[2089]: EsalConfig::EsalConfig ciRole 0 <NL> [  147.340257] layer1_control_layer[2089]: EsalConfig is not running inside container. <NL> [  147.350735] layer1_control_layer[2089]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.350832] layer1_control_layer[2089]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.350926] layer1_control_layer[2089]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.351019] layer1_control_layer[2089]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.351092] layer1_control_layer[2089]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  147.351194] layer1_control_layer[2089]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  147.351256] layer1_control_layer[2089]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  147.351316] layer1_control_layer[2089]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  147.351383] layer1_control_layer[2089]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  147.351506] layer1_control_layer[2089]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  147.351570] layer1_control_layer[2089]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  147.351631] layer1_control_layer[2089]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  147.351698] layer1_control_layer[2089]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  147.351758] layer1_control_layer[2089]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  147.351816] layer1_control_layer[2089]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  147.351886] layer1_control_layer[2089]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf"}
{"timestamp_utc": "2024-07-31T08:17:31.597Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  147.351949] layer1_control_layer[2089]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  149.764216] python3[2198]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  149.764413] python3[2198]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  149.764490] python3[2198]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  149.764555] python3[2198]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  149.764612] python3[2198]: max_slotNumber=5 <NL> [  160.602672] python3[2440]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  160.621390] python3[2440]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  160.621484] python3[2440]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  160.621552] python3[2440]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  160.621612] python3[2440]: max_slotNumber=5 <NL> [  160.621674] python3[2440]:  prov channel is 127.0.0.1:10000 <NL> [  160.628027] python3[2440]: success: command executed <NL> [  161.960374] layer1_hal[2110]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  162.010964] layer1_control_layer[2089]:    ChalApi Constructor with tid = 2386 <NL> 2024-07-31 08:15:42,509 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=6 <NL> [  228.291549] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  228.293592] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  228.293680] ntputils_client.py[1740]: b'31 Jul 08:15:53 ntpdate[2589]: no server suitable for synchronization found\\n' <NL> [  240.762753] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  240.792770] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  240.792898] ntputils_client.py[1740]: b'31 Jul 08:16:06 ntpdate[2615]: no server suitable for synchronization found\\n' <NL> [  252.695598] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  252.695789] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  252.695850] ntputils_client.py[1740]: b'31 Jul 08:16:18 ntpdate[2643]: no server suitable for synchronization found\\n' <NL> [  265.537561] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  265.537818] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  265.537899] ntputils_client.py[1740]: b'31 Jul 08:16:31 ntpdate[2664]: no server suitable for synchronization found\\n' <NL> [  284.660196] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  284.660626] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  284.660698] ntputils_client.py[1740]: b'31 Jul 08:16:50 ntpdate[2706]: no server suitable for synchronization found\\n' <NL> [  298.147022] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  298.147422] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  298.147521] ntputils_client.py[1740]: b'31 Jul 08:17:03 ntpdate[2729]: no server suitable for synchronization found\\n' <NL> [  312.354187] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  312.354585] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  312.354666] ntputils_client.py[1740]: b'31 Jul 08:17:17 ntpdate[2753]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:17:32.521Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:32 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:35.918Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:17:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:35 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:35 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:37.802Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:40.458Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:40 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:40 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:44.665Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  297.442065] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  297.752135] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 2 <NL> [  299.352101] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  299.353021] python3[2409]: [.150] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1! <NL> [  300.762770] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 3 <NL> [  302.456100] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  302.483879] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  303.773817] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 4 <NL> [  306.769559] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 5 <NL> [  307.446153] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  307.446383] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  309.356272] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  309.356465] python3[2409]: [.162] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  309.770401] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 6 <NL> [  312.454786] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  312.455208] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  312.775502] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 7 <NL> [  315.806808] txid_tracker[3784]: ::::create_confd_subscription_connection() try number 8 <NL> [  317.466344] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  317.494832] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  319.423942] python3[2409]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  319.424111] python3[2409]: [.178] hookhdlr 140061943105344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  320.134298] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 1 <NL> [  322.470841] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  322.472456] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  323.111965] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 2 <NL> [  326.124343] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 3 <NL> [  327.478015] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  327.478163] confd_phase_sentry[2422]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f4d721fc5c7; Failed to connect to ConfD: Connection refused <NL> [  329.168289] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 4 <NL> [  329.451079] python3[2409]: DEBUG EOF on socket to ConfD <NL> [  329.451260] python3[2409]: [.246] hookhdlr 140061943105344 callbackhdlr:457 Exception to create daemon <NL> [  329.451334] python3[2409]: Traceback (most recent call last): <NL> [  329.498183] python3[2409]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  329.556244] python3[2409]:     daemon = self.create_daemon() <NL> [  329.556325] python3[2409]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  329.556383] python3[2409]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  329.556439] python3[2409]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  329.556502] python3[2409]:     self._init_connection() <NL> [  329.556558] python3[2409]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  329.556612] python3[2409]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  329.556684] python3[2409]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  329.556739] python3[2409]:     _tm.dp.connect( <NL> [  329.556805] python3[2409]: _confd.error.EOF: ConfD closed connection <NL> [  329.556863] python3[2409]: [.249] hookhdlr 140061943105344 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  331.288141] rasis_system_stats.py[2425]: Traceback (most recent call last): <NL> [  331.288479] rasis_system_stats.py[2425]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  331.288991] rasis_system_stats.py[2425]:     main() <NL> [  331.289109] rasis_system_stats.py[2425]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  331.298795] rasis_system_stats.py[2425]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  331.299044] rasis_system_stats.py[2425]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  331.299480] rasis_system_stats.py[2425]:     self._init_connection() <NL> [  331.299595] rasis_system_stats.py[2425]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  331.299941] rasis_system_stats.py[2425]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  331.300063] rasis_system_stats.py[2425]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  331.307692] rasis_system_stats.py[2425]:     _tm.dp.connect( <NL> [  331.307900] rasis_system_stats.py[2425]: _confd.error.EOF: ConfD closed connection <NL> [  332.186955] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 5 <NL> [  332.479814] confd_phase_sentry[2422]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  332.521996] confd_phase_sentry[2422]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2"}
{"timestamp_utc": "2024-07-31T08:17:44.666Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  335.248143] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 6 <NL> [  335.323173] db_info.py[2384]: Traceback (most recent call last): <NL> [  335.394581] db_info.py[2384]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  335.395308] db_info.py[2384]:     main() <NL> [  335.395707] db_info.py[2384]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  335.396331] db_info.py[2384]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  335.498886] db_info.py[2384]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  335.560470] db_info.py[2384]:     self._init_connection() <NL> [  335.560547] db_info.py[2384]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  335.560601] db_info.py[2384]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  335.560654] db_info.py[2384]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  335.560706] db_info.py[2384]:     _tm.dp.connect( <NL> [  335.560761] db_info.py[2384]: _confd.error.EOF: ConfD closed connection <NL> [  336.462826] healthcheck_result_display.py[2400]: Traceback (most recent call last): <NL> [  336.463036] healthcheck_result_display.py[2400]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  336.463115] healthcheck_result_display.py[2400]:     main(hc_utils.setup_logging(__name__)) <NL> [  336.463179] healthcheck_result_display.py[2400]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  336.463254] healthcheck_result_display.py[2400]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT)"}
{"timestamp_utc": "2024-07-31T08:17:45.593Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:45 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:45 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:50.832Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:17:50 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:50 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:50 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:52.716Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:52 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:55.975Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:17:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:55 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:55 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:56.537Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  304.885242] confd_phase_sentry[2419]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  304.913028] confd_phase_sentry[2419]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  305.504285] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 5 <NL> [  305.974590] db_info.py[2376]: Traceback (most recent call last): <NL> [  305.974868] db_info.py[2376]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  305.975560] db_info.py[2376]:     main() <NL> [  305.975730] db_info.py[2376]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  305.976136] db_info.py[2376]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  305.976298] db_info.py[2376]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  305.976661] db_info.py[2376]:     self._init_connection() <NL> [  305.976789] db_info.py[2376]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  305.977221] db_info.py[2376]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  305.977370] db_info.py[2376]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  306.036330] db_info.py[2376]:     _tm.dp.connect( <NL> [  306.137425] db_info.py[2376]: _confd.error.EOF: ConfD closed connection <NL> [  308.501882] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 6 <NL> [  310.842173] healthcheck_result_display.py[2392]: Traceback (most recent call last): <NL> [  310.842528] healthcheck_result_display.py[2392]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  310.843129] healthcheck_result_display.py[2392]:     main(hc_utils.setup_logging(__name__)) <NL> [  310.843324] healthcheck_result_display.py[2392]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  310.843748] healthcheck_result_display.py[2392]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  310.843902] healthcheck_result_display.py[2392]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  310.844263] healthcheck_result_display.py[2392]:     self._init_connection() <NL> [  310.844436] healthcheck_result_display.py[2392]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  310.868497] healthcheck_result_display.py[2392]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  310.956279] healthcheck_result_display.py[2392]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  310.956432] healthcheck_result_display.py[2392]:     _tm.dp.connect( <NL> [  310.956644] healthcheck_result_display.py[2392]: _confd.error.EOF: ConfD closed connection <NL> [  310.981888] rasis_system_stats.py[2421]: Traceback (most recent call last): <NL> [  311.005370] rasis_system_stats.py[2421]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  311.066601] rasis_system_stats.py[2421]:     main() <NL> [  311.066747] rasis_system_stats.py[2421]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  311.066822] rasis_system_stats.py[2421]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  311.066908] rasis_system_stats.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  311.066976] rasis_system_stats.py[2421]:     self._init_connection() <NL> [  311.067047] rasis_system_stats.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  311.067114] rasis_system_stats.py[2421]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  311.067172] rasis_system_stats.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  311.067230] rasis_system_stats.py[2421]:     _tm.dp.connect( <NL> [  311.067286] rasis_system_stats.py[2421]: _confd.error.EOF: ConfD closed connection <NL> [  311.529286] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 7 <NL> [  311.642822] python3[2405]: DEBUG EOF on socket to ConfD <NL> [  311.643019] python3[2405]: [.000] hookhdlr 140013762971456 callbackhdlr:457 Exception to create daemon <NL> [  311.643081] python3[2405]: Traceback (most recent call last): <NL> [  311.643128] python3[2405]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  311.643177] python3[2405]:     daemon = self.create_daemon() <NL> [  311.643225] python3[2405]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  311.643281] python3[2405]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  311.643329] python3[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  311.643374] python3[2405]:     self._init_connection() <NL> [  311.643418] python3[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  311.643463] python3[2405]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  311.643517] python3[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  311.643569] python3[2405]:     _tm.dp.connect( <NL> [  311.643622] python3[2405]: _confd.error.EOF: ConfD closed connection <NL> [  311.644191] python3[2405]: [.054] hookhdlr 140013762971456 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  314.522240] txid_tracker[3811]: ::::create_confd_subscription_connection() try number 8 <NL> [  319.115086] txid_tracker[3855]: ::::create_confd_subscription_connection() connected <NL> [  321.674176] python3[2405]: [.082] hookhdlr 140013762971456 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  322.097621] python3[2405]: [.466] hookhdlr 140013762971456 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  322.097790] python3[2405]: [.466] hookhdlr 140013762971456 callbackhdlr:293 Loading schemas <NL> [  322.367722] python3[2405]: DEBUG item does not exist - shared memory schema not enabled <NL> [  329.609114] python3[2405]: [.002] hookhdlr 140013762971456 callbackhdlr:382 Done load schemas <NL> [  329.609687] python3[2405]: [.002] hookhdlr 140013762971456 callbackhdlr:389 Done register transaction callback <NL> [  331.179230] python3[2405]: [.578] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  331.264455] python3[2405]: [.673] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb admin-status-hook"}
{"timestamp_utc": "2024-07-31T08:17:56.538Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  331.360214] python3[2405]: [.745] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  331.606790] python3[2405]: [.016] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  332.099478] python3[2405]: [.489] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  332.363865] python3[2405]: [.769] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  332.443470] python3[2405]: [.845] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  332.524588] python3[2405]: [.934] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  333.623871] python3[2405]: [.033] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  333.745050] python3[2405]: [.153] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  333.850403] python3[2405]: [.257] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  333.962995] python3[2405]: [.371] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  338.145846] python3[2405]: [.555] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  341.733517] python3[2405]: [.142] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  344.609732] python3[2405]: [.004] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  347.297332] python3[2405]: [.680] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook"}
{"timestamp_utc": "2024-07-31T08:17:57.461Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:00.721Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:00 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:00 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:05.964Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:05 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:05 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:10.125Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  247.562845] ntp_oper_data.py[1729]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> 2024-07-31 08:16:13,543 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:16:13,608 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> [  247.827978] ntp_oper_data.py[1729]: INFO:root:redundancy status now set to standalone <NL> 2024-07-31 08:16:13,756 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> [  248.001345] ntp_oper_data.py[1729]: INFO:root:Received redundancy topic <NL> 2024-07-31 08:16:14,166 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  248.500671] ntp_oper_data.py[1729]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:16:14,475 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  249.218291] ntputils[1728]: bool NTPServer::handle_command(const string&) <NL> 2024-07-31 08:16:15,207 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  249.535655] ntputils[1728]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:16:15,618 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> [  249.923660] ntputils[1728]: got Platform::RedundancyMode: WORK <NL> 2024-07-31 08:16:15,618 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  250.236826] ntputils[1728]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:16:15,964 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> [  250.646649] ntputils[1728]: my current red mode is: UNKNOWN <NL> [  251.465136] ntputils[1728]: new red mode is: WORK <NL> 2024-07-31 08:16:16,286 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  253.951774] ntputils[1728]: my current red status is: STANDALONE <NL> 2024-07-31 08:16:18,774 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:16:28,425 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM"}
{"timestamp_utc": "2024-07-31T08:18:10.126Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  262.692235] ntputils[1728]: new red status is: STANDALONE[  268.047390] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> 2024-07-31 08:16:33,762 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:16:39,787 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')...[  274.070443] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  273.996749] ntputils[1728]: red mode change, update: UNKNOWN => WORK <NL> [  277.497517] ntputils[1728]: no active/not-active status change: 0 <NL> 2024-07-31 08:16:43,684 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:16:50,129 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  285.887810] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:55,425 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  291.175102] ntputils[1728]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:17:00,516 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  296.368648] ntputils[1728]: child pid is 2155 <NL> [  299.016040] ntputils[1728]: exited, status is 0 <NL> 2024-07-31 08:17:04,908 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  299.604157] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  300.231147] ntputils[1728]: poller time change delta is: 1 <NL> 2024-07-31 08:17:06,543 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  301.229443] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> 2024-07-31 08:17:08,905 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  303.383163] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  304.477533] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> 2024-07-31 08:17:10,401 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:17:11,448 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  306.075898] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:17:14,906 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  311.134825] ntputils[1728]: push_local_changes OK <NL> [  323.751687] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:17:29,151 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  325.114135] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  328.146447] ntputils[1728]: child pid is 2186 <NL> 2024-07-31 08:17:36,035 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  331.197227] ntputils[1728]: exited, status is 0 <NL> [  337.715498] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  338.902238] ntputils[1728]: poller time change delta is: 6 <NL> 2024-07-31 08:17:41,937 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  340.753844] ntputils[1728]: push_local_changes user_changed: 0 delta: 6 <NL> 2024-07-31 08:17:51,899 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  347.455126] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  348.673449] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 6 <NL> 2024-07-31 08:17:54,652 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  351.543711] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:17:58,199 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  353.012697] ntputils[1728]: push_local_changes OK <NL> [  353.869713] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  353.884742] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  353.885308] ntputils[1728]: child pid is 2219 <NL> [  353.896631] ntputils[1728]: exited, status is 0 <NL> [  355.266875] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  355.294081] ntputils[1728]: poller time change delta is: 10 <NL> [  355.294627] ntputils[1728]: push_local_changes user_changed: 0 delta: 10 <NL> [  355.325070] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  355.325670] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 10 <NL> [  355.357578] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  355.890599] ntputils[1728]: push_local_changes OK <NL> [  355.918908] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:18:03,712 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  357.962528] ntputils[1728]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:18:06,724 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  361.767329] ntputils[1728]: child pid is 2226"}
{"timestamp_utc": "2024-07-31T08:18:10.686Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:10 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:10 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:10 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:12.570Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:12 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:15.998Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:15 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:15 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:18.216Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:20.774Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:20 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:20 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:26.087Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:25 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:25 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:31.340Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:30 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:30 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:30 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:32.731Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:32 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:35.997Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:35 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:35 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:37.883Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> [  350.618224] python3[2405]: [.980] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  350.698520] python3[2405]: [.086] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  350.702331] python3[2405]: [.102] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  350.730465] python3[2405]: [.104] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  350.735470] python3[2405]: [.128] hookhdlr 140013762971456 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  350.756320] python3[2405]: [.128] hookhdlr 140013762971456 callbackhdlr:391 Done register data callbacks <NL> [  387.018296] confd_mgr[2874]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  387.046746] confd_mgr[4016]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:18:32 UTC 2024 <NL> [  387.115614] confd_mgr[4016]: Starting valhdlr.service <NL> [  387.444894] confd_mgr[4016]: Starting validation-handler.service <NL> [  387.609473] confd_mgr[4016]: Starting snmp-fss-fw.service <NL> [  387.787378] python3[2405]: DEBUG No crypto keys configured <NL> [  387.837102] python3[2405]: [.226] hookhdlr 140013762971456 callbackhdlr:401 Unable to install crypto keys! <NL> [  387.944298] python3[2405]: [.330] hookhdlr 140013762971456 callbackhdlr:322 Started data handler daemon... <NL> [  388.086038] confd_mgr[2874]: leaving: sm_startconfd::start_confd_p0 <NL> [  388.086185] confd_mgr[2874]: entering: sm_startconfd::wait_for_p0 <NL> [  388.086243] confd_mgr[2874]: PROCESS1 has not registered yet. <NL> [  388.086307] confd_mgr[2874]: PROCESS_SNMP_CLID has not registered yet. <NL> [  388.086364] confd_mgr[2874]: PROCESS_VALHDLR has not registered yet. <NL> [  388.187193] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  388.195268] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  388.202740] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  388.213025] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  388.261779] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  388.263515] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  388.265160] confd_mgr[2874]: ConfdHA Not supported command CONFIRM <NL> [  388.303792] confd_mgr[2874]: sm_startconfd::p0_ready_dbc <NL> [  388.339664] confd_mgr[2874]: Find message MESSAGE1 <NL> [  388.340947] confd_mgr[2874]: PROCESS_SNMP_CLID has not registered yet. <NL> [  388.348547] confd_mgr[2874]: PROCESS_VALHDLR has not registered yet. <NL> [  388.396216] confd_mgr[2874]: sm_startconfd::p0_not_ready <NL> [  388.411367] confd_mgr[2874]: Find message MESSAGE1 <NL> [  388.424597] confd_mgr[2874]: PROCESS_SNMP_CLID has not registered yet. <NL> [  388.425380] confd_mgr[2874]: PROCESS_VALHDLR has not registered yet. <NL> [  388.426056] confd_mgr[2874]: leaving: sm_startconfd::wait_for_p0 <NL> [  388.493287] confd_mgr[2874]: entering: sm_startconfd::wait_for_p0 <NL> [  388.494198] confd_mgr[2874]: PROCESS_SNMP_CLID has not registered yet. <NL> [  388.494898] confd_mgr[2874]: PROCESS_VALHDLR has not registered yet. <NL> [  388.496620] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  388.522638] confd_mgr[2874]: Timer /ConfdAT|wait_for_p0 already created <NL> [  388.533429] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  388.534295] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  390.052075] python3[4026]: [.461] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  390.065448] python3[4026]: [.461] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  390.114446] python3[4026]: [.463] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  390.198839] python3[4026]: [.463] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  390.284860] python3[4026]: [.463] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  390.344173] python3[4026]: [.463] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  390.410729] python3[4026]: [.521] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  390.423906] python3[4026]: [.596] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  390.432309] python3[4026]: [.596] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  390.440510] python3[4026]: [.596] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  390.455627] python3[4026]: [.596] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  390.456755] python3[4026]: [.596] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  390.471191] python3[4026]: [.596] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  390.489976] python3[4026]: [.680] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  390.491051] python3[4026]: [.720] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  390.492102] python3[4026]: [.720] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  390.513296] python3[4026]: [.720] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  390.531034] python3[4026]: [.720] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'}"}
{"timestamp_utc": "2024-07-31T08:18:37.884Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  390.542929] python3[4026]: [.721] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  390.563147] python3[4026]: [.721] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  390.581164] python3[4026]: [.721] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  390.594966] python3[4026]: [.721] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  390.596306] python3[4026]: [.721] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  390.625516] python3[4026]: [.721] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  390.658750] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  390.676543] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  390.685471] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  390.722802] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  390.738473] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  390.749080] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  390.752219] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  390.782042] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  390.784879] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  390.793656] python3[4026]: [.776] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  390.855740] python3[4026]: [.820] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  390.867325] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  390.868562] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  390.895138] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'}"}
{"timestamp_utc": "2024-07-31T08:18:41.150Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:40 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:40 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:46.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:45 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:45 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:48.913Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:17:04,584 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  299.523909] ntputils[1724]: my current red mode is: UNKNOWN <NL> [  308.963210] ntputils[1724]: new red mode is: UNKNOWN <NL> 2024-07-31 08:17:16,112 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  309.892535] ntputils[1724]: my current red status is: STANDALONE <NL> 2024-07-31 08:17:19,474 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> [  314.766266] ntputils[1724]: new red status is: STANDALONE <NL> 2024-07-31 08:17:22,815 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> 2024-07-31 08:17:22,894 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  314.896991] ntputils[1724]: received unknown! <NL> [  315.062750] ntputils[1724]: new red mode is: UNKNOWN <NL> 2024-07-31 08:17:23,061 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:17:24,150 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  316.234203] ntputils[1724]: new red status is: STANDALONE <NL> [  316.520416] ntputils[1724]: no active/not-active status change: 0 <NL> 2024-07-31 08:17:24,621 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:17:24,621 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  317.327201] rdm[1730]: RdmConfig: file_exist 0 <NL> 2024-07-31 08:17:26,933 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> [  322.067821] rdm[1730]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  324.883763] rdm[1730]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> 2024-07-31 08:17:28,118 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  325.963326] rdm[1730]: start rdm msg hdlr thd <NL> 2024-07-31 08:17:33,165 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  335.354586] ntp_oper_data.py[1725]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> 2024-07-31 08:17:43,546 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  338.800028] ntp_oper_data.py[1725]: INFO:root:redundancy status now set to standalone <NL> 2024-07-31 08:17:51,674 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  346.067267] ntp_oper_data.py[1725]: INFO:root:Received redundancy topic <NL> [  346.789044] ntp_oper_data.py[1725]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:17:55,111 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')...[  348.696470] hrtimer: interrupt took 2041127 ns <NL> [  347.268433] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> [  350.111184] ntputils[1724]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:17:58,147 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:17:58,765 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  350.781927] ntputils[1724]: got Platform::RedundancyMode: WORK <NL> 2024-07-31 08:17:59,258 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  353.317834] ntputils[1724]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:18:02,119 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2[  369.866307] rcu: INFO: rcu_preempt detected stalls on CPUs/tasks: <NL> [  369.896564] rcu: \tTasks blocked on level-0 rcu_node (CPUs 0-0): P2412/1:b..l <NL> [  369.924329] \t(detected by 0, t=21004 jiffies, g=66865, q=6163) <NL> [  369.938001] task:sshd            state:R  running task     stack:    0 pid: 2412 ppid:     1 flags:0x00000000 <NL> [  369.961701] Call Trace: <NL> [  369.981085]  __schedule+0x2eb/0x8b0 <NL> [  369.983708]  preempt_schedule_irq+0x3d/0x60 <NL> [  369.985252]  irqentry_exit+0x5f/0x70 <NL> [  369.986421]  sysvec_apic_timer_interrupt+0x45/0xe0 <NL> [  370.008128]  asm_sysvec_apic_timer_interrupt+0x12/0x20 <NL> [  370.009963] RIP: 0010:cgroup_throttle_swaprate+0x40/0x110 <NL> [  370.043097] Code: e9 ff e8 33 7a e4 ff 48 85 c0 75 15 e9 be 00 00 00 48 8b 80 c0 00 00 00 48 85 c0 0f 84 cb 00 00 00 48 8b 10 8b 92 50 0a 00 00 <85> d2 74 e3 e8 97 02 ea ff 65 48 8b 04 25 00 ad 01 00 48 83 b8 20 <NL> [  370.090936] RSP: 0000:ffff916744137e00 EFLAGS: 00000282"}
{"timestamp_utc": "2024-07-31T08:18:48.914Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  370.092494] RAX: ffffffffb72e3680 RBX: 0000000000000255 RCX: 0007ffffffffffff <NL> [  370.095466] RDX: 0000000000000000 RSI: 0000000000000040 RDI: ffffe96c000b3040 <NL> [  370.146417] RBP: ffff916744137e00 R08: ffff916744137d5f R09: 0000000000000000 <NL> [  370.148436] R10: 00000000ffffffff R11: ffff8981f6a02d80 R12: ffffe96c000b3040 <NL> [  370.150528] R13: 00007fc015cde2c0 R14: 0000000000000040 R15: 0000000000000001 <NL> [  370.187594]  handle_mm_fault+0x955/0x10f0 <NL> [  370.188888]  ? _raw_spin_unlock_irq+0x17/0x40 <NL> [  370.190517]  do_user_addr_fault+0x1ea/0x3f0 <NL> [  370.192579]  exc_page_fault+0x67/0x150 <NL> [  370.233302]  ? asm_exc_page_fault+0x8/0x30 <NL> [  370.248423]  asm_exc_page_fault+0x1e/0x30 <NL> [  370.249665] RIP: 0033:0x7fc0163ac38a <NL> [  370.250690] RSP: 002b:00007ffe4eab2288 EFLAGS: 00010206 <NL> [  370.252180] RAX: 00007fc015cde2c0 RBX: 0000000000000040 RCX: 00007fc015cdecc8 <NL> [  370.254522] RDX: 00000000000009c0 RSI: 0000000000000000 RDI: 00007fc015cde2c0 <NL> [  370.306923] RBP: 00007fc015cddb80 R08: 0000000000000000 R09: 0000000000000090 <NL> [  370.308977] R10: 0000000000000001 R11: 0000000000000090 R12: 0000000000001100 <NL> [  370.311054] R13: 00007fc0163bf2b0 R14: 0000000000000001 R15: 0000000000000000 <NL> } <NL> } <NL> } <NL> [  356.393876] ntputils[1724]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:18:23,518 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:18:27,787 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:18:28,262 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:18:30,727 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:18:31,258 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  385.071583] ntputils[1724]: new red mode is: WORK <NL> 2024-07-31 08:18:33,925 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  386.548924] ntputils[1724]: my current red status is: STANDALONE <NL> 2024-07-31 08:18:37,141 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  390.374460] ntputils[1724]: new red status is: STANDALONE <NL> 2024-07-31 08:18:39,099 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  392.318612] ntputils[1724]: red mode change, update: UNKNOWN => WORK <NL> 2024-07-31 08:18:40,937 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  394.429344] ntputils[1724]: no active/not-active status change: 0 <NL> [  398.126221] ntputils[1724]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:18:50.801Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:50 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:50 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:50 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:52.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:52 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:54.054Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  241.543281] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  241.545767] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  241.545871] ntputils_client.py[1761]: b'31 Jul 08:16:09 ntpdate[2609]: no server suitable for synchronization found\\n' <NL> [  254.743537] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  254.743916] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  254.744025] ntputils_client.py[1761]: b'31 Jul 08:16:22 ntpdate[2643]: no server suitable for synchronization found\\n' <NL> [  276.616640] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  276.616898] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  276.617013] ntputils_client.py[1761]: b'31 Jul 08:16:44 ntpdate[2682]: no server suitable for synchronization found\\n' <NL> [  294.058666] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  294.058950] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  294.059030] ntputils_client.py[1761]: b'31 Jul 08:17:01 ntpdate[2708]: no server suitable for synchronization found\\n' <NL> [  308.726210] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  308.726513] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  308.726581] ntputils_client.py[1761]: b'31 Jul 08:17:16 ntpdate[2735]: no server suitable for synchronization found\\n' <NL> [  322.205855] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  322.206090] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  322.206164] ntputils_client.py[1761]: b'31 Jul 08:17:29 ntpdate[2755]: no server suitable for synchronization found\\n' <NL> [  336.551790] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  336.552654] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  336.553440] ntputils_client.py[1761]: b'31 Jul 08:17:44 ntpdate[2794]: no server suitable for synchronization found\\n' <NL> [  350.574360] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  350.575097] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  350.626904] ntputils_client.py[1761]: b'31 Jul 08:17:58 ntpdate[2823]: no server suitable for synchronization found\\n' <NL> [  369.433368] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  369.453116] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  369.453975] ntputils_client.py[1761]: b'31 Jul 08:18:17 ntpdate[2877]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:18:29,883 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:18:29,903 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:18:29,980 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:18:29,983 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:18:30,018 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:18:30,019 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1}"}
{"timestamp_utc": "2024-07-31T08:18:54.055Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "2024-07-31 08:18:30,019 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:18:30,028 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:18:30,038 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:18:30,057 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:18:29,984 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:18:30,129 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:18:30,173 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:18:30,268 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":1} <NL> 2024-07-31 08:18:30,273 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:18:30,101 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:18:30,285 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:18:30,468 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:18:30,468 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:18:30,468 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:18:30,469 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:18:30,469 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:18:30,469 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:18:30,478 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:18:30,607 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:18:30,609 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:18:30,645 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:18:31,518 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:18:31,518 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:18:31,544 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:18:37,661 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:18:37,666 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  405.774864] ntputils_client.py[1761]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:18:55.940Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:55 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:55.941Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:55 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:57.827Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:01.090Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:00 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:00 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:05.254Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:18:09,021 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:18:09,131 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  364.084939] ntputils[1728]: exited, status is 0 <NL> [  368.279387] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> 2024-07-31 08:18:14,529 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  369.242290] ntputils[1728]: poller time change delta is: 1 <NL> 2024-07-31 08:18:16,202 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> [  370.737617] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> 2024-07-31 08:18:17,760 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> [  372.361360] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  373.193533] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> 2024-07-31 08:18:19,179 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  373.641413] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:18:19,419 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:18:20,447 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  375.496444] ntputils[1728]: push_local_changes OK <NL> 2024-07-31 08:18:23,336 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  378.868575] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:18:24,726 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  381.576798] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  383.334344] ntputils[1728]: child pid is 2265 <NL> [  384.797649] ntputils[1728]: exited, status is 0 <NL> [  384.828096] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  386.570159] ntputils[1728]: poller time change delta is: 10 <NL> [  386.997706] ntputils[1728]: push_local_changes user_changed: 0 delta: 10 <NL> [  388.008392] systemd-coredump[2782]: Resource limits disable core dumping for process 325 (systemd-journal). <NL> [  388.057928] systemd-coredump[2782]: Process 325 (systemd-journal) of user 0 dumped core. <NL> [  388.511175] systemd[1]: systemd-journald.service: Main process exited, code=dumped, status=6/ABRT <NL> 2024-07-31 08:18:34,315 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup[  388.656918] systemd[1]: systemd-journald.service: Failed with result 'watchdog'. <NL> [  388.680326] systemd[1]: systemd-journald.service: Consumed 11.139s CPU time. <NL> [  388.804659] systemd[1]: systemd-journald.service: #####FSS:Service:EntRestart: Mgr not stopping - allowing restart <NL> [  388.983645] systemd[1]: systemd-journald.service: Scheduled restart job, restart counter is at 1. <NL> [  389.307686] systemd[1]: Started OpenSSH Per-Connection Daemon (172.17.0.1:33122). <NL> [  389.429898] systemd[1]: Stopped Journal Service. <NL> [  389.465791] systemd[1]: systemd-journald.service: Consumed 11.139s CPU time. <NL> [  389.467798] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> 2024-07-31 08:18:36,289 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> 2024-07-31 08:18:37,779 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:18:37,860 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True[  393.958580] systemd[1]: Starting Journal Service... <NL> 2024-07-31 08:18:40,140 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:18:40,339 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:18:40,374 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: [  395.490394] systemd[1]: txid-tracker.service: Deactivated successfully. <NL> 2024-07-31 08:18:41,633 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE"}
{"timestamp_utc": "2024-07-31T08:19:05.255Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:18:42,011 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:18:42,265 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: [  396.990836] systemd[1]: txid-tracker.service: #####FSS:Service:EntRestart: Mgr not stopping - allowing restart <NL> [  397.075500] systemd[1]: txid-tracker.service: Scheduled restart job, restart counter is at 4. <NL> [  397.166433] systemd[1]: Stopped Confd CDB Transaction ID Tracker. <NL> [  397.302698] systemd[1]: Started Confd CDB Transaction ID Tracker. <NL> 2024-07-31 08:18:43,096 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:18:44,458 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: [  401.750562] systemd-journald[2788]: File /run/log/journal/86eb0ba16c45495db592a1e742dfce29/system.journal corrupted or uncleanly shut down, renaming and replacing. <NL> 2024-07-31 08:18:47,431 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:18:48,331 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:18:50,560 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:18:50,587 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:18:50,854 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> 2024-07-31 08:18:50,998 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> 2024-07-31 08:18:52,165 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:18:53,314 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:18:53,748 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: [  409.224911] systemd[1]: Started OpenSSH Per-Connection Daemon (172.17.0.1:53164). <NL> 2024-07-31 08:18:55,539 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:18:56,654 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:18:57,284 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:18:59,704 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:19:02,355 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion #[  416.774240] systemd[1]: Started Journal Service. <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  416.660320] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 10 <NL> [  417.460117] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  417.714179] ntputils[1728]: push_local_changes OK <NL> [  417.857146] ntputils[1728]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:19:05.836Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:05 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:05 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:07.723Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  390.896211] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  390.897470] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  390.930275] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  390.977637] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  390.985721] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  390.995159] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  391.005341] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  391.006407] python3[4026]: [.821] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  391.007389] python3[4026]: [.822] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  391.048725] python3[4026]: [.822] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  391.058820] python3[4026]: [.822] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  391.059886] python3[4026]: [.822] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  391.084490] python3[4026]: [.822] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  391.093740] python3[4026]: [.822] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  391.094841] python3[4026]: [.833] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  391.095885] python3[4026]: [.836] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  391.131124] python3[4026]: [.836] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  391.153675] python3[4026]: [.836] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  391.163105] python3[4026]: [.836] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  391.172156] python3[4026]: [.836] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  391.173255] python3[4026]: [.836] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  391.174267] python3[4026]: [.864] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  391.225317] python3[4026]: [.864] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  391.245556] python3[4026]: [.868] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  391.259959] python3[4026]: [.868] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  391.262675] python3[4026]: [.868] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  391.303677] python3[4026]: [.868] valhdlr 140510596204352 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  391.326904] python3[4026]: [.868] valhdlr 140510596204352 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  391.329240] python3[4026]: [.881] valhdlr 140510596204352 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  391.362396] python3[4026]: [.881] valhdlr 140510596204352 callbackhdlr:293 Loading schemas <NL> [  391.364506] python3[4026]: DEBUG item does not exist - shared memory schema not enabled <NL> [  391.740619] snmp_clid[4035]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  392.462019] python3[4026]: [.832] valhdlr 140510596204352 callbackhdlr:382 Done load schemas <NL> [  392.497965] python3[4026]: [.893] valhdlr 140510596204352 callbackhdlr:389 Done register transaction callback <NL> [  393.430324] python3[4026]: [.840] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  393.721658] python3[4026]: [.131] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  393.786682] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  393.786862] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  393.786927] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  393.786987] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  393.787055] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  393.787113] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  393.787170] confd_mgr[2874]: sm_startconfd::p0_ready_dbc <NL> [  393.787226] confd_mgr[2874]: Find message SNMP_CLID_CONFIRM <NL> [  393.787448] confd_mgr[2874]: PROCESS_VALHDLR has not registered yet. <NL> [  393.787516] confd_mgr[2874]: sm_startconfd::p0_not_ready <NL> [  393.787573] confd_mgr[2874]: Find message SNMP_CLID_CONFIRM <NL> [  393.787640] confd_mgr[2874]: PROCESS_VALHDLR has not registered yet. <NL> [  393.787722] confd_mgr[2874]: leaving: sm_startconfd::wait_for_p0 <NL> [  393.787780] confd_mgr[2874]: entering: sm_startconfd::wait_for_p0 <NL> [  393.787837] confd_mgr[2874]: PROCESS_VALHDLR has not registered yet. <NL> [  393.787897] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  393.787955] confd_mgr[2874]: ConfdHA Not supported command CONFIRM <NL> [  393.788022] confd_mgr[2874]: Timer /ConfdAT|wait_for_p0 already created <NL> [  393.788079] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  393.788136] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  393.788512] snmp_clid[4052]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  394.080882] python3[4026]: [.489] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  408.135176] python3[4026]: [.539] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  408.199472] python3[4026]: [.605] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  408.634482] python3[4026]: [.043] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  408.684673] python3[4026]: [.094] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  408.884434] python3[4026]: [.290] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  408.939742] python3[4026]: [.348] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  409.102669] python3[4026]: [.510] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  409.204237] python3[4026]: [.597] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  409.269613] python3[4026]: [.660] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  409.400478] python3[4026]: [.790] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  412.319861] python3[4026]: [.708] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  415.631689] python3[4026]: [.041] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  418.633261] python3[4026]: [.042] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb profile_id_validation"}
{"timestamp_utc": "2024-07-31T08:19:10.988Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:19:10 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:10.989Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:10 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:10 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:11.915Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  336.463338] healthcheck_result_display.py[2400]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  336.463417] healthcheck_result_display.py[2400]:     self._init_connection() <NL> [  336.463474] healthcheck_result_display.py[2400]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  336.463570] healthcheck_result_display.py[2400]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  336.463629] healthcheck_result_display.py[2400]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  336.779590] healthcheck_result_display.py[2400]:     _tm.dp.connect( <NL> [  336.779727] healthcheck_result_display.py[2400]: _confd.error.EOF: ConfD closed connection <NL> [  338.233516] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 7 <NL> [  339.475115] python3[2409]: [.271] hookhdlr 140061943105344 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  339.684992] python3[2409]: [.480] hookhdlr 140061943105344 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  339.685209] python3[2409]: [.480] hookhdlr 140061943105344 callbackhdlr:293 Loading schemas <NL> [  339.811613] python3[2409]: DEBUG item does not exist - shared memory schema not enabled <NL> [  341.236798] txid_tracker[3835]: ::::create_confd_subscription_connection() try number 8 <NL> [  341.870513] python3[2409]: [.645] hookhdlr 140061943105344 callbackhdlr:382 Done load schemas <NL> [  341.870663] python3[2409]: [.645] hookhdlr 140061943105344 callbackhdlr:389 Done register transaction callback <NL> [  343.556939] python3[2409]: [.353] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  343.618400] python3[2409]: [.408] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  343.655529] python3[2409]: [.452] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  343.897149] python3[2409]: [.686] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  344.391475] python3[2409]: [.197] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  344.857475] python3[2409]: [.638] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  344.945284] python3[2409]: [.750] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  345.024280] python3[2409]: [.828] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  345.179504] python3[2409]: [.985] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  345.309921] python3[2409]: [.116] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  345.691524] python3[2409]: [.497] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  345.818999] txid_tracker[3888]: ::::create_confd_subscription_connection() connected <NL> [  345.879913] python3[2409]: [.685] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  352.303021] python3[2409]: [.072] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  356.392670] python3[2409]: [.197] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  359.499816] python3[2409]: [.243] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  362.248246] python3[2409]: [.054] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  365.804056] python3[2409]: [.609] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  365.838081] python3[2409]: [.644] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  365.873527] python3[2409]: [.676] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  365.909456] python3[2409]: [.715] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  365.950428] python3[2409]: [.742] hookhdlr 140061943105344 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  366.001893] python3[2409]: [.742] hookhdlr 140061943105344 callbackhdlr:391 Done register data callbacks <NL> [  420.855660] confd_mgr[2866]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  420.963026] confd_mgr[4052]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:19:07 UTC 2024 <NL> [  421.173466] confd_mgr[4052]: Starting valhdlr.service <NL> [  421.587959] confd_mgr[4052]: Starting validation-handler.service <NL> [  421.811578] confd_mgr[4052]: Starting snmp-fss-fw.service <NL> [  421.956765] python3[2409]: DEBUG No crypto keys configured <NL> [  422.007617] python3[2409]: [.762] hookhdlr 140061943105344 callbackhdlr:401 Unable to install crypto keys! <NL> [  422.052879] python3[2409]: [.858] hookhdlr 140061943105344 callbackhdlr:322 Started data handler daemon... <NL> [  422.221171] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted <NL> [  422.250721] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  422.393811] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  422.513275] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  422.585831] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  422.615452] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  422.635382] confd_mgr[2866]: ConfdHA Not supported command CONFIRM <NL> [  422.669500] confd_mgr[2866]: leaving: sm_startconfd::start_confd_p0 <NL> [  422.678703] confd_mgr[2866]: entering: sm_startconfd::wait_for_p0 <NL> [  422.690813] confd_mgr[2866]: PROCESS1 has not registered yet. <NL> [  422.701017] confd_mgr[2866]: PROCESS_SNMP_CLID has not registered yet. <NL> [  422.713668] confd_mgr[2866]: PROCESS_VALHDLR has not registered yet. <NL> [  422.747148] confd_mgr[2866]: sm_startconfd::p0_ready_dbc <NL> [  422.775426] confd_mgr[2866]: Find message MESSAGE1 <NL> [  422.786829] confd_mgr[2866]: PROCESS_SNMP_CLID has not registered yet. <NL> [  422.798926] confd_mgr[2866]: PROCESS_VALHDLR has not registered yet. <NL> [  422.812882] confd_mgr[2866]: sm_startconfd::p0_not_ready <NL> [  422.825845] confd_mgr[2866]: Find message MESSAGE1 <NL> [  422.846710] confd_mgr[2866]: PROCESS_SNMP_CLID has not registered yet. <NL> [  422.858177] confd_mgr[2866]: PROCESS_VALHDLR has not registered yet. <NL> [  422.862701] confd_mgr[2866]: leaving: sm_startconfd::wait_for_p0 <NL> [  422.875792] confd_mgr[2866]: entering: sm_startconfd::wait_for_p0 <NL> [  422.885377] confd_mgr[2866]: PROCESS_SNMP_CLID has not registered yet. <NL> [  422.899804] confd_mgr[2866]: PROCESS_VALHDLR has not registered yet."}
{"timestamp_utc": "2024-07-31T08:19:11.916Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  422.910266] confd_mgr[2866]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  422.918302] confd_mgr[2866]: Timer /ConfdAT|wait_for_p0 already created <NL> [  422.930482] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  422.938862] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  424.163268] python3[4065]: [.967] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  424.240214] python3[4065]: [.968] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  424.240312] python3[4065]: [.968] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  424.240369] python3[4065]: [.968] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  424.240428] python3[4065]: [.968] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  424.245511] python3[4065]: [.968] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  424.245767] python3[4065]: [.968] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'}"}
{"timestamp_utc": "2024-07-31T08:19:12.841Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:19:12 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp85.fnc.net.local:46486\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:16.101Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  424.245829] python3[4065]: [.978] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  424.246696] python3[4065]: [.978] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  424.264888] python3[4065]: [.978] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  424.265082] python3[4065]: [.978] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  424.265150] python3[4065]: [.978] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  424.265212] python3[4065]: [.978] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  424.265277] python3[4065]: [.993] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  424.265353] python3[4065]: [.993] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  424.265408] python3[4065]: [.993] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  424.265463] python3[4065]: [.993] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  424.265520] python3[4065]: [.999] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  424.265579] python3[4065]: [.000] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'}"}
{"timestamp_utc": "2024-07-31T08:19:16.102Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  424.265635] python3[4065]: [.000] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  424.265721] python3[4065]: [.000] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  424.265776] python3[4065]: [.000] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  424.265831] python3[4065]: [.000] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  424.265885] python3[4065]: [.000] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  424.271724] python3[4065]: [.018] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  424.271862] python3[4065]: [.018] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  424.271920] python3[4065]: [.018] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  424.271978] python3[4065]: [.019] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  424.272056] python3[4065]: [.019] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  424.272114] python3[4065]: [.019] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  424.272171] python3[4065]: [.019] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  424.272227] python3[4065]: [.019] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  424.272287] python3[4065]: [.019] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  424.837326] python3[4065]: [.019] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  424.838389] python3[4065]: [.041] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  424.874990] python3[4065]: [.041] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  424.926881] python3[4065]: [.041] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  424.926958] python3[4065]: [.041] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  424.927044] python3[4065]: [.041] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  424.927105] python3[4065]: [.041] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  424.927193] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  424.927255] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  424.927314] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  424.927374] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  424.927426] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  424.927555] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  424.927606] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  424.927658] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  424.927707] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  424.927758] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  424.927807] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  424.927859] python3[4065]: [.042] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  424.927907] python3[4065]: [.071] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  424.927955] python3[4065]: [.071] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  424.928023] python3[4065]: [.175] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  424.928073] python3[4065]: [.175] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  424.928121] python3[4065]: [.175] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  424.928170] python3[4065]: [.175] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  424.928219] python3[4065]: [.175] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  424.928271] python3[4065]: [.183] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  424.928319] python3[4065]: [.183] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  424.928368] python3[4065]: [.183] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  424.928417] python3[4065]: [.183] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  424.928475] python3[4065]: [.183] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  424.928535] python3[4065]: [.183] valhdlr 140435052689216 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  424.928618] python3[4065]: [.183] valhdlr 140435052689216 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  424.990700] python3[4065]: [.781] valhdlr 140435052689216 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  425.369838] python3[4065]: [.782] valhdlr 140435052689216 callbackhdlr:293 Loading schemas <NL> [  425.369914] python3[4065]: DEBUG item does not exist - shared memory schema not enabled <NL> [  427.089677] python3[4065]: [.883] valhdlr 140435052689216 callbackhdlr:382 Done load schemas <NL> [  427.089995] python3[4065]: [.883] valhdlr 140435052689216 callbackhdlr:389 Done register transaction callback <NL> [  427.768639] snmp_clid[4073]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> # 03:19:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:15 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:15 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:18.583Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:19:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:20.957Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:20 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:20 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:26.202Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:25 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:25 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:31.470Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:19:30 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp85.fnc.net.local:46502\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:30 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:30 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:35.632Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:19:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:35.888Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:35 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:36.143Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:35 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:41.380Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:40 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:40 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:46.623Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:45 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:45 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:51.860Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:50 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:50 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:52.784Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:18:46,265 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  399.301937] ntputils[1724]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:18:52,050 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  404.103755] ntputils[1724]: child pid is 2176 <NL> 2024-07-31 08:18:52,529 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  404.776514] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:18:56,719 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  408.829510] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> 2024-07-31 08:18:58,484 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  412.466099] ntputils[1724]: poller time change delta is: 3 <NL> [  412.900123] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [  412.901147] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> 2024-07-31 08:19:01,001 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> [  414.317410] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  418.130987] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:19:06,346 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  418.750770] ntputils[1724]: push_local_changes OK <NL> [  419.088351] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  419.089040] ntputils[1724]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:19:07,469 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  419.925858] ntputils[1724]: child pid is 2206 <NL> [  420.394492] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:19:08,501 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> [  420.679729] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> 2024-07-31 08:19:09,319 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  421.628660] ntputils[1724]: poller time change delta is: 6 <NL> 2024-07-31 08:19:09,803 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:19:11,186 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  424.148683] ntputils[1724]: push_local_changes user_changed: 0 delta: 6 <NL> 2024-07-31 08:19:15,903 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:19:15,904 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  429.457306] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> 2024-07-31 08:19:17,541 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  430.121503] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 6 <NL> [  430.646488] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  430.647105] ntputils[1724]: push_local_changes OK <NL> [  430.647570] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  430.804642] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  430.848248] ntputils[1724]: child pid is 2225 <NL> [  431.151779] ntputils[1724]: exited, status is 0 <NL> [  431.452941] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> 2024-07-31 08:19:19,897 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> [  432.288064] ntputils[1724]: poller time change delta is: 1 <NL> [  432.588972] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> 2024-07-31 08:19:20,356 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  432.745511] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> 2024-07-31 08:19:20,610 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:19:21,189 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  433.783578] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> 2024-07-31 08:19:22,731 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:19:23,680 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:19:23,278 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  435.698208] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:19:23,873 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:19:24,457 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  436.886445] ntputils[1724]: push_local_changes OK <NL> 2024-07-31 08:19:25,027 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:19:25,385 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  438.007880] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:19:26,531 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:19:27,650 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  440.207719] ntputils[1724]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:19:29,196 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> 2024-07-31 08:19:30,045 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  442.993340] ntputils[1724]: child pid is 2250 <NL> [  444.956241] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:19:33,248 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  446.138056] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> 2024-07-31 08:19:35,149 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank {"}
{"timestamp_utc": "2024-07-31T08:19:52.785Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  448.360071] ntputils[1724]: poller time change delta is: 2 <NL> 2024-07-31 08:19:40,643 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  452.942439] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> 2024-07-31 08:19:42,352 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  455.493423] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> 2024-07-31 08:19:44,790 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  457.576957] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> 2024-07-31 08:19:46,313 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  458.863947] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:19:47,482 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  460.678180] ntputils[1724]: push_local_changes OK <NL> 2024-07-31 08:19:50,040 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank {"}
{"timestamp_utc": "2024-07-31T08:19:56.047Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:55 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:56 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:01.284Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:00 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:01 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:03.800Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  417.858880] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  418.861048] ntputils[1728]: child pid is 2278 <NL> [  418.882929] ntputils[1728]: exited, status is 0 <NL> [  418.883422] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  418.893029] ntputils[1728]: poller time change delta is: 4 <NL> [  419.333964] ntputils[1728]: push_local_changes user_changed: 0 delta: 4 <NL> [  421.647700] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  421.864686] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  422.382088] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  422.684067] ntputils[1728]: push_local_changes OK <NL> [  423.588513] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  423.589316] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  423.630941] ntputils[1728]: child pid is 2317 <NL> [  423.631409] ntputils[1728]: exited, status is 0 <NL> [  423.631924] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  424.941185] ntputils[1728]: poller time change delta is: 5 <NL> [  425.126495] ntputils[1728]: push_local_changes user_changed: 0 delta: 5 <NL> [  425.619760] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  428.879238] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [  429.294886] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  430.527735] hrtimer: interrupt took 451161 ns"}
{"timestamp_utc": "2024-07-31T08:20:03.801Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  431.877751] ntputils[1728]: push_local_changes OK <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> [  432.567974] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  433.902301] ntputils[1728]: /sbin/hwclock -u --systohc <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  434.787633] ntputils[1728]: child pid is 2324 <NL> [  435.771915] ntputils[1728]: exited, status is 0 <NL> [  436.712456] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  438.441983] ntputils[1728]: poller time change delta is: 1 <NL> [  439.835338] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  440.126599] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  440.766355] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  440.971706] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  441.426349] ntputils[1728]: push_local_changes OK <NL> [  442.350642] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  443.193934] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  443.797265] ntputils[1728]: child pid is 2357 <NL> [  445.121035] ntputils[1728]: exited, status is 0 <NL> [  445.750183] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  447.006118] ntputils[1728]: poller time change delta is: 4 <NL> [  447.796989] ntputils[1728]: push_local_changes user_changed: 0 delta: 4 <NL> [  448.875259] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  449.088906] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  449.893805] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  450.630576] ntputils[1728]: push_local_changes OK <NL> [  450.631105] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  450.685323] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  451.036657] ntputils[1728]: child pid is 2395 <NL> [  451.331114] ntputils[1728]: exited, status is 0 <NL> [  451.767824] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  452.575523] ntputils[1728]: poller time change delta is: 2 <NL> [  453.773183] ntputils[1728]: push_local_changes user_changed: 0 delta: 2 <NL> [  454.412217] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> [  455.148175] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  456.150320] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  456.541015] ntputils[1728]: push_local_changes OK <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  458.872292] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  459.540982] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  459.980411] ntputils[1728]: child pid is 2425 <NL> [  460.269062] ntputils[1728]: exited, status is 0 <NL> [  460.484075] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  460.846043] ntputils[1728]: poller time change delta is: 3 <NL> [  461.553482] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  461.847256] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  462.371831] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  463.516696] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  463.948249] ntputils[1728]: push_local_changes OK <NL> [  464.252358] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  464.930752] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  465.258221] ntputils[1728]: child pid is 2459 <NL> [  465.448291] ntputils[1728]: exited, status is 0 <NL> [  465.448767] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  465.799285] ntputils[1728]: poller time change delta is: 4 <NL> [  466.140780] ntputils[1728]: push_local_changes user_changed: 0 delta: 4 <NL> [  466.785653] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  467.453575] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  467.612714] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  467.617279] ntputils[1728]: push_local_changes OK <NL> [  467.727278] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  467.849077] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  468.766703] ntputils[1728]: child pid is 2474 <NL> [  469.139909] ntputils[1728]: exited, status is 0 <NL> [  469.140421] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  469.183621] ntputils[1728]: poller time change delta is: 3 <NL> [  469.299487] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  469.361563] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  469.362249] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  469.362903] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  469.520155] ntputils[1728]: push_local_changes OK <NL> [  469.520903] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  469.780714] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  470.056366] ntputils[1728]: child pid is 2489 <NL> [  470.210239] ntputils[1728]: exited, status is 0 <NL> [  470.345142] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  470.956969] ntputils[1728]: poller time change delta is: 2 <NL> [  471.161425] ntputils[1728]: push_local_changes user_changed: 0 delta: 2 <NL> [  471.486230] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  471.531928] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  471.651901] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  471.882053] ntputils[1728]: push_local_changes OK <NL> [  471.949533] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  472.245703] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  472.478169] ntputils[1728]: child pid is 2503 <NL> [  472.651729] ntputils[1728]: exited, status is 0 <NL> [  472.680285] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  472.680964] ntputils[1728]: poller time change delta is: 2 <NL> [  472.681504] ntputils[1728]: push_local_changes user_changed: 0 delta: 2"}
{"timestamp_utc": "2024-07-31T08:20:03.802Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  472.682134] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  472.754809] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  473.218580] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  473.219211] ntputils[1728]: push_local_changes OK <NL> [  473.279568] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  473.530258] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  473.905275] ntputils[1728]: child pid is 2522 <NL> [  474.244567] ntputils[1728]: exited, status is 0 <NL> [  474.837236] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  475.285242] ntputils[1728]: poller time change delta is: 3 <NL> [  475.728874] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  476.486241] ntputils[1728]: local_push OK u Platform::Time changedByUser 0"}
{"timestamp_utc": "2024-07-31T08:20:05.164Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:05 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:20:06.088Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:05 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:06 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:10.248Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> [  325.948957] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  325.949334] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  325.949406] ntputils_client.py[1740]: b'31 Jul 08:17:31 ntpdate[2779]: no server suitable for synchronization found\\n' <NL> [  340.765714] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  340.766128] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:20:10.249Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  340.766201] ntputils_client.py[1740]: b'31 Jul 08:17:46 ntpdate[2809]: no server suitable for synchronization found\\n' <NL> [  352.743869] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  352.744134] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  352.744208] ntputils_client.py[1740]: b'31 Jul 08:17:58 ntpdate[2835]: no server suitable for synchronization found\\n' <NL> [  366.548566] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  366.566824] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  366.575508] ntputils_client.py[1740]: b'31 Jul 08:18:12 ntpdate[2882]: no server suitable for synchronization found\\n' <NL> [  381.211835] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  381.215096] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  381.255499] ntputils_client.py[1740]: b'31 Jul 08:18:26 ntpdate[2912]: no server suitable for synchronization found\\n' <NL> [  396.358090] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  396.358555] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  396.358631] ntputils_client.py[1740]: b'31 Jul 08:18:41 ntpdate[2946]: no server suitable for synchronization found\\n' <NL> [  412.496309] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  412.496863] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  412.496945] ntputils_client.py[1740]: b'31 Jul 08:18:58 ntpdate[2972]: no server suitable for synchronization found\\n' <NL> [  458.178102] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  458.178675] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  458.178854] ntputils_client.py[1740]: b'31 Jul 08:19:43 ntpdate[3057]: no server suitable for synchronization found\\n' <NL> [  470.498147] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  470.498863] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  470.530538] ntputils_client.py[1740]: b'31 Jul 08:19:55 ntpdate[3079]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:20:02,214 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:20:02,216 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:20:02,353 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:20:02,381 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:20:02,466 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:20:02,528 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:20:02,529 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:20:02,547 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:20:02,547 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:20:02,548 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:20:02,548 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:20:02,630 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:20:02,676 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:20:02,678 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":1} <NL> 2024-07-31 08:20:02,688 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:20:02,698 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:20:02,771 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:20:02,832 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:20:02,896 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:20:02,896 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:20:02,922 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:20:02,922 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:20:02,922 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:20:02,923 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:20:02,924 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:20:03,008 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:20:03,072 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:20:03,900 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:20:03,900 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:20:03,901 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  482.538986] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  482.539372] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  482.539442] ntputils_client.py[1740]: b'31 Jul 08:20:08 ntpdate[3151]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:20:11.175Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:10 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:11 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:13.058Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:20:12 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp85.fnc.net.local:46502\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:20:16.318Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:16 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:16 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:17.680Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:20:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:22.537Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:21 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:21 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:26.052Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:26.053Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:26 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:26.308Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:26 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:30.877Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  477.108279] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  477.521032] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  477.585052] ntputils[1728]: push_local_changes OK <NL> [  477.732911] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  478.009093] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  478.263546] ntputils[1728]: child pid is 2534 <NL> [  478.539179] ntputils[1728]: exited, status is 0 <NL> [  479.267498] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  479.481297] ntputils[1728]: poller time change delta is: 2 <NL> Exception: [  480.044739] ntputils[1728]: push_local_changes user_changed: 0 delta: 2 <NL> Connect failed[  480.445110] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  480.478456] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  480.479230] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  480.479791] ntputils[1728]: push_local_changes OK <NL> [  480.863653] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  481.582703] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  481.896782] ntputils[1728]: child pid is 2550 <NL> [  482.229286] ntputils[1728]: exited, status is 0 <NL> [  482.436931] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  482.474975] ntputils[1728]: poller time change delta is: 8 <NL> HA_MODE=1+1, MAIN_TRIB_RED=FALSE <NL> [  482.921994] ntputils[1728]: push_local_changes user_changed: 0 delta: 8 <NL> grep: [  483.259005] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> /var/shared/confd/ResetType[  484.060945] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 8 <NL> : No such file or directory[  485.115245] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  485.608358] ntputils[1728]: push_local_changes OK <NL> [  485.608917] ntputils[1728]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:20:30.878Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  485.609517] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  485.609995] ntputils[1728]: child pid is 2557 <NL> [  485.610423] ntputils[1728]: exited, status is 0 <NL> [  485.610867] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  485.880586] ntputils[1728]: poller time change delta is: 1 <NL> [  486.233331] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  486.536519] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  486.757257] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  487.183577] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  487.184067] ntputils[1728]: push_local_changes OK <NL> [  487.184443] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  487.184864] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  487.426625] ntputils[1728]: child pid is 2576 <NL> [  487.560212] ntputils[1728]: exited, status is 0 <NL> [  487.960938] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  488.271849] ntputils[1728]: poller time change delta is: 1 <NL> [  488.762490] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  489.070558] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  489.275913] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  489.674951] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  489.992100] ntputils[1728]: push_local_changes OK <NL> [  490.653979] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  490.821838] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  491.041652] ntputils[1728]: child pid is 2586 <NL> [  491.412854] ntputils[1728]: exited, status is 0 <NL> [  492.204546] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  492.790978] ntputils[1728]: poller time change delta is: 1 <NL> [  494.245088] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  494.441169] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  494.751256] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  494.970213] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  495.454929] ntputils[1728]: push_local_changes OK <NL> [  495.589790] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  496.120661] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  496.121260] ntputils[1728]: child pid is 2595 <NL> [  496.121684] ntputils[1728]: exited, status is 0 <NL> [  496.207590] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  496.208342] ntputils[1728]: poller time change delta is: 3 <NL> [  496.411253] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  496.425986] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  496.427315] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  496.429197] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  496.441184] ntputils[1728]: push_local_changes OK <NL> [  496.491861] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  496.743254] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  496.794134] ntputils[1728]: child pid is 2613 <NL> [  496.935190] ntputils[1728]: exited, status is 0 <NL> [  497.169747] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift"}
{"timestamp_utc": "2024-07-31T08:20:30.879Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  497.170551] ntputils[1728]: poller time change delta is: 2 <NL> [  497.337664] ntputils[1728]: push_local_changes user_changed: 0 delta: 2 <NL> [  497.370987] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  497.485306] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  498.364986] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  498.431460] ntputils[1728]: push_local_changes OK <NL> /run/rdm_status.sh created successfully <NL> [  498.707746] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  499.131696] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  499.184249] ntputils[1728]: child pid is 2632 <NL> [  499.184843] ntputils[1728]: exited, status is 0 <NL> [  499.185406] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  499.254453] ntputils[1728]: poller time change delta is: 5 <NL> [  499.376862] ntputils[1728]: push_local_changes user_changed: 0 delta: 5 <NL> [  499.689593] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  499.909769] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  500.108713] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  500.109387] ntputils[1728]: push_local_changes OK <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  500.199433] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  500.306759] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  500.540262] ntputils[1728]: child pid is 2653 <NL> [  500.752996] ntputils[1728]: exited, status is 0 <NL> [  500.822589] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  500.957804] ntputils[1728]: poller time change delta is: 3 <NL> [  500.958680] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  500.959514] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  501.182423] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  501.299190] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  501.535154] ntputils[1728]: push_local_changes OK <NL> [  501.535775] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  501.536371] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  501.564960] ntputils[1728]: child pid is 2661 <NL> [  501.565435] ntputils[1728]: exited, status is 0 <NL> [  501.565934] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  501.566590] ntputils[1728]: poller time change delta is: 3 <NL> [  501.653777] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  501.654462] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  502.197445] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  502.266469] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  502.383214] ntputils[1728]: push_local_changes OK <NL> [  503.117871] ntputils[1728]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:20:31.147Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:31 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:31.402Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:31 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:32.326Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  462.329490] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:19:52,430 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  465.290491] ntputils[1724]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:19:54,021 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  466.341036] ntputils[1724]: child pid is 2266 <NL> [  467.221327] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:19:55,244 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  468.728996] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  470.554179] ntputils[1724]: poller time change delta is: 4 <NL> [  470.686800] ntputils[1724]: push_local_changes user_changed: 0 delta: 4 <NL> [  471.171244] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  471.659875] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  471.993315] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  472.078866] ntputils[1724]: push_local_changes OK <NL> [  472.612485] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> [  473.858571] ntputils[1724]: /sbin/hwclock -u --systohc <NL> STANDALONE <NL> [  474.790300] ntputils[1724]: child pid is 2284 <NL> ======= Changing UNKNOWN redMode ========= <NL> [  475.471025] ntputils[1724]: exited, status is 0 <NL> [  475.864511] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  476.455895] ntputils[1724]: poller time change delta is: 3 <NL> [  476.874075] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [  477.033377] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  477.868128] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  478.206193] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  478.494582] ntputils[1724]: push_local_changes OK <NL> [  478.495172] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  478.716848] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  479.016605] ntputils[1724]: child pid is 2295 <NL> [  479.017851] ntputils[1724]: exited, status is 0 <NL> [  479.401840] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  479.796923] ntputils[1724]: poller time change delta is: 1 <NL> [  479.910768] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  480.296037] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  480.969085] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  481.884982] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  482.454771] ntputils[1724]: push_local_changes OK <NL> [  483.664085] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  483.801202] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  484.379302] ntputils[1724]: child pid is 2330 <NL> [  485.373944] ntputils[1724]: exited, status is 0 <NL> [  486.222588] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  486.816074] ntputils[1724]: poller time change delta is: 2 <NL> [  487.587927] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [  487.609048] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  487.621934] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  487.634474] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  488.369634] ntputils[1724]: push_local_changes OK <NL> [  488.406961] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  488.488025] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  488.516250] ntputils[1724]: child pid is 2360"}
{"timestamp_utc": "2024-07-31T08:20:32.327Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  488.540233] ntputils[1724]: exited, status is 0 <NL> [  488.713394] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  488.868248] ntputils[1724]: poller time change delta is: 3 <NL> [  489.092626] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [  489.673389] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  489.992249] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  490.553932] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  490.830642] ntputils[1724]: push_local_changes OK <NL> [  491.058618] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  491.411263] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  492.294258] ntputils[1724]: child pid is 2375 <NL> [  492.445863] ntputils[1724]: exited, status is 0 <NL> [  492.712663] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  493.238569] ntputils[1724]: poller time change delta is: 2 <NL> [  493.358879] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [  493.435370] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  493.477969] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  493.552576] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  493.611060] ntputils[1724]: push_local_changes OK <NL> [  493.694135] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  493.843380] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  494.224275] ntputils[1724]: child pid is 2405 <NL> [  494.262760] ntputils[1724]: exited, status is 0 <NL> [  494.263268] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  494.264025] ntputils[1724]: poller time change delta is: 5 <NL> [  494.465947] ntputils[1724]: push_local_changes user_changed: 0 delta: 5 <NL> [  494.695293] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  494.840295] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [  495.187208] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  495.493886] ntputils[1724]: push_local_changes OK <NL> [  495.778609] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  495.905139] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  496.124747] ntputils[1724]: child pid is 2439 <NL> [  496.342086] ntputils[1724]: exited, status is 0 <NL> [  496.780479] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  497.155243] ntputils[1724]: poller time change delta is: 8 <NL> [  497.182149] ntputils[1724]: push_local_changes user_changed: 0 delta: 8 <NL> Exception: [  497.672668] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> Connect failed[  498.473290] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 8 <NL> [  498.832908] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  499.466224] ntputils[1724]: push_local_changes OK <NL> [  499.680817] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  500.242952] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  500.601439] ntputils[1724]: child pid is 2485 <NL> [  500.602669] ntputils[1724]: exited, status is 0 <NL> [  500.603876] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> HA_MODE=1+1, MAIN_TRIB_RED=FALSE <NL> [  500.812707] ntputils[1724]: poller time change delta is: 4 <NL> grep: /var/shared/confd/ResetType[  501.070930] ntputils[1724]: push_local_changes user_changed: 0 delta: 4 <NL> : No such file or directory[  501.457582] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  501.701452] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  501.926845] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  502.209486] ntputils[1724]: push_local_changes OK <NL> [  502.225523] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  502.432497] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  502.472039] ntputils[1724]: child pid is 2501 <NL> [  502.475783] ntputils[1724]: exited, status is 0 <NL> [  502.531471] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  502.758527] ntputils[1724]: poller time change delta is: 4 <NL> [  502.894763] ntputils[1724]: push_local_changes user_changed: 0 delta: 4 <NL> [  503.028868] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  503.029753] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  503.030456] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  503.044214] ntputils[1724]: push_local_changes OK"}
{"timestamp_utc": "2024-07-31T08:20:34.878Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  503.180775] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  503.201410] ntputils[1728]: child pid is 2686 <NL> [  503.203124] ntputils[1728]: exited, status is 0 <NL> [  503.221097] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  503.247903] ntputils[1728]: poller time change delta is: 3 <NL> [  503.248486] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  503.249110] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  503.249736] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  503.266870] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  503.287404] ntputils[1728]: push_local_changes OK <NL> [  503.298309] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  503.299089] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  503.299805] ntputils[1728]: child pid is 2694 <NL> [  503.300429] ntputils[1728]: exited, status is 0 <NL> [  503.318481] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  503.319443] ntputils[1728]: poller time change delta is: 2 <NL> [  503.320151] ntputils[1728]: push_local_changes user_changed: 0 delta: 2 <NL> [  503.367704] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  503.397855] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  503.432964] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  503.443208] ntputils[1728]: push_local_changes OK <NL> [  503.443848] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  503.444975] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  503.445736] ntputils[1728]: child pid is 2703 <NL> [  503.457069] ntputils[1728]: exited, status is 0 <NL> [  503.457730] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  503.458620] ntputils[1728]: poller time change delta is: 1 <NL> [  503.459345] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  503.484386] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  503.493553] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  503.499473] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  503.500227] ntputils[1728]: push_local_changes OK <NL> [  503.500858] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  503.501539] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  503.502216] ntputils[1728]: child pid is 2717 <NL> [  503.510201] ntputils[1728]: exited, status is 0 <NL> [  503.518950] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  503.523261] ntputils[1728]: poller time change delta is: 2 <NL> [  503.531032] ntputils[1728]: push_local_changes user_changed: 0 delta: 2 <NL> [  503.541714] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  503.586348] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  503.587266] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  503.587889] ntputils[1728]: push_local_changes OK <NL> [  503.588437] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  503.604131] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  504.082954] ntputils[1728]: child pid is 2832 <NL> [  504.091043] ntputils[1728]: exited, status is 0 <NL> [  504.109636] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  504.120398] ntputils[1728]: poller time change delta is: 25 <NL> [  504.130957] ntputils[1728]: push_local_changes user_changed: 0 delta: 25 <NL> [  504.149053] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  504.166350] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 25 <NL> [  504.217081] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  504.273687] ntputils[1728]: push_local_changes OK <NL> [  504.338531] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  504.387926] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  504.443661] ntputils[1728]: child pid is 2839 <NL> [  504.478677] ntputils[1728]: exited, status is 0 <NL> [  504.511686] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  504.536583] ntputils[1728]: poller time change delta is: 2 <NL> [  504.545529] ntputils[1728]: push_local_changes user_changed: 0 delta: 2 <NL> [  504.556732] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  504.570322] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  504.579374] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  504.607449] ntputils[1728]: push_local_changes OK <NL> [  504.629235] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  504.653107] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  504.736621] ntputils[1728]: child pid is 2849 <NL> [  504.774454] ntputils[1728]: exited, status is 0 <NL> [  504.823569] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  504.887181] ntputils[1728]: poller time change delta is: 1 <NL> [  504.933778] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  504.934455] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  504.935134] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  504.977642] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  505.010434] ntputils[1728]: push_local_changes OK <NL> [  505.101922] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  505.169135] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  505.176380] ntputils[1728]: child pid is 2878 <NL> [  505.202730] ntputils[1728]: exited, status is 0 <NL> [  505.216921] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  505.323136] ntputils[1728]: poller time change delta is: 4 <NL> [  505.339542] ntputils[1728]: push_local_changes user_changed: 0 delta: 4 <NL> [  505.415058] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  505.430646] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  505.510708] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  506.117979] ntputils[1728]: push_local_changes OK <NL> [  506.179657] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  506.228143] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  506.261065] ntputils[1728]: child pid is 2889 <NL> [  506.300282] ntputils[1728]: exited, status is 0 <NL> [  506.339983] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  506.382098] ntputils[1728]: poller time change delta is: 4 <NL> [  506.397629] ntputils[1728]: push_local_changes user_changed: 0 delta: 4 <NL> [  506.409296] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  506.418799] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  506.437031] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  506.449559] ntputils[1728]: push_local_changes OK <NL> [  506.459765] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  506.499692] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  506.570430] ntputils[1728]: child pid is 2904 <NL> [  506.571068] ntputils[1728]: exited, status is 0 <NL> [  506.571567] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  506.641028] ntputils[1728]: poller time change delta is: 1 <NL> [  506.642637] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  506.688650] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  506.827638] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  506.843898] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  506.857665] ntputils[1728]: push_local_changes OK"}
{"timestamp_utc": "2024-07-31T08:20:34.879Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  506.871142] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  507.230144] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  507.293391] ntputils[1728]: child pid is 2933 <NL> [  507.430395] ntputils[1728]: exited, status is 0 <NL> [  507.493645] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  507.494357] ntputils[1728]: poller time change delta is: 7 <NL> [  507.494909] ntputils[1728]: push_local_changes user_changed: 0 delta: 7 <NL> [  507.495525] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  507.496215] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 7 <NL> [  507.508358] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  507.509573] ntputils[1728]: push_local_changes OK <NL> [  507.520462] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  507.529871] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  507.712692] ntputils[1728]: child pid is 2943"}
{"timestamp_utc": "2024-07-31T08:20:36.275Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:36 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:36 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:41.635Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:41 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:41 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:42.197Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  503.044730] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  503.055192] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  503.161873] ntputils[1724]: child pid is 2519 <NL> [  503.450807] ntputils[1724]: exited, status is 0 <NL> [  503.652316] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  503.762259] ntputils[1724]: poller time change delta is: 5 <NL> [  503.875642] ntputils[1724]: push_local_changes user_changed: 0 delta: 5 <NL> [  503.990881] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  504.483728] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [  504.628271] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  504.628860] ntputils[1724]: push_local_changes OK <NL> [  504.629393] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  504.629908] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  504.794508] ntputils[1724]: child pid is 2535 <NL> [  504.949715] ntputils[1724]: exited, status is 0 <NL> [  505.025905] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  505.179502] ntputils[1724]: poller time change delta is: 3 <NL> [  505.407080] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [  506.311565] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  506.360323] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  506.435427] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  506.504530] ntputils[1724]: push_local_changes OK <NL> [  506.518129] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  506.557989] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  506.606669] ntputils[1724]: child pid is 2604 <NL> [  506.627976] ntputils[1724]: exited, status is 0 <NL> [  506.648746] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  506.677448] ntputils[1724]: poller time change delta is: 1 <NL> [  506.692861] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  506.707214] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  506.748384] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1"}
{"timestamp_utc": "2024-07-31T08:20:42.198Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  506.768901] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  506.782558] ntputils[1724]: push_local_changes OK <NL> [  506.802468] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  506.833095] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  506.859255] ntputils[1724]: child pid is 2615 <NL> [  506.892038] ntputils[1724]: exited, status is 0 <NL> [  506.941957] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  507.035747] ntputils[1724]: poller time change delta is: 2 <NL> [  507.137281] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [  507.222872] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  507.223576] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  507.224352] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  507.351468] ntputils[1724]: push_local_changes OK <NL> [  507.409133] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  507.502626] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  507.522464] ntputils[1724]: child pid is 2627 <NL> [  507.580122] ntputils[1724]: exited, status is 0 <NL> [  507.651511] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  507.786722] ntputils[1724]: poller time change delta is: 1 <NL> [  507.896740] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  507.981989] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  508.039493] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  508.062821] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  508.095887] ntputils[1724]: push_local_changes OK <NL> [  508.166699] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  508.271838] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  508.365133] ntputils[1724]: child pid is 2650 <NL> [  508.444861] ntputils[1724]: exited, status is 0 <NL> [  508.480728] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  508.575872] ntputils[1724]: poller time change delta is: 5 <NL> [  508.603331] ntputils[1724]: push_local_changes user_changed: 0 delta: 5 <NL> [  508.656948] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  508.815937] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [  508.978648] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  509.007305] ntputils[1724]: push_local_changes OK <NL> [  509.166842] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  509.274744] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  509.350117] ntputils[1724]: child pid is 2662 <NL> [  509.374950] ntputils[1724]: exited, status is 0 <NL> [  509.450654] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  509.755803] ntputils[1724]: poller time change delta is: 1 <NL> [  509.763526] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  509.780349] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  509.794541] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  509.816833] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  509.833081] ntputils[1724]: push_local_changes OK <NL> [  509.864536] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  509.912599] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  509.958708] ntputils[1724]: child pid is 2695 <NL> [  509.995932] ntputils[1724]: exited, status is 0 <NL> [  510.077917] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  510.224535] ntputils[1724]: poller time change delta is: 18 <NL> [  510.340838] ntputils[1724]: push_local_changes user_changed: 0 delta: 18 <NL> [  510.471965] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  510.635349] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 18 <NL> [  510.636145] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  510.636721] ntputils[1724]: push_local_changes OK <NL> [  510.637230] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  510.678874] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  510.693747] ntputils[1724]: child pid is 2711 <NL> [  510.694232] ntputils[1724]: exited, status is 0 <NL> [  510.694725] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  510.702908] ntputils[1724]: poller time change delta is: 3 <NL> [  510.703588] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [  510.704477] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  510.862889] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  510.941811] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  511.022087] ntputils[1724]: push_local_changes OK <NL> [  511.323579] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  511.492786] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  511.890837] ntputils[1724]: child pid is 2722"}
{"timestamp_utc": "2024-07-31T08:20:42.199Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  512.000089] ntputils[1724]: exited, status is 0 <NL> [  512.120624] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  512.209953] ntputils[1724]: poller time change delta is: 1 <NL> [  512.258868] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  512.315934] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  512.356678] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  512.427475] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  512.468674] ntputils[1724]: push_local_changes OK <NL> [  512.499669] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  512.524875] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  512.542431] ntputils[1724]: child pid is 2729 <NL> [  512.560153] ntputils[1724]: exited, status is 0 <NL> [  512.587491] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  512.612755] ntputils[1724]: poller time change delta is: 2 <NL> [  512.613514] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [  512.635281] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  512.640550] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  512.660146] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  512.692887] ntputils[1724]: push_local_changes OK <NL> [  512.703950] ntputils[1724]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:20:46.357Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:45 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',) <NL> # 03:20:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:46 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:46 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:49.617Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  507.762572] ntputils[1728]: exited, status is 0 <NL> [  507.787833] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  507.871671] ntputils[1728]: poller time change delta is: 3 <NL> [  508.033636] ntputils[1728]: push_local_changes user_changed: 0 delta: 3 <NL> [  508.362220] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  508.399443] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  508.407411] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  508.429283] ntputils[1728]: push_local_changes OK <NL> [  508.430120] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  508.447085] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  508.469519] ntputils[1728]: child pid is 2956 <NL> [  508.588776] ntputils[1728]: exited, status is 0 <NL> [  508.589287] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  508.666903] ntputils[1728]: poller time change delta is: 1 <NL> [  508.799952] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  508.872578] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  509.010716] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  509.366987] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  509.379093] ntputils[1728]: push_local_changes OK <NL> [  509.560363] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  509.845973] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  510.092155] ntputils[1728]: child pid is 3061 <NL> [  510.354943] ntputils[1728]: exited, status is 0 <NL> [  510.439735] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  510.574132] ntputils[1728]: poller time change delta is: 1 <NL> [  510.777040] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  510.833568] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  510.865900] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  511.048690] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  511.050041] ntputils[1728]: push_local_changes OK <NL> [  511.050479] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  511.051078] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  511.123359] ntputils[1728]: child pid is 3086 <NL> [  511.170984] ntputils[1728]: exited, status is 0 <NL> [  511.227050] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  511.285570] ntputils[1728]: poller time change delta is: 1 <NL> [  511.326407] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  511.327711] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  511.328437] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  511.329166] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  511.339897] ntputils[1728]: push_local_changes OK <NL> [  511.396987] fujitsu-check-ssh-host-key.pl[2021]: Checking system account status... <NL> [  511.561747] fujitsu-check-ssh-host-key.pl[2021]: System account found... <NL> [  511.628457] fujitsu-check-ssh-host-key.pl[2021]: 3004 <NL> [  511.706502] fujitsu-check-ssh-host-key.pl[2021]: /bin/bash <NL> [  511.708128] fujitsu-check-ssh-host-key.pl[2021]: /home/system exists <NL> [  511.708741] fujitsu-check-ssh-host-key.pl[2021]: Checking for trib... <NL> [  511.802737] fujitsu-check-ssh-host-key.pl[2021]: Checking for PIU ... <NL> [  511.820163] fujitsu-check-ssh-host-key.pl[2021]: slot number (0) is not a PIU. <NL> [  511.820808] fujitsu-check-ssh-host-key.pl[2021]: Trib check done. <NL> [  511.995067] startup_finished.py[2045]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  512.152875] ains_manager[2046]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set."}
{"timestamp_utc": "2024-07-31T08:20:49.618Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:20:38,072 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  512.347412] usb_script_handler.py[1738]: usb: INFO - usb_base.check_manual_bind_unbind[251] kernel mimic check to manually verify usb presence <NL> [  512.451428] ains_manager[2132]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> 2024-07-31 08:20:38,447 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  512.872543] startup[2049]: Startup, World! <NL> [  513.430397] startup[2049]: Cmd arg set to loop 1 <NL> [  514.232171] common_alarm_handler[2137]: gen_util: DDS_P2MP not available <NL> [  514.462698] common_alarm_handler[2137]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  514.695626] common_alarm_handler[2137]: topic = SystemProv; id = 1 <NL> [  514.696421] common_alarm_handler[2137]: topic = WdmcfgProv; id = 2 <NL> [  514.697211] common_alarm_handler[2137]: topic = LicenseStatusTopic; id = 3 <NL> [  514.815521] common_alarm_handler[2137]: topic = ShelfProv; id = 5 <NL> [  514.862074] common_alarm_handler[2137]: topic = SlotProv; id = 6 <NL> [  514.998246] common_alarm_handler[2137]: topic = PortProv; id = 7 <NL> [  515.485966] common_alarm_handler[2137]: topic = SubportProv; id = 8 <NL> [  515.603866] common_alarm_handler[2137]: topic = FconProv; id = 9 <NL> [  515.991286] common_alarm_handler[2137]: topic = XconProv; id = 10 <NL> [  516.202307] common_alarm_handler[2137]: topic = OchProv; id = 11 <NL> [  516.453696] common_alarm_handler[2137]: topic = OmsProv; id = 12 <NL> [  516.660906] common_alarm_handler[2137]: topic = OtsProv; id = 13 <NL> [  516.903344] common_alarm_handler[2137]: topic = EthernetProv; id = 14 <NL> [  517.146611] common_alarm_handler[2137]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  517.363122] common_alarm_handler[2137]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  517.644746] common_alarm_handler[2137]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  518.188443] common_alarm_handler[2137]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  518.392614] common_alarm_handler[2137]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  518.681475] common_alarm_handler[2137]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  519.054418] common_alarm_handler[2137]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  519.456504] common_alarm_handler[2137]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  519.566946] common_alarm_handler[2137]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  519.733916] common_alarm_handler[2137]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  519.936242] common_alarm_handler[2137]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  520.120373] common_alarm_handler[2137]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  520.257216] common_alarm_handler[2137]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  520.401470] common_alarm_handler[2137]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  520.488775] common_alarm_handler[2137]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  520.545759] common_alarm_handler[2137]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> Exception: [  520.825446] common_alarm_handler[2137]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> Connect failed[  520.973111] common_alarm_handler[2137]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  521.222792] common_alarm_handler[2137]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> [  521.399050] common_alarm_handler[2137]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  521.437242] common_alarm_handler[2137]: topic = AlarmNotification; id = 40 <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  521.465683] common_alarm_handler[2137]: topic = GenericOperInfoReq; id = 41 <NL> [  521.721873] common_alarm_handler[2137]: topic = PmRtrvReq; id = 42 <NL> [  521.811553] common_alarm_handler[2137]: topic = PmRtrvResp; id = 43 <NL> [  522.066359] common_alarm_handler[2137]: topic = PmInitReq; id = 44 <NL> [  522.190432] common_alarm_handler[2137]: topic = PmOperData; id = 45 <NL> [  512.738111] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  512.769609] ntputils[1724]: child pid is 2795 <NL> [  512.807623] ntputils[1724]: exited, status is 0 <NL> [  512.939777] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  513.050880] ntputils[1724]: poller time change delta is: 1 <NL> [  513.085665] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  513.182341] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  513.241758] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  513.242473] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  513.251633] ntputils[1724]: push_local_changes OK <NL> [  513.269687] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  513.287170] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  513.292696] ntputils[1724]: child pid is 2821 <NL> [  513.298738] ntputils[1724]: exited, status is 0 <NL> [  513.312981] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  513.321332] ntputils[1724]: poller time change delta is: 3 <NL> [  513.338900] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [  513.352983] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  513.362610] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  513.383467] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  513.415490] ntputils[1724]: push_local_changes OK <NL> [  513.427477] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  513.431850] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  513.434912] ntputils[1724]: child pid is 2831 <NL> [  513.474788] ntputils[1724]: exited, status is 0 <NL> [  513.546445] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  513.586054] ntputils[1724]: poller time change delta is: 3 <NL> [  513.622536] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [  513.674162] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> /run/rdm_status.sh created successfully <NL> [  513.805892] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  513.853873] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  513.953667] ntputils[1724]: push_local_changes OK <NL> [  514.031125] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  514.104407] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  514.245638] ntputils[1724]: child pid is 2846 <NL> [  514.294879] ntputils[1724]: exited, status is 0 <NL> [  514.327921] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  514.416552] ntputils[1724]: poller time change delta is: 3 <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  514.536188] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  514.739119] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  514.862143] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [  515.016476] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  515.110270] ntputils[1724]: push_local_changes OK <NL> [  515.217047] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  515.313996] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  515.404399] ntputils[1724]: child pid is 2907 <NL> [  515.451749] ntputils[1724]: exited, status is 0 <NL> [  515.519422] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  515.579337] ntputils[1724]: poller time change delta is: 34 <NL> [  515.579904] ntputils[1724]: push_local_changes user_changed: 0 delta: 34 <NL> [  515.580504] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  515.632860] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 34 <NL> [  515.633599] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  515.788189] ntputils[1724]: push_local_changes OK <NL> [  515.788960] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  515.789564] ntputils[1724]: /sbin/hwclock -u --systohc"}
{"timestamp_utc": "2024-07-31T08:20:49.619Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  515.854611] ntputils[1724]: child pid is 2919 <NL> [  515.855105] ntputils[1724]: exited, status is 0 <NL> [  515.855590] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  515.913352] ntputils[1724]: poller time change delta is: 4 <NL> [  515.964928] ntputils[1724]: push_local_changes user_changed: 0 delta: 4 <NL> [  516.060279] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  516.140993] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  516.193443] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  516.227631] ntputils[1724]: push_local_changes OK <NL> [  516.253390] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  516.286940] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  516.335613] ntputils[1724]: child pid is 2931 <NL> [  516.390282] ntputils[1724]: exited, status is 0 <NL> [  516.416318] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  516.461674] ntputils[1724]: poller time change delta is: 2 <NL> [  516.462367] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [  516.462978] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  516.463625] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  516.642566] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  516.755729] ntputils[1724]: push_local_changes OK <NL> [  516.848514] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  516.940920] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  516.942280] ntputils[1724]: child pid is 2938 <NL> [  517.022227] ntputils[1724]: exited, status is 0 <NL> [  517.091393] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  517.198717] ntputils[1724]: poller time change delta is: 2 <NL> [  517.271558] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [  517.387217] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  517.445201] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  517.464169] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  517.482190] ntputils[1724]: push_local_changes OK <NL> [  517.494321] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  517.597427] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  517.652980] ntputils[1724]: child pid is 3016 <NL> [  517.720472] ntputils[1724]: exited, status is 0 <NL> [  517.772663] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  517.829563] ntputils[1724]: poller time change delta is: 1 <NL> [  517.999117] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  518.339850] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  518.495078] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  518.769836] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  518.805957] ntputils[1724]: push_local_changes OK <NL> [  519.236964] fujitsu-check-ssh-host-key.pl[2017]: Checking system account status... <NL> [  519.319808] fujitsu-check-ssh-host-key.pl[2017]: System account found... <NL> [  519.354664] fujitsu-check-ssh-host-key.pl[2017]: 3004 <NL> [  519.382867] fujitsu-check-ssh-host-key.pl[2017]: /bin/bash <NL> [  519.422139] fujitsu-check-ssh-host-key.pl[2017]: /home/system exists <NL> [  519.451781] fujitsu-check-ssh-host-key.pl[2017]: Checking for trib... <NL> [  519.452502] fujitsu-check-ssh-host-key.pl[2017]: Checking for PIU ... <NL> [  519.453175] fujitsu-check-ssh-host-key.pl[2017]: slot number (0) is not a PIU. <NL> [  519.459548] fujitsu-check-ssh-host-key.pl[2017]: Trib check done. <NL> [  519.518544] startup_finished.py[2047]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  519.576317] ains_manager[2048]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  519.673320] ains_manager[2484]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> 2024-07-31 08:20:47,770 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0"}
{"timestamp_utc": "2024-07-31T08:20:50.980Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:51.235Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:51 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:51 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp85.fnc.net.local:46502\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:20:51.489Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:51 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:56.804Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:56 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:56 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:01.012Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:20:48,276 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  522.628210] common_alarm_handler[2137]: topic = StateChange; id = 46 <NL> [  522.686766] common_alarm_handler[2137]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  522.747292] common_alarm_handler[2137]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  522.814259] common_alarm_handler[2137]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> [  522.908040] common_alarm_handler[2137]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  522.954781] common_alarm_handler[2137]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  523.184272] usb_script_handler.py[1738]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  523.275499] usb_script_handler.py[1738]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  523.308612] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[106] trying to mount usb as secondary storage <NL> [  523.389398] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[108] checking for /dev/mapper/usb-secondary device <NL> [  523.599368] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[111] found /dev/mapper/usb-secondary device <NL> ERROR:root:empty repository <NL> [  523.863609] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[118] USB ssw mount successful <NL> [  524.230990] usb_script_handler.py[1738]: usb: INFO - usb_base.update_usb_psi_info[550] Publishing Mocked USB PSI Info on Qemu <NL> [  524.480887] usb_script_handler.py[1738]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> 2024-07-31 08:20:50,445 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  524.827620] usb_script_handler.py[1738]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> [  524.984953] common_alarm_handler[2137]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  525.162788] common_alarm_handler[2137]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> 2024-07-31 08:20:50,972 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  525.542555] common_alarm_handler[2137]: topic = EthIfProv; id = 56 <NL> 2024-07-31 08:20:51,575 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  525.905488] common_alarm_handler[2137]: topic = DcnNat64Attributes; id = 57 <NL> 2024-07-31 08:20:51,971 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  526.327197] common_alarm_handler[2137]: topic = DcnNat44Nat44Attributes; id = 58 <NL> 2024-07-31 08:20:52,353 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  526.701603] common_alarm_handler[2137]: topic = LldpGlobalCfgProv; id = 59 <NL> 2024-07-31 08:20:52,903 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  527.267134] common_alarm_handler[2137]: topic = LldpPortCfgProv; id = 60 <NL> 2024-07-31 08:20:53,321 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  527.601202] common_alarm_handler[2137]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> 2024-07-31 08:20:53,570 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  527.866365] common_alarm_handler[2137]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  529.060430] common_alarm_handler[2137]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  529.101420] common_alarm_handler[2137]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  529.201761] common_alarm_handler[2137]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  529.202413] common_alarm_handler[2137]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  529.203059] common_alarm_handler[2137]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  529.203681] common_alarm_handler[2137]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  529.227421] common_alarm_handler[2137]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  529.228237] common_alarm_handler[2137]: topic = DcnPppAttributesProv; id = 70 <NL> [  529.228861] common_alarm_handler[2137]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  529.287618] common_alarm_handler[2137]: topic = LldpBladeCfgProv; id = 72 <NL> [  529.288223] common_alarm_handler[2137]: topic = LldpPortInstCfgProv; id = 73 <NL> [  529.288765] common_alarm_handler[2137]: topic = DcnGreTunnelProv; id = 74 <NL> [  529.311897] common_alarm_handler[2137]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  529.312486] common_alarm_handler[2137]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  529.312993] common_alarm_handler[2137]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  529.313539] common_alarm_handler[2137]: topic = SysGnmiCertProv; id = 78 <NL> [  529.314042] common_alarm_handler[2137]: topic = IetfInterfaceProv; id = 79 <NL> [  529.367837] common_alarm_handler[2137]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  529.412230] common_alarm_handler[2137]: topic = SystemAutoLogoffProv; id = 81 <NL> [  529.412860] common_alarm_handler[2137]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  529.413604] common_alarm_handler[2137]: topic = SystemPortsProv; id = 83 <NL> [  529.414244] common_alarm_handler[2137]: topic = OspfProvisioningModeProv; id = 84 <NL> [  529.507760] common_alarm_handler[2137]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  529.530677] common_alarm_handler[2137]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  529.623405] common_alarm_handler[2137]: topic = BasicGroupProv; id = 87 <NL> [  529.697989] common_alarm_handler[2137]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  529.970304] common_alarm_handler[2137]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  530.412530] common_alarm_handler[2137]: topic = SystemFipsProv; id = 90 <NL> [  530.701105] common_alarm_handler[2137]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  531.249709] common_alarm_handler[2137]: topic = SecuritySystemwideProv; id = 92 <NL> [  531.639244] common_alarm_handler[2137]: topic = DataEncryptionProv; id = 93 <NL> [  531.841634] common_alarm_handler[2137]: topic = SystemServicesProv; id = 94 <NL> [  532.011526] common_alarm_handler[2137]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  532.211171] common_alarm_handler[2137]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  532.465500] common_alarm_handler[2137]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  532.649189] common_alarm_handler[2137]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  533.049355] common_alarm_handler[2137]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  533.249123] common_alarm_handler[2137]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  533.360813] common_alarm_handler[2137]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  533.416656] common_alarm_handler[2137]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  533.581273] trb-cdsf-app[2138]: DDD cdsf-app running <NL> [  533.620061] usb_script_handler.py[3121]: 2024-Jul-31 08:20:43CommClient::CommClient Connection refused <NL> [  533.709035] usb_script_handler.py[3121]: 2024-Jul-31 08:20:45CommClient::CommClient Connection refused <NL> [  533.709885] usb_script_handler.py[3121]: 2024-Jul-31 08:20:48CommClient::CommClient Connection refused <NL> [  428.134090] python3[4065]: [.932] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  428.535637] python3[4065]: [.340] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  428.604259] python3[4065]: [.401] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  429.593054] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted"}
{"timestamp_utc": "2024-07-31T08:21:01.013Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  429.593351] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  429.593415] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  429.593480] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  429.593544] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  429.593597] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  429.593648] confd_mgr[2866]: sm_startconfd::p0_ready_dbc <NL> [  429.593704] confd_mgr[2866]: Find message SNMP_CLID_CONFIRM <NL> [  429.593760] confd_mgr[2866]: PROCESS_VALHDLR has not registered yet. <NL> [  429.593812] confd_mgr[2866]: sm_startconfd::p0_not_ready <NL> [  429.593874] confd_mgr[2866]: Find message SNMP_CLID_CONFIRM <NL> [  429.593931] confd_mgr[2866]: PROCESS_VALHDLR has not registered yet. <NL> [  429.593999] confd_mgr[2866]: leaving: sm_startconfd::wait_for_p0 <NL> [  429.594068] confd_mgr[2866]: entering: sm_startconfd::wait_for_p0 <NL> [  429.594211] confd_mgr[2866]: PROCESS_VALHDLR has not registered yet. <NL> [  429.594280] confd_mgr[2866]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  429.594341] confd_mgr[2866]: Timer /ConfdAT|wait_for_p0 already created <NL> [  429.675842] confd_mgr[2866]: ConfdHA Not supported command CONFIRM <NL> [  429.676020] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  429.676081] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  429.676586] snmp_clid[4089]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  442.811743] python3[4065]: [.575] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  442.981334] python3[4065]: [.751] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  443.231073] python3[4065]: [.014] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  443.231277] python3[4065]: [.022] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  443.425071] python3[4065]: [.230] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  443.442786] python3[4065]: [.248] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  443.540745] python3[4065]: [.344] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  443.593352] python3[4065]: [.355] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  443.666274] python3[4065]: [.424] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  443.789775] python3[4065]: [.586] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  447.597080] python3[4065]: [.394] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  450.660510] python3[4065]: [.467] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  453.790226] python3[4065]: [.568] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  456.215856] python3[4065]: [.021] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  456.303822] python3[4065]: [.070] valhdlr 140435052689216 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  456.344971] python3[4065]: [.071] valhdlr 140435052689216 callbackhdlr:391 Done register data callbacks <NL> [  456.453557] python3[4065]: DEBUG No crypto keys configured <NL> [  456.455065] python3[4065]: [.071] valhdlr 140435052689216 callbackhdlr:401 Unable to install crypto keys! <NL> [  456.536100] python3[4065]: [.091] valhdlr 140435052689216 callbackhdlr:322 Started data handler daemon... <NL> [  456.538450] python3[4065]: [.092] valhdlr 140435052689216 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  456.596812] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted <NL> [  456.628548] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  456.638936] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  456.648774] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  456.677095] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  456.690896] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  456.700841] confd_mgr[2866]: sm_startconfd::p0_ready_dbc <NL> [  456.706722] confd_mgr[2866]: Find message VALHDLR_CONFIRM <NL> [  456.715123] confd_mgr[2866]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  456.723530] confd_mgr[2866]: sm_startconfd::p0_not_ready <NL> [  456.740583] confd_mgr[2866]: Find message VALHDLR_CONFIRM <NL> [  456.754292] confd_mgr[2866]: sm_startconfd::p0_ready_no_dbc <NL> [  456.775793] confd_mgr[2866]: Find message VALHDLR_CONFIRM <NL> [  456.788346] confd_mgr[2866]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  456.806033] confd_mgr[2866]: leaving: sm_startconfd::wait_for_p0 <NL> [  456.806594] confd_mgr[2866]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  456.807195] confd_mgr[2866]: entering: sm_startconfd::start_confd_p1 <NL> [  456.856400] confd_mgr[2866]: ConfdHA Not supported command CONFIRM <NL> [  456.857061] confd_mgr[2866]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  456.892469] confd_mgr[4143]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:19:43 UTC 2024 <NL> [  457.117215] confd_mgr[4154]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  457.177611] confd_mgr[2866]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  512.120815] txid_tracker[3888]: ::::create_confd_subscription_connection() connected <NL> [  529.335196] confd_mgr[2866]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  529.386915] confd_mgr[4392]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:20:56 UTC 2024 <NL> [  529.531517] confd_mgr[4392]: Invoking confd_load_upgrade_xml.py <NL> [  531.423439] confd_mgr[4399]: confd_load_upgrade_xml.py: Start <NL> [  531.423655] confd_mgr[4399]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  532.353427] confd_mgr[2866]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  532.496506] confd_mgr[4413]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  532.604365] confd_mgr[2866]: CONFD IN PHASE 1 <NL> [  532.604525] confd_mgr[2866]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  532.604594] confd_mgr[2866]: leaving: sm_startconfd::start_confd_p1 <NL> [  532.605013] confd_mgr[2866]: entering: sm_startconfd::wait_for_p1 <NL> [  532.605077] confd_mgr[2866]: PROCESS3 has not registered yet. <NL> [  532.605137] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  532.605192] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  532.605275] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted <NL> [  532.605331] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  532.605396] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  532.605454] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  532.605509] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  532.641185] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO"}
{"timestamp_utc": "2024-07-31T08:21:01.268Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:01 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:01.525Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:01 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:02.455Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  519.839307] usb_script_handler.py[1734]: usb: INFO - usb_base.check_manual_bind_unbind[251] kernel mimic check to manually verify usb presence <NL> [  519.909614] startup[2051]: Startup, World! <NL> 2024-07-31 08:20:47,992 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  520.232344] startup[2051]: Cmd arg set to loop 1 <NL> [  520.445609] common_alarm_handler[2123]: gen_util: DDS_P2MP not available <NL> [  520.656861] common_alarm_handler[2123]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  520.796592] common_alarm_handler[2123]: topic = SystemProv; id = 1 <NL> [  520.930709] common_alarm_handler[2123]: topic = WdmcfgProv; id = 2 <NL> [  521.352174] common_alarm_handler[2123]: topic = LicenseStatusTopic; id = 3 <NL> [  521.352864] common_alarm_handler[2123]: topic = ShelfProv; id = 5 <NL> [  521.549609] common_alarm_handler[2123]: topic = SlotProv; id = 6 <NL> [  521.550370] common_alarm_handler[2123]: topic = PortProv; id = 7 <NL> [  521.787912] common_alarm_handler[2123]: topic = SubportProv; id = 8 <NL> [  521.881634] common_alarm_handler[2123]: topic = FconProv; id = 9 <NL> [  522.072308] common_alarm_handler[2123]: topic = XconProv; id = 10"}
{"timestamp_utc": "2024-07-31T08:21:02.456Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  522.392842] common_alarm_handler[2123]: topic = OchProv; id = 11 <NL> [  522.727103] common_alarm_handler[2123]: topic = OmsProv; id = 12 <NL> [  522.975263] common_alarm_handler[2123]: topic = OtsProv; id = 13 <NL> [  523.249152] common_alarm_handler[2123]: topic = EthernetProv; id = 14 <NL> [  523.347641] common_alarm_handler[2123]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  523.460857] common_alarm_handler[2123]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  523.461673] common_alarm_handler[2123]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  523.462397] common_alarm_handler[2123]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  523.847849] common_alarm_handler[2123]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  524.175397] common_alarm_handler[2123]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  524.566731] common_alarm_handler[2123]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  525.021317] common_alarm_handler[2123]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  525.512736] common_alarm_handler[2123]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  525.707608] common_alarm_handler[2123]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  525.928683] common_alarm_handler[2123]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  526.201859] common_alarm_handler[2123]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  526.370679] common_alarm_handler[2123]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  526.464166] common_alarm_handler[2123]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  526.554118] common_alarm_handler[2123]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  526.660705] common_alarm_handler[2123]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  526.792750] common_alarm_handler[2123]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> [  526.805497] common_alarm_handler[2123]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  526.818218] common_alarm_handler[2123]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  527.342861] common_alarm_handler[2123]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  527.438217] common_alarm_handler[2123]: topic = AlarmNotification; id = 40 <NL> [  527.510950] common_alarm_handler[2123]: topic = GenericOperInfoReq; id = 41 <NL> [  527.758482] common_alarm_handler[2123]: topic = PmRtrvReq; id = 42 <NL> [  527.986699] common_alarm_handler[2123]: topic = PmRtrvResp; id = 43 <NL> [  528.230321] common_alarm_handler[2123]: topic = PmInitReq; id = 44"}
{"timestamp_utc": "2024-07-31T08:21:02.457Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  528.374368] common_alarm_handler[2123]: topic = PmOperData; id = 45 <NL> [  528.513996] common_alarm_handler[2123]: topic = StateChange; id = 46 <NL> [  528.676486] common_alarm_handler[2123]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  528.846368] common_alarm_handler[2123]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  528.987447] common_alarm_handler[2123]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> ERROR:root:empty repository <NL> [  529.098946] common_alarm_handler[2123]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  529.314672] common_alarm_handler[2123]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  529.628415] common_alarm_handler[2123]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  529.722326] common_alarm_handler[2123]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  529.837649] common_alarm_handler[2123]: topic = EthIfProv; id = 56 <NL> [  530.032747] common_alarm_handler[2123]: topic = DcnNat64Attributes; id = 57 <NL> [  530.149288] common_alarm_handler[2123]: topic = DcnNat44Nat44Attributes; id = 58 <NL> 2024-07-31 08:20:58,275 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  530.327792] common_alarm_handler[2123]: topic = LldpGlobalCfgProv; id = 59 <NL> 2024-07-31 08:20:58,437 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  530.559158] common_alarm_handler[2123]: topic = LldpPortCfgProv; id = 60 <NL> 2024-07-31 08:20:58,653 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  530.731213] common_alarm_handler[2123]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> 2024-07-31 08:20:58,827 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  530.906620] common_alarm_handler[2123]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> 2024-07-31 08:20:58,995 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  531.073300] common_alarm_handler[2123]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  531.311934] common_alarm_handler[2123]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> 2024-07-31 08:20:59,359 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  531.460458] common_alarm_handler[2123]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> 2024-07-31 08:20:59,640 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  531.695415] common_alarm_handler[2123]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> 2024-07-31 08:20:59,848 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  531.976366] common_alarm_handler[2123]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  532.608121] common_alarm_handler[2123]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  532.640060] common_alarm_handler[2123]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  532.671397] common_alarm_handler[2123]: topic = DcnPppAttributesProv; id = 70 <NL> [  532.694492] common_alarm_handler[2123]: topic = LldpGlobalInstCfgProv; id = 71"}
{"timestamp_utc": "2024-07-31T08:21:02.458Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  532.756137] common_alarm_handler[2123]: topic = LldpBladeCfgProv; id = 72 <NL> [  532.813588] common_alarm_handler[2123]: topic = LldpPortInstCfgProv; id = 73 <NL> [  532.860190] common_alarm_handler[2123]: topic = DcnGreTunnelProv; id = 74 <NL> [  532.898562] common_alarm_handler[2123]: topic = DcnDnsClientResolverProv; id = 75"}
{"timestamp_utc": "2024-07-31T08:21:06.614Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:06 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:06 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:06.870Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  533.710679] usb_script_handler.py[3121]: 2024-Jul-31 08:20:50CommClient::CommClient Connection refused <NL> [  533.911890] usb_script_handler.py[3121]: 2024-Jul-31 08:20:52CommClient::CommClient Connection refused <NL> [  534.048052] usb_script_handler.py[3121]: 2024-Jul-31 08:20:54CommClient::CommClient Connection refused <NL> [  534.268368] usb_script_handler.py[3121]: 2024-Jul-31 08:20:56CommClient::CommClient Connection refused <NL> [  534.342879] common_alarm_handler[2137]: topic = FscProv; id = 111 <NL> [  534.512851] common_alarm_handler[2137]: topic = XconProv_v2Prov; id = 112 <NL> [  534.645508] common_alarm_handler[2137]: topic = OchIfProv; id = 113 <NL> [  535.064611] common_alarm_handler[2137]: topic = AclProfileProv; id = 114 <NL> [  535.420972] common_alarm_handler[2137]: topic = OtuProv; id = 115 <NL> [  535.580548] common_alarm_handler[2137]: topic = GeProv; id = 116 <NL> [  535.769193] common_alarm_handler[2137]: topic = OduProv; id = 117 <NL> [  535.956216] common_alarm_handler[2137]: topic = TcmProv; id = 118 <NL> [  536.205685] common_alarm_handler[2137]: topic = OCnProv; id = 119 <NL> [  536.251331] common_alarm_handler[2137]: topic = OnDemandDM; id = 120 <NL> [  536.343853] common_alarm_handler[2137]: topic = OducnProv; id = 121 <NL> [  536.430683] common_alarm_handler[2137]: topic = OtsiProv; id = 122 <NL> [  536.515260] common_alarm_handler[2137]: topic = OtsigProv; id = 123 <NL> [  536.616241] common_alarm_handler[2137]: topic = OtucnProv; id = 124 <NL> [  536.648244] common_alarm_handler[2137]: topic = YpgProv; id = 125 <NL> [  536.709478] common_alarm_handler[2137]: topic = EpgProv; id = 126 <NL> [  536.767200] common_alarm_handler[2137]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  536.920636] common_alarm_handler[2137]: topic = DataEncryptionOperReq; id = 128 <NL> [  537.011575] common_alarm_handler[2137]: topic = RoutePolicyTableProv; id = 129 <NL> [  537.047108] common_alarm_handler[2137]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  537.175804] common_alarm_handler[2137]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  537.255195] common_alarm_handler[2137]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  537.303244] common_alarm_handler[2137]: topic = ShapingProfileProv; id = 133 <NL> [  537.379636] common_alarm_handler[2137]: topic = TaildropProfileProv; id = 134 <NL> [  537.495203] common_alarm_handler[2137]: topic = PolicingProfileProv; id = 135 <NL> [  537.569714] common_alarm_handler[2137]: topic = CapabilityProfileProv; id = 136 <NL> [  537.586535] common_alarm_handler[2137]: topic = TransportInterfaceRateProv; id = 137 <NL> [  537.672954] common_alarm_handler[2137]: topic = PmRtrvReqSess; id = 138 <NL> [  537.769930] common_alarm_handler[2137]: topic = PmRtrvRespSess; id = 139 <NL> [  537.852983] common_alarm_handler[2137]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  537.901434] common_alarm_handler[2137]: topic = DataEncryptionPskReq; id = 141 <NL> 2024-07-31 08:21:03,767 swdllite(mgr): INFO - swdl_base_fsm_fn.cmd_line_processing[110] executing command: ssw-sync <NL> [  537.957938] common_alarm_handler[2137]: topic = SystemWebserverProv; id = 142 <NL> 2024-07-31 08:21:03,794 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  537.993484] common_alarm_handler[2137]: NO match: <NL> 2024-07-31 08:21:03,829 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  538.026480] common_alarm_handler[2137]: NO match: <NL> 2024-07-31 08:21:03,866 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  538.071618] common_alarm_handler[2137]: NO match: <NL> 2024-07-31 08:21:03,906 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  538.123266] cia_control_layer[2139]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:21:03,971 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> [  538.160077] cia_control_layer[2139]: EsalConfig::EsalConfig main 1 <NL> 2024-07-31 08:21:03,971 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  538.196189] cia_control_layer[2139]: EsalConfig::EsalConfig trib 0 <NL> 2024-07-31 08:21:04,047 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  538.239197] cia_control_layer[2139]: EsalConfig::EsalConfig ciRole 0 <NL> 2024-07-31 08:21:04,086 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  538.275265] cia_control_layer[2139]: EsalConfig is not running inside container. <NL> [  538.296460] cia_control_layer[2139]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> 2024-07-31 08:21:04,136 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  538.317262] cia_control_layer[2139]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  538.337658] cia_control_layer[2139]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  538.371408] cia_control_layer[2139]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  538.520310] cia_control_layer[2139]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  538.567454] cia_control_layer[2139]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  538.647125] cia_control_layer[2139]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  538.694181] cia_control_layer[2139]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  538.737633] cia_control_layer[2139]: isFileValid /var/shared/commsOscMode.conf  returning 1"}
{"timestamp_utc": "2024-07-31T08:21:06.871Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  538.839179] cia_control_layer[2139]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  538.937821] cia_control_layer[2139]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  538.996814] cia_control_layer[2139]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  539.043727] cia_control_layer[2139]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  539.101034] cia_control_layer[2139]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  539.166145] cia_control_layer[2139]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  539.252255] cia_control_layer[2139]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  539.470423] cia_control_layer[2139]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  539.701221] cia_control_layer[2139]: Control Layer started successfully. <NL> [  539.764914] cia_control_layer[2139]: Got the unitName from Platform General topic: BDC2-C200 <NL> [  539.765777] cia_control_layer[2139]: Xml found in the map for unitName: BDC2-C200 <NL> [  539.830500] cia_control_layer[2139]: Going with file C200_shelfData.xml <NL> [  539.831193] cia_control_layer[2139]: Setting Pm xml files as below: <NL> [  539.831810] cia_control_layer[2139]: Shelf: C200_shelfPmData.xml <NL> [  539.876521] cia_control_layer[2139]: Port: C200_pluggablePmData.xml <NL> [  539.877340] cia_control_layer[2139]: Eth: C200_dcnL2EthernetIfData.xml <NL> [  539.907694] usb_script_handler.py[3122]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf noSecondaryStorage' <NL> [  539.967519] usb_script_handler.py[3122]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" noSecondaryStorage' <NL> [  540.005212] usb_script_handler.py[3122]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  540.019736] usb_script_handler.py[3122]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  540.021367] sncp_app[2141]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  540.057243] usb_script_handler.py[3119]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf invalidUSB'"}
{"timestamp_utc": "2024-07-31T08:21:10.191Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  532.929669] common_alarm_handler[2123]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  532.988868] common_alarm_handler[2123]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  532.996092] common_alarm_handler[2123]: topic = SysGnmiCertProv; id = 78 <NL> [  532.996669] common_alarm_handler[2123]: topic = IetfInterfaceProv; id = 79 <NL> [  532.997357] common_alarm_handler[2123]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  533.038710] common_alarm_handler[2123]: topic = SystemAutoLogoffProv; id = 81 <NL> [  533.040420] common_alarm_handler[2123]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  533.128877] common_alarm_handler[2123]: topic = SystemPortsProv; id = 83 <NL> [  533.235671] common_alarm_handler[2123]: topic = OspfProvisioningModeProv; id = 84 <NL> [  533.406611] common_alarm_handler[2123]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  533.495495] common_alarm_handler[2123]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  533.602955] common_alarm_handler[2123]: topic = BasicGroupProv; id = 87 <NL> [  533.714739] common_alarm_handler[2123]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  533.785468] common_alarm_handler[2123]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  533.898706] common_alarm_handler[2123]: topic = SystemFipsProv; id = 90 <NL> [  533.910835] common_alarm_handler[2123]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  534.031817] common_alarm_handler[2123]: topic = SecuritySystemwideProv; id = 92 <NL> [  534.136938] common_alarm_handler[2123]: topic = DataEncryptionProv; id = 93 <NL> [  534.244854] common_alarm_handler[2123]: topic = SystemServicesProv; id = 94 <NL> [  534.287495] common_alarm_handler[2123]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  534.346931] common_alarm_handler[2123]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  534.382698] common_alarm_handler[2123]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  534.457964] common_alarm_handler[2123]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  534.509233] common_alarm_handler[2123]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  534.576520] common_alarm_handler[2123]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  534.627210] common_alarm_handler[2123]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  534.823460] common_alarm_handler[2123]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  534.979767] usb_script_handler.py[1734]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  535.146386] usb_script_handler.py[1734]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  535.249349] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[106] trying to mount usb as secondary storage <NL> Exception: Connect failed[  535.331034] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[108] checking for /dev/mapper/usb-secondary device <NL> [  535.460247] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[111] found /dev/mapper/usb-secondary device <NL> [  535.492187] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[118] USB ssw mount successful <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> [  535.618346] usb_script_handler.py[1734]: usb: INFO - usb_base.update_usb_psi_info[550] Publishing Mocked USB PSI Info on Qemu <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  535.718834] usb_script_handler.py[1734]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  535.896972] usb_script_handler.py[1734]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> [  536.304961] trb-cdsf-app[2124]: DDD cdsf-app running <NL> [  536.314602] common_alarm_handler[2123]: topic = FscProv; id = 111 <NL> [  536.315257] common_alarm_handler[2123]: topic = XconProv_v2Prov; id = 112 <NL> [  536.355893] common_alarm_handler[2123]: topic = OchIfProv; id = 113 <NL> [  536.605888] common_alarm_handler[2123]: topic = AclProfileProv; id = 114 <NL> [  536.817693] common_alarm_handler[2123]: topic = OtuProv; id = 115 <NL> [  536.867472] common_alarm_handler[2123]: topic = GeProv; id = 116 <NL> [  536.868136] common_alarm_handler[2123]: topic = OduProv; id = 117 <NL> [  536.868714] common_alarm_handler[2123]: topic = TcmProv; id = 118 <NL> [  536.870223] common_alarm_handler[2123]: topic = OCnProv; id = 119 <NL> [  536.872203] common_alarm_handler[2123]: topic = OnDemandDM; id = 120 <NL> [  536.996878] common_alarm_handler[2123]: topic = OducnProv; id = 121 <NL> [  536.997571] common_alarm_handler[2123]: topic = OtsiProv; id = 122 <NL> [  536.998166] common_alarm_handler[2123]: topic = OtsigProv; id = 123 <NL> [  536.998821] common_alarm_handler[2123]: topic = OtucnProv; id = 124 <NL> 2024-07-31 08:21:05,119 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  537.142166] common_alarm_handler[2123]: topic = YpgProv; id = 125 <NL> [  537.173288] common_alarm_handler[2123]: topic = EpgProv; id = 126 <NL> [  537.173883] common_alarm_handler[2123]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  537.341706] common_alarm_handler[2123]: topic = DataEncryptionOperReq; id = 128"}
{"timestamp_utc": "2024-07-31T08:21:10.192Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  537.461931] common_alarm_handler[2123]: topic = RoutePolicyTableProv; id = 129 <NL> [  537.630988] common_alarm_handler[2123]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  537.798279] common_alarm_handler[2123]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  537.799314] common_alarm_handler[2123]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  537.800309] common_alarm_handler[2123]: topic = ShapingProfileProv; id = 133 <NL> [  537.925835] common_alarm_handler[2123]: topic = TaildropProfileProv; id = 134 <NL> [  538.135333] common_alarm_handler[2123]: topic = PolicingProfileProv; id = 135 <NL> [  538.474528] common_alarm_handler[2123]: topic = CapabilityProfileProv; id = 136 <NL> [  538.784864] common_alarm_handler[2123]: topic = TransportInterfaceRateProv; id = 137 <NL> [  538.994337] common_alarm_handler[2123]: topic = PmRtrvReqSess; id = 138 <NL> [  539.227753] common_alarm_handler[2123]: topic = PmRtrvRespSess; id = 139 <NL> [  539.303202] common_alarm_handler[2123]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  539.304058] common_alarm_handler[2123]: topic = DataEncryptionPskReq; id = 141 <NL> [  539.358894] common_alarm_handler[2123]: topic = SystemWebserverProv; id = 142 <NL> [  539.437843] common_alarm_handler[2123]: NO match: <NL> [  539.456453] common_alarm_handler[2123]: NO match: <NL> [  539.472535] common_alarm_handler[2123]: NO match: <NL> [  539.531731] usb_script_handler.py[3093]: 2024-Jul-31 08:20:54CommClient::CommClient Connection refused <NL> [  539.621981] usb_script_handler.py[3093]: 2024-Jul-31 08:20:56CommClient::CommClient Connection refused <NL> [  539.789860] usb_script_handler.py[3093]: 2024-Jul-31 08:20:58CommClient::CommClient Connection refused <NL> [  539.935791] usb_script_handler.py[3093]: 2024-Jul-31 08:21:00CommClient::CommClient Connection refused <NL> [  539.998229] usb_script_handler.py[3093]: 2024-Jul-31 08:21:02CommClient::CommClient Connection refused <NL> [  540.127092] cia_control_layer[2125]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  540.251435] cia_control_layer[2125]: EsalConfig::EsalConfig main 1 <NL> [  540.334183] cia_control_layer[2125]: EsalConfig::EsalConfig trib 0 <NL> [  540.405623] cia_control_layer[2125]: EsalConfig::EsalConfig ciRole 0 <NL> [  540.529624] cia_control_layer[2125]: EsalConfig is not running inside container. <NL> [  540.530339] cia_control_layer[2125]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  540.531315] cia_control_layer[2125]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  540.626794] cia_control_layer[2125]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  540.735124] cia_control_layer[2125]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  540.777755] cia_control_layer[2125]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> 2024-07-31 08:21:08,793 swdllite(mgr): INFO - swdl_base_fsm_fn.cmd_line_processing[110] executing command: ssw-sync"}
{"timestamp_utc": "2024-07-31T08:21:11.557Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:11 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:11 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:13.448Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  421.721840] python3[4026]: [.131] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  421.741411] python3[4026]: [.151] valhdlr 140510596204352 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  421.764556] python3[4026]: [.151] valhdlr 140510596204352 callbackhdlr:391 Done register data callbacks <NL> [  421.771852] python3[4026]: DEBUG No crypto keys configured <NL> [  421.771982] python3[4026]: [.175] valhdlr 140510596204352 callbackhdlr:401 Unable to install crypto keys! <NL> [  421.795833] python3[4026]: [.183] valhdlr 140510596204352 callbackhdlr:322 Started data handler daemon... <NL> [  421.795973] python3[4026]: [.183] valhdlr 140510596204352 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  421.796648] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  421.796760] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  421.796848] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  421.796914] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  421.796970] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  421.833297] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  421.863310] confd_mgr[2874]: sm_startconfd::p0_ready_dbc <NL> [  421.863389] confd_mgr[2874]: Find message VALHDLR_CONFIRM <NL> [  421.863451] confd_mgr[2874]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  421.863506] confd_mgr[2874]: sm_startconfd::p0_not_ready <NL> [  421.863552] confd_mgr[2874]: Find message VALHDLR_CONFIRM <NL> [  421.863601] confd_mgr[2874]: sm_startconfd::p0_ready_no_dbc <NL> [  421.863658] confd_mgr[2874]: Find message VALHDLR_CONFIRM <NL> [  421.863703] confd_mgr[2874]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  421.863747] confd_mgr[2874]: leaving: sm_startconfd::wait_for_p0 <NL> [  421.863802] confd_mgr[2874]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  421.863853] confd_mgr[2874]: entering: sm_startconfd::start_confd_p1 <NL> [  421.863959] confd_mgr[2874]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  421.864054] confd_mgr[2874]: ConfdHA Not supported command CONFIRM <NL> [  421.864533] confd_mgr[4109]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:19:07 UTC 2024 <NL> [  422.270805] confd_mgr[4119]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  422.279115] confd_mgr[2874]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  476.996830] txid_tracker[3855]: ::::create_confd_subscription_connection() connected <NL> [  492.998846] confd_mgr[2874]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  493.045921] confd_mgr[4352]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:20:18 UTC 2024 <NL> [  493.176373] confd_mgr[4352]: Invoking confd_load_upgrade_xml.py <NL> [  495.422399] confd_mgr[4359]: confd_load_upgrade_xml.py: Start <NL> [  495.423336] confd_mgr[4359]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  496.319926] confd_mgr[2874]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  496.379573] confd_mgr[4374]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  496.444751] confd_mgr[2874]: CONFD IN PHASE 1 <NL> [  496.444923] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  496.452463] confd_mgr[2874]: leaving: sm_startconfd::start_confd_p1 <NL> [  496.452563] confd_mgr[2874]: entering: sm_startconfd::wait_for_p1 <NL> [  496.452626] confd_mgr[2874]: PROCESS3 has not registered yet. <NL> [  496.480919] python3[4107]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  496.546165] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  496.576757] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  496.587661] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  496.587744] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  496.587814] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  496.587876] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  496.587934] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  496.588018] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  496.613146] confd_mgr[2874]: sm_startconfd::p1_not_ready <NL> [  496.652667] confd_mgr[2874]: Find message MESSAGE3 <NL> [  496.652777] confd_mgr[2874]: sm_startconfd::p1_ready <NL> [  496.652841] confd_mgr[2874]: Find message MESSAGE3 <NL> [  496.652897] confd_mgr[2874]: leaving: sm_startconfd::wait_for_p1 <NL> [  496.652959] confd_mgr[2874]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  496.653037] confd_mgr[2874]: entering: sm_startconfd::wait_for_rm <NL> [  496.653095] confd_mgr[2874]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  496.653161] confd_mgr[2874]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  496.653220] confd_mgr[2874]: ConfdHA Not supported command CONFIRM <NL> [  496.653892] confd_mgr[4379]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:20:21 UTC 2024 <NL> [  497.057898] confd_mgr[4393]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  497.076169] confd_mgr[4396]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory"}
{"timestamp_utc": "2024-07-31T08:21:13.449Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  497.368350] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  497.407244] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  497.407405] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  497.431123] confd_mgr[4406]: /usr/bin/replay_manager NONE <NL> [  497.512937] confd_mgr[4404]: redundancy_status is STANDALONE <NL> [  497.513410] confd_mgr[4404]: DDS ports will be opened. <NL> [  497.513556] confd_mgr[4404]: execute replay_manager NONE TRUE <NL> [  498.180730] confd_mgr[4411]: TRACE Connected (cdb) to ConfD <NL> [  498.237528] confd_mgr[4411]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  498.238328] confd_mgr[4411]: TRACE Connected (cdb) to ConfD <NL> [  498.286472] confd_mgr[4411]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  503.344403] confd_mgr[4411]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  503.538666] txid_tracker[3855]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  503.584073] txid_tracker[4436]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  503.638566] confd_mgr[4411]: TRACE CDB_TRIGGER_SUBS <NL> [  503.643264] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  503.673570] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  503.696443] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  503.698768] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  503.718165] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  503.729661] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  503.745581] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  503.754987] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  519.880913] systemd-journald[360]: Data hash table of /run/log/journal/f8c9085252d349cbaec7cd0908673c96/system.journal has a fill level at 75.0 (13654 of 18204 items, 10485760 file size, 767 bytes per hash table item), suggesting rotation. <NL> [  519.989572] systemd-journald[360]: /run/log/journal/f8c9085252d349cbaec7cd0908673c96/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  539.682652] systemd-sysv-generator[4531]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  547.633116] systemd-sysv-generator[4563]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust."}
{"timestamp_utc": "2024-07-31T08:21:14.811Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  540.180739] usb_script_handler.py[3119]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" invalidUSB' <NL> [  540.248691] usb_script_handler.py[3119]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  540.380090] usb_script_handler.py[3119]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  540.676819] ypg_app[2142]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  540.981133] usb_script_handler.py[3121]: 2024-Jul-31 08:20:58CommClient::CommClient Connection refused <NL> [  541.449707] usb_script_handler.py[3121]: 2024-Jul-31 08:21:00CommClient::CommClient Connection refused <NL> [  541.650923] usb_script_handler.py[3121]: 2024-Jul-31 08:21:02CommClient::CommClient Connection refused <NL> [  542.056073] usb_script_handler.py[3124]: {\"command\": \"ssw-sync\"} <NL> ERROR:root:empty repository <NL> [  542.264392] usb_script_handler.py[3124]: {'return-value': 0, 'response-message': 'Ok, command accepted'} <NL> [  542.660400] usb_script_handler.py[3121]: 2024-Jul-31 08:21:04CommClient::CommClient Connection refused <NL> [  542.984954] usb_script_handler.py[3121]: Exception: Connect failed <NL> [  543.319422] confd_mgr_action_server[2144]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 200 <NL> [  543.763927] python3[2157]: [.709] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  544.043886] python3[2157]: [.733] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  544.059216] python3[2157]: [.749] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  544.064204] python3[2157]: [.749] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  544.065200] python3[2157]: [.750] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  544.066177] python3[2157]: [.768] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  544.067117] python3[2157]: [.774] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> 2024-07-31 08:21:09,986 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  544.414342] python3[2157]: [.794] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> 2024-07-31 08:21:10,445 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  544.749328] python3[2157]: [.794] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> 2024-07-31 08:21:10,704 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  545.145950] python3[2157]: [.795] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> 2024-07-31 08:21:11,344 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  545.613280] python3[2157]: [.839] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> 2024-07-31 08:21:11,590 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  545.842324] python3[2157]: [.850] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> 2024-07-31 08:21:11,801 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  546.036353] python3[2157]: [.880] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> 2024-07-31 08:21:11,909 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  546.107384] python3[2157]: [.880] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> 2024-07-31 08:21:11,988 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  546.184612] python3[2157]: [.880] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  546.354132] python3[2157]: [.880] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  546.401085] python3[2157]: [.885] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  546.438176] python3[2157]: [.885] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  546.461039] python3[2157]: [.885] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  546.566323] python3[2157]: [.917] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  546.652976] python3[2157]: [.917] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  546.701491] python3[2157]: [.917] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  546.731857] python3[2157]: [.917] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  546.786701] python3[2157]: [.946] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  546.847112] python3[2157]: [.974] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  546.896201] python3[2157]: [.974] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  546.938246] python3[2157]: [.999] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  546.956426] python3[2157]: [.999] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  546.962345] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  546.998590] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  547.043139] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  547.094434] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  547.146280] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  547.270251] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  547.352366] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  547.488762] python3[2157]: [.345] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  547.623117] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  547.725829] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  547.886853] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'}"}
{"timestamp_utc": "2024-07-31T08:21:16.697Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:16 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:16 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> [  540.798240] cia_control_layer[2125]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> 2024-07-31 08:21:08,809 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  540.814752] cia_control_layer[2125]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> 2024-07-31 08:21:08,833 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  540.852150] cia_control_layer[2125]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> 2024-07-31 08:21:08,883 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  540.907330] cia_control_layer[2125]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> 2024-07-31 08:21:08,937 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  540.947607] cia_control_layer[2125]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> 2024-07-31 08:21:08,962 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:21:08,962 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  540.983149] cia_control_layer[2125]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> 2024-07-31 08:21:09,040 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  541.084086] cia_control_layer[2125]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> 2024-07-31 08:21:09,138 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  541.188903] cia_control_layer[2125]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  541.217147] cia_control_layer[2125]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> 2024-07-31 08:21:09,237 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  541.281377] cia_control_layer[2125]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  541.326099] cia_control_layer[2125]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  541.368205] cia_control_layer[2125]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  541.393351] cia_control_layer[2125]: Control Layer started successfully. <NL> [  541.440168] cia_control_layer[2125]: Got the unitName from Platform General topic: BDC2-C200 <NL> [  541.504959] cia_control_layer[2125]: Xml found in the map for unitName: BDC2-C200 <NL> [  541.515747] cia_control_layer[2125]: Going with file C200_shelfData.xml <NL> [  541.558317] cia_control_layer[2125]: Setting Pm xml files as below: <NL> [  541.634252] cia_control_layer[2125]: Shelf: C200_shelfPmData.xml <NL> [  541.691938] cia_control_layer[2125]: Port: C200_pluggablePmData.xml <NL> [  541.729353] cia_control_layer[2125]: Eth: C200_dcnL2EthernetIfData.xml <NL> [  541.782286] usb_script_handler.py[3087]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf invalidUSB' <NL> [  541.861232] usb_script_handler.py[3087]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" invalidUSB' <NL> [  541.964396] usb_script_handler.py[3087]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  542.019585] usb_script_handler.py[3087]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  542.061408] usb_script_handler.py[3093]: 2024-Jul-31 08:21:04CommClient::CommClient Connection refused <NL> [  542.086375] ypg_app[2128]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  542.172784] usb_script_handler.py[3090]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf noSecondaryStorage' <NL> [  542.271981] usb_script_handler.py[3090]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" noSecondaryStorage' <NL> [  542.375605] usb_script_handler.py[3090]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  542.451401] usb_script_handler.py[3090]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  542.572641] usb_script_handler.py[3093]: 2024-Jul-31 08:21:06CommClient::CommClient Connection refused <NL> [  542.620219] usb_script_handler.py[3093]: 2024-Jul-31 08:21:08CommClient::CommClient Connection refused <NL> [  542.729553] confd_mgr_action_server[2130]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 200 <NL> [  542.858148] usb_script_handler.py[3091]: {\"command\": \"ssw-sync\"} <NL> [  542.938303] usb_script_handler.py[3091]: {'return-value': 0, 'response-message': 'Ok, command accepted'} <NL> [  543.113653] sncp_app[2127]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  543.265291] usb_script_handler.py[3093]: 2024-Jul-31 08:21:10CommClient::CommClient Connection refused <NL> [  544.037848] python3[2140]: [.100] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  544.118918] python3[2140]: [.100] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  544.294270] python3[2140]: [.132] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  544.472276] python3[2140]: [.155] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  544.647258] python3[2140]: [.155] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  544.754975] python3[2140]: [.185] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  544.804317] python3[2140]: [.211] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  544.889596] python3[2140]: [.211] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  544.994484] python3[2140]: [.211] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  545.230425] python3[2140]: [.297] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  545.415673] python3[2140]: [.298] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  545.570651] python3[2140]: [.298] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  545.709914] python3[2140]: [.298] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  546.111600] python3[2140]: [.298] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  546.261806] python3[2140]: [.303] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'}"}
{"timestamp_utc": "2024-07-31T08:21:16.698Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "ERROR:root:empty repository <NL> [  546.484140] python3[2140]: [.304] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  546.647872] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  546.885740] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  546.983534] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  547.151192] usb_script_handler.py[3093]: 2024-Jul-31 08:21:12CommClient::CommClient Connection refused <NL> [  547.265195] usb_script_handler.py[3093]: 2024-Jul-31 08:21:14CommClient::CommClient Connection refused <NL> [  547.322674] usb_script_handler.py[3093]: Exception: Connect failed <NL> [  547.338981] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'}"}
{"timestamp_utc": "2024-07-31T08:21:18.665Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  547.391784] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  547.456136] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> 2024-07-31 08:21:15,478 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  547.513649] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  547.558509] python3[2140]: [.418] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> 2024-07-31 08:21:15,588 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  547.612894] python3[2140]: [.509] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> 2024-07-31 08:21:15,641 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  547.662524] python3[2140]: [.555] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> 2024-07-31 08:21:15,678 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  547.700169] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> 2024-07-31 08:21:15,728 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  547.747077] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> 2024-07-31 08:21:15,772 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  547.794430] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  547.844162] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> 2024-07-31 08:21:15,866 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  547.874301] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  547.894727] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  547.919768] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> 2024-07-31 08:21:15,936 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {},"}
{"timestamp_utc": "2024-07-31T08:21:18.666Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "\"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  547.963966] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  548.072956] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  548.097805] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  548.119683] python3[2140]: [.587] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  548.135259] python3[2140]: [.588] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  548.251702] python3[2140]: [.588] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  548.289358] python3[2140]: [.588] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  548.316320] python3[2140]: [.588] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  548.343558] python3[2140]: [.588] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  548.375337] python3[2140]: [.588] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  548.398579] python3[2140]: [.588] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  548.419625] python3[2140]: [.599] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  548.439117] python3[2140]: [.599] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  548.454745] python3[2140]: [.637] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  548.462188] python3[2140]: [.637] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  548.483868] python3[2140]: [.637] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  548.496304] python3[2140]: [.637] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  548.509577] python3[2140]: [.637] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  548.533269] python3[2140]: [.637] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  548.544346] python3[2140]: [.669] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  548.553869] python3[2140]: [.669] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  548.569386] python3[2140]: [.669] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  548.570349] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  548.586879] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  548.621736] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  548.686296] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  548.713788] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  548.738329] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  548.762513] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  548.798186] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  548.810932] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  548.823733] python3[2140]: [.671] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  548.830369] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  548.849906] python3[2140]: [.699] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  548.871435] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  548.882705] python3[2140]: [.036] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  548.902647] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  548.088193] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  548.155116] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  548.275131] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  548.388701] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  548.467931] python3[2157]: [.346] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  548.497961] python3[2157]: [.424] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  548.620152] python3[2157]: [.424] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  548.699928] python3[2157]: [.432] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  548.791232] python3[2157]: [.435] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  548.813111] python3[2157]: [.466] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  548.841238] python3[2157]: [.466] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  548.901892] python3[2157]: [.466] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  548.990992] python3[2157]: [.466] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  549.049022] python3[2157]: [.496] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  549.087431] python3[2157]: [.496] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  549.128801] python3[2157]: [.496] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  549.159293] python3[2157]: [.496] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  549.195999] python3[2157]: [.496] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  549.367973] python3[2157]: [.496] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  549.475750] python3[2157]: [.497] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  549.555939] python3[2157]: [.497] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  549.616553] python3[2157]: [.513] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  549.661248] python3[2157]: [.339] hookhdlr 139927729420096 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  549.673126] python3[2157]: [.340] hookhdlr 139927729420096 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  549.674813] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.716221] python3[2157]: [.782] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  549.748464] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.767943] python3[2157]: [.800] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  549.768998] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.786419] python3[2157]: [.998] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  549.808976] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.809726] python3[2157]: [.139] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  549.886522] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.887636] python3[2157]: [.163] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  549.966352] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.967128] python3[2157]: [.177] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  549.993646] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  550.062707] python3[2157]: [.239] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  550.101067] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  550.101772] python3[2157]: [.295] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  550.102746] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  550.193202] python3[2157]: [.338] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  550.489539] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  550.595191] python3[2157]: [.357] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  550.664159] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  550.710947] python3[2157]: [.868] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1!"}
{"timestamp_utc": "2024-07-31T08:21:18.667Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  550.833317] confd_phase_sentry[2163]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  550.903060] confd_phase_sentry[2163]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  550.961876] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.060854] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.115809] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.223107] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.280707] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.359476] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.385327] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.463794] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.518968] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.587200] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.606485] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.622242] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.627607] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.638220] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:21:21.943Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:21 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:21 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:22.503Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  551.656479] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.729858] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.799309] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  551.927124] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.965519] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  552.085391] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.129112] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  552.264233] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.313381] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  552.381794] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.413252] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  552.489734] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.525809] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  552.609966] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.651041] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  552.707260] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.839169] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  552.940645] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.979389] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.036295] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.044220] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.045828] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.051975] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.053634] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.054476] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.063858] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.065348] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.157367] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.185476] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.207030] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.231867] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.296278] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.519046] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  553.979173] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.084093] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  554.333592] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.445908] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  554.693109] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.873127] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  555.051650] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.157713] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  555.382105] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.499501] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  555.542132] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.542868] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  555.581965] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.582761] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  555.619506] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.823906] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  555.828175] python3[2157]: [.903] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1!"}
{"timestamp_utc": "2024-07-31T08:21:23.063Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:21:22 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:21:23.624Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  548.921948] python3[2140]: [.095] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  548.945122] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  548.954577] python3[2140]: [.122] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  548.972603] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  548.987821] python3[2140]: [.218] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  549.012829] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.036905] python3[2140]: [.278] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  549.050026] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.050764] python3[2140]: [.523] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  549.088297] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.128315] python3[2140]: [.537] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  549.259857] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.286204] python3[2140]: [.574] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  549.311939] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.317178] python3[2140]: [.803] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1! <NL> [  549.318625] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.324991] python3[2140]: [.814] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1! <NL> [  549.345938] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.346720] python3[2140]: [.878] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  549.404708] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.429848] python3[2140]: [.957] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  549.462608] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.494547] python3[2140]: [.972] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 15 of -1! <NL> [  549.532590] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.551679] python3[2140]: [.986] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 16 of -1! <NL> [  549.563690] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  549.574485] python3[2140]: [.015] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 17 of -1! <NL> [  549.622667] confd_phase_sentry[2144]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  549.756283] confd_phase_sentry[2144]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  549.871583] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  550.209290] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  550.399030] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  550.992902] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.168536] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  551.633778] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.648259] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  551.694601] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.709258] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  551.771871] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.792722] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  551.819871] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.820916] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  551.873705] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.168835] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  552.308249] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.464051] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  552.678889] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  552.842308] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  553.104989] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:21:23.625Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  553.234177] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  553.444325] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.520376] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  553.610277] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.685099] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  553.788162] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.840657] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  553.921574] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.957449] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.026265] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.099446] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:21:26.199Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  554.183384] python3[2140]: [.029] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 18 of -1! <NL> [  554.266071] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.338276] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.364338] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.397734] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.398498] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.479660] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.509399] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.554698] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.567383] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.735182] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.759500] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.767079] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:21:26.200Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  554.772850] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.851074] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.853825] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  554.855477] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  554.999640] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.002661] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.003397] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.124827] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.155196] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.207509] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.215997] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.218046] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.257660] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.259260] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.259969] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.304781] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.346986] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.387808] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.388644] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.390257] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.500648] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.649840] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.690436] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.749351] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.818099] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.859876] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.860678] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.894834] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  555.930827] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  555.976567] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.027881] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.051508] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.063267] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.093130] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.138070] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.139708] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:21:26.456Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:26 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> [  555.917067] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.049373] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:21:26.457Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  556.108108] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.206257] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.224731] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.315306] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.401264] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.517790] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.592568] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.716744] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.759623] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.827547] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.883307] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.927323] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.961510] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  556.996354] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.194452] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  557.322107] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.396887] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  557.473204] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.474568] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  557.634710] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.665239] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  557.772158] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.819658] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  557.915487] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.981176] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  558.037855] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  558.059216] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  558.190954] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  558.313792] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  558.452348] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  558.611725] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.015068] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.050060] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.120292] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.155303] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.191648] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.192409] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.227867] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.229371] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.354364] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.356566] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.366955] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.392715] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.574458] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.575346] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.598414] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  559.629661] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.838115] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> # 03:21:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:26 retry-ssh-command INFO: attempt 105, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:27.907Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:21:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:28.466Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:21:28 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp85.fnc.net.local:46502\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:21:31.729Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:31 retry-ssh-command INFO: attempt 105, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:31 retry-ssh-command INFO: attempt 106, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:33.620Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:21:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:36.882Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:36 retry-ssh-command INFO: attempt 106, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:36 retry-ssh-command INFO: attempt 107, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> [  556.248510] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.289883] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.315541] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.369647] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.394296] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.460381] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.553090] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.612331] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.653414] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.655137] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.655891] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.720763] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.755283] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.797402] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.814860] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  556.853709] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.983149] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.004411] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.005215] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.097203] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.106042] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.107821] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.108523] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.136152] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.136884] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.201994] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.202771] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.245260] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.246020] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.273406] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.274134] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.305732] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  557.384578] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  557.554671] temp_acct_cleanup_app[2152]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  557.583481] temp_acct_cleanup_app[2152]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  557.683818] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 1 <NL> [  557.721204] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 2 <NL> [  557.762967] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 3 <NL> [  557.802439] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 4 <NL> [  557.843709] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 5 <NL> [  557.844443] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 6 <NL> [  557.875126] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 7 <NL> [  557.875948] txid_tracker[2153]: ::::create_confd_subscription_connection() try number 8 <NL> [  559.039905] cseries_hal[2159]: HAL main() begins. <NL> [  559.197466] cseries_hal[2159]: hal_default::hal_init() called <NL> [  559.198103] cseries_hal[2159]: EsalPmiClient::EsalPmiClient <NL> [  559.693974] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  560.089427] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  563.890940] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 1"}
{"timestamp_utc": "2024-07-31T08:21:36.883Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  564.312095] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 2 <NL> [  564.724269] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 3 <NL> [  564.793388] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 4 <NL> [  564.978865] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 5 <NL> [  565.215822] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 6 <NL> [  565.216647] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 7 <NL> [  565.217353] txid_tracker[2354]: ::::create_confd_subscription_connection() try number 8 <NL> [  565.322198] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  565.465218] python3[2140]: [.061] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 19 of -1! <NL> [  565.730314] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  565.809389] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  566.631527] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 1"}
{"timestamp_utc": "2024-07-31T08:21:42.119Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:41 retry-ssh-command INFO: attempt 107, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:41 retry-ssh-command INFO: attempt 108, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:46.282Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:46 retry-ssh-command INFO: attempt 108, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:46.538Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:46 retry-ssh-command INFO: attempt 109, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:51.779Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:51 retry-ssh-command INFO: attempt 109, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> [  559.872882] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  559.967149] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  560.025920] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  560.198303] temp_acct_cleanup_app[2172]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  560.312043] temp_acct_cleanup_app[2172]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  560.433997] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 1 <NL> [  560.730298] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 2 <NL> [  560.796722] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 3 <NL> [  560.938728] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 4 <NL> [  561.017945] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 5 <NL> [  561.110056] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 6 <NL> [  561.173366] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 7 <NL> [  561.285328] txid_tracker[2173]: ::::create_confd_subscription_connection() try number 8 <NL> [  561.644608] cseries_hal[2178]: HAL main() begins. <NL> [  562.028748] cseries_hal[2178]: hal_default::hal_init() called <NL> [  562.115707] cseries_hal[2178]: EsalPmiClient::EsalPmiClient <NL> [  562.596684] cseries_hal[2178]: EsalPmiClient::sharedMemoryInit nPorts/size/nPorts/additionalBuffers 50/6160/50/49 <NL> [  562.708375] cseries_hal[2178]: EsalShm::createShmSegment <NL> [  562.737677] cseries_hal[2178]: EsalShm::createShmSegment attaching to existing shm segment <NL> [  563.940148] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 1 <NL> [  563.978379] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 2 <NL> [  564.158756] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 3 <NL> [  564.258541] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 4 <NL> [  564.325100] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 5 <NL> [  564.461737] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 6 <NL> [  564.472802] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 7 <NL> [  564.505578] txid_tracker[2294]: ::::create_confd_subscription_connection() try number 8 <NL> [  564.801247] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  565.305502] python3[2157]: [.960] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  565.488426] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  565.805985] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  566.851453] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 1 <NL> [  567.689201] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 2 <NL> [  568.520989] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 3 <NL> [  568.844478] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 4 <NL> [  568.993848] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 5 <NL> [  569.721871] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 6 <NL> [  570.116220] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 7 <NL> [  570.584360] txid_tracker[2490]: ::::create_confd_subscription_connection() try number 8 <NL> [  571.463925] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  573.143767] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  575.202671] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  575.203504] python3[2157]: [.181] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  575.361750] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  575.849299] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  576.211892] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 1 <NL> [  576.510248] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 2 <NL> [  576.822350] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 3 <NL> [  577.365830] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 4 <NL> [  577.944161] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 5 <NL> [  578.721123] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 6 <NL> [  579.047278] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 7 <NL> [  579.403662] txid_tracker[2631]: ::::create_confd_subscription_connection() try number 8 <NL> [  580.030600] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  580.271839] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  580.877612] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 1 <NL> [  580.878730] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 2 <NL> [  581.075758] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 3 <NL> [  581.209036] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 4 <NL> [  581.308620] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 5 <NL> [  581.388461] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 6 <NL> [  581.526614] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 7 <NL> [  581.606248] txid_tracker[2799]: ::::create_confd_subscription_connection() try number 8 <NL> [  581.786951] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 1 <NL> [  581.841136] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 2 <NL> [  581.901525] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 3 <NL> [  582.037816] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 4 <NL> [  582.209164] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 5 <NL> [  582.393427] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 6 <NL> [  582.526554] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 7 <NL> [  582.736566] txid_tracker[2918]: ::::create_confd_subscription_connection() try number 8 <NL> [  582.957288] startup_finished.py[2045]: Startup Finished: systemd state is non-Production mode and running <NL> [  583.262170] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 1 <NL> [  583.522644] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 2"}
{"timestamp_utc": "2024-07-31T08:21:51.780Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  583.658435] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 3 <NL> [  583.659204] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 4 <NL> [  583.789161] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 5 <NL> [  584.147938] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 6 <NL> [  584.240608] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 7 <NL> [  584.441386] txid_tracker[3001]: ::::create_confd_subscription_connection() try number 8 <NL> [  584.608036] confd_director.py[3280]: rm: cannot remove '/var/shared/confd/ha_status': No such file or directory <NL> # 03:21:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:51 retry-ssh-command INFO: attempt 110, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:57.020Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:56 retry-ssh-command INFO: attempt 110, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:56 retry-ssh-command INFO: attempt 111, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:58.383Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  567.363532] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 2 <NL> [  567.499926] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 3 <NL> [  567.712409] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 4 <NL> [  567.816495] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 5 <NL> [  567.974521] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 6 <NL> [  568.060591] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 7 <NL> [  568.215697] txid_tracker[2518]: ::::create_confd_subscription_connection() try number 8 <NL> [  569.078261] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 1 <NL> [  569.321281] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 2 <NL> [  569.719504] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 3 <NL> [  570.010177] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 4 <NL> [  570.847593] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 5 <NL> [  571.297437] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 6 <NL> [  571.732273] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 7 <NL> [  572.142632] txid_tracker[2666]: ::::create_confd_subscription_connection() try number 8 <NL> [  572.547041] confd_director.py[3202]: rm: cannot remove '/var/shared/confd/ha_status': No such file or directory <NL> [  573.434450] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  573.576140] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  575.240482] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  575.346185] python3[2140]: [.288] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 20 of -1! <NL> [  575.517508] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  575.828907] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  576.191711] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 1 <NL> [  576.514269] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 2 <NL> [  576.515117] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 3 <NL> [  576.515817] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 4 <NL> [  576.719042] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 5 <NL> [  577.094337] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 6 <NL> [  577.397860] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 7 <NL> [  577.877836] txid_tracker[2859]: ::::create_confd_subscription_connection() try number 8 <NL> [  578.377612] cseries_hal[2159]: EsalPmiClient::sharedMemoryInit nPorts/size/nPorts/additionalBuffers 50/6160/50/49 <NL> [  578.654684] cseries_hal[2159]: EsalShm::createShmSegment <NL> [  578.655311] cseries_hal[2159]: EsalShm::createShmSegment attaching to existing shm segment <NL> [  578.688178] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 1 <NL> [  578.688935] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 2 <NL> [  578.809221] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 3 <NL> [  578.887349] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 4 <NL> [  579.098447] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 5 <NL> [  579.431648] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 6 <NL> [  579.675724] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 7 <NL> [  579.840493] txid_tracker[2946]: ::::create_confd_subscription_connection() try number 8 <NL> [  580.246946] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  580.582249] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  581.005610] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 1 <NL> [  581.006443] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 2 <NL> [  581.072992] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 3 <NL> [  581.085657] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 4 <NL> [  581.155843] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 5 <NL> [  581.291700] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 6 <NL> [  581.399932] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 7 <NL> [  581.504543] txid_tracker[3012]: ::::create_confd_subscription_connection() try number 8 <NL> [  581.633964] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 1 <NL> [  581.903187] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 2 <NL> [  581.978826] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 3 <NL> [  581.979597] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 4 <NL> [  581.980311] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 5 <NL> [  582.049955] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 6 <NL> [  582.051891] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 7 <NL> [  582.296039] txid_tracker[3052]: ::::create_confd_subscription_connection() try number 8 <NL> [  582.560521] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 1 <NL> [  582.643238] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 2 <NL> [  582.884733] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 3 <NL> [  583.158664] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 4 <NL> [  583.427449] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 5 <NL> [  583.468229] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 6 <NL> [  583.554865] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 7 <NL> [  583.785440] txid_tracker[3130]: ::::create_confd_subscription_connection() try number 8 <NL> [  583.969498] startup_finished.py[2047]: Startup Finished: systemd state is non-Production mode and running <NL> [  584.499679] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  584.628858] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  584.864515] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  584.927046] python3[2140]: [.476] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 21 of -1! <NL> [  585.373635] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 1 <NL> [  585.664067] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 2 <NL> [  586.037078] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 3 <NL> [  586.214761] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 4 <NL> [  586.395448] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 5 <NL> [  586.609335] cseries_hal[2159]: EsalShm::createShmSegment timeout opening syncPath <NL> [  586.798364] cseries_hal[2159]: EsalPmiClient::dumpShm pmShm is null <NL> [  587.004924] startup_finished.py[2047]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  588.061633] confd_mgr[3273]: ConfdMgrConf: DB signature is NOT supported <NL> [  588.618090] confd_mgr[3273]: Read reset type failed basic_ios::clear: iostream error <NL> [  588.819536] confd_mgr[3273]: Use reset_type = NONE    rollback_timer = 000000"}
{"timestamp_utc": "2024-07-31T08:22:01.647Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:22:01 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',) <NL> # 03:22:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:01 retry-ssh-command INFO: attempt 111, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:01 retry-ssh-command INFO: attempt 112, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:04.162Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  588.313484] ntputils[1963]: bool NTPServer::handle_command(const string&) <NL> [  588.313650] ntputils[1963]: bool NTPServer::handle_configure_cmd(const string&) <NL> [  588.313741] ntputils[1963]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  588.313823] ntputils[1963]: parse_time_persistent_topic ddskind create <NL> [  588.313878] ntputils[1963]: parse_time_persistent_topic name key config <NL> [  588.313936] ntputils[1963]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  588.314035] ntputils[1963]: parse_time_topics command_data enable=yes; <NL> [  588.314090] ntputils[1963]: handle_configure_cmd token is: enable=yes <NL> [  588.314145] ntputils[1963]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  588.314200] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  588.314288] ntputils[1963]: systemctl --no-block stop ntpd <NL> [  588.601827] ntputils[1963]: child pid is 4637 <NL> [  588.888163] ntputils[1963]: exited, status is 0 <NL> [  588.888712] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  589.333721] ntputils[1963]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  589.540154] ntputils[1963]: child pid is 4651 <NL> [  589.540546] ntputils[1963]: exited, status is 0 <NL> [  589.540623] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  589.540678] ntputils[1963]: /bin/systemctl reset-failed ntpd <NL> [  589.573971] ntputils[1963]: child pid is 4668 <NL> [  589.646565] userddssub[4638]: useradd: user 'fujitsu' already exists <NL> [  589.745332] ntputils[1963]: exited, status is 0 <NL> [  589.791164] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  589.811979] ntputils[1963]: systemctl --no-block start ntpd <NL> [  589.949428] ntputils[1963]: child pid is 4674 <NL> [  590.121836] dcn_dns_controller[1592]: fin_file is open <NL> [  590.278063] userddssub[2438]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  590.645769] ntputils[1963]: exited, status is 0 <NL> [  590.645905] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  590.645960] ntputils[1963]: systemctl --no-block start ntpscript <NL> [  590.646033] ntputils[1963]: child pid is 4681 <NL> [  590.646096] ntputils[1963]: exited, status is 0 <NL> [  590.646159] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  590.655291] ntputils[1963]: /bin/systemctl --no-block start init_state_check.timer <NL> [  590.655374] ntputils[1963]: child pid is 4684 <NL> [  591.327256] ntputils[1963]: exited, status is 0 <NL> [  591.327373] ntputils[1963]: Configure command handled successfully, writing to RTC"}
{"timestamp_utc": "2024-07-31T08:22:04.163Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  591.327431] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  591.327483] ntputils[1963]: /sbin/hwclock -u --systohc <NL> [  591.386348] ntputils[1963]: child pid is 4704 <NL> [  591.707670] dcn_dns_controller[1592]: fin_file is open <NL> [  591.762362] ntputils[1963]: exited, status is 0 <NL> [  591.883591] ntputils[1963]: bool NTPServer::handle_command(const string&) <NL> [  592.068696] ntputils[1963]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [  592.068887] ntputils[1963]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  592.068948] ntputils[1963]: parse_time_persistent_topic ddskind create <NL> [  592.070398] ntputils[1963]: parse_time_persistent_topic name key setTZ <NL> [  592.070560] ntputils[1963]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  592.070620] ntputils[1963]: parse_time_topics command_data timezone=UTC; <NL> [  592.070685] ntputils[1963]: bool NTPServer::set_timezone(const string&) <NL> [  592.163832] ntputils[1963]: NTPServer::execute_cmd spawning: <NL> [  592.352147] ntputils[1963]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  592.352292] ntputils[1963]: child pid is 4712 <NL> [  592.353667] ntputils[1963]: exited, status is 0 <NL> [  592.353752] ntputils[1963]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  592.353811] ntputils[1963]: push_local_changes user_changed: 1 delta: 0 <NL> [  592.353870] ntputils[1963]: local_push OK u Platform::Time changedByUser 1 <NL> [  592.353932] ntputils[1963]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  592.353988] ntputils[1963]: local_push OK w Platform::Time 0 0 <NL> [  592.561506] ntputils[1963]: push_local_changes OK <NL> [  592.561620] ntputils[1963]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  592.561673] ntputils[1963]: publish_local_changes OK <NL> [  593.994203] ntp_alarm_event_monitor.py[4683]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  593.994358] ntp_alarm_event_monitor.py[4683]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  594.105949] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3416 <NL> [  594.157278] layer1_control_layer[2411]: EsalConfig::EsalConfig main 1 <NL> [  594.157401] layer1_control_layer[2411]: EsalConfig::EsalConfig trib 0 <NL> [  594.157460] layer1_control_layer[2411]: EsalConfig::EsalConfig ciRole 0 <NL> [  594.505776] ntp_alarm_event_monitor.py[4683]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  594.597586] ntp_alarm_event_monitor.py[4683]: INFO:root:redundancy status now set to standalone <NL> [  594.661898] layer1_control_layer[2411]: EsalConfig is not running inside container. <NL> [  594.676602] layer1_control_layer[2411]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  594.676762] layer1_control_layer[2411]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  594.676825] layer1_control_layer[2411]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  594.676884] layer1_control_layer[2411]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  594.676944] layer1_control_layer[2411]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  594.677015] layer1_control_layer[2411]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  594.677074] layer1_control_layer[2411]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  594.677133] layer1_control_layer[2411]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  594.677194] layer1_control_layer[2411]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  594.677259] layer1_control_layer[2411]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  594.677903] layer1_control_layer[2411]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  594.677990] layer1_control_layer[2411]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  594.678064] layer1_control_layer[2411]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  594.678124] layer1_control_layer[2411]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  594.678182] layer1_control_layer[2411]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  594.678247] layer1_control_layer[2411]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  594.678307] layer1_control_layer[2411]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  595.409781] ntp_alarm_event_monitor.py[4683]: INFO:root:Publish Alarm: Raising alarm <NL> [  595.410494] ntp_alarm_event_monitor.py[4683]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  596.319444] confd_mgr[4411]:  --> CONFD_OK <NL> [  596.525604] confd_mgr[4806]: openDdsPorts interfaces  eth5.2003 <NL> [  596.525853] confd_mgr[4806]: openDdsPorts Input udpPorts-  7660 <NL> [  596.627070] confd_mgr[4806]: openDdsPorts Output udpPorts-  7660 <NL> [  596.879173] confd_mgr[4806]: openDdsPorts Input udpPorts-  7661 <NL> [  597.075175] confd_mgr[4806]: openDdsPorts Output udpPorts-  7661 <NL> [  597.360689] confd_mgr[4806]: openDdsPorts Input udpPorts-  7650 <NL> [  597.450072] confd_mgr[4806]: openDdsPorts Output udpPorts-  7650 <NL> [  597.500853] confd_mgr[4806]: openDdsPorts Input udpPorts-  7651 <NL> [  597.697829] confd_mgr[4806]: openDdsPorts Output udpPorts-  7651 <NL> [  597.827412] confd_mgr[4806]: openDdsPorts Input udpPorts-  7900 <NL> [  598.029081] confd_mgr[4806]: openDdsPorts Output udpPorts-  7900 <NL> [  598.215620] confd_mgr[4806]: openDdsPorts Input udpPorts-  7901"}
{"timestamp_utc": "2024-07-31T08:22:06.674Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:22:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:06 retry-ssh-command INFO: attempt 112, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:06 retry-ssh-command INFO: attempt 113, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:07.599Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:22:07 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp85.fnc.net.local:46502\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:22:12.535Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:11 retry-ssh-command INFO: attempt 113, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:11 retry-ssh-command INFO: attempt 114, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:16.766Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:16 retry-ssh-command INFO: attempt 114, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:16 retry-ssh-command INFO: attempt 115, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:22.128Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:21 retry-ssh-command INFO: attempt 115, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:21 retry-ssh-command INFO: attempt 116, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:27.464Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:26 retry-ssh-command INFO: attempt 116, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:26 retry-ssh-command INFO: attempt 117, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',) <NL> [  584.915664] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  585.031180] python3[2157]: [.216] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 15 of -1! <NL> [  585.721140] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  585.960506] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  586.374664] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 1 <NL> [  587.198459] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 2 <NL> [  587.200258] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 3 <NL> [  587.202397] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 4 <NL> [  587.206106] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 5 <NL> [  587.460861] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 6 <NL> [  587.940670] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 7 <NL> [  588.398995] txid_tracker[3053]: ::::create_confd_subscription_connection() try number 8 <NL> [  589.177429] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 1 <NL> [  589.630986] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 2 <NL> [  589.856332] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 3 <NL> [  590.016224] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 4 <NL> [  590.082037] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 5 <NL> [  590.241519] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 6 <NL> [  590.345811] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 7 <NL> [  590.453077] txid_tracker[3125]: ::::create_confd_subscription_connection() try number 8 <NL> [  590.883022] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  591.020496] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  591.644520] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 1 <NL> [  591.904091] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 2 <NL> [  592.271720] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 3 <NL> [  592.530070] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 4 <NL> [  593.038130] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 5 <NL> [  593.608380] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 6 <NL> [  594.116276] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 7 <NL> [  594.782245] txid_tracker[3200]: ::::create_confd_subscription_connection() try number 8 <NL> [  595.547391] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  596.317701] python3[2157]: [.314] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 16 of -1! <NL> [  596.430094] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  596.431296] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  596.587451] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 1 <NL> [  596.588277] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 2 <NL> [  596.684728] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 3 <NL> [  596.831737] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 4 <NL> [  596.937424] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 5 <NL> [  597.179392] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 6 <NL> [  597.395529] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 7 <NL> [  597.673177] txid_tracker[3265]: ::::create_confd_subscription_connection() try number 8 <NL> [  598.316120] dcn_dns_controller[1390]: dnsClientStartup() <NL> [  598.488444] dcn_dns_controller[1390]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  598.736191] dcn_dns_controller[1390]: fin_dnsmasq_conf is open <NL> [  600.100314] startup_finished.py[2045]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  600.686532] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  601.047406] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  601.689377] cseries_hal[2178]: EsalShm::createShmSegment timeout opening syncPath <NL> [  602.151192] cseries_hal[2178]: EsalPmiClient::dumpShm pmShm is null <NL> [  603.150977] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 1 <NL> [  604.630372] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  604.841298] python3[2157]: [.401] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 17 of -1! <NL> [  606.150458] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 2 <NL> [  606.624538] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  606.702231] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  608.008862] cia_control_layer[2139]:    ChalApi Constructor with tid = 3044 <NL> [  608.354357] cseries_hal[2178]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  609.539382] startup_finished.py[2045]: *****Startup Finished: stopping EOW timer***** <NL> [  610.302587] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 3 <NL> [  610.476934] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  610.838795] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  612.264345] led_controller[2179]:    ChalApi Constructor with tid = 2179 <NL> [  613.287366] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 4 <NL> [  613.785325] startup_finished.py[2045]: systemctl stop startup_finished_limit.timer <NL> [  614.875211] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  615.108841] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  615.561960] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  615.624244] python3[2157]: [.475] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 18 of -1! <NL> [  617.090410] python3[3321]: INFO:root:Started rsync_logfile.py... <NL> [  617.203659] python3[3321]: INFO:root:redundancy status = STANDALONE <NL> [  617.274744] python3[3321]: INFO:root:redundancy mode = UNKNOWN <NL> [  617.276456] python3[3321]: <NL> [  617.301184] python3[3321]: ERROR:root:Error: System is not in redundancy mode <NL> [  617.506439] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 5 <NL> [  618.146431] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 6 <NL> [  618.375265] dcn_ka[1392]: KaSessMgr Process Startup"}
{"timestamp_utc": "2024-07-31T08:22:27.465Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  620.190195] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:22:30.738Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  210.235058] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.072229, delay 0.03954\\n31 Jul 08:15:38 ntpdate[2681]: no server suitable for synchronization found\\n' <NL> [  222.351777] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  222.351955] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  222.352045] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.079059, delay 0.07661\\n31 Jul 08:15:50 ntpdate[2708]: no server suitable for synchronization found\\n' <NL> [  234.271643] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  234.272083] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  234.272161] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.082975, delay 0.08937\\n31 Jul 08:16:02 ntpdate[2739]: no server suitable for synchronization found\\n' <NL> [  246.178210] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  246.178581] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  246.178669] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.075999, delay 0.03719\\n31 Jul 08:16:14 ntpdate[2793]: no server suitable for synchronization found\\n' <NL> [  258.603260] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  258.603533] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  258.603610] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.080487, delay 0.06624\\n31 Jul 08:16:27 ntpdate[2820]: no server suitable for synchronization found\\n' <NL> [  270.699765] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  270.708318] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  270.723084] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.077824, delay 0.05450\\n31 Jul 08:16:39 ntpdate[2854]: no server suitable for synchronization found\\n' <NL> [  282.568204] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  282.568954] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  282.600475] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.071017, delay 0.02773\\n31 Jul 08:16:51 ntpdate[2881]: no server suitable for synchronization found\\n' <NL> [  294.458820] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  294.523370] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  294.659091] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.072919, delay 0.04465\\n31 Jul 08:17:02 ntpdate[2914]: no server suitable for synchronization found\\n' <NL> [  306.332386] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  306.352072] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  306.375376] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.084517, delay 0.06190\\n31 Jul 08:17:14 ntpdate[2954]: no server suitable for synchronization found\\n' <NL> [  318.242518] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  318.256716] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  318.285824] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.074678, delay 0.04169\\n31 Jul 08:17:26 ntpdate[2982]: no server suitable for synchronization found\\n' <NL> [  330.286422] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  330.337421] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  330.337507] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.073359, delay 0.03609\\n31 Jul 08:17:38 ntpdate[3016]: no server suitable for synchronization found\\n' <NL> [  342.249755] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  342.267348] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  342.288640] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.082645, delay 0.07396\\n31 Jul 08:17:50 ntpdate[3057]: no server suitable for synchronization found\\n' <NL> [  354.156144] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  354.158129] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  354.200136] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.074875, delay 0.03688\\n31 Jul 08:18:02 ntpdate[3084]: no server suitable for synchronization found\\n' <NL> [  366.174772] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  366.174982] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  366.207546] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.071616, delay 0.02921\\n31 Jul 08:18:14 ntpdate[3149]: no server suitable for synchronization found\\n' <NL> [  378.072228] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  378.095139] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  378.122342] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.070644, delay 0.02643\\n31 Jul 08:18:26 ntpdate[3179]: no server suitable for synchronization found\\n' <NL> [  389.991746] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  389.994639] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  389.994734] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.070676, delay 0.02719\\n31 Jul 08:18:38 ntpdate[3216]: no server suitable for synchronization found\\n' <NL> [  401.897887] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  401.898082] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  401.898152] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.065077, delay 0.04108\\n31 Jul 08:18:50 ntpdate[3247]: no server suitable for synchronization found\\n' <NL> [  413.958373] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  413.958788] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  413.958853] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.064854, delay 0.05382\\n31 Jul 08:19:02 ntpdate[3274]: no server suitable for synchronization found\\n' <NL> [  425.641333] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  425.641551] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  425.641696] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.073312, delay 0.03221\\n31 Jul 08:19:14 ntpdate[3302]: no server suitable for synchronization found\\n' <NL> [  437.577027] ntputils_client.py[1727]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:22:30.739Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  437.579590] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  437.591917] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.076287, delay 0.05942\\n31 Jul 08:19:26 ntpdate[3347]: no server suitable for synchronization found\\n' <NL> [  449.493417] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  449.546603] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  449.547604] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.073762, delay 0.04221\\n31 Jul 08:19:38 ntpdate[3379]: no server suitable for synchronization found\\n' <NL> [  593.734459] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  593.734869] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  593.757886] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.009946, delay 0.04512\\n31 Jul 08:22:02 ntpdate[3794]: no server suitable for synchronization found\\n' <NL> [  602.394240] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  602.394444] ntputils_client.py[1727]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  602.394511] ntputils_client.py[1727]: b'31 Jul 08:22:10 ntpdate[3803]: no server suitable for synchronization found\\n' <NL> [  609.561134] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  609.614295] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  609.614376] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.009635, delay 0.04028\\n31 Jul 08:22:18 ntpdate[3853]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:22:31.698Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:31 retry-ssh-command INFO: attempt 117, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:31.955Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:31 retry-ssh-command INFO: attempt 118, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:37.207Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:36 retry-ssh-command INFO: attempt 118, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:36 retry-ssh-command INFO: attempt 119, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:39.096Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  532.889378] python3[4141]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  532.889514] confd_mgr[2866]: sm_startconfd::p1_not_ready <NL> [  532.889595] confd_mgr[2866]: Find message MESSAGE3 <NL> [  532.889659] confd_mgr[2866]: sm_startconfd::p1_ready <NL> [  532.889803] confd_mgr[2866]: Find message MESSAGE3 <NL> [  532.889893] confd_mgr[2866]: leaving: sm_startconfd::wait_for_p1 <NL> [  532.889971] confd_mgr[2866]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  532.890045] confd_mgr[2866]: entering: sm_startconfd::wait_for_rm <NL> [  532.890107] confd_mgr[2866]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  532.890170] confd_mgr[2866]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  532.890231] confd_mgr[2866]: ConfdHA Not supported command CONFIRM <NL> [  533.014889] confd_mgr[4418]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:20:59 UTC 2024 <NL> [  533.261440] confd_mgr[4434]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  533.379459] confd_mgr[4438]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  533.584600] confd_mgr[2866]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  533.585067] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  533.585234] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  533.635166] confd_mgr[4448]: /usr/bin/replay_manager NONE <NL> [  533.690696] confd_mgr[4446]: redundancy_status is STANDALONE <NL> [  533.691514] confd_mgr[4446]: DDS ports will be opened. <NL> [  533.692165] confd_mgr[4446]: execute replay_manager NONE TRUE <NL> [  534.514708] confd_mgr[4453]: TRACE Connected (cdb) to ConfD <NL> [  534.648863] confd_mgr[4453]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  534.680305] confd_mgr[4453]: TRACE Connected (cdb) to ConfD <NL> [  534.783968] confd_mgr[4453]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  539.887436] confd_mgr[4453]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  539.985220] txid_tracker[3888]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  540.153087] confd_mgr[4453]: TRACE CDB_TRIGGER_SUBS <NL> [  540.153631] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted <NL> [  540.153722] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  540.153828] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  540.153895] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  540.153959] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  540.154035] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  540.282579] txid_tracker[4477]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  540.383299] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  540.383387] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  559.247217] systemd-journald[359]: Data hash table of /run/log/journal/0e8d7ca0912d45e69819aeb1822a793f/system.journal has a fill level at 75.0 (13654 of 18204 items, 10485760 file size, 767 bytes per hash table item), suggesting rotation. <NL> [  559.350909] systemd-journald[359]: /run/log/journal/0e8d7ca0912d45e69819aeb1822a793f/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  573.961155] systemd-sysv-generator[4578]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  581.966239] systemd-sysv-generator[4602]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  628.509230] userddssub[4710]: useradd: user 'fujitsu' already exists <NL> [  628.754547] dcn_dns_controller[1599]: fin_file is open <NL> [  628.918016] dcn_dns_controller[1599]: fin_file is open <NL> [  629.028607] ntputils[1958]: bool NTPServer::handle_command(const string&) <NL> [  629.028803] ntputils[1958]: bool NTPServer::handle_configure_cmd(const string&) <NL> [  629.028968] ntputils[1958]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  629.029047] ntputils[1958]: parse_time_persistent_topic ddskind create <NL> [  629.029103] ntputils[1958]: parse_time_persistent_topic name key config <NL> [  629.029158] ntputils[1958]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  629.097012] ntputils[1958]: parse_time_topics command_data enable=yes; <NL> [  629.443734] ntputils[1958]: handle_configure_cmd token is: enable=yes <NL> [  629.443800] ntputils[1958]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  629.443855] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  629.443922] ntputils[1958]: systemctl --no-block stop ntpd <NL> [  629.443974] ntputils[1958]: child pid is 4748 <NL> [  629.445199] userddssub[2446]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  629.609610] ntputils[1958]: exited, status is 0 <NL> [  629.609684] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  629.609799] ntputils[1958]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  629.609852] ntputils[1958]: child pid is 4767 <NL> [  629.863029] ntputils[1958]: exited, status is 0 <NL> [  629.863147] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  629.863218] ntputils[1958]: /bin/systemctl reset-failed ntpd <NL> [  629.975087] ntputils[1958]: child pid is 4794 <NL> [  630.393460] ntputils[1958]: exited, status is 0 <NL> [  630.572333] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  630.572412] ntputils[1958]: systemctl --no-block start ntpd <NL> [  630.572696] ntputils[1958]: child pid is 4809 <NL> [  630.817553] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3351 <NL> [  630.817822] layer1_control_layer[2410]: EsalConfig::EsalConfig main 1 <NL> [  630.817893] layer1_control_layer[2410]: EsalConfig::EsalConfig trib 0 <NL> [  630.818415] layer1_control_layer[2410]: EsalConfig::EsalConfig ciRole 0 <NL> [  630.818543] layer1_control_layer[2410]: EsalConfig is not running inside container. <NL> [  630.818663] layer1_control_layer[2410]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  630.818736] layer1_control_layer[2410]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  630.818864] layer1_control_layer[2410]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:22:39.097Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  630.818923] layer1_control_layer[2410]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  630.819203] layer1_control_layer[2410]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  630.819661] layer1_control_layer[2410]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  630.819786] layer1_control_layer[2410]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  630.819911] layer1_control_layer[2410]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  630.820026] layer1_control_layer[2410]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  630.820271] layer1_control_layer[2410]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  630.820637] layer1_control_layer[2410]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  630.820770] layer1_control_layer[2410]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  630.820837] layer1_control_layer[2410]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  630.821041] layer1_control_layer[2410]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  630.821303] layer1_control_layer[2410]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  630.821650] layer1_control_layer[2410]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf"}
{"timestamp_utc": "2024-07-31T08:22:40.983Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:22:40 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:22:41.546Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:41 retry-ssh-command INFO: attempt 119, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:41.801Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:41 retry-ssh-command INFO: attempt 120, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:45.967Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:22:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> [  589.037941] dcn_dns_controller[1388]: dnsClientStartup() <NL> [  589.445659] dcn_dns_controller[1388]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  589.865981] dcn_dns_controller[1388]: fin_dnsmasq_conf is open <NL> [  590.396301] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  591.012881] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  591.931751] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 6 <NL> [  592.245822] confd_mgr[3273]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  592.572909] confd_mgr[3273]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  592.787790] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 7 <NL> [  593.110520] confd_mgr[3288]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:21:59 UTC 2024 <NL> [  593.229869] confd_mgr[3310]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  593.817157] confd_mgr[3288]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  594.759811] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  595.169376] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  595.285647] confd_mgr[3317]: /usr/bin/ui_sys_reset.py NONE <NL> [  595.287597] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  595.514270] python3[2140]: [.045] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 22 of -1!"}
{"timestamp_utc": "2024-07-31T08:22:45.968Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  595.991474] txid_tracker[3208]: ::::create_confd_subscription_connection() try number 8 <NL> [  598.324434] cia_control_layer[2125]:    ChalApi Constructor with tid = 3004 <NL> [  598.878187] cseries_hal[2159]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  599.844613] led_controller[2160]:    ChalApi Constructor with tid = 2160 <NL> [  599.896435] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  600.933354] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  601.813712] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 1 <NL> [  602.148473] startup_finished.py[2047]: *****Startup Finished: stopping EOW timer***** <NL> [  604.281986] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 2 <NL> [  605.955781] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  606.100864] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  607.697185] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  608.622247] python3[2140]: [.119] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 23 of -1! <NL> [  610.602456] startup_finished.py[2047]: systemctl stop startup_finished_limit.timer <NL> [  611.475792] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 3 <NL> [  611.580593] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 4 <NL> [  611.658093] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  612.403952] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  613.153215] dcn_ka[1390]: KaSessMgr Process Startup <NL> [  614.063074] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 5 <NL> [  615.108399] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  615.109186] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  615.686029] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  616.150833] python3[2140]: [.533] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 24 of -1! <NL> [  618.527487] confd_mgr[3399]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  618.689216] confd_mgr[3399]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  619.388791] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 6 <NL> [  620.507341] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 7 <NL> [  621.606264] python3[3343]: INFO:root:Started rsync_logfile.py... <NL> [  622.989284] python3[3343]: INFO:root:redundancy status = STANDALONE <NL> [  623.590363] python3[3343]: INFO:root:redundancy mode = UNKNOWN <NL> [  623.811301] python3[3343]: <NL> [  623.982401] python3[3343]: ERROR:root:Error: System is not in redundancy mode <NL> [  624.197914] confd_mgr[3400]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  624.432137] confd_mgr[3400]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  624.628268] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  624.834216] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  625.750241] txid_tracker[3338]: ::::create_confd_subscription_connection() try number 8 <NL> [  626.116736] confd_mgr[3401]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  626.376959] confd_mgr[3401]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  627.199413] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  627.200245] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  627.360904] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  627.708969] python3[2140]: [.611] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 25 of -1! <NL> [  628.441774] confd_mgr[3318]: DDS Peristency is enabled <NL> [  628.730130] confd_mgr[3318]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  629.182518] confd_mgr[3318]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  629.962887] confd_mgr[3318]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  630.779403] confd_mgr[3318]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  631.831220] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 1 <NL> [  632.302575] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 2 <NL> [  632.682196] confd_mgr[3317]: /usr/bin/dbrestore_no.py <NL> [  632.908333] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  633.057199] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  633.899666] healthcheck_agt.py[3444]: /bin/sh: line 1: podman: command not found <NL> [  634.213618] confd_mgr[3415]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  634.432739] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 3 <NL> [  634.680097] confd_mgr[3273]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  635.453617] confd_mgr[3273]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  635.886198] confd_mgr[3273]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  636.048525] confd_mgr[3273]: entering: wait_for_alarm_event <NL> [  636.543851] confd_mgr[3273]: Creating ConfdAT startconfd SM, bank type = 1"}
{"timestamp_utc": "2024-07-31T08:22:46.529Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:46 retry-ssh-command INFO: attempt 120, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:46.783Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:47.039Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:46 retry-ssh-command INFO: attempt 121, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:50.303Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:22:50 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp85.fnc.net.local:46502\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:22:51.667Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:51 retry-ssh-command INFO: attempt 121, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:51.923Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:51 retry-ssh-command INFO: attempt 122, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:54.441Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  288.472974] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  288.483558] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  288.483660] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.533198, delay 0.02699\\n31 Jul 08:16:53 ntpdate[2861]: no server suitable for synchronization found\\n' <NL> [  300.618259] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  300.650325] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  300.650496] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.550892, delay 0.06488\\n31 Jul 08:17:05 ntpdate[2901]: no server suitable for synchronization found\\n' <NL> [  312.414540] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  312.414804] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  312.414880] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.537753, delay 0.03613\\n31 Jul 08:17:17 ntpdate[2928]: no server suitable for synchronization found\\n' <NL> [  324.486539] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  324.487074] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  324.487154] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.531248, delay 0.03069\\n31 Jul 08:17:29 ntpdate[2960]: no server suitable for synchronization found\\n' <NL> [  336.381425] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  336.381804] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  336.381887] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.529404, delay 0.03397\\n31 Jul 08:17:41 ntpdate[3000]: no server suitable for synchronization found\\n' <NL> [  348.271134] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  348.271331] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  348.271386] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.510246, delay 0.07199\\n31 Jul 08:17:53 ntpdate[3031]: no server suitable for synchronization found\\n' <NL> [  360.245446] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  360.245684] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  360.245774] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.532518, delay 0.03444\\n31 Jul 08:18:05 ntpdate[3073]: no server suitable for synchronization found\\n' <NL> [  372.155266] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  372.209066] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  372.209207] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.529972, delay 0.03253\\n31 Jul 08:18:17 ntpdate[3126]: no server suitable for synchronization found\\n' <NL> [  384.128187] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  384.128406] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  384.128469] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.523019, delay 0.06117\\n31 Jul 08:18:29 ntpdate[3162]: no server suitable for synchronization found\\n' <NL> [  396.067670] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  396.067854] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  396.067938] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.558173, delay 0.07903\\n31 Jul 08:18:41 ntpdate[3196]: no server suitable for synchronization found\\n' <NL> [  408.026066] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  408.026235] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  408.026296] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.536520, delay 0.04649\\n31 Jul 08:18:53 ntpdate[3223]: no server suitable for synchronization found\\n' <NL> [  419.887478] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  419.896860] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  419.897728] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.532777, delay 0.03783\\n31 Jul 08:19:05 ntpdate[3263]: no server suitable for synchronization found\\n' <NL> [  431.994932] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  432.008183] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  432.009022] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.532418, delay 0.02917\\n31 Jul 08:19:17 ntpdate[3296]: no server suitable for synchronization found\\n' <NL> [  444.016134] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  444.078769] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  444.122405] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.523073, delay 0.05701\\n31 Jul 08:19:29 ntpdate[3327]: no server suitable for synchronization found\\n' <NL> [  455.826600] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  455.853258] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  455.860904] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.533999, delay 0.02861\\n31 Jul 08:19:41 ntpdate[3362]: no server suitable for synchronization found\\n' <NL> [  467.734310] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  467.766918] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  467.829427] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset -0.534036, delay 0.02879\\n31 Jul 08:19:53 ntpdate[3393]: no server suitable for synchronization found\\n' <NL> [  638.662612] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  638.663158] ntputils_client.py[1726]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  638.663237] ntputils_client.py[1726]: b'server 127.1.254.254, stratum 16, offset +0.002496, delay 0.02945\\n31 Jul 08:22:43 ntpdate[3897]: no server suitable for synchronization found\\n' <NL> [  647.200197] ntputils_client.py[1726]: INFO:root:command failed. <NL> [  647.200502] ntputils_client.py[1726]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  647.274943] ntputils_client.py[1726]: b'31 Jul 08:22:52 ntpdate[3899]: no server suitable for synchronization found\\n' <NL> [  647.732787] ntputils_client.py[1726]: time.localtime() now is  time.struct_time(tm_year=2024, tm_mon=7, tm_mday=31, tm_hour=8, tm_min=22, tm_sec=43, tm_wday=2, tm_yday=213, tm_isdst=0) <NL> [  647.732985] ntputils_client.py[1726]: Traceback (most recent call last): <NL> [  647.733075] ntputils_client.py[1726]:   File \"/usr/local/fnc/ntputils/ntputils_client.py\", line 208, in publish_local_changes <NL> [  647.846376] ntputils_client.py[1726]:     pub_socket.bind(LOCALPUB_PROTOCOL) <NL> [  647.846590] ntputils_client.py[1726]:   File \"/usr/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 214, in bind <NL> [  647.846670] ntputils_client.py[1726]:     super().bind(addr) <NL> [  647.846745] ntputils_client.py[1726]:   File \"zmq/backend/cython/socket.pyx\", line 540, in zmq.backend.cython.socket.Socket.bind <NL> [  647.846807] ntputils_client.py[1726]:   File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc <NL> [  647.846874] ntputils_client.py[1726]: zmq.error.ZMQError: Address already in use <NL> [  647.847905] ntputils_client.py[1726]: During handling of the above exception, another exception occurred: <NL> [  647.848071] ntputils_client.py[1726]: Traceback (most recent call last): <NL> [  647.848139] ntputils_client.py[1726]:   File \"/usr/local/fnc/ntputils/ntputils_client.py\", line 381, in <module>"}
{"timestamp_utc": "2024-07-31T08:22:54.442Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  647.848203] ntputils_client.py[1726]:     NtputilsClient(TEST_RUN).run() <NL> [  647.848274] ntputils_client.py[1726]:   File \"/usr/local/fnc/ntputils/ntputils_client.py\", line 90, in run <NL> [  647.848341] ntputils_client.py[1726]:     self.process_server_msg(message) <NL> [  647.848399] ntputils_client.py[1726]:   File \"/usr/local/fnc/ntputils/ntputils_client.py\", line 254, in process_server_msg <NL> [  647.848463] ntputils_client.py[1726]:     self.set_timezone(message) <NL> [  647.848535] ntputils_client.py[1726]:   File \"/usr/local/fnc/ntputils/ntputils_client.py\", line 136, in set_timezone"}
{"timestamp_utc": "2024-07-31T08:22:55.368Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:22:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:55.624Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  630.821783] layer1_control_layer[2410]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  631.076016] ntputils[1958]: exited, status is 0 <NL> [  631.076129] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  631.076184] ntputils[1958]: systemctl --no-block start ntpscript <NL> [  631.076251] ntputils[1958]: child pid is 4816 <NL> [  631.456112] ntputils[1958]: exited, status is 0 <NL> [  631.585858] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  631.699906] ntputils[1958]: /bin/systemctl --no-block start init_state_check.timer <NL> [  631.703614] ntputils[1958]: child pid is 4831 <NL> [  632.161510] ntputils[1958]: exited, status is 0 <NL> [  632.161713] ntputils[1958]: Configure command handled successfully, writing to RTC <NL> [  632.161780] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  632.161836] ntputils[1958]: /sbin/hwclock -u --systohc <NL> [  632.161895] ntputils[1958]: child pid is 4843 <NL> [  632.509969] ntputils[1958]: exited, status is 0 <NL> [  634.429992] ntputils[1958]: bool NTPServer::handle_command(const string&) <NL> [  634.486820] ntputils[1958]: bool NTPServer::handle_set_time_cmd(const string&)"}
{"timestamp_utc": "2024-07-31T08:22:55.625Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  634.500049] ntputils[1958]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  634.525743] ntputils[1958]: parse_time_persistent_topic ddskind create <NL> [  634.532368] ntputils[1958]: parse_time_persistent_topic name key setTZ <NL> [  634.580720] ntputils[1958]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  634.653856] ntputils[1958]: parse_time_topics command_data timezone=UTC; <NL> [  634.664663] ntputils[1958]: bool NTPServer::set_timezone(const string&) <NL> [  634.777032] ntputils[1958]: NTPServer::execute_cmd spawning: <NL> [  634.788403] ntputils[1958]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  634.898916] ntputils[1958]: child pid is 4866 <NL> [  634.898996] ntputils[1958]: exited, status is 0 <NL> [  634.899061] ntputils[1958]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  634.899118] ntputils[1958]: push_local_changes user_changed: 1 delta: 0 <NL> [  634.899196] ntputils[1958]: local_push OK u Platform::Time changedByUser 1 <NL> [  634.899254] ntputils[1958]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  635.197137] ntputils[1958]: local_push OK w Platform::Time 0 0 <NL> [  635.395247] ntputils[1958]: push_local_changes OK <NL> [  635.395798] ntputils[1958]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  635.396634] ntputils[1958]: publish_local_changes OK <NL> [  636.593511] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3350 <NL> [  636.593669] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3350 <NL> [  636.674375] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3350 <NL> [  636.820665] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3350 <NL> [  636.820825] layer1_hal[2451]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  636.904264] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3353 <NL> [  636.904376] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3350 <NL> [  637.005221] layer1_hal[2451]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  637.005454] layer1_control_layer[2410]:    ChalApi Constructor with tid = 3350 <NL> [  637.634963] ntp_alarm_event_monitor.py[4821]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  637.765949] ntp_alarm_event_monitor.py[4821]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  638.165365] ntp_alarm_event_monitor.py[4821]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  638.165540] ntp_alarm_event_monitor.py[4821]: INFO:root:redundancy status now set to standalone <NL> [  638.917155] confd_mgr[4453]:  --> CONFD_OK <NL> [  638.991768] ntp_alarm_event_monitor.py[4821]: INFO:root:Publish Alarm: Raising alarm <NL> [  639.107410] ntp_alarm_event_monitor.py[4821]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  639.293159] confd_mgr[4911]: openDdsPorts interfaces  eth5.2003 <NL> [  639.293403] confd_mgr[4911]: openDdsPorts Input udpPorts-  7660 <NL> [  639.358946] confd_mgr[4911]: openDdsPorts Output udpPorts-  7660 <NL> [  639.512149] confd_mgr[4911]: openDdsPorts Input udpPorts-  7661 <NL> [  639.584433] confd_mgr[4911]: openDdsPorts Output udpPorts-  7661 <NL> [  639.698776] confd_mgr[4911]: openDdsPorts Input udpPorts-  7650 <NL> [  639.772230] confd_mgr[4911]: openDdsPorts Output udpPorts-  7650 <NL> [  640.007385] confd_mgr[4911]: openDdsPorts Input udpPorts-  7651 <NL> [  640.235049] confd_mgr[4911]: openDdsPorts Output udpPorts-  7651 <NL> [  640.339672] confd_mgr[4911]: openDdsPorts Input udpPorts-  7900 <NL> [  640.447953] confd_mgr[4911]: openDdsPorts Output udpPorts-  7900 <NL> [  640.700463] confd_mgr[4911]: openDdsPorts Input udpPorts-  7901 <NL> [  641.035862] confd_mgr[4911]: openDdsPorts Output udpPorts-  7901 <NL> [  641.036205] confd_mgr[4911]: openDdsPorts Input udpPorts-  7910 <NL> [  641.130406] confd_mgr[4911]: openDdsPorts Output udpPorts-  7910 <NL> [  641.159070] confd_mgr[4911]: openDdsPorts Input udpPorts-  7911 <NL> [  641.209018] confd_mgr[4911]: openDdsPorts Output udpPorts-  7911 <NL> [  641.252271] confd_mgr[4911]: openDdsPorts Input udpPorts-  8150 <NL> [  641.279073] confd_mgr[4911]: openDdsPorts Output udpPorts-  8150 <NL> [  641.432386] confd_mgr[4911]: openDdsPorts Input udpPorts-  8151 <NL> [  641.432551] confd_mgr[4911]: openDdsPorts Output udpPorts-  8151 <NL> [  641.443525] confd_mgr[4911]: openDdsPorts Input udpPorts-  8160 <NL> [  641.737894] confd_mgr[4911]: openDdsPorts Output udpPorts-  8160 <NL> [  641.755069] confd_mgr[4911]: openDdsPorts Input udpPorts-  8161 <NL> [  642.076590] confd_mgr[4911]: openDdsPorts Output udpPorts-  8161 <NL> [  642.805544] confd_mgr[4453]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  642.805753] confd_mgr[4453]: replay_manager:  Start-Wed Jul 31 08:21:01 2024 <NL> [  642.805828] confd_mgr[4453]:  ++++++++++++++++++++++ <NL> [  642.805889] confd_mgr[4453]: replay_manager: TXID NOT FOUND ================================== <NL> [  642.805948] confd_mgr[4453]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  642.942797] confd_mgr[4453]: replay_manager: Need to do trigger full replay. <NL> [  643.036366] confd_mgr[4453]: replay_manager: Creating the purge file. <NL> [  643.159567] confd_mgr[4453]: replay_manager: Open DDS Ports <NL> [  643.207549] confd_mgr[4453]: replay_manager: NOW deleting the purge file. <NL> [  643.307298] confd_mgr[4453]: replay_manager:  End-Wed Jul 31 08:22:48 2024 <NL> [  643.307405] confd_mgr[4453]:  ++++++++++++++++++++++ <NL> [  643.307474] confd_mgr[4453]: Not 1+1 Mode <NL> [  643.307537] confd_mgr[4453]: DipLog_pimpl destructor called <NL> [  643.307613] confd_mgr[4453]: DipVerbosity Listener ZMQ error <NL> [  643.307710] confd_mgr[4453]:     ret='Context was terminated <NL> [  643.307779] confd_mgr[4453]: deleting subscriber_ socket <NL> [  643.307842] confd_mgr[4453]: Exiting verb listener <NL> [  643.619255] confd_mgr[2866]: CommAT::asio_subscriber: Connection accepted <NL> [  643.619473] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  643.696937] confd_mgr[2866]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  643.697159] confd_mgr[2866]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  643.735010] confd_mgr[2866]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  643.796677] confd_mgr[2866]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  643.796767] confd_mgr[2866]: sm_startconfd::rm_ready <NL> [  643.796825] confd_mgr[2866]: leaving: sm_startconfd::wait_for_rm <NL> [  643.796880] confd_mgr[2866]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [  643.796936] confd_mgr[2866]: entering: sm_startconfd::start_confd_p2 <NL> [  643.796991] confd_mgr[2866]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [  643.797123] confd_mgr[2866]: ConfdHA Not supported command CONFIRM <NL> [  644.322021] confd_mgr[4963]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:22:50 UTC 2024 <NL> [  645.038968] confd_mgr[4974]: cmnEvtXML has stopped <NL> [  645.061707] confd_mgr[4974]: start event-handler.service <NL> [  648.071859] confd_mgr[4994]: condition_name: systemRestart <NL> [  648.072100] confd_mgr[4994]: entity_type: COM <NL> [  648.072186] confd_mgr[4994]: num_instances: 1"}
{"timestamp_utc": "2024-07-31T08:22:56.555Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  620.726545] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  621.595137] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 7 <NL> [  624.925097] confd_mgr[3425]: ConfdMgrConf: DB signature is NOT supported <NL> [  625.750162] confd_mgr[3425]: Read reset type failed basic_ios::clear: iostream error <NL> [  626.282685] confd_mgr[3425]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  627.163696] txid_tracker[3322]: ::::create_confd_subscription_connection() try number 8 <NL> [  628.297126] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  629.315672] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  629.610953] ntputils[1728]: child pid is 3438 <NL> [  629.867750] ntputils[1728]: exited, status is 0 <NL> [  630.009779] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  630.238117] ntputils[1728]: poller time change delta is: 1 <NL> [  630.515647] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  630.756974] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  630.771305] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  630.772042] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  630.779990] ntputils[1728]: push_local_changes OK <NL> [  630.780721] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  630.781551] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  630.795747] ntputils[1728]: child pid is 3447 <NL> [  630.797197] ntputils[1728]: exited, status is 0 <NL> [  630.948500] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift <NL> [  630.993783] ntputils[1728]: poller time change delta is: 1 <NL> [  631.019846] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  631.166444] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  631.546689] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  632.349788] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  632.614854] ntputils[1728]: push_local_changes OK <NL> [  633.173284] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  633.174255] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  633.378257] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  633.379030] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  633.906253] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  633.906966] python3[2157]: [.751] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 19 of -1! <NL> [  634.439955] confd_mgr[3425]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  634.441265] confd_mgr[3425]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  634.765434] healthcheck_agt.py[3479]: /bin/sh: line 1: podman: command not found <NL> [  635.029730] confd_mgr[3461]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:22:36 UTC 2024 <NL> [  635.176765] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  635.296612] python3[2157]: [.765] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 20 of -1! <NL> [  635.404150] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  635.569897] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  635.999842] confd_mgr[3480]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  636.126337] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 1 <NL> [  636.228053] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 2 <NL> [  636.451047] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 3 <NL> [  636.629981] confd_mgr[3461]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  636.779775] confd_mgr[3491]: /usr/bin/ui_sys_reset.py NONE <NL> [  636.947787] confd_mgr[3497]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  637.090801] confd_mgr[3497]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  637.385214] confd_mgr[3498]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  637.769495] confd_mgr[3498]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  638.027671] confd_mgr[3500]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  638.355391] confd_mgr[3500]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  638.756541] confd_mgr[3492]: DDS Peristency is enabled <NL> [  638.952024] confd_mgr[3492]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  639.200921] confd_mgr[3492]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  639.459972] confd_mgr[3492]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  639.460685] confd_mgr[3492]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  639.768530] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 4 <NL> [  639.769709] confd_mgr[3491]: /usr/bin/dbrestore_no.py <NL> [  640.276792] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  640.856832] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  641.765457] confd_mgr[3502]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  642.503502] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 5 <NL> [  642.763666] confd_mgr[3425]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  642.950670] confd_mgr[3425]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  643.214731] confd_mgr[3425]: main:: /run/swdl_ready.shentering: wait_for_alarm_event <NL> [  643.260726] confd_mgr[3425]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  643.261405] confd_mgr[3425]: ha_sm : wait_for_SWDL_s timer is set <NL> [  643.287347] confd_mgr[3425]:  found. Invoking it. <NL> [  643.287832] confd_mgr[3425]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  643.309505] confd_mgr[3425]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  643.457119] confd_mgr[3425]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  643.544656] confd_mgr[3425]: Creating ConfdAT startconfd SM, bank type = 2"}
{"timestamp_utc": "2024-07-31T08:22:56.556Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  643.545408] confd_mgr[3425]: entering: at_sm::wait_for_SWDL <NL> [  643.545940] confd_mgr[3425]: CommAT::asio_subscriber: Connection accepted <NL> [  643.546566] confd_mgr[3425]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  643.649573] confd_mgr[3425]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  643.719150] confd_mgr[3425]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  644.062853] confd_mgr[3425]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  644.626600] confd_mgr[3425]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  644.912533] confd_mgr[3425]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  645.138041] confd_mgr[3425]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  645.971311] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  646.445389] python3[2157]: [.775] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 21 of -1! <NL> [  646.802295] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 6 <NL> [  647.924571] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  648.155321] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  648.549731] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 7 <NL> # 03:22:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:56.811Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:56 retry-ssh-command INFO: attempt 122, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:57.068Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:56 retry-ssh-command INFO: attempt 123, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:57.325Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  598.294283] confd_mgr[4806]: openDdsPorts Output udpPorts-  7901 <NL> [  598.338821] confd_mgr[4806]: openDdsPorts Input udpPorts-  7910 <NL> [  598.427809] confd_mgr[4806]: openDdsPorts Output udpPorts-  7910 <NL> [  598.481512] confd_mgr[4806]: openDdsPorts Input udpPorts-  7911 <NL> [  598.593880] confd_mgr[4806]: openDdsPorts Output udpPorts-  7911 <NL> [  598.660416] confd_mgr[4806]: openDdsPorts Input udpPorts-  8150 <NL> [  598.835613] confd_mgr[4806]: openDdsPorts Output udpPorts-  8150 <NL> [  599.048182] confd_mgr[4806]: openDdsPorts Input udpPorts-  8151 <NL> [  599.333983] confd_mgr[4806]: openDdsPorts Output udpPorts-  8151 <NL> [  599.334096] confd_mgr[4806]: openDdsPorts Input udpPorts-  8160 <NL> [  599.334889] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3415 <NL> [  599.335051] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3415 <NL> [  599.335188] confd_mgr[4806]: openDdsPorts Output udpPorts-  8160 <NL> [  599.335256] confd_mgr[4806]: openDdsPorts Input udpPorts-  8161 <NL> [  599.716531] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3415 <NL> [  599.803186] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3415 <NL> [  599.962021] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3415 <NL> [  599.962136] layer1_hal[2448]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  599.962220] layer1_hal[2448]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  600.112698] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3415 <NL> [  600.113427] confd_mgr[4806]: openDdsPorts Output udpPorts-  8161 <NL> [  600.417194] layer1_control_layer[2411]:    ChalApi Constructor with tid = 3418 <NL> [  600.774891] confd_mgr[4411]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  600.775085] confd_mgr[4411]: replay_manager:  Start-Wed Jul 31 08:20:23 2024 <NL> [  600.775152] confd_mgr[4411]:  ++++++++++++++++++++++ <NL> [  600.775224] confd_mgr[4411]: replay_manager: TXID NOT FOUND ================================== <NL> [  600.775283] confd_mgr[4411]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  600.775355] confd_mgr[4411]: replay_manager: Need to do trigger full replay. <NL> [  600.775412] confd_mgr[4411]: replay_manager: Creating the purge file. <NL> [  600.775475] confd_mgr[4411]: replay_manager: Open DDS Ports <NL> [  600.775537] confd_mgr[4411]: replay_manager: NOW deleting the purge file. <NL> [  600.775608] confd_mgr[4411]: replay_manager:  End-Wed Jul 31 08:22:05 2024 <NL> [  600.775737] confd_mgr[4411]:  ++++++++++++++++++++++ <NL> [  600.775788] confd_mgr[4411]: Not 1+1 Mode <NL> [  600.775838] confd_mgr[4411]: DipLog_pimpl destructor called"}
{"timestamp_utc": "2024-07-31T08:22:57.326Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  600.775900] confd_mgr[4411]: DipVerbosity Listener ZMQ error <NL> [  600.775968] confd_mgr[4411]:     ret='Context was terminated <NL> [  600.776031] confd_mgr[4411]: deleting subscriber_ socket <NL> [  600.776080] confd_mgr[4411]: Exiting verb listener <NL> [  600.978342] confd_mgr[2874]: CommAT::asio_subscriber: Connection accepted <NL> [  600.978537] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  600.978658] confd_mgr[2874]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  600.978730] confd_mgr[2874]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  600.978795] confd_mgr[2874]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  600.979250] confd_mgr[2874]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  600.979384] confd_mgr[2874]: sm_startconfd::rm_ready <NL> [  600.979455] confd_mgr[2874]: leaving: sm_startconfd::wait_for_rm <NL> [  600.979528] confd_mgr[2874]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [  600.979600] confd_mgr[2874]: entering: sm_startconfd::start_confd_p2 <NL> [  600.979690] confd_mgr[2874]: ConfdHA Not supported command CONFIRM <NL> [  601.177629] confd_mgr[2874]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [  601.472128] confd_mgr[4857]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:22:06 UTC 2024 <NL> [  602.267694] confd_mgr[4872]: cmnEvtXML has stopped <NL> [  602.267858] confd_mgr[4872]: start event-handler.service <NL> [  604.844598] confd_mgr[4881]: condition_name: systemRestart <NL> [  604.849510] confd_mgr[4881]: entity_type: COM <NL> [  604.849642] confd_mgr[4881]: num_instances: 1 <NL> [  604.849705] confd_mgr[4881]: num_samples: 1 <NL> [  604.871975] confd_mgr[4881]:  EventNotification does not have condition_group. Skipping. <NL> [  605.039427] confd_mgr[4881]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [  605.039522] confd_mgr[4881]: CmnEvtPublisher::main: returning <NL> [  605.247587] confd_mgr[4872]: /usr/bin/confd_mgr_in_spm.sh <NL> [  605.536211] confd_mgr[4872]: /usr/bin/ui_sys_reset.py NONE <NL> [  607.198054] ops-service[4929]: rebind_listener \"webui\" <NL> [  607.248477] ops-service[4929]: TRACE Connected (maapi) to ConfD <NL> [  607.257280] ops-service[4929]: TRACE MAAPI_REBIND_LISTENER <NL> [  607.257355] ops-service[4929]:  31-Jul-2024::08:22:12.667 4929/7f3ce20dfc40/4 SEND op=407 isrel=0 th=-1 16 <NL> [  607.258243] ops-service[4929]:  --> CONFD_OK <NL> [  607.259053] ops-service[4929]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  607.287174] confd_mgr[4932]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  607.287321] confd_mgr[4932]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  607.327645] confd_mgr[4933]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  607.352769] confd_mgr[4933]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  607.355880] confd_mgr[4934]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  607.355998] confd_mgr[4934]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  607.356208] ops-service[4931]: rebind_listener \"snmp\" <NL> [  607.356273] ops-service[4931]: TRACE Connected (maapi) to ConfD <NL> [  607.370669] ops-service[4931]: TRACE MAAPI_REBIND_LISTENER <NL> [  607.371475] ops-service[4931]:  31-Jul-2024::08:22:12.762 4931/7f26e606dc40/4 SEND op=407 isrel=0 th=-1 4 <NL> [  607.371635] ops-service[4931]:  --> CONFD_OK <NL> [  607.371716] ops-service[4931]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  607.415705] confd_mgr[4918]: DDS Peristency is enabled <NL> [  607.471901] confd_mgr[4918]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  607.471992] confd_mgr[4918]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  607.472066] confd_mgr[4918]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  607.472117] confd_mgr[4918]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  607.707113] confd_mgr[4945]: Execute check_db_status.sh <NL> [  608.027733] confd_mgr[4945]: NE is running a default database! <NL> [  608.954103] confd_mgr[4857]: Starting valhdlr.service if not started already[  609.341806] systemd-sysv-generator[4974]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  615.125166] confd_mgr[4857]: Starting validation-handler.service if not started already <NL> [  615.314898] confd_mgr[4857]: Starting snmp-fss-fw.service if not started already <NL> [  616.497105] systemd-sysv-generator[4994]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  623.689249] confd_mgr[2874]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [  647.049357] confd_phase_sentry[2419]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [  647.049639] confd_phase_sentry[2419]: ConfdPhaseSentry: starting confd-ready.service <NL> [  647.322341] echo[5105]: Starting confd-ready <NL> [  647.620871] confd_mgr[2874]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [  647.728945] confd_mgr[5112]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:22:53 UTC 2024 <NL> [  648.156027] netconfEventSyslog[5120]: EventSyslogDaemon: Trying to connect to Confd <NL> [  648.156349] automater.sh[5113]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [  649.650744] confd_mgr[5142]: Execute common_confd_nb_ready_cb.sh <NL> [  649.953700] confd_mgr[5112]: Invoking confd_nb_enable.py"}
{"timestamp_utc": "2024-07-31T08:23:02.576Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:01 retry-ssh-command INFO: attempt 123, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:01 retry-ssh-command INFO: attempt 124, sleep 5: \"rtxoialp85.fnc.net.local:46517\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:06.745Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:06 retry-ssh-command INFO: attempt 124, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:07.001Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:23:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46517, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:23:12.163Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:11 retry-ssh-command INFO: attempt 125, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:17.466Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:23:16 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:23:16 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:23:16 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"stderr\": DONE <NL> # 03:23:16 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"stdout\": DONE <NL> # 03:23:16 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\": process 3440 terminated with exitcode 0 <NL> # 03:23:16 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:23:16 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:23:16 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p03.main-startup (s)) <NL> # 03:23:16 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #2 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:23:16 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 3 children running (n01.p09.s01.startup (p)) <NL> # 03:23:16 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.s02.NE2-main-cli\", exit_code 0 <NL> # 03:23:16 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.main-startup (s)\", exit_code 0 <NL> [  636.575298] confd_mgr[3273]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  636.854878] confd_mgr[3273]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  637.741852] confd_mgr[3273]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  638.214861] confd_mgr[3273]: entering: at_sm::wait_for_SWDL <NL> [  638.869944] confd_mgr[3273]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  639.067875] confd_mgr[3273]: ha_sm : wait_for_SWDL_s timer is set <NL> [  639.278122] confd_mgr[3273]: CommAT::asio_subscriber: Connection accepted <NL> [  639.637764] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  641.278155] confd_mgr[3273]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  641.380276] confd_mgr[3273]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  641.381025] confd_mgr[3273]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  641.458651] confd_mgr[3273]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  641.459255] confd_mgr[3273]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  641.459967] confd_mgr[3273]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  641.918854] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 4 <NL> [  642.110842] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 5 <NL> [  643.134620] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  643.906419] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  645.146776] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  645.536372] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  646.066579] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  646.519445] python3[2140]: [.627] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 26 of -1! <NL> [  646.883514] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  647.707755] python3[2140]: [.673] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 27 of -1! <NL> [  648.371564] confd_mgr[3429]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': '1+1', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  649.204890] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  649.592268] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  650.645903] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 6 <NL> [  651.059808] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 7 <NL> [  651.401896] txid_tracker[3434]: ::::create_confd_subscription_connection() try number 8 <NL> [  651.427389] confd_mgr[3273]: ConfdMgrConf::reload: DB signature set to false <NL> [  651.428163] confd_mgr[3273]: is_swdl_alarm_0 <NL> [  651.428696] confd_mgr[3273]: sdb_restore_= 0 <NL> [  651.520390] confd_mgr[3273]: swdl_alarm_ = NONE <NL> [  651.616455] confd_mgr[3273]: swdl_alarm_tag_ = <NL> [  651.658134] confd_mgr[3273]: swdl status = SUCCESS <NL> [  651.731421] confd_mgr[3273]: is_swdl_in_swupgrade = 0 <NL> [  651.785950] confd_mgr[3273]: is_swdl_alarm_0 <NL> [  651.952924] confd_mgr[3273]: sdb_restore_= 0 <NL> [  652.159855] confd_mgr[3273]: swdl_alarm_ = NONE <NL> [  652.295545] confd_mgr[3273]: swdl_alarm_tag_ = <NL> [  652.378906] confd_mgr[3273]: swdl status = SUCCESS <NL> [  652.387303] confd_mgr[3273]: is_swdl_in_swupgrade = 0 <NL> [  652.387808] confd_mgr[3273]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  652.487218] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  652.585243] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  652.998121] confd_mgr[3424]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  653.213099] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  653.320696] confd_mgr[3273]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  653.321899] confd_mgr[3273]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  653.625862] confd_mgr[3273]: main::/run/rdm_status.sh found. Invoking it."}
{"timestamp_utc": "2024-07-31T08:23:17.467Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  654.032655] confd_mgr[3273]: CommAT::asio_subscriber: Connection accepted <NL> [  654.581866] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  654.762170] confd_mgr[3273]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  655.171787] confd_mgr[3273]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  655.172466] confd_mgr[3273]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  655.173169] confd_mgr[3273]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  655.173769] confd_mgr[3273]: ConfdMgrConf::reload: DB signature set to false <NL> [  655.254201] confd_mgr[3273]: confd_db_init::sConfd_db_init_executed_=false <NL> [  655.278063] confd_mgr[3273]: ConfdMgrConf::reload: DB signature set to false <NL> [  655.369673] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  655.464935] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  655.520852] confd_mgr[3529]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  655.678513] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 1 <NL> [  655.774601] confd_mgr[3470]: build /etc/confd/confd.conf.bank0 1+1 <NL> [  655.775261] confd_mgr[3470]: 1+1 <NL> [  655.775649] confd_mgr[3470]: add_child <NL> [  655.877555] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  655.878397] python3[2140]: [.697] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 28 of -1! <NL> [  655.960274] confd_mgr[3543]: add field enabled true <NL> [  656.056642] confd_mgr[3543]: add field ip 127.1.254.253 <NL> [  656.107087] confd_mgr[3543]: add field port 4569 <NL> [  656.148804] confd_mgr[3543]: add field tickTimeout PT20S <NL> [  656.200217] confd_mgr[3549]: add field enabled false <NL> [  656.278779] confd_mgr[3549]: add field address <NL> [  656.365192] confd_mgr[3470]: /etc/confd/default_backup.dbs <NL> [  656.458764] confd_mgr[3470]: Create default DB in bank0 <NL> [  657.960696] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 2 <NL> [  660.908077] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  661.157274] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  661.722770] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 3 <NL> [  663.950771] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 4 <NL> [  665.432842] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  666.203998] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  667.111603] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 5 <NL> [  667.431698] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> # 03:23:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:16 retry-ssh-command INFO: attempt 126, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:20.741Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:23:20 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:23:21.782Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:21 retry-ssh-command INFO: attempt 127, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:25.946Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:23:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:23:26.870Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:26 retry-ssh-command INFO: attempt 128, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:32.108Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:31 retry-ssh-command INFO: attempt 129, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:34.631Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:23:34 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp85.fnc.net.local:46502\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:23:37.156Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:36 retry-ssh-command INFO: attempt 130, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:39.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:23:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None <NL> [  650.073433] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  650.606261] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  652.195096] txid_tracker[3458]: ::::create_confd_subscription_connection() try number 8 <NL> [  652.752926] confd_mgr[3519]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': '1+1', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  654.082200] confd_mgr[3425]: ConfdMgrConf::reload: DB signature set to false <NL> [  654.334756] confd_mgr[3425]: is_swdl_alarm_0 <NL> [  654.648534] confd_mgr[3425]: sdb_restore_= 0 <NL> [  654.649027] confd_mgr[3425]: swdl_alarm_ = NONE <NL> [  654.694144] confd_mgr[3425]: swdl_alarm_tag_ = <NL> [  655.326969] confd_mgr[3425]: swdl status = SUCCESS"}
{"timestamp_utc": "2024-07-31T08:23:39.689Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  656.131385] confd_mgr[3425]: is_swdl_in_swupgrade = 0 <NL> [  656.207150] confd_mgr[3425]: is_swdl_alarm_0 <NL> [  656.743965] confd_mgr[3425]: sdb_restore_= 0 <NL> [  657.613822] confd_mgr[3425]: swdl_alarm_ = NONE <NL> [  657.783446] confd_mgr[3425]: swdl_alarm_tag_ = <NL> [  658.015250] confd_mgr[3425]: swdl status = SUCCESS <NL> [  658.519576] confd_mgr[3425]: is_swdl_in_swupgrade = 0 <NL> [  659.044978] confd_mgr[3425]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  660.059732] dcn_dns_controller[1390]: subscribe_data Enter main loop <NL> [  660.335156] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  660.817237] python3[2157]: [.992] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 22 of -1! <NL> [  661.396195] confd_mgr[3515]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  662.358687] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  663.229623] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  663.863380] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  664.383863] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  666.332180] confd_mgr[3425]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  666.772028] confd_mgr[3425]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  667.434397] confd_mgr[3425]: main::/run/rdm_status.sh found. Invoking it. <NL> [  667.896293] confd_mgr[3425]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  667.897070] confd_mgr[3425]: CommAT::asio_subscriber: Connection accepted <NL> [  667.897635] confd_mgr[3425]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  667.898469] confd_mgr[3425]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  668.206241] confd_mgr[3425]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  668.492645] confd_mgr[3425]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  668.987989] confd_mgr[3425]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  669.357493] confd_mgr[3425]: ConfdMgrConf::reload: DB signature set to false <NL> [  669.802427] confd_mgr[3425]: confd_db_init::sConfd_db_init_executed_=false <NL> [  669.803148] confd_mgr[3425]: ConfdMgrConf::reload: DB signature set to false <NL> [  669.805447] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  669.896558] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  670.130272] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  670.256304] python3[2157]: [.036] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 23 of -1! <NL> [  670.319365] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 1 <NL> [  670.351306] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 2 <NL> [  670.471271] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 3 <NL> [  670.671835] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 4 <NL> [  670.918068] confd_mgr[3638]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  671.153768] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  671.305392] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  671.835826] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 5 <NL> [  671.882797] confd_mgr[3577]: build /etc/confd/confd.conf.bank0 1+1 <NL> [  671.902320] confd_mgr[3577]: 1+1 <NL> [  672.044688] confd_mgr[3577]: add_child <NL> [  672.124176] confd_mgr[3651]: add field enabled true <NL> [  672.324706] confd_mgr[3651]: add field ip 127.1.254.253 <NL> [  672.688534] confd_mgr[3651]: add field port 4569 <NL> [  672.689162] confd_mgr[3651]: add field tickTimeout PT20S <NL> [  673.072350] confd_mgr[3656]: add field enabled false <NL> [  673.307110] confd_mgr[3656]: add field address <NL> [  673.415659] confd_mgr[3577]: /etc/confd/default_backup.dbs <NL> [  673.416302] confd_mgr[3577]: Create default DB in bank0 <NL> [  674.150458] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 6 <NL> [  675.502459] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  676.108325] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  677.765595] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  677.801267] python3[2157]: [.236] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 24 of -1! <NL> [  678.610781] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 7 <NL> [  680.145676] txid_tracker[3579]: ::::create_confd_subscription_connection() try number 8 <NL> [  680.315552] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  680.464693] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  685.089765] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  686.302837] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  686.887236] python3[2157]: [.307] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 25 of -1! <NL> [  687.290699] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  687.903076] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 1 <NL> [  689.037933] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 2"}
{"timestamp_utc": "2024-07-31T08:23:39.690Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  690.250962] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  691.069836] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  691.858971] ntputils[1728]: NTPServer::execute_cmd spawning: <NL> [  692.035882] ntputils[1728]: /sbin/hwclock -u --systohc <NL> [  692.144520] ntputils[1728]: child pid is 3787 <NL> [  692.289916] ntputils[1728]: exited, status is 0 <NL> [  692.564502] ntputils[1728]: poller time change reason is: local_pub_str.ntp_drift"}
{"timestamp_utc": "2024-07-31T08:23:42.211Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:41 retry-ssh-command INFO: attempt 131, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:47.450Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:46 retry-ssh-command INFO: attempt 132, sleep 5: \"rtxoialp85.fnc.net.local:46533\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:51.507Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  667.434524] python3[2140]: [.082] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 29 of -1! <NL> [  668.101268] dcn_dns_controller[1388]: subscribe_data Enter main loop <NL> [  669.758900] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 6 <NL> [  671.795875] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  672.496147] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  673.887263] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 7 <NL> [  675.920412] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  676.875330] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  678.899749] confd_mgr[3273]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  679.391716] confd_mgr[3273]: confd_db_init::RESET REASON IS NONE <NL> [  679.744818] confd_mgr[3273]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  680.188461] confd_mgr[3273]: ha_sm is_ha_mode_not_none_g cur_mode is 1+1 <NL> [  681.078360] confd_mgr[3273]: ha_sm leaving: wait_for_SWDL_s <NL> [  681.678928] confd_mgr[3273]: ha_sm::start_active_agent_a: The HA mode is 1+1 <NL> [  682.322584] confd_mgr[3273]: ha_sm_active entering: wait_for_active_agent_s <NL> [  682.580493] confd_mgr[3273]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  682.790964] confd_mgr[3273]: leaving: at_sm::wait_for_SWDL <NL> [  683.304908] confd_mgr[3273]: entering: at_sm::wait_for_start_bank <NL> [  683.305641] confd_mgr[3273]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  683.306527] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  683.476729] confd_mgr[3273]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  683.691962] txid_tracker[3574]: ::::create_confd_subscription_connection() try number 8 <NL> [  683.873464] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  683.910505] python3[2140]: [.331] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 30 of -1! <NL> [  684.273154] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  684.535773] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  684.704695] confd_mgr[3459]: TRUE <NL> [  684.854193] confd_mgr[3273]: leaving: at_sm::wait_for_start_bank <NL> [  684.961857] confd_mgr[3273]: ConfdTribActiveAgent start_rep_server <NL> [  685.234376] confd_mgr[3273]: ConfdTribActiveAgent::server address 127.1.254.254 port 4050 <NL> [  685.463181] confd_mgr[3273]: calling accept_handler <NL> [  685.463708] confd_mgr[3273]: entering: at_sm_dbready::wait_for_db_status <NL> [  685.464324] confd_mgr[3273]: In ConfdTribActiveAgent::check_reset <NL> [  685.464927] confd_mgr[3273]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  685.510987] confd_mgr[3273]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  685.513875] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 1 <NL> [  685.558557] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 2 <NL> [  685.891791] confd_mgr[3844]: Executing check_db.sh <NL> [  686.015352] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  686.290204] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  686.880269] confd_mgr[3273]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  687.312941] confd_mgr[3273]: ha_sm_active leaving: wait_for_active_agent_s <NL> [  687.849653] confd_mgr[3273]: process_ha_alarm raise noSecondaryDatabase <NL> [  687.850342] confd_mgr[3273]: ha_sm_active entering: wait_for_standby_s <NL> [  687.850945] confd_mgr[3273]: Maskable Alarm <NL> [  687.930558] confd_mgr[3273]: leaving: wait_for_alarm_event <NL> [  688.203905] confd_mgr[3273]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:152:add_to_alarms: OPERATION=raise CONDITION=noSecondaryDatabase #ALARMS=1 <NL> [  688.596391] confd_mgr[3273]: entering: wait_for_alarm_process <NL> [  688.739259] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  688.954527] python3[2140]: [.412] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 31 of -1! <NL> [  689.215229] confd_mgr[3844]: check_db.sh: found xml files <NL> [  689.316969] confd_mgr[3844]: 0 <NL> [  689.500510] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 3 <NL> [  689.757057] confd_mgr[3273]: Found no error <NL> [  689.908620] confd_mgr[3273]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  690.043796] confd_mgr[3273]: cur_gdbissue 24.1.1 gdbissue 24.1.1 rc = 1 <NL> [  690.175593] confd_mgr[3273]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  690.312658] confd_mgr[3273]: TSeries-CIS is in the list: TSeries-CIS <NL> [  690.497334] confd_mgr[3273]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear"}
{"timestamp_utc": "2024-07-31T08:23:51.508Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  690.939586] confd_mgr[3273]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  691.590272] confd_mgr[3273]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  692.581567] confd_mgr[3273]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  692.944982] confd_mgr[3273]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  693.201443] confd_mgr[3273]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  693.509194] confd_mgr[3273]: guard is_db_okay_g: The HA mode is 1+1 <NL> [  693.799466] confd_mgr[3273]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  694.129620] confd_mgr[3273]: entering: sm_startconfd::start_confd_p0 <NL> [  694.130273] confd_mgr[3273]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  694.312588] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 4 <NL> [  694.313435] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 5 <NL> [  694.396759] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  694.490178] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  694.815329] confd_mgr[3854]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:23:29 UTC 2024 <NL> [  695.061731] confd_mgr[3273]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  695.275231] confd_mgr[3273]: leaving: wait_for_alarm_process <NL> [  695.501971] confd_mgr[3273]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:160:write_alarms_to_file: #ALARMS=1 <NL> [  695.581586] confd_mgr[3273]:  write_db_alarm rename was successful <NL> [  695.727302] confd_mgr[3273]: entering: wait_for_alarm_event <NL> [  695.871807] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  696.255737] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  696.903426] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 6 <NL> [  697.367868] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  697.588125] python3[2140]: [.424] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 32 of -1! <NL> [  699.718778] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 7 <NL> [  700.728041] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:23:52.251Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:23:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46533, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:23:54.774Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  405.775380] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  405.775443] ntputils_client.py[1761]: b'31 Jul 08:18:53 ntpdate[3006]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0"}
{"timestamp_utc": "2024-07-31T08:23:54.775Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  422.313494] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  422.313890] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  422.313952] ntputils_client.py[1761]: b'31 Jul 08:19:10 ntpdate[3055]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:19:15,549 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  441.388685] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  441.388911] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  441.389045] ntputils_client.py[1761]: b'31 Jul 08:19:29 ntpdate[3124]: no server suitable for synchronization found\\n' <NL> [  453.555778] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  453.621305] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  453.621406] ntputils_client.py[1761]: b'31 Jul 08:19:41 ntpdate[3160]: no server suitable for synchronization found\\n' <NL> [  465.820904] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  465.821126] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  465.821202] ntputils_client.py[1761]: b'31 Jul 08:19:53 ntpdate[3198]: no server suitable for synchronization found\\n' <NL> [  477.808252] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  477.809074] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  477.813961] ntputils_client.py[1761]: b'31 Jul 08:20:05 ntpdate[3232]: no server suitable for synchronization found\\n' <NL> [  489.908987] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  489.937110] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  489.955454] ntputils_client.py[1761]: b'31 Jul 08:20:17 ntpdate[3283]: no server suitable for synchronization found\\n' <NL> [  502.239158] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  502.281507] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  502.282587] ntputils_client.py[1761]: b'31 Jul 08:20:29 ntpdate[3322]: no server suitable for synchronization found\\n' <NL> [  514.226835] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  514.256366] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  514.256440] ntputils_client.py[1761]: b'31 Jul 08:20:41 ntpdate[3364]: no server suitable for synchronization found\\n' <NL> [  526.250872] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  526.251145] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  526.251277] ntputils_client.py[1761]: b'31 Jul 08:20:53 ntpdate[3397]: no server suitable for synchronization found\\n' <NL> [  538.325592] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  538.325781] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  538.325854] ntputils_client.py[1761]: b'31 Jul 08:21:06 ntpdate[3440]: no server suitable for synchronization found\\n' <NL> [  550.393091] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  550.414189] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  550.443074] ntputils_client.py[1761]: b'31 Jul 08:21:18 ntpdate[3493]: no server suitable for synchronization found\\n' <NL> [  562.445522] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  562.446248] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  562.529628] ntputils_client.py[1761]: b'31 Jul 08:21:30 ntpdate[3536]: no server suitable for synchronization found\\n' <NL> [  574.675753] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  574.699257] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  574.758954] ntputils_client.py[1761]: b'31 Jul 08:21:42 ntpdate[3579]: no server suitable for synchronization found\\n' <NL> [  586.647653] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  586.662945] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  586.679800] ntputils_client.py[1761]: b'31 Jul 08:21:54 ntpdate[3613]: no server suitable for synchronization found\\n' <NL> [  598.562215] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  598.563126] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  598.614085] ntputils_client.py[1761]: b'31 Jul 08:22:06 ntpdate[3653]: no server suitable for synchronization found\\n' <NL> [  610.589701] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  610.590460] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  610.591196] ntputils_client.py[1761]: b'31 Jul 08:22:18 ntpdate[3680]: no server suitable for synchronization found\\n' <NL> [  622.578922] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  622.579255] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  622.579315] ntputils_client.py[1761]: b'31 Jul 08:22:30 ntpdate[3722]: no server suitable for synchronization found\\n' <NL> [  634.489749] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  634.495214] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  634.496291] ntputils_client.py[1761]: b'31 Jul 08:22:42 ntpdate[3781]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:23:54.776Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  646.445180] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  646.445851] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  646.446621] ntputils_client.py[1761]: b'31 Jul 08:22:54 ntpdate[3818]: no server suitable for synchronization found\\n' <NL> [  658.338659] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  658.339653] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  658.340577] ntputils_client.py[1761]: b'31 Jul 08:23:06 ntpdate[3850]: no server suitable for synchronization found\\n' <NL> [  670.434594] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  670.486618] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  670.531403] ntputils_client.py[1761]: b'31 Jul 08:23:18 ntpdate[3883]: no server suitable for synchronization found\\n' <NL> [  682.300558] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  682.311384] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  682.339186] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.547195, delay 0.03818\\n31 Jul 08:23:30 ntpdate[3916]: no server suitable for synchronization found\\n' <NL> [  694.365405] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  694.414561] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  694.457119] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.547696, delay 0.03711\\n31 Jul 08:23:42 ntpdate[3970]: no server suitable for synchronization found\\n' <NL> [  706.483923] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  706.503047] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:24:01.312Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  648.072245] confd_mgr[4994]: num_samples: 1 <NL> [  648.145754] confd_mgr[4994]:  EventNotification does not have condition_group. Skipping. <NL> [  648.145933] confd_mgr[4994]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [  648.146203] confd_mgr[4994]: CmnEvtPublisher::main: returning <NL> [  648.434170] confd_mgr[4974]: /usr/bin/confd_mgr_in_spm.sh <NL> [  648.517459] ops-service[5011]: rebind_listener \"webui\" <NL> [  648.589408] ops-service[5011]: TRACE Connected (maapi) to ConfD <NL> [  648.589630] ops-service[5011]: TRACE MAAPI_REBIND_LISTENER <NL> [  648.589703] ops-service[5011]:  31-Jul-2024::08:22:55.391 5011/7fddc97aac40/4 SEND op=407 isrel=0 th=-1 16 <NL> [  648.690147] ops-service[5011]:  --> CONFD_OK <NL> [  648.758203] ops-service[5011]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  648.808410] confd_mgr[4974]: /usr/bin/ui_sys_reset.py NONE <NL> [  648.809205] ops-service[5017]: rebind_listener \"snmp\" <NL> [  648.880832] ops-service[5017]: TRACE Connected (maapi) to ConfD <NL> [  648.881049] ops-service[5017]: TRACE MAAPI_REBIND_LISTENER <NL> [  648.881134] ops-service[5017]:  31-Jul-2024::08:22:55.671 5017/7fc76d243c40/4 SEND op=407 isrel=0 th=-1 4 <NL> [  648.881200] ops-service[5017]:  --> CONFD_OK <NL> [  648.943313] ops-service[5017]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK"}
{"timestamp_utc": "2024-07-31T08:24:01.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  650.579465] confd_mgr[5038]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  650.615690] confd_mgr[5038]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  650.654499] confd_mgr[5039]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  650.696530] confd_mgr[5039]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  650.734585] confd_mgr[5040]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  650.783614] confd_mgr[5040]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  650.825340] confd_mgr[5018]: DDS Peristency is enabled <NL> [  650.856771] confd_mgr[5018]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  650.863476] confd_mgr[5018]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  650.916728] confd_mgr[5018]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  650.945357] confd_mgr[5018]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  651.055177] confd_mgr[5042]: Execute check_db_status.sh <NL> [  651.355962] confd_mgr[5042]: NE is running a default database! <NL> [  652.663414] systemd-sysv-generator[5061]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  652.496594] confd_mgr[4963]: Starting valhdlr.service if not started already <NL> [  658.915975] confd_mgr[4963]: Starting validation-handler.service if not started already <NL> [  661.433359] systemd-sysv-generator[5084]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  669.530367] confd_mgr[4963]: Starting snmp-fss-fw.service if not started already <NL> [  670.305153] confd_mgr[2866]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [  690.550182] confd_phase_sentry[2422]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [  690.550627] confd_phase_sentry[2422]: ConfdPhaseSentry: starting confd-ready.service <NL> [  690.726651] echo[5143]: Starting confd-ready <NL> [  691.414238] netconfEventSyslog[5149]: EventSyslogDaemon: Trying to connect to Confd <NL> [  692.559284] automater.sh[5146]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [  692.880797] confd_mgr[2866]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [  693.404334] confd_mgr[5168]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:23:40 UTC 2024 <NL> [  693.741990] confd_mgr[5191]: Execute common_confd_nb_ready_cb.sh <NL> [  693.815016] confd_mgr[5168]: Invoking confd_nb_enable.py <NL> [  693.924786] snmp_trapd[5159]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  695.429053] snmp_trapd[5159]: gen_util: DDS_P2MP not available <NL> [  699.902722] confd_mgr[5195]: nb_enable.py: INFO: Start <NL> [  699.902939] confd_mgr[5195]: Running \"systemctl stop netconf_socket_change.path\" <NL> [  699.903033] confd_mgr[5195]: Running \"systemctl stop cli_socket_change.path\" <NL> [  699.903091] confd_mgr[5195]: Running \"iptables -w -F chain-incoming-northbound\" <NL> [  699.903161] confd_mgr[5195]: Running \"iptables -w -D INPUT -p tcp -j chain-incoming-northbound\" <NL> [  699.903219] confd_mgr[5195]: Running \"iptables -w -X chain-incoming-northbound\" <NL> [  700.586765] confd_mgr[5168]: Exiting confd_nb_ready_cb.sh - Wed Jul 31 08:23:47 UTC 2024 <NL> [  702.620487] confd_mgr[2866]: Sending Startup notif <NL> [  707.451068] confd_mgr[5353]:  DB Notif Gen <NL> [  708.027569] confd_mgr[2866]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  708.027725] confd_mgr[2866]: leaving: sm_startconfd::start_confd_p2. <NL> [  708.082430] confd_mgr[4961]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  708.082625] confd_mgr[2866]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  708.082694] confd_mgr[2866]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  708.203969] confd_mgr[4446]: DDS Ports are opened <NL> [  709.363233] confd_mgr[5431]: openDdsPorts interfaces  eth5.2003 <NL> [  709.363649] confd_mgr[5431]: openDdsPorts Input udpPorts-  7660 <NL> [  709.480924] confd_mgr[5433]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  709.481666] confd_mgr[5431]: openDdsPorts Output udpPorts-  7660 <NL> [  709.572444] confd_mgr[5434]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  709.573062] confd_mgr[5431]: openDdsPorts Input udpPorts-  7661 <NL> [  709.732905] confd_mgr[5437]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  709.772922] confd_mgr[5431]: openDdsPorts Output udpPorts-  7661 <NL> [  709.789753] confd_mgr[5440]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  709.789903] confd_mgr[5431]: openDdsPorts Input udpPorts-  7650 <NL> [  710.033568] confd_mgr[5442]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  710.135044] confd_mgr[5431]: openDdsPorts Output udpPorts-  7650 <NL> [  710.388181] confd_mgr[5448]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  710.477698] confd_mgr[5431]: openDdsPorts Input udpPorts-  7651 <NL> [  710.670678] confd_mgr[5453]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  710.670869] confd_mgr[5431]: openDdsPorts Output udpPorts-  7651 <NL> [  711.197126] confd_mgr[5455]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  711.326090] confd_mgr[5431]: openDdsPorts Input udpPorts-  7900 <NL> [  711.725893] zero-touch-boot[5164]: NO match: <NL> [  711.886660] zero-touch-boot[5164]: NO match: <NL> [  712.047184] zero-touch-boot[5164]: NO match: <NL> [  712.247999] confd_mgr[5464]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  712.490916] confd_mgr[5431]: openDdsPorts Output udpPorts-  7900 <NL> [  712.644517] confd_mgr[5474]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  712.907153] confd_mgr[5431]: openDdsPorts Input udpPorts-  7901 <NL> [  713.325495] confd_mgr[5482]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  713.537836] confd_mgr[5431]: openDdsPorts Output udpPorts-  7901 <NL> [  713.630264] confd_mgr[5483]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  713.663115] confd_mgr[5431]: openDdsPorts Input udpPorts-  7910 <NL> [  713.682989] confd_mgr[5484]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  713.707078] confd_mgr[5431]: openDdsPorts Output udpPorts-  7910 <NL> [  713.707318] confd_mgr[5487]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  713.707401] confd_mgr[5431]: openDdsPorts Input udpPorts-  7911 <NL> [  713.707554] confd_mgr[5488]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  713.707623] confd_mgr[5431]: openDdsPorts Output udpPorts-  7911 <NL> [  713.707808] confd_mgr[5498]: iptables: Bad rule (does a matching rule exist in that chain?)."}
{"timestamp_utc": "2024-07-31T08:24:01.874Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:24:01 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:24:01 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:24:01 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"stderr\": DONE <NL> # 03:24:01 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"stdout\": DONE <NL> # 03:24:01 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\": process 3446 terminated with exitcode 0 <NL> # 03:24:01 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:24:01 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:24:01 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p01.main-startup (s)) <NL> # 03:24:01 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #0 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:24:01 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 2 children running (n01.p09.s01.startup (p)) <NL> # 03:24:01 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.s02.NE1-main-cli\", exit_code 0 <NL> # 03:24:01 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.main-startup (s)\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:24:10.168Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:24:09 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:24:14.336Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:24:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:24:19.645Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  651.426845] snmp_trapd[5130]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  652.071094] snmp_trapd[5130]: gen_util: DDS_P2MP not available <NL> [  657.950851] confd_mgr[5144]: nb_enable.py: INFO: Start <NL> [  658.076427] confd_mgr[5144]: Running \"systemctl stop netconf_socket_change.path\" <NL> [  658.199427] confd_mgr[5144]: Running \"systemctl stop cli_socket_change.path\" <NL> [  658.287104] confd_mgr[5144]: Running \"iptables -w -F chain-incoming-northbound\" <NL> [  658.516768] confd_mgr[5144]: Running \"iptables -w -D INPUT -p tcp -j chain-incoming-northbound\" <NL> [  658.550591] confd_mgr[5144]: Running \"iptables -w -X chain-incoming-northbound\" <NL> [  659.024473] confd_mgr[5112]: Exiting confd_nb_ready_cb.sh - Wed Jul 31 08:23:04 UTC 2024 <NL> [  661.026279] confd_mgr[2874]: Sending Startup notif <NL> [  668.235838] confd_mgr[5312]:  DB Notif Gen <NL> [  669.180220] confd_mgr[2874]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  669.262062] confd_mgr[2874]: leaving: sm_startconfd::start_confd_p2. <NL> [  669.268741] confd_mgr[4855]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  669.283869] confd_mgr[2874]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  669.324485] confd_mgr[2874]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  669.571388] confd_mgr[4404]: DDS Ports are opened <NL> [  670.582616] confd_mgr[5390]: openDdsPorts interfaces  eth5.2003 <NL> [  670.598527] confd_mgr[5390]: openDdsPorts Input udpPorts-  7660 <NL> [  670.598679] zero-touch-boot[5134]: NO match: <NL> [  670.598766] zero-touch-boot[5134]: NO match: <NL> [  670.636589] zero-touch-boot[5134]: NO match: <NL> [  670.940851] confd_mgr[5397]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.025049] confd_mgr[5390]: openDdsPorts Output udpPorts-  7660 <NL> [  671.400207] confd_mgr[5398]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.400390] confd_mgr[5390]: openDdsPorts Input udpPorts-  7661 <NL> [  671.400538] confd_mgr[5408]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.400598] confd_mgr[5390]: openDdsPorts Output udpPorts-  7661 <NL> [  671.400748] confd_mgr[5409]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.400808] confd_mgr[5390]: openDdsPorts Input udpPorts-  7650 <NL> [  671.400966] confd_mgr[5410]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.401041] confd_mgr[5390]: openDdsPorts Output udpPorts-  7650 <NL> [  671.558577] confd_mgr[5413]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.593611] confd_mgr[5390]: openDdsPorts Input udpPorts-  7651 <NL> [  671.701953] confd_mgr[5416]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.702241] confd_mgr[5390]: openDdsPorts Output udpPorts-  7651"}
{"timestamp_utc": "2024-07-31T08:24:19.646Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  671.704423] confd_mgr[5422]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.749284] confd_mgr[5390]: openDdsPorts Input udpPorts-  7900 <NL> [  671.914168] confd_mgr[5425]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.914659] confd_mgr[5390]: openDdsPorts Output udpPorts-  7900 <NL> [  671.991065] confd_mgr[5426]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  671.991294] confd_mgr[5390]: openDdsPorts Input udpPorts-  7901 <NL> [  672.043144] confd_mgr[5435]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.077250] confd_mgr[5390]: openDdsPorts Output udpPorts-  7901 <NL> [  672.227864] confd_mgr[5438]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.310483] confd_mgr[5390]: openDdsPorts Input udpPorts-  7910 <NL> [  672.310757] confd_mgr[5444]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.310829] confd_mgr[5390]: openDdsPorts Output udpPorts-  7910 <NL> [  672.434104] confd_mgr[5445]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.434285] confd_mgr[5390]: openDdsPorts Input udpPorts-  7911 <NL> [  672.596524] confd_mgr[5448]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.601952] confd_mgr[5390]: openDdsPorts Output udpPorts-  7911 <NL> [  672.602522] confd_mgr[5452]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.674495] confd_mgr[5390]: openDdsPorts Input udpPorts-  8150 <NL> [  672.767601] confd_mgr[5453]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.826205] confd_mgr[5390]: openDdsPorts Output udpPorts-  8150 <NL> [  672.898095] confd_mgr[5458]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.930704] confd_mgr[5390]: openDdsPorts Input udpPorts-  8151 <NL> [  672.932440] confd_mgr[5459]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  672.966678] confd_mgr[5390]: openDdsPorts Output udpPorts-  8151 <NL> [  672.985070] confd_mgr[5460]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  673.002032] confd_mgr[5390]: openDdsPorts Input udpPorts-  8160 <NL> [  673.139450] confd_mgr[5466]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  673.259867] confd_mgr[5390]: openDdsPorts Output udpPorts-  8160 <NL> [  673.353348] confd_mgr[5470]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  673.353438] confd_mgr[5390]: openDdsPorts Input udpPorts-  8161 <NL> [  673.876430] confd_mgr[5474]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  673.897014] confd_mgr[5390]: openDdsPorts Output udpPorts-  8161 <NL> [  673.950783] confd_mgr[5491]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  675.089807] confd_mgr[5519]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  675.989735] netconfEventSyslog[5120]: EventSyslogDaemon Waiting for event notifications... <NL> [  686.516256] confd_mgr[5519]: ==================== saving database ================== <NL> [  686.757604] confd_mgr[5581]: A.cdb <NL> [  686.925900] confd_mgr[5581]: A.cdb.sig <NL> [  686.926119] confd_mgr[5581]: C.cdb <NL> [  688.415566] confd_mgr[5581]: C.cdb.sig <NL> [  688.440649] confd_mgr[5581]: DefTxId <NL> [  688.447107] confd_mgr[5581]: O.cdb <NL> [  688.455096] confd_mgr[5581]: compact.lock <NL> [  688.467132] confd_mgr[5581]: dbmgmtdata.conf <NL> [  688.476019] confd_mgr[5581]: replay.cdb <NL> [  688.577569] confd_mgr[5581]: schema.sig <NL> [  688.643420] confd_mgr[2874]: entering: sm_startconfd::exit_to_ready <NL> [  688.652367] confd_mgr[2874]: leaving: sm_startconfd::exit_to_ready <NL> [  688.653053] confd_mgr[2874]: action at_sm_dbready::do_db_ready_a <NL> [  688.653816] confd_mgr[2874]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME <NL> [  688.655185] confd_mgr[2874]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME not defined. <NL> [  688.656413] confd_mgr[2874]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/recipe-sysroot/usr/include/boost/property_tree/detail/ptree_implementation.hpp(576): Throw in function boost::property_tree::basic_ptree<K, D, C>& boost::property_tree::basic_ptree<Key, Data, KeyCompare>::get_child(const path_type&) [with Key = std::__cxx11::basic_string<char>; Data = std::__cxx11::basic_string<char>; KeyCompare = std::less<std::__cxx11::basic_string<char> >; boost::property_tree::basic_ptree<Key, Data, KeyCompare>::path_type = boost::property_tree::string_path<std::__cxx11::basic_string<char>, boost::property_tree::id_translator<std::__cxx11::basic_string<char> > >] <NL> [  688.704009] confd_mgr[2874]: Dynamic exception type: boost::wrapexcept<boost::property_tree::ptree_bad_path> <NL> [  688.746166] confd_mgr[2874]: std::exception::what: No such node (DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME) <NL> [  688.747186] confd_mgr[2874]: Node is not present in the xml. Ignore the above exception. <NL> [  688.747952] confd_mgr[2874]: The dbmgmt_data_path_ and cdb file path passed to timestamp_operation.py script /var/shared/confd/bank0/dbmgmtdata.conf   /var/shared/confd/bank0/A.cdb <NL> [  689.972252] confd_mgr[2874]: ConfdHA::process_sdb_op SDB_REP_START <NL> [  690.029768] confd_mgr[2874]: ha_sm leaving: no_ha_s <NL> [  690.030327] confd_mgr[2874]: ha_sm entering: no_ha_s <NL> [  733.019193] zero-touch-boot[5746]: ls: cannot access './var/lib/dhcp/DHCPCV*.leases.ztp': No such file or directory"}
{"timestamp_utc": "2024-07-31T08:24:19.914Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:24:19 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp85.fnc.net.local:46502\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:24:22.425Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  693.102647] ntputils[1728]: poller time change delta is: 1 <NL> [  693.562067] ntputils[1728]: push_local_changes user_changed: 0 delta: 1 <NL> [  694.113848] ntputils[1728]: local_push OK u Platform::Time changedByUser 0 <NL> [  694.747050] ntputils[1728]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  695.111234] ntputils[1728]: local_push OK w Platform::Time 0 0 <NL> [  695.281923] ntputils[1728]: push_local_changes OK <NL> [  695.294964] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  695.296935] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  695.308959] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 3 <NL> [  695.315306] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 4 <NL> [  695.543823] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  695.545855] python3[2157]: [.333] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 26 of -1! <NL> [  698.511892] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 5 <NL> [  700.441199] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  701.739986] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  704.089770] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 6 <NL> [  704.671372] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 7 <NL> [  705.808914] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  706.665603] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  708.036281] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  708.738323] python3[2157]: [.363] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 27 of -1! <NL> [  709.831103] txid_tracker[3748]: ::::create_confd_subscription_connection() try number 8 <NL> [  711.196991] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  711.968039] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  712.913857] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 1 <NL> [  715.360716] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  715.851888] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  717.781814] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  718.456359] python3[2157]: [.384] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 28 of -1! <NL> [  718.696070] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 2 <NL> [  721.039941] confd_mgr[3425]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  721.200667] confd_mgr[3425]: confd_db_init::RESET REASON IS NONE <NL> [  721.366775] confd_mgr[3425]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  721.458442] confd_mgr[3425]: leaving: at_sm::wait_for_SWDL <NL> [  721.458988] confd_mgr[3425]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  721.618534] confd_mgr[3425]: ha_sm is_ha_mode_not_none_g cur_mode is 1+1 <NL> [  721.619713] confd_mgr[3425]: ha_sm leaving: wait_for_SWDL_s <NL> [  721.848318] confd_mgr[3425]: ha_sm::start_active_agent_a: The HA mode is 1+1 <NL> [  721.875354] confd_mgr[3425]: ha_sm_active entering: wait_for_active_agent_s <NL> [  721.875976] confd_mgr[3425]: ConfdTribActiveAgent start_rep_server <NL> [  721.931658] confd_mgr[3425]: ConfdTribActiveAgent::server address 127.1.254.254 port 4050 <NL> [  722.215636] confd_mgr[3425]: entering: at_sm::wait_for_start_bank <NL> [  722.230873] confd_mgr[3425]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  722.243358] confd_mgr[3425]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  722.515687] confd_mgr[3425]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  723.085531] confd_mgr[3425]: leaving: at_sm::wait_for_start_bank <NL> [  723.766088] confd_mgr[3425]: entering: at_sm_dbready::wait_for_db_status <NL> [  723.846626] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 3 <NL> [  724.459819] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 4 <NL> [  724.742244] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:24:22.426Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  725.562890] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  727.073764] confd_mgr[3575]: TRUE <NL> [  727.469452] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  727.646857] python3[2157]: [.565] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 29 of -1! <NL> [  728.310847] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  728.593249] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  729.045961] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 5 <NL> [  729.497649] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 6 <NL> [  729.762155] confd_mgr[3425]: calling accept_handler <NL> [  730.033572] confd_mgr[3425]: In ConfdTribActiveAgent::check_reset <NL> [  730.310686] confd_mgr[3425]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  730.463498] confd_mgr[3425]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  730.678540] confd_mgr[3425]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  730.960068] confd_mgr[3425]: ha_sm_active leaving: wait_for_active_agent_s <NL> [  731.438323] confd_mgr[3425]: process_ha_alarm raise noSecondaryDatabase <NL> [  731.965367] confd_mgr[3425]: ha_sm_active entering: wait_for_standby_s <NL> [  732.467418] confd_mgr[3425]: Maskable Alarm <NL> [  732.724206] confd_mgr[3425]: leaving: wait_for_alarm_event <NL> [  732.724833] confd_mgr[3425]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:152:add_to_alarms: OPERATION=raise CONDITION=noSecondaryDatabase #ALARMS=1 <NL> [  732.851457] confd_mgr[3425]: entering: wait_for_alarm_process <NL> [  733.548602] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 7 <NL> [  734.155924] confd_mgr[3999]: Executing check_db.sh <NL> [  734.260942] confd_mgr[3999]: check_db.sh: found xml files <NL> [  734.454082] confd_mgr[3999]: 0 <NL> [  734.598414] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  734.620244] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  734.777521] txid_tracker[3927]: ::::create_confd_subscription_connection() try number 8 <NL> [  734.913330] confd_mgr[3425]: Found no error <NL> [  734.996301] confd_mgr[3425]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  735.115407] confd_mgr[3425]: cur_gdbissue 24.1.1 gdbissue 24.1.1 rc = 1 <NL> [  735.367576] confd_mgr[3425]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  735.598164] confd_mgr[3425]: TSeries-CIS is in the list: TSeries-CIS"}
{"timestamp_utc": "2024-07-31T08:24:24.939Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:24:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46502, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:24:47.070Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "2024-07-31 08:20:10,059 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:20:10,060 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  494.594211] ntputils_client.py[1740]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:24:47.071Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  494.614499] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  494.614579] ntputils_client.py[1740]: b'31 Jul 08:20:20 ntpdate[3200]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  507.093267] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  507.093476] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  507.093545] ntputils_client.py[1740]: b'31 Jul 08:20:32 ntpdate[3247]: no server suitable for synchronization found\\n' <NL> [  519.084658] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  519.140263] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  519.235429] ntputils_client.py[1740]: b'31 Jul 08:20:44 ntpdate[3285]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:20:48,141 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  531.162046] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  531.168592] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  531.169416] ntputils_client.py[1740]: b'31 Jul 08:20:56 ntpdate[3328]: no server suitable for synchronization found\\n' <NL> [  543.129701] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  543.130463] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  543.131214] ntputils_client.py[1740]: b'31 Jul 08:21:08 ntpdate[3370]: no server suitable for synchronization found\\n' <NL> [  555.058534] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  555.058741] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  555.058805] ntputils_client.py[1740]: b'31 Jul 08:21:20 ntpdate[3422]: no server suitable for synchronization found\\n' <NL> [  567.173312] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  567.173658] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  567.204659] ntputils_client.py[1740]: b'31 Jul 08:21:32 ntpdate[3459]: no server suitable for synchronization found\\n' <NL> [  579.523375] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  579.523832] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  579.523918] ntputils_client.py[1740]: b'31 Jul 08:21:45 ntpdate[3502]: no server suitable for synchronization found\\n' <NL> [  591.490656] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  591.491045] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  591.491119] ntputils_client.py[1740]: b'31 Jul 08:21:56 ntpdate[3530]: no server suitable for synchronization found\\n' <NL> [  604.002159] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  604.002431] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  604.002871] ntputils_client.py[1740]: b'31 Jul 08:22:09 ntpdate[3576]: no server suitable for synchronization found\\n' <NL> [  616.301738] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  616.302076] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  616.302150] ntputils_client.py[1740]: b'31 Jul 08:22:21 ntpdate[3617]: no server suitable for synchronization found\\n' <NL> [  628.281230] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  628.281409] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  628.281469] ntputils_client.py[1740]: b'31 Jul 08:22:33 ntpdate[3668]: no server suitable for synchronization found\\n' <NL> [  640.248054] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  640.248345] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  640.248494] ntputils_client.py[1740]: b'31 Jul 08:22:45 ntpdate[3705]: no server suitable for synchronization found\\n' <NL> [  652.316059] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  652.316235] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  652.316298] ntputils_client.py[1740]: b'31 Jul 08:22:57 ntpdate[3732]: no server suitable for synchronization found\\n' <NL> [  664.261976] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  664.347057] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  664.347173] ntputils_client.py[1740]: b'31 Jul 08:23:09 ntpdate[3765]: no server suitable for synchronization found\\n' <NL> [  676.283298] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  676.294361] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  676.294479] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, offset -1.051795, delay 0.02888\\n31 Jul 08:23:21 ntpdate[3814]: no server suitable for synchronization found\\n' <NL> [  688.282956] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  688.283259] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  688.283356] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, offset -1.047807, delay 0.03464\\n31 Jul 08:23:33 ntpdate[3859]: no server suitable for synchronization found\\n' <NL> [  700.154771] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  700.155141] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  700.155214] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, offset -1.047835, delay 0.03482\\n31 Jul 08:23:45 ntpdate[3887]: no server suitable for synchronization found\\n' <NL> [  712.276450] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  712.276719] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  712.276771] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, offset -1.052848, delay 0.09158\\n31 Jul 08:23:57 ntpdate[3921]: no server suitable for synchronization found\\n' <NL> [  724.241067] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  724.265164] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  724.288165] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, offset -1.047468, delay 0.09952\\n31 Jul 08:24:09 ntpdate[3955]: no server suitable for synchronization found\\n' <NL> [  736.438064] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  736.438225] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:24:47.072Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  736.438280] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, offset -1.042115, delay 0.04630\\n31 Jul 08:24:21 ntpdate[4039]: no server suitable for synchronization found\\n' <NL> [  748.379582] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  748.390044] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  748.390143] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, offset -1.044569, delay 0.04561\\n31 Jul 08:24:33 ntpdate[4083]: no server suitable for synchronization found\\n' <NL> [  760.355612] ntputils_client.py[1740]: INFO:root:command failed. <NL> [  760.355905] ntputils_client.py[1740]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:24:57.012Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:24:56 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:24:56 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:24:56 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:24:56 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:24:56 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\": process 3364 terminated with exitcode 0 <NL> # 03:24:56 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:24:56 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:24:56 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46501', '--delay', '5'] (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:24:56 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p05.s02.NE3-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46501', '--delay', '5'] <NL> # 03:24:56 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:24:56 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"command\" <NL> # 03:24:56 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:24:57.267Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:24:57 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46501, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:24:57.523Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:24:57 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:02.936Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:02 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:04.884Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  701.099264] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  702.774815] txid_tracker[3846]: ::::create_confd_subscription_connection() try number 8 <NL> [  706.070890] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  707.862180] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  709.652501] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  710.386071] python3[2140]: [.466] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 33 of -1! <NL> [  711.816908] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  713.132699] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  714.080268] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 1 <NL> [  714.496981] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 2 <NL> [  715.805312] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 3 <NL> [  716.542560] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  716.672977] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  717.125588] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  717.713330] python3[2140]: [.527] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 34 of -1! <NL> [  718.679835] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 4 <NL> [  720.879267] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  721.374813] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  722.091475] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 5 <NL> [  724.634838] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 6 <NL> [  726.365916] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  727.065339] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  728.790802] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  729.738421] python3[2140]: [.540] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 35 of -1! <NL> [  730.266787] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 7 <NL> [  732.916405] txid_tracker[3953]: ::::create_confd_subscription_connection() try number 8 <NL> [  733.648980] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  735.288786] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  737.543536] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  737.780856] python3[2140]: [.598] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 36 of -1! <NL> [  737.883489] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:25:04.885Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  738.089326] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  738.758817] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 1 <NL> [  741.054918] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 2 <NL> [  741.805916] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  741.822136] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  744.007879] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 3 <NL> [  747.559204] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  747.767835] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  749.130972] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  750.020755] python3[2140]: [.671] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 37 of -1! <NL> [  751.202549] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 4 <NL> [  751.322061] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 5 <NL> [  752.316950] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  753.173485] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  754.300622] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 6 <NL> [  756.452627] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 7 <NL> [  757.863348] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  758.623631] python3[2140]: [.746] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 38 of -1! <NL> [  759.823351] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  760.668813] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  761.237394] txid_tracker[4033]: ::::create_confd_subscription_connection() try number 8 <NL> [  761.777608] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  762.069698] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  766.310264] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 1 <NL> [  767.449673] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  768.001141] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  768.467534] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  768.689422] python3[2140]: [.545] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 39 of -1! <NL> [  769.324718] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 2 <NL> [  771.819789] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  773.500117] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  773.841412] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 3"}
{"timestamp_utc": "2024-07-31T08:25:05.814Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:25:05 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:25:07.699Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:07 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:10.963Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:25:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:25:12.665Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:12 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:17.915Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:17 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:18.475Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  621.547833] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  621.552341] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  621.552422] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.004028, delay 0.03999\\n31 Jul 08:22:30 ntpdate[3901]: no server suitable for synchronization found\\n' <NL> [  633.455586] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  633.455804] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  633.455866] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.006769, delay 0.06750\\n31 Jul 08:22:41 ntpdate[3942]: no server suitable for synchronization found\\n' <NL> [  643.999439] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2403 <NL> [  644.043880] layer1_control_layer[2053]: EsalConfig::EsalConfig main 0 <NL> [  644.047069] layer1_control_layer[2053]: EsalConfig::EsalConfig trib 1 <NL> [  644.053599] layer1_control_layer[2053]: EsalConfig::EsalConfig ciRole 0 <NL> [  644.095857] layer1_control_layer[2053]: EsalConfig is not running inside container. <NL> [  644.096070] layer1_control_layer[2053]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  644.096157] layer1_control_layer[2053]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  644.096220] layer1_control_layer[2053]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  644.096278] layer1_control_layer[2053]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  644.096384] layer1_control_layer[2053]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  644.096440] layer1_control_layer[2053]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  644.096496] layer1_control_layer[2053]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  644.096672] layer1_control_layer[2053]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  644.096735] layer1_control_layer[2053]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  644.096793] layer1_control_layer[2053]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  644.096859] layer1_control_layer[2053]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  644.096928] layer1_control_layer[2053]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  644.096992] layer1_control_layer[2053]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  644.097065] layer1_control_layer[2053]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  644.097135] layer1_control_layer[2053]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  644.097197] layer1_control_layer[2053]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  644.097255] layer1_control_layer[2053]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  644.525020] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2402 <NL> [  644.584314] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2402 <NL> [  644.744600] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2402 <NL> [  644.744840] layer1_hal[2087]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  644.826694] layer1_hal[2087]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  644.853043] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2402 <NL> [  644.911881] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2402 <NL> [  645.017165] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2402 <NL> [  645.180561] layer1_control_layer[2053]:    ChalApi Constructor with tid = 2405 <NL> [  645.626250] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  645.626420] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  645.626476] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.050332, delay 0.12263\\n31 Jul 08:22:54 ntpdate[3980]: no server suitable for synchronization found\\n' <NL> [  657.371160] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  657.371753] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  657.371846] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.001510, delay 0.03392\\n31 Jul 08:23:05 ntpdate[4038]: no server suitable for synchronization found\\n' <NL> [  669.591115] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  669.591320] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  669.591384] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset +0.005248, delay 0.04532\\n31 Jul 08:23:18 ntpdate[4079]: no server suitable for synchronization found\\n' <NL> [  681.576525] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  681.576715] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  681.576796] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.003070, delay 0.02872\\n31 Jul 08:23:30 ntpdate[4110]: no server suitable for synchronization found\\n' <NL> [  693.481699] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  693.482636] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  693.483387] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.006224, delay 0.03030\\n31 Jul 08:23:42 ntpdate[4146]: no server suitable for synchronization found\\n' <NL> [  705.441220] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  705.441604] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  705.441685] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.029293, delay 0.07698\\n31 Jul 08:23:53 ntpdate[4173]: no server suitable for synchronization found\\n' <NL> [  717.254216] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  717.254394] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  717.254458] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.003687, delay 0.03951\\n31 Jul 08:24:05 ntpdate[4199]: no server suitable for synchronization found\\n' <NL> [  729.186035] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  729.186246] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  729.186308] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.010293, delay 0.03917\\n31 Jul 08:24:17 ntpdate[4243]: no server suitable for synchronization found\\n' <NL> [  741.147309] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  741.150363] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  741.151042] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.008222, delay 0.03546\\n31 Jul 08:24:29 ntpdate[4299]: no server suitable for synchronization found\\n' <NL> [  753.042713] ntputils_client.py[1727]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:25:18.476Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  753.077513] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  753.134373] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.011985, delay 0.04343\\n31 Jul 08:24:41 ntpdate[4338]: no server suitable for synchronization found\\n' <NL> [  765.168358] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  765.168591] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  765.168656] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.003938, delay 0.02820\\n31 Jul 08:24:53 ntpdate[4365]: no server suitable for synchronization found\\n' <NL> [  777.215113] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  777.215487] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  777.215565] ntputils_client.py[1727]: b'server 127.1.254.254, stratum 16, offset -0.022767, delay 0.06316\\n31 Jul 08:25:05 ntpdate[4392]: no server suitable for synchronization found\\n' <NL> [  789.216146] ntputils_client.py[1727]: INFO:root:command failed. <NL> [  789.256313] ntputils_client.py[1727]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:25:22.639Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  735.921270] confd_mgr[3425]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  736.278795] confd_mgr[3425]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  736.799705] confd_mgr[3425]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  737.127777] confd_mgr[3425]: guard at_sm_dbready::sw_not_synced_dfltsys_g"}
{"timestamp_utc": "2024-07-31T08:25:22.640Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  737.502674] confd_mgr[3425]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  738.683705] confd_mgr[3425]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  739.389291] confd_mgr[3425]: guard is_db_okay_g: The HA mode is 1+1 <NL> [  740.463884] confd_mgr[3425]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  741.576997] confd_mgr[3425]: entering: sm_startconfd::start_confd_p0 <NL> [  741.749434] confd_mgr[3425]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  742.350334] confd_mgr[4016]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:24:08 UTC 2024 <NL> [  742.988378] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  743.152726] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  743.449123] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  743.660689] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  744.104034] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  744.179384] python3[2157]: [.672] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 30 of -1! <NL> [  745.487349] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 1 <NL> [  745.938505] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 2 <NL> [  746.559241] confd_mgr[3425]: leaving: wait_for_alarm_process <NL> [  747.230226] confd_mgr[3425]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:160:write_alarms_to_file: #ALARMS=1 <NL> [  747.278411] confd_mgr[3425]:  write_db_alarm rename was successful <NL> [  747.615113] confd_mgr[3425]: entering: wait_for_alarm_event <NL> [  747.855956] confd_mgr[3425]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  749.100681] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  749.729236] python3[2157]: [.723] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 31 of -1! <NL> [  750.000316] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  750.159215] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  750.341694] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 3 <NL> [  750.589461] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 4 <NL> [  750.891064] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  751.065941] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  752.186681] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 5 <NL> [  755.251349] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 6 <NL> [  756.057088] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  756.478078] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  757.002658] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  757.370493] python3[2157]: [.743] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 32 of -1! <NL> [  758.039169] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 7 <NL> [  761.051443] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  761.071842] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  761.228525] txid_tracker[4103]: ::::create_confd_subscription_connection() try number 8 <NL> [  766.214510] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  766.231862] python3[2157]: [.778] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 33 of -1! <NL> [  766.619756] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  766.638546] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  766.793553] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 1 <NL> [  769.773803] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 2 <NL> [  771.545657] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  771.907058] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  773.606329] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 3 <NL> [  775.745410] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 4 <NL> [  778.772868] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  780.552648] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  786.714020] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  786.717751] python3[2157]: [.789] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 34 of -1! <NL> [  787.057550] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  787.696602] python3[2157]: [.406] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 35 of -1! <NL> [  789.184272] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  790.832655] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  791.944807] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  792.233927] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  793.066807] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 5 <NL> [  793.297549] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 6 <NL> [  793.298380] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 7 <NL> [  793.300182] txid_tracker[4173]: ::::create_confd_subscription_connection() try number 8 <NL> [  793.814641] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  794.104140] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> # 03:25:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:22 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:28.003Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:27 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:33.248Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:32 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:38.490Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:37 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:43.087Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:42 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:47.266Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  647.848607] ntputils_client.py[1726]:     self.publish_local_changes(time_change_reason, time_delta) <NL> [  647.848691] ntputils_client.py[1726]:   File \"/usr/local/fnc/ntputils/ntputils_client.py\", line 214, in publish_local_changes <NL> [  647.848768] ntputils_client.py[1726]:     logging.info('publish_local_changes ZMQ Error %s', str(err.what())) <NL> [  647.848849] ntputils_client.py[1726]: AttributeError: 'ZMQError' object has no attribute 'what' <NL> [  651.369526] ntputils_client.py[3939]: Disabling ntputils_client() <NL> [  671.408241] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  671.408447] ntputils_client.py[3991]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  671.408523] ntputils_client.py[3991]: b'31 Jul 08:23:16 ntpdate[3999]: no server suitable for synchronization found\\n' <NL> [  678.538878] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  678.572835] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  678.594169] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset +0.001191, delay 0.02681\\n31 Jul 08:23:23 ntpdate[4032]: no server suitable for synchronization found\\n' <NL> [  689.559100] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2402 <NL> [  689.648529] layer1_control_layer[2082]: EsalConfig::EsalConfig main 0 <NL> [  689.648678] layer1_control_layer[2082]: EsalConfig::EsalConfig trib 1 <NL> [  689.648727] layer1_control_layer[2082]: EsalConfig::EsalConfig ciRole 0 <NL> [  689.681680] layer1_control_layer[2082]: EsalConfig is not running inside container. <NL> [  689.681858] layer1_control_layer[2082]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  689.681927] layer1_control_layer[2082]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  689.681985] layer1_control_layer[2082]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  689.682056] layer1_control_layer[2082]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  689.682109] layer1_control_layer[2082]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  689.682166] layer1_control_layer[2082]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  689.682222] layer1_control_layer[2082]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  689.682274] layer1_control_layer[2082]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  689.682327] layer1_control_layer[2082]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  689.682379] layer1_control_layer[2082]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  689.682543] layer1_control_layer[2082]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  689.682610] layer1_control_layer[2082]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  689.682667] layer1_control_layer[2082]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  689.682720] layer1_control_layer[2082]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  689.682773] layer1_control_layer[2082]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  689.682826] layer1_control_layer[2082]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  689.682877] layer1_control_layer[2082]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  690.055704] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2401 <NL> [  690.131870] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2401 <NL> [  690.166175] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2401"}
{"timestamp_utc": "2024-07-31T08:25:47.267Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  690.257554] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2401 <NL> [  690.272393] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2401 <NL> [  690.335730] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2401 <NL> [  690.398516] layer1_hal[2101]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  690.433578] layer1_hal[2101]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  690.483266] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  690.484922] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  690.498712] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset +0.004678, delay 0.05551\\n31 Jul 08:23:35 ntpdate[4064]: no server suitable for synchronization found\\n' <NL> [  690.774120] layer1_control_layer[2082]:    ChalApi Constructor with tid = 2404 <NL> [  702.588267] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  702.602215] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  702.602972] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset +0.007014, delay 0.05113\\n31 Jul 08:23:47 ntpdate[4147]: no server suitable for synchronization found\\n' <NL> [  714.527927] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  714.616959] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  714.741426] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset +0.018225, delay 0.06064\\n31 Jul 08:23:59 ntpdate[4180]: no server suitable for synchronization found\\n' <NL> [  726.356481] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  726.363871] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  726.374107] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset +0.019754, delay 0.06575\\n31 Jul 08:24:11 ntpdate[4223]: no server suitable for synchronization found\\n' <NL> [  738.269880] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  738.270840] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  738.292963] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset -0.000205, delay 0.02863\\n31 Jul 08:24:23 ntpdate[4271]: no server suitable for synchronization found\\n' <NL> [  750.244978] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  750.245172] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  750.245238] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset -0.005186, delay 0.04301\\n31 Jul 08:24:35 ntpdate[4297]: no server suitable for synchronization found\\n' <NL> [  762.202406] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  762.202760] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  762.202849] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset -0.002999, delay 0.03612\\n31 Jul 08:24:47 ntpdate[4332]: no server suitable for synchronization found\\n' <NL> [  774.050036] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  774.050279] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  774.050351] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset -0.034267, delay 0.09695\\n31 Jul 08:24:58 ntpdate[4378]: no server suitable for synchronization found\\n' <NL> [  785.951877] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  785.952183] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  785.952243] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset +0.001444, delay 0.02704\\n31 Jul 08:25:10 ntpdate[4405]: no server suitable for synchronization found\\n' <NL> [  797.798610] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  797.798784] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  797.798865] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset -0.006264, delay 0.05928\\n31 Jul 08:25:22 ntpdate[4433]: no server suitable for synchronization found\\n' <NL> [  809.749690] ntputils_client.py[3991]: INFO:root:command failed. <NL> [  809.749894] ntputils_client.py[3991]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  809.749954] ntputils_client.py[3991]: b'server 127.1.254.254, stratum 16, offset +0.001100, delay 0.02650\\n31 Jul 08:25:34 ntpdate[4460]: no server suitable for synchronization found\\n' <NL> [  821.509887] ntputils_client.py[3991]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:25:47.831Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:47 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:53.081Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:52 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:57.246Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:25:56 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:25:57.806Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:57 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:02.527Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:26:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:26:02.784Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:02 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:08.162Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:07 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:13.401Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:12 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:16.668Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  775.336103] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 4 <NL> [  776.711359] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  777.456035] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  778.334042] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 5 <NL> [  778.624732] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  779.183432] python3[2140]: [.647] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 40 of -1! <NL> [  781.321357] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 6 <NL> [  782.585902] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  783.215947] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  784.151569] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 7 <NL> [  788.240296] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  789.556819] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  792.473191] txid_tracker[4098]: ::::create_confd_subscription_connection() try number 8 <NL> [  793.759965] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  794.081960] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  794.887239] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  795.161106] python3[2140]: [.862] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 41 of -1! <NL> [  796.684171] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 1 <NL> [  796.684977] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 2 <NL> [  796.877897] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  797.316332] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  798.334840] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  798.812940] python3[2140]: [.166] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 42 of -1! <NL> [  799.707663] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 3 <NL> [  802.212148] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  802.782970] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  803.178083] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 4 <NL> [  805.717952] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 5 <NL> [  806.868546] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  807.685950] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  808.820857] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 6 <NL> [  809.418386] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  809.800461] python3[2140]: [.417] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 43 of -1! <NL> [  811.862642] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 7 <NL> [  811.991597] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  812.412665] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  814.766996] txid_tracker[4160]: ::::create_confd_subscription_connection() try number 8 <NL> [  817.150501] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  817.872599] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  819.420516] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  819.800332] python3[2140]: [.431] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 44 of -1! <NL> [  820.600323] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 1 <NL> [  822.446701] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  823.127450] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  825.458845] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 2 <NL> [  825.813658] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 3 <NL> [  826.973316] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  827.802884] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  828.916694] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  829.363797] python3[2140]: [.445] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 45 of -1! <NL> [  829.874830] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 4 <NL> [  831.825096] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 5 <NL> [  833.267581] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  833.782272] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  835.367565] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 6 <NL> [  837.215300] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  837.548403] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  837.854789] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 7 <NL> [  838.457328] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  838.740244] python3[2140]: [.459] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 46 of -1! <NL> [  840.871460] txid_tracker[4241]: ::::create_confd_subscription_connection() try number 8 <NL> [  842.003829] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:26:18.032Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:17 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:23.419Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:22 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:28.676Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:27 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:32.874Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:32 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:33.803Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  795.353263] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 1 <NL> [  795.474372] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 2 <NL> [  796.267371] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  796.819021] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  796.903341] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  796.904468] python3[2157]: [.418] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 36 of -1! <NL> [  798.248720] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 3 <NL> [  802.678820] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 4 <NL> [  803.657977] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  803.939452] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  805.591734] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 5 <NL> [  806.574424] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  807.144857] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  807.868974] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 6"}
{"timestamp_utc": "2024-07-31T08:26:33.804Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  809.280493] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  809.856705] python3[2157]: [.541] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 37 of -1! <NL> [  811.415767] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 7 <NL> [  813.951866] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  815.088713] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  816.157967] txid_tracker[4235]: ::::create_confd_subscription_connection() try number 8 <NL> [  816.438374] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  817.493428] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  818.746626] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  819.536032] python3[2157]: [.597] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 38 of -1! <NL> [  822.012379] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  822.444807] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  822.803863] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 1 <NL> [  824.583617] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 2 <NL> [  826.415341] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  826.655269] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  827.535103] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  827.761466] python3[2157]: [.609] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 39 of -1! <NL> [  828.359675] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 3 <NL> [  830.798519] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 4 <NL> [  831.456848] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  832.101748] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  833.578087] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 5 <NL> [  836.474388] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  836.846441] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  838.793642] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 6 <NL> [  839.025623] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  839.563761] python3[2157]: [.673] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 40 of -1! <NL> [  840.231425] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 7 <NL> [  841.497557] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  842.214935] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  844.338971] txid_tracker[4312]: ::::create_confd_subscription_connection() try number 8[  845.118584] systemd-sysv-generator[4420]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  846.795139] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  847.452830] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  848.851910] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  850.484574] python3[2157]: [.717] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 41 of -1! <NL> [  851.777830] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  852.345733] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  856.711976] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  857.416023] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused[  858.326835] tun: Universal TUN/TAP device driver, 1.6 <NL> [  858.968538] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  859.100435] python3[2157]: [.844] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 42 of -1! <NL> [  860.020259] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 1 <NL> [  862.036028] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  862.076325] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  862.788660] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 2 <NL> [  865.792329] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 3"}
{"timestamp_utc": "2024-07-31T08:26:38.100Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:26:37 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp85.fnc.net.local:46486\" AuthenticationException('Authentication timeout.',) <NL> # 03:26:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:37 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:43.638Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:26:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46486, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:42 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:47.885Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:47 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:53.143Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:52 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:58.470Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:57 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:03.828Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:03 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:08.084Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:27:07 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:27:07 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:27:07 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:27:07 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:27:07 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\": process 3366 terminated with exitcode 0 <NL> # 03:27:07 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:27:07 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:27:07 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46485', '--delay', '5'] (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:27:07 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p07.s02.NE4-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp85.fnc.net.local', '--port', '46485', '--delay', '5'] <NL> # 03:27:07 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:27:07 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"command\" <NL> # 03:27:07 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", exit_code 0 <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6."}
{"timestamp_utc": "2024-07-31T08:27:08.085Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "from cryptography.hazmat.backends import default_backend <NL> # 03:27:07 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp85.fnc.net.local', port 46485, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:07 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:08.383Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:08 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:13.763Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:13 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:13 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:18.041Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:18 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:18.297Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:18 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:21.718Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  843.157529] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused[  847.254246] systemd-sysv-generator[4381]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  848.939185] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  849.912615] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  853.700837] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  854.634594] python3[2140]: [.490] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 47 of -1! <NL> [  856.712857] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  858.339460] tun: Universal TUN/TAP device driver, 1.6 <NL> [  858.141310] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  860.714599] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  861.022566] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  862.430246] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  863.479280] python3[2140]: [.516] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 48 of -1! <NL> [  863.974165] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  864.228061] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  864.696471] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 1 <NL> [  865.002913] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 2 <NL> [  865.846992] systemd-journald[324]: Data hash table of /run/log/journal/4ffda74c328b4ae7adf1371a3c95bfd6/system.journal has a fill level at 75.0 (13654 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  866.365763] systemd-journald[324]: /run/log/journal/4ffda74c328b4ae7adf1371a3c95bfd6/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  866.716852] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 3 <NL> [  867.178903] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  867.179777] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  868.527083] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  869.110401] python3[2140]: [.528] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 49 of -1! <NL> [  869.643325] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 4 <NL> [  872.199692] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  872.460581] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  873.253505] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 5 <NL> [  875.665889] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 6 <NL> [  877.213524] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  877.349367] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  878.575529] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  879.054085] python3[2140]: [.577] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 50 of -1! <NL> [  879.260749] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 7 <NL> [  881.924138] txid_tracker[4409]: ::::create_confd_subscription_connection() try number 8 <NL> [  882.799803] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  883.911888] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  886.946842] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 1 <NL> [  887.332473] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  887.475767] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  888.605556] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  888.866585] python3[2140]: [.647] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 51 of -1! <NL> [  890.022676] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 2 <NL> [  892.231660] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  893.278074] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  894.646797] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 3 <NL> [  896.167706] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 4 <NL> [  897.332839] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  897.997992] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  901.056151] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 5 <NL> [  901.647947] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  902.341038] python3[2140]: [.670] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 52 of -1! <NL> [  903.866954] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 6 <NL> [  904.203873] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  904.667711] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  905.661559] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 7 <NL> [  907.266852] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  907.808404] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  908.723001] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  909.120523] txid_tracker[4467]: ::::create_confd_subscription_connection() try number 8 <NL> [  909.677643] python3[2140]: [.679] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 53 of -1! <NL> [  912.404496] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:27:23.085Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:23 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:27:23.340Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:23 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:28.702Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:28 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:28 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:33.961Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:33 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:33 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:38.258Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:38 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:38.515Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:38 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:43.761Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:43 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:43 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:44.323Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  867.034976] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  867.143121] python3[2157]: [.898] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 43 of -1! <NL> [  867.453046] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  867.463351] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  868.797923] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 4 <NL> [  871.816452] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 5 <NL> [  872.083933] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  872.217772] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  874.842164] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 6 <NL> [  877.090231] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  877.264869] python3[2157]: [.917] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 44 of -1! <NL> [  877.633647] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  877.634474] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  877.842372] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 7 <NL> [  880.854485] txid_tracker[4450]: ::::create_confd_subscription_connection() try number 8 <NL> [  882.149607] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  882.241427] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  886.154774] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 1 <NL> [  887.126839] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  887.588329] python3[2157]: [.009] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 45 of -1! <NL> [  887.828329] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  888.048116] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  889.198952] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 2 <NL> [  892.229296] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 3 <NL> [  892.368812] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  892.475360] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  895.228173] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 4 <NL> [  897.251844] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  897.253016] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  898.481059] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 5 <NL> [  898.958886] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  899.028667] python3[2157]: [.224] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 46 of -1! <NL> [  901.356173] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 6 <NL> [  902.267969] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  902.311953] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  904.307223] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 7 <NL> [  907.284566] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  907.762339] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  908.379184] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  908.532935] python3[2157]: [.292] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 47 of -1! <NL> [  909.088133] txid_tracker[4522]: ::::create_confd_subscription_connection() try number 8 <NL> [  912.287892] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  913.251772] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  914.162762] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 1"}
{"timestamp_utc": "2024-07-31T08:27:44.324Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  917.260760] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 2 <NL> [  917.848076] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  918.226658] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  919.109485] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  919.471164] python3[2157]: [.872] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 48 of -1! <NL> [  920.714744] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 3 <NL> [  922.527792] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  922.872667] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  923.444962] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 4 <NL> [  926.834429] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 5 <NL> [  927.451945] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  927.555522] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  928.149749] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  928.282626] python3[2157]: [.889] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 49 of -1! <NL> [  929.550809] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 6 <NL> [  932.490406] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  932.491227] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  933.413108] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 7 <NL> [  935.670090] txid_tracker[4592]: ::::create_confd_subscription_connection() try number 8 <NL> [  937.514345] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:27:48.497Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:48 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:48 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:53.760Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:53 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:53 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:59.015Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:58 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:58 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:03.325Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:03 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:03.584Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:03 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:08.866Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:08 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:08 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:14.131Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:28:14.132Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:13 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:13 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:16.647Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  937.639028] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  938.347715] python3[2157]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  938.483814] python3[2157]: [.124] hookhdlr 139927729420096 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 50 of -1! <NL> [  941.231546] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 1 <NL> [  942.538361] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  942.638303] confd_phase_sentry[2163]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f488ebd45c7; Failed to connect to ConfD: Connection refused <NL> [  944.391718] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 2 <NL> [  946.620281] rasis_system_stats.py[2167]: Traceback (most recent call last): <NL> [  946.712661] rasis_system_stats.py[2167]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  946.741615] rasis_system_stats.py[2167]:     main() <NL> [  946.743731] rasis_system_stats.py[2167]:   File \"/usr/bin/rasis_system_stats.py\", line 352, in main <NL> [  946.767887] rasis_system_stats.py[2167]:     maapi.Maapi(port=CONFD_PORT) <NL> [  946.846858] rasis_system_stats.py[2167]:   File \"/usr/lib/python3.10/site-packages/confd/maapi.py\", line 321, in __init__ <NL> [  946.983473] rasis_system_stats.py[2167]:     self.msock = connect(ip, port, path) <NL> [  947.057828] rasis_system_stats.py[2167]:   File \"/usr/lib/python3.10/site-packages/confd/maapi.py\", line 118, in connect <NL> [  947.100954] rasis_system_stats.py[2167]:     _tm.maapi.connect(msock, ip, port) <NL> [  947.190942] rasis_system_stats.py[2167]: _confd.error.EOF: ConfD closed connection <NL> [  947.407294] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 3 <NL> [  947.600289] confd_phase_sentry[2163]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  947.769554] confd_phase_sentry[2163]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  948.415775] python3[2157]: DEBUG EOF on socket to ConfD <NL> [  948.512419] python3[2157]: [.227] hookhdlr 139927729420096 callbackhdlr:457 Exception to create daemon <NL> [  948.607802] python3[2157]: Traceback (most recent call last): <NL> [  948.636568] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  948.637784] python3[2157]:     daemon = self.create_daemon() <NL> [  948.669099] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  948.747987] python3[2157]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  948.811225] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  948.841081] python3[2157]:     self._init_connection() <NL> [  948.919680] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  949.115422] python3[2157]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  949.149395] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  949.204706] python3[2157]:     _tm.dp.connect( <NL> [  949.207563] python3[2157]: _confd.error.EOF: ConfD closed connection <NL> [  949.208856] python3[2157]: [.331] hookhdlr 139927729420096 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  950.330588] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 4 <NL> [  953.332850] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 5 <NL> [  956.245292] db_info.py[2146]: Traceback (most recent call last): <NL> [  956.536465] db_info.py[2146]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  957.251133] db_info.py[2146]:     main() <NL> [  957.379679] db_info.py[2146]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  957.531975] db_info.py[2146]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  958.427075] db_info.py[2146]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  958.872530] db_info.py[2146]:     self._init_connection() <NL> [  959.315846] db_info.py[2146]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  959.644390] db_info.py[2146]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  959.945216] db_info.py[2146]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  960.373660] db_info.py[2146]:     _tm.dp.connect( <NL> [  960.507876] db_info.py[2146]: _confd.error.EOF: ConfD closed connection <NL> [  960.637405] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 6 <NL> [  960.793362] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 7 <NL> [  961.344291] python3[2157]: [.344] hookhdlr 139927729420096 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  961.658720] python3[2157]: DEBUG EOF on socket to ConfD <NL> [  961.659308] python3[2157]: [.788] hookhdlr 139927729420096 callbackhdlr:457 Exception to create daemon <NL> [  961.660112] python3[2157]: Traceback (most recent call last):"}
{"timestamp_utc": "2024-07-31T08:28:16.648Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  961.686041] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  962.011068] python3[2157]:     daemon = self.create_daemon() <NL> [  962.036621] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  962.162847] python3[2157]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  962.393727] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  962.679988] python3[2157]:     self._init_connection() <NL> [  962.767931] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  962.870319] python3[2157]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  963.088197] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  963.336498] python3[2157]:     _tm.dp.connect( <NL> [  963.428953] python3[2157]: _confd.error.EOF: ConfD closed connection <NL> [  963.540797] python3[2157]: [.940] hookhdlr 139927729420096 callbackhdlr:471 Failed to run daemon main, retry 2 of -1 <NL> [  963.687327] healthcheck_result_display.py[2154]: Traceback (most recent call last): <NL> [  963.864944] healthcheck_result_display.py[2154]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  964.113798] healthcheck_result_display.py[2154]:     main(hc_utils.setup_logging(__name__)) <NL> [  964.198786] healthcheck_result_display.py[2154]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  964.257106] healthcheck_result_display.py[2154]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  964.275089] healthcheck_result_display.py[2154]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  964.276799] healthcheck_result_display.py[2154]:     self._init_connection() <NL> [  964.278310] healthcheck_result_display.py[2154]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  964.378633] healthcheck_result_display.py[2154]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  964.479260] healthcheck_result_display.py[2154]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  964.630946] healthcheck_result_display.py[2154]:     _tm.dp.connect( <NL> [  964.754353] healthcheck_result_display.py[2154]: _confd.error.EOF: ConfD closed connection <NL> [  964.977722] txid_tracker[4651]: ::::create_confd_subscription_connection() try number 8 <NL> [  967.464434] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 1 <NL> [  969.155096] python3[2157]: [.980] hookhdlr 139927729420096 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  969.504777] python3[2157]: DEBUG EOF on socket to ConfD <NL> [  969.609303] python3[2157]: [.331] hookhdlr 139927729420096 callbackhdlr:457 Exception to create daemon"}
{"timestamp_utc": "2024-07-31T08:28:18.533Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:18 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:18.790Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:18 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:21.308Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  912.405273] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  916.001648] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 1 <NL> [  917.415231] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  918.626551] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  919.470269] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 2 <NL> [  920.210509] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  921.081876] python3[2140]: [.991] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 54 of -1! <NL> [  923.034626] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 3 <NL> [  923.627179] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  924.717059] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  926.549069] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 4 <NL> [  927.672615] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  927.916884] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  928.258332] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 5 <NL> [  930.058036] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  930.131212] python3[2140]: [.002] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 55 of -1! <NL> [  931.228790] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 6 <NL> [  932.682193] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  932.731758] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  934.233900] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 7 <NL> [  937.249885] txid_tracker[4545]: ::::create_confd_subscription_connection() try number 8 <NL> [  937.688680] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  937.958706] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  940.010504] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  940.105752] python3[2140]: [.012] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 56 of -1! <NL> [  942.065450] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 1 <NL> [  942.716168] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  942.732306] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  945.081138] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 2 <NL> [  947.719901] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  947.746053] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  948.068727] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 3 <NL> [  950.033382] python3[2140]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  950.737444] python3[2140]: [.035] hookhdlr 140335681558336 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 57 of -1! <NL> [  951.079935] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 4 <NL> [  952.802699] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  952.968640] confd_phase_sentry[2144]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fcf4e7ca5c7; Failed to connect to ConfD: Connection refused <NL> [  954.107943] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 5 <NL> [  957.111569] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 6 <NL> [  957.736286] confd_phase_sentry[2144]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  957.858513] confd_phase_sentry[2144]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  960.132981] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 7 <NL> [  960.980457] python3[2140]: DEBUG EOF on socket to ConfD <NL> [  961.210227] python3[2140]: [.969] hookhdlr 140335681558336 callbackhdlr:457 Exception to create daemon <NL> [  961.393292] python3[2140]: Traceback (most recent call last): <NL> [  961.456810] python3[2140]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  961.502683] python3[2140]:     daemon = self.create_daemon() <NL> [  961.591308] python3[2140]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  961.634070] python3[2140]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  961.707071] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  961.837833] python3[2140]:     self._init_connection() <NL> [  961.921223] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  962.147139] python3[2140]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  962.198534] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  962.264374] python3[2140]:     _tm.dp.connect( <NL> [  962.357114] python3[2140]: _confd.error.EOF: ConfD closed connection <NL> [  962.452496] python3[2140]: [.145] hookhdlr 140335681558336 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  963.155174] txid_tracker[4623]: ::::create_confd_subscription_connection() try number 8 <NL> [  965.811492] healthcheck_result_display.py[2138]: Traceback (most recent call last): <NL> [  966.550755] healthcheck_result_display.py[2138]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  966.782440] healthcheck_result_display.py[2138]:     main(hc_utils.setup_logging(__name__)) <NL> [  967.129613] healthcheck_result_display.py[2138]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  967.291395] healthcheck_result_display.py[2138]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT)"}
{"timestamp_utc": "2024-07-31T08:28:21.309Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  967.705621] healthcheck_result_display.py[2138]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  968.247183] healthcheck_result_display.py[2138]:     self._init_connection() <NL> [  968.282256] healthcheck_result_display.py[2138]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  968.357686] healthcheck_result_display.py[2138]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  968.381702] healthcheck_result_display.py[2138]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  968.395126] healthcheck_result_display.py[2138]:     _tm.dp.connect( <NL> [  968.395690] healthcheck_result_display.py[2138]: _confd.error.EOF: ConfD closed connection <NL> [  969.121742] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 1 <NL> [  971.217572] python3[2140]: [.172] hookhdlr 140335681558336 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  971.745601] python3[2140]: DEBUG EOF on socket to ConfD"}
{"timestamp_utc": "2024-07-31T08:28:23.823Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:23 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:23 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:29.067Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:28 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:28 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:34.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:33 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:33 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:38.523Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:38 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:38.779Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:38 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:42.943Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  706.561225] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.546866, delay 0.03867\\n31 Jul 08:23:54 ntpdate[4004]: no server suitable for synchronization found\\n' <NL> [  718.457310] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  718.464208] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  718.465033] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.549662, delay 0.03314\\n31 Jul 08:24:06 ntpdate[4037]: no server suitable for synchronization found\\n' <NL> [  730.343032] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  730.343905] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  730.356454] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.552704, delay 0.02695\\n31 Jul 08:24:18 ntpdate[4088]: no server suitable for synchronization found\\n' <NL> [  742.431567] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  742.451323] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  742.489132] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.543131, delay 0.04623\\n31 Jul 08:24:30 ntpdate[4139]: no server suitable for synchronization found\\n' <NL> [  754.243480] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  754.244327] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  754.261263] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.566559, delay 0.07173\\n31 Jul 08:24:41 ntpdate[4184]: no server suitable for synchronization found\\n' <NL> [  766.270218] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  766.270571] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  766.270639] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.554171, delay 0.03273\\n31 Jul 08:24:53 ntpdate[4231]: no server suitable for synchronization found\\n' <NL> [  778.353842] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  778.364609] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  778.423242] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.543832, delay 0.05481\\n31 Jul 08:25:06 ntpdate[4265]: no server suitable for synchronization found\\n' <NL> [  790.455522] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  790.479951] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  790.530845] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.566254, delay 0.06136\\n31 Jul 08:25:18 ntpdate[4298]: no server suitable for synchronization found\\n' <NL> [  802.358329] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  802.359105] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  802.364040] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.550334, delay 0.03172\\n31 Jul 08:25:30 ntpdate[4331]: no server suitable for synchronization found\\n' <NL> [  814.363372] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  814.364185] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  814.364924] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.541642, delay 0.04927\\n31 Jul 08:25:42 ntpdate[4372]: no server suitable for synchronization found\\n' <NL> [  826.366797] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  826.384210] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  826.384876] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.547831, delay 0.04211\\n31 Jul 08:25:54 ntpdate[4405]: no server suitable for synchronization found\\n' <NL> [  838.366992] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  838.384610] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  838.394831] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.557288, delay 0.03749\\n31 Jul 08:26:06 ntpdate[4455]: no server suitable for synchronization found\\n' <NL> [  850.528379] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  850.528993] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  850.540120] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.478066, delay 0.19641\\n31 Jul 08:26:18 ntpdate[4488]: no server suitable for synchronization found\\n' <NL> [  862.504301] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  862.504931] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  862.505622] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.541584, delay 0.04942\\n31 Jul 08:26:30 ntpdate[4537]: no server suitable for synchronization found\\n' <NL> [  874.424135] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  874.425119] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  874.461235] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.542744, delay 0.04729\\n31 Jul 08:26:42 ntpdate[4571]: no server suitable for synchronization found\\n' <NL> [  886.390035] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  886.390232] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  886.390293] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.542646, delay 0.04778\\n31 Jul 08:26:54 ntpdate[4605]: no server suitable for synchronization found\\n' <NL> [  898.705384] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  898.705724] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  898.705806] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.551837, delay 0.05302\\n31 Jul 08:27:06 ntpdate[4642]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:28:42.944Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  910.735630] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  910.735802] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  910.735863] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.547277, delay 0.03792\\n31 Jul 08:27:18 ntpdate[4710]: no server suitable for synchronization found\\n' <NL> [  922.679358] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  922.679570] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  922.679652] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.554783, delay 0.09280\\n31 Jul 08:27:30 ntpdate[4740]: no server suitable for synchronization found\\n' <NL> [  934.634499] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  934.634672] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  934.634739] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.552511, delay 0.02760\\n31 Jul 08:27:42 ntpdate[4786]: no server suitable for synchronization found\\n' <NL> [  946.614298] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  946.614955] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  946.615097] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.551040, delay 0.03342\\n31 Jul 08:27:54 ntpdate[4822]: no server suitable for synchronization found\\n' <NL> [  958.633596] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  958.633778] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  958.633841] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.552695, delay 0.02708\\n31 Jul 08:28:06 ntpdate[4861]: no server suitable for synchronization found\\n' <NL> [  970.572555] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  970.572742] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  970.572800] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.564693, delay 0.05046\\n31 Jul 08:28:18 ntpdate[4902]: no server suitable for synchronization found\\n' <NL> [  982.576364] ntputils_client.py[1761]: INFO:root:command failed. <NL> [  982.576523] ntputils_client.py[1761]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  982.576574] ntputils_client.py[1761]: b'server 127.1.254.254, stratum 16, offset -0.551101, delay 0.03284\\n31 Jul 08:28:30 ntpdate[4935]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:28:43.508Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:43 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:43.765Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:43 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:47.038Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  969.801129] python3[2157]: Traceback (most recent call last): <NL> [  969.928264] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  970.257177] python3[2157]:     daemon = self.create_daemon() <NL> [  970.425090] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  970.868245] python3[2157]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  971.189730] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  971.190627] python3[2157]:     self._init_connection() <NL> [  971.191116] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  971.263394] python3[2157]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  971.436929] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  971.836300] python3[2157]:     _tm.dp.connect( <NL> [  971.836803] python3[2157]: _confd.error.EOF: ConfD closed connection <NL> [  972.173242] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 2 <NL> [  972.637992] python3[2157]: [.363] hookhdlr 139927729420096 callbackhdlr:471 Failed to run daemon main, retry 3 of -1 <NL> [  973.328313] rasis_system_stats.py[4693]: Traceback (most recent call last): <NL> [  973.960319] rasis_system_stats.py[4693]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  974.261536] rasis_system_stats.py[4693]:     main() <NL> [  974.523279] rasis_system_stats.py[4693]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  974.997814] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 3 <NL> [  975.202855] rasis_system_stats.py[4693]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  975.491713] rasis_system_stats.py[4693]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  975.905430] rasis_system_stats.py[4693]:     self._init_connection() <NL> [  975.959788] rasis_system_stats.py[4693]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  976.162411] rasis_system_stats.py[4693]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  976.321108] rasis_system_stats.py[4693]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  976.721933] rasis_system_stats.py[4693]:     _tm.dp.connect( <NL> [  976.963143] rasis_system_stats.py[4693]: _confd.error.EOF: ConfD closed connection <NL> [  977.648628] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 4 <NL> [  979.690331] python3[2157]: [.381] hookhdlr 139927729420096 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  980.086541] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 5 <NL> [  980.451406] python3[2157]: DEBUG EOF on socket to ConfD <NL> [  980.489913] python3[2157]: [.091] hookhdlr 139927729420096 callbackhdlr:457 Exception to create daemon <NL> [  980.616929] python3[2157]: Traceback (most recent call last): <NL> [  980.731265] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  980.840526] python3[2157]:     daemon = self.create_daemon() <NL> [  980.841117] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  980.842080] python3[2157]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  980.933439] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  981.001970] python3[2157]:     self._init_connection() <NL> [  981.049695] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  981.225458] python3[2157]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  981.719938] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  982.163308] python3[2157]:     _tm.dp.connect( <NL> [  982.306593] python3[2157]: _confd.error.EOF: ConfD closed connection <NL> [  982.591929] python3[2157]: [.262] hookhdlr 139927729420096 callbackhdlr:471 Failed to run daemon main, retry 4 of -1 <NL> [  982.903197] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 6 <NL> [  985.626376] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 7 <NL> [  988.726308] txid_tracker[4722]: ::::create_confd_subscription_connection() try number 8 <NL> [  989.731841] db_info.py[4723]: Traceback (most recent call last): <NL> [  990.052064] db_info.py[4723]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  990.314071] db_info.py[4723]:     main() <NL> [  990.445477] db_info.py[4723]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  990.837553] db_info.py[4723]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  991.307158] db_info.py[4723]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  991.823058] db_info.py[4723]:     self._init_connection() <NL> [  992.279169] db_info.py[4723]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  992.783056] db_info.py[4723]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  992.790520] db_info.py[4723]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  992.838094] db_info.py[4723]:     _tm.dp.connect( <NL> [  992.838698] db_info.py[4723]: _confd.error.EOF: ConfD closed connection <NL> [  993.069545] python3[2157]: [.272] hookhdlr 139927729420096 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  993.402610] python3[2157]: DEBUG EOF on socket to ConfD <NL> [  993.605429] python3[2157]: [.842] hookhdlr 139927729420096 callbackhdlr:457 Exception to create daemon <NL> [  993.917073] python3[2157]: Traceback (most recent call last): <NL> [  994.099039] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  994.269280] python3[2157]:     daemon = self.create_daemon() <NL> [  994.357144] python3[2157]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  994.830765] python3[2157]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  994.976883] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  995.255038] python3[2157]:     self._init_connection() <NL> [  995.375932] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  995.455980] python3[2157]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  995.632412] python3[2157]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  995.774689] python3[2157]:     _tm.dp.connect( <NL> [  996.015706] python3[2157]: _confd.error.EOF: ConfD closed connection"}
{"timestamp_utc": "2024-07-31T08:28:47.039Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  996.105701] python3[2157]: [.842] hookhdlr 139927729420096 callbackhdlr:471 Failed to run daemon main, retry 5 of -1 <NL> [  996.287331] healthcheck_result_display.py[4733]: Traceback (most recent call last): <NL> [  996.442704] healthcheck_result_display.py[4733]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  996.768495] healthcheck_result_display.py[4733]:     main(hc_utils.setup_logging(__name__)) <NL> [  996.880165] healthcheck_result_display.py[4733]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  997.048987] healthcheck_result_display.py[4733]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  997.135361] healthcheck_result_display.py[4733]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  997.563164] healthcheck_result_display.py[4733]:     self._init_connection() <NL> [  998.289815] healthcheck_result_display.py[4733]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  998.645811] healthcheck_result_display.py[4733]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  999.226740] healthcheck_result_display.py[4733]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  999.823824] healthcheck_result_display.py[4733]:     _tm.dp.connect("}
{"timestamp_utc": "2024-07-31T08:28:49.622Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:48 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:48 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:54.178Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:53 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:54.179Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:53 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:58.781Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:58 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:59.040Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:58 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:04.295Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:03 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:03 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:09.541Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:08 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:08 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:13.726Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:13 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:13.983Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:29:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:13 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:19.245Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:18 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:18 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:24.491Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:23 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:23 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:28.828Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:28 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:29.084Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:29:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:28 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:31.049Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  972.037128] python3[2140]: [.748] hookhdlr 140335681558336 callbackhdlr:457 Exception to create daemon <NL> [  972.366174] python3[2140]: Traceback (most recent call last): <NL> [  972.366760] python3[2140]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  972.390337] python3[2140]:     daemon = self.create_daemon() <NL> [  972.401236] python3[2140]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  972.863662] python3[2140]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  973.249465] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  973.643093] python3[2140]:     self._init_connection() <NL> [  973.756943] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  974.020108] python3[2140]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  974.286387] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  974.568710] python3[2140]:     _tm.dp.connect( <NL> [  974.671116] python3[2140]: _confd.error.EOF: ConfD closed connection <NL> [  974.826410] python3[2140]: [.748] hookhdlr 140335681558336 callbackhdlr:471 Failed to run daemon main, retry 2 of -1 <NL> [  974.974578] db_info.py[2132]: Traceback (most recent call last): <NL> [  975.047134] db_info.py[2132]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  975.122415] db_info.py[2132]:     main() <NL> [  975.171410] db_info.py[2132]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  975.327747] db_info.py[2132]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  975.328688] db_info.py[2132]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  975.408247] db_info.py[2132]:     self._init_connection() <NL> [  975.408877] db_info.py[2132]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  975.576056] db_info.py[2132]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  975.714699] db_info.py[2132]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  975.858457] db_info.py[2132]:     _tm.dp.connect( <NL> [  975.972668] db_info.py[2132]: _confd.error.EOF: ConfD closed connection <NL> [  976.069486] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 2 <NL> [  976.070380] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 3 <NL> [  976.072211] rasis_system_stats.py[2147]: Traceback (most recent call last): <NL> [  976.168957] rasis_system_stats.py[2147]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  976.169827] rasis_system_stats.py[2147]:     main() <NL> [  976.170311] rasis_system_stats.py[2147]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  976.231428] rasis_system_stats.py[2147]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  976.238866] rasis_system_stats.py[2147]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  976.296096] rasis_system_stats.py[2147]:     self._init_connection() <NL> [  976.388025] rasis_system_stats.py[2147]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  976.506994] rasis_system_stats.py[2147]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  976.642121] rasis_system_stats.py[2147]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  976.829535] rasis_system_stats.py[2147]:     _tm.dp.connect( <NL> [  976.878724] rasis_system_stats.py[2147]: _confd.error.EOF: ConfD closed connection <NL> [  978.146889] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 4 <NL> [  981.162469] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 5 <NL> [  981.786535] python3[2140]: [.788] hookhdlr 140335681558336 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  981.891095] python3[2140]: DEBUG EOF on socket to ConfD <NL> [  982.067251] python3[2140]: [.892] hookhdlr 140335681558336 callbackhdlr:457 Exception to create daemon <NL> [  982.485692] python3[2140]: Traceback (most recent call last): <NL> [  982.641226] python3[2140]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  982.874892] python3[2140]:     daemon = self.create_daemon() <NL> [  982.954135] python3[2140]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  983.145147] python3[2140]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  983.231910] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  983.428426] python3[2140]:     self._init_connection() <NL> [  983.594141] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  983.651535] python3[2140]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  983.964960] python3[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  984.126644] python3[2140]:     _tm.dp.connect( <NL> [  984.326649] python3[2140]: _confd.error.EOF: ConfD closed connection <NL> [  984.521817] python3[2140]: [.019] hookhdlr 140335681558336 callbackhdlr:471 Failed to run daemon main, retry 3 of -1 <NL> [  985.144750] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 6 <NL> [  987.243822] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 7 <NL> [  990.373310] txid_tracker[4687]: ::::create_confd_subscription_connection() try number 8 <NL> [  992.048701] python3[2140]: [.050] hookhdlr 140335681558336 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  992.563709] python3[2140]: [.566] hookhdlr 140335681558336 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  993.219747] python3[2140]: [.640] hookhdlr 140335681558336 callbackhdlr:293 Loading schemas <NL> [  994.132724] python3[2140]: DEBUG item does not exist - shared memory schema not enabled <NL> [  996.509736] txid_tracker[4761]: ::::create_confd_subscription_connection() connected <NL> [ 1016.813091] python3[2140]: [.810] hookhdlr 140335681558336 callbackhdlr:382 Done load schemas <NL> [ 1016.823148] python3[2140]: [.826] hookhdlr 140335681558336 callbackhdlr:389 Done register transaction callback <NL> [ 1018.333751] python3[2140]: [.336] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb supp-if-hook"}
{"timestamp_utc": "2024-07-31T08:29:31.050Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[ 1018.549722] python3[2140]: [.426] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [ 1018.724162] python3[2140]: [.726] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [ 1018.858449] python3[2140]: [.861] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [ 1018.875309] python3[2140]: [.878] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [ 1019.063527] python3[2140]: [.066] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [ 1019.353122] python3[2140]: [.355] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [ 1019.758142] python3[2140]: [.760] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [ 1019.916313] python3[2140]: [.783] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [ 1020.010931] python3[2140]: [.912] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [ 1020.502835] python3[2140]: [.952] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [ 1020.880585] python3[2140]: [.122] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [ 1021.346177] python3[2140]: [.155] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [ 1028.583089] python3[2140]: [.585] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [ 1035.947719] python3[2140]: [.950] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook"}
{"timestamp_utc": "2024-07-31T08:29:34.386Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:33 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:33 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:39.667Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:38 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:38 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:43.920Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:43 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:44.175Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:29:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:44 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:49.424Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:48 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:49 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:54.667Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:53 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:54 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:58.974Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:29:59.233Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:58 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:59 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:04.600Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:03 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:04 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:09.993Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:08 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:09 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:14.163Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:14 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:14.418Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:14 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:19.663Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:19 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:19 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:24.905Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:24 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:30:24.906Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:24 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:30.144Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:29 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:29 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:34.306Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:34 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:34 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:39.547Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:39 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:39 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:44.788Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:44 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:44 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:49.635Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[ 1041.756562] python3[2140]: [.758] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [ 1050.806149] python3[2140]: [.808] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [ 1057.003416] python3[2140]: [.005] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [ 1057.226993] python3[2140]: [.229] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [ 1057.428334] python3[2140]: [.324] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [ 1057.561554] python3[2140]: [.354] hookhdlr 140335681558336 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [ 1057.762771] python3[2140]: [.354] hookhdlr 140335681558336 callbackhdlr:391 Done register data callbacks <NL> [ 1108.478304] confd_mgr[3273]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [ 1108.574481] confd_mgr[5067]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:30:36 UTC 2024 <NL> [ 1108.821885] confd_mgr[5067]: Starting valhdlr.service <NL> [ 1109.445949] confd_mgr[5067]: Starting validation-handler.service <NL> [ 1109.803238] confd_mgr[5067]: Starting snmp-fss-fw.service <NL> [ 1110.805609] confd_mgr[3273]: leaving: sm_startconfd::start_confd_p0 <NL> [ 1111.121712] confd_mgr[3273]: entering: sm_startconfd::wait_for_p0 <NL> [ 1111.596688] confd_mgr[3273]: PROCESS1 has not registered yet. <NL> [ 1112.064463] confd_mgr[3273]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1112.065131] confd_mgr[3273]: PROCESS_VALHDLR has not registered yet. <NL> [ 1112.155083] python3[2140]: DEBUG No crypto keys configured <NL> [ 1112.477848] python3[2140]: [.199] hookhdlr 140335681558336 callbackhdlr:401 Unable to install crypto keys! <NL> [ 1112.752736] python3[2140]: [.435] hookhdlr 140335681558336 callbackhdlr:322 Started data handler daemon... <NL> [ 1113.017533] confd_mgr[3273]: CommAT::asio_subscriber: Connection accepted <NL> [ 1113.247815] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [ 1113.437070] confd_mgr[3273]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [ 1113.570332] confd_mgr[3273]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1113.640327] confd_mgr[3273]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1113.747374] confd_mgr[3273]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1113.852608] confd_mgr[3273]: ConfdHA Not supported command CONFIRM <NL> [ 1113.882635] confd_mgr[3273]: sm_startconfd::p0_ready_dbc <NL> [ 1113.925265] confd_mgr[3273]: Find message MESSAGE1 <NL> [ 1114.012585] confd_mgr[3273]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1114.069591] confd_mgr[3273]: PROCESS_VALHDLR has not registered yet. <NL> [ 1114.117774] confd_mgr[3273]: sm_startconfd::p0_not_ready <NL> [ 1114.157632] confd_mgr[3273]: Find message MESSAGE1 <NL> [ 1114.600584] confd_mgr[3273]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1114.707773] confd_mgr[3273]: PROCESS_VALHDLR has not registered yet. <NL> [ 1114.936353] confd_mgr[3273]: leaving: sm_startconfd::wait_for_p0 <NL> [ 1115.244401] confd_mgr[3273]: entering: sm_startconfd::wait_for_p0 <NL> [ 1115.577435] confd_mgr[3273]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1115.685211] confd_mgr[3273]: PROCESS_VALHDLR has not registered yet. <NL> [ 1115.908774] confd_mgr[3273]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [ 1115.946964] confd_mgr[3273]: Timer /ConfdAT|wait_for_p0 already created <NL> [ 1116.086956] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [ 1116.130051] confd_mgr[3273]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [ 1116.226231] python3[5076]: [.228] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1116.228497] python3[5076]: [.231] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1116.391864] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1116.469514] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1116.597064] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1116.681396] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [ 1116.987648] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [ 1117.092224] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1117.253309] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [ 1117.350191] python3[5076]: [.276] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1117.427545] python3[5076]: [.301] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1117.461101] python3[5076]: [.301] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1117.488811] python3[5076]: [.301] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1117.610337] python3[5076]: [.301] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1117.736599] python3[5076]: [.301] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [ 1117.784447] python3[5076]: [.301] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1117.936141] python3[5076]: [.301] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1118.013073] python3[5076]: [.342] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1118.064740] python3[5076]: [.342] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1118.277723] python3[5076]: [.342] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1118.341511] python3[5076]: [.342] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1118.527575] python3[5076]: [.353] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1118.698451] python3[5076]: [.353] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [ 1118.836156] python3[5076]: [.353] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [ 1118.877298] python3[5076]: [.353] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [ 1119.022940] python3[5076]: [.353] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [ 1119.151295] python3[5076]: [.353] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1119.153488] python3[5076]: [.353] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1119.174744] python3[5076]: [.407] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1119.292503] python3[5076]: [.408] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1119.518714] python3[5076]: [.408] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1119.628349] python3[5076]: [.408] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1119.691060] python3[5076]: [.408] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1119.692192] python3[5076]: [.408] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> # 03:30:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:30:49.636Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:49 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:49 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:54.886Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:54 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:54 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:00.129Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:59 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:30:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:59 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:04.292Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:04 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:04.547Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:04 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:09.793Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:09 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:09 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:11.683Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1000.001130] healthcheck_result_display.py[4733]: _confd.error.EOF: ConfD closed connection <NL> [ 1000.219909] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 1 <NL> [ 1000.341842] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 2 <NL> [ 1000.586211] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 3 <NL> [ 1001.193355] python3[2157]: [.853] hookhdlr 139927729420096 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [ 1001.762371] python3[2157]: [.589] hookhdlr 139927729420096 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [ 1002.059245] python3[2157]: [.683] hookhdlr 139927729420096 callbackhdlr:293 Loading schemas <NL> [ 1002.884848] python3[2157]: DEBUG item does not exist - shared memory schema not enabled <NL> [ 1003.515865] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 4 <NL> [ 1006.103178] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 5 <NL> [ 1009.112749] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 6 <NL> [ 1012.117063] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 7 <NL> [ 1015.164140] txid_tracker[4792]: ::::create_confd_subscription_connection() try number 8 <NL> [ 1021.075400] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 1 <NL> [ 1024.080409] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 2 <NL> [ 1027.194879] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 3 <NL> [ 1030.149291] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 4 <NL> [ 1033.194367] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 5"}
{"timestamp_utc": "2024-07-31T08:31:11.684Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1036.135393] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 6 <NL> [ 1038.985131] python3[2157]: [.617] hookhdlr 139927729420096 callbackhdlr:382 Done load schemas <NL> [ 1039.230858] python3[2157]: [.653] hookhdlr 139927729420096 callbackhdlr:389 Done register transaction callback <NL> [ 1039.445372] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 7 <NL> [ 1042.174324] txid_tracker[4848]: ::::create_confd_subscription_connection() try number 8 <NL> [ 1045.468820] python3[2157]: [.295] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [ 1045.656968] python3[2157]: [.378] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [ 1046.017030] python3[2157]: [.843] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [ 1046.076795] python3[2157]: [.899] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [ 1047.001949] python3[2157]: [.278] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [ 1047.295209] python3[2157]: [.598] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [ 1047.317644] python3[2157]: [.083] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [ 1047.532459] txid_tracker[4901]: ::::create_confd_subscription_connection() connected <NL> [ 1047.706260] python3[2157]: [.533] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [ 1047.884889] python3[2157]: [.581] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [ 1048.086453] python3[2157]: [.707] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [ 1048.814737] python3[2157]: [.778] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [ 1049.080700] python3[2157]: [.216] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [ 1049.233731] python3[2157]: [.247] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [ 1054.964882] python3[2157]: [.791] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [ 1062.198728] python3[2157]: [.025] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [ 1067.984683] python3[2157]: [.811] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [ 1073.754047] python3[2157]: [.580] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [ 1082.078752] python3[2157]: [.905] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [ 1082.267821] python3[2157]: [.988] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [ 1082.432224] python3[2157]: [.002] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [ 1082.530657] python3[2157]: [.059] hookhdlr 139927729420096 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [ 1082.709468] python3[2157]: [.059] hookhdlr 139927729420096 callbackhdlr:391 Done register data callbacks <NL> [ 1137.347055] confd_mgr[3425]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [ 1137.382937] confd_mgr[5159]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:31:03 UTC 2024 <NL> [ 1137.404366] confd_mgr[5159]: Starting valhdlr.service <NL> [ 1137.603155] confd_mgr[5159]: Starting validation-handler.service <NL> [ 1137.763837] confd_mgr[5159]: Starting snmp-fss-fw.service <NL> [ 1139.284324] confd_mgr[3425]: leaving: sm_startconfd::start_confd_p0 <NL> [ 1139.444571] confd_mgr[3425]: entering: sm_startconfd::wait_for_p0 <NL> [ 1139.911772] confd_mgr[3425]: PROCESS1 has not registered yet. <NL> [ 1140.379246] confd_mgr[3425]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1140.379908] confd_mgr[3425]: PROCESS_VALHDLR has not registered yet. <NL> [ 1140.475925] python3[2157]: DEBUG No crypto keys configured <NL> [ 1140.488207] python3[2157]: [.275] hookhdlr 139927729420096 callbackhdlr:401 Unable to install crypto keys! <NL> [ 1140.621902] python3[2157]: [.384] hookhdlr 139927729420096 callbackhdlr:322 Started data handler daemon... <NL> [ 1141.003369] confd_mgr[3425]: CommAT::asio_subscriber: Connection accepted <NL> [ 1141.187371] confd_mgr[3425]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [ 1141.367550] confd_mgr[3425]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [ 1141.541648] confd_mgr[3425]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1141.721567] confd_mgr[3425]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1141.790891] confd_mgr[3425]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1141.896060] confd_mgr[3425]: ConfdHA Not supported command CONFIRM <NL> [ 1142.004952] confd_mgr[3425]: sm_startconfd::p0_ready_dbc <NL> [ 1142.476956] confd_mgr[3425]: Find message MESSAGE1 <NL> [ 1142.557278] confd_mgr[3425]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1142.596754] confd_mgr[3425]: PROCESS_VALHDLR has not registered yet. <NL> [ 1142.665656] confd_mgr[3425]: sm_startconfd::p0_not_ready <NL> [ 1142.751225] confd_mgr[3425]: Find message MESSAGE1 <NL> [ 1142.752080] confd_mgr[3425]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1142.752762] confd_mgr[3425]: PROCESS_VALHDLR has not registered yet. <NL> [ 1142.818170] confd_mgr[3425]: leaving: sm_startconfd::wait_for_p0 <NL> [ 1142.818783] confd_mgr[3425]: entering: sm_startconfd::wait_for_p0 <NL> [ 1142.874907] confd_mgr[3425]: PROCESS_SNMP_CLID has not registered yet. <NL> [ 1142.914810] confd_mgr[3425]: PROCESS_VALHDLR has not registered yet. <NL> [ 1142.965254] confd_mgr[3425]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [ 1143.078331] confd_mgr[3425]: Timer /ConfdAT|wait_for_p0 already created <NL> [ 1143.182449] confd_mgr[3425]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [ 1143.284264] confd_mgr[3425]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [ 1144.432864] python3[5167]: [.249] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1144.624334] python3[5167]: [.302] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'}"}
{"timestamp_utc": "2024-07-31T08:31:14.949Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:14 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:14 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:20.189Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:19 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:19 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:22.701Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1144.873834] python3[5167]: [.302] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1145.063518] python3[5167]: [.302] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1145.322178] python3[5167]: [.302] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1145.355842] python3[5167]: [.302] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [ 1145.541395] python3[5167]: [.343] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [ 1145.785074] python3[5167]: [.343] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1146.238599] python3[5167]: [.343] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [ 1146.622952] python3[5167]: [.343] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1146.881755] python3[5167]: [.345] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1147.153315] python3[5167]: [.352] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1147.312521] python3[5167]: [.352] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1147.506889] python3[5167]: [.522] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1147.703757] python3[5167]: [.522] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'}"}
{"timestamp_utc": "2024-07-31T08:31:22.702Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1147.995096] python3[5167]: [.522] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1148.302314] python3[5167]: [.522] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1148.554626] python3[5167]: [.661] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1148.745313] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1148.895938] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1149.111763] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1149.112780] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1149.222087] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [ 1149.281943] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [ 1149.329241] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [ 1149.534895] python3[5167]: [.662] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [ 1149.770449] python3[5167]: [.663] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1149.964484] python3[5167]: [.663] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1150.118885] python3[5167]: [.689] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1150.215759] python3[5167]: [.690] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1150.287274] python3[5167]: [.691] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1150.359335] python3[5167]: [.691] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1150.360190] python3[5167]: [.691] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1150.405922] python3[5167]: [.691] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1150.406862] python3[5167]: [.764] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1150.465043] python3[5167]: [.764] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1150.540857] python3[5167]: [.764] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1150.689261] python3[5167]: [.771] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1150.816170] python3[5167]: [.771] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1150.940178] python3[5167]: [.771] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1151.033878] python3[5167]: [.785] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1151.153043] python3[5167]: [.785] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1151.253174] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1151.398988] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1151.563262] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1151.749364] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [ 1151.868930] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [ 1151.968051] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [ 1152.122740] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [ 1152.194256] python3[5167]: [.786] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [ 1152.417432] python3[5167]: [.792] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1152.779774] python3[5167]: [.796] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [ 1153.319753] python3[5167]: [.799] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [ 1153.533905] snmp_clid[5174]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [ 1153.973292] python3[5167]: [.804] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [ 1154.354886] python3[5167]: [.856] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1154.557391] python3[5167]: [.856] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [ 1154.790035] python3[5167]: [.856] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [ 1155.029732] python3[5167]: [.856] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [ 1155.030735] python3[5167]: [.910] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1155.031686] python3[5167]: [.911] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1155.139914] python3[5167]: [.913] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1155.441442] python3[5167]: [.913] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1155.597264] python3[5167]: [.914] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1155.891638] python3[5167]: [.914] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'}"}
{"timestamp_utc": "2024-07-31T08:31:23.627Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[ 1119.708554] python3[5076]: [.508] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1119.796101] python3[5076]: [.508] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1119.898165] python3[5076]: [.508] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1120.157797] python3[5076]: [.508] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1120.181641] python3[5076]: [.508] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1120.182603] python3[5076]: [.509] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1120.188233] python3[5076]: [.511] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1120.260286] python3[5076]: [.541] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1120.467472] python3[5076]: [.541] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1120.789912] python3[5076]: [.543] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1121.008502] python3[5076]: [.558] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1121.494418] python3[5076]: [.560] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [ 1121.624203] python3[5076]: [.560] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [ 1121.770026] python3[5076]: [.560] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [ 1122.273728] python3[5076]: [.560] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [ 1122.457646] python3[5076]: [.640] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [ 1122.666521] python3[5076]: [.641] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1122.794441] python3[5076]: [.641] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [ 1122.812033] python3[5076]: [.641] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [ 1122.907649] python3[5076]: [.641] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [ 1122.966156] python3[5076]: [.642] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'}"}
{"timestamp_utc": "2024-07-31T08:31:23.628Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[ 1123.155256] python3[5076]: [.642] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [ 1123.184179] python3[5076]: [.642] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [ 1123.279518] python3[5076]: [.642] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [ 1123.631230] python3[5076]: [.690] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [ 1123.918725] python3[5076]: [.690] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [ 1124.023199] python3[5076]: [.690] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [ 1124.243646] python3[5076]: [.690] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [ 1124.918184] python3[5076]: [.690] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [ 1125.726011] python3[5076]: [.690] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [ 1126.116092] python3[5076]: [.690] valhdlr 139715158787904 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [ 1126.215518] python3[5076]: [.779] valhdlr 139715158787904 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [ 1126.348201] python3[5076]: [.838] valhdlr 139715158787904 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [ 1126.378222] python3[5076]: [.839] valhdlr 139715158787904 callbackhdlr:293 Loading schemas <NL> [ 1126.379045] python3[5076]: DEBUG item does not exist - shared memory schema not enabled <NL> [ 1126.379751] python3[5076]: [.281] valhdlr 139715158787904 callbackhdlr:382 Done load schemas <NL> [ 1126.381383] python3[5076]: [.281] valhdlr 139715158787904 callbackhdlr:389 Done register transaction callback <NL> [ 1126.407340] python3[5076]: [.036] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [ 1126.554030] python3[5076]: [.171] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [ 1126.640600] python3[5076]: [.420] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [ 1126.687654] python3[5076]: [.965] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [ 1126.777450] snmp_clid[5080]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [ 1126.909485] confd_mgr[3273]: CommAT::asio_subscriber: Connection accepted <NL> [ 1126.949496] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [ 1127.029449] confd_mgr[3273]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [ 1127.155165] confd_mgr[3273]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1127.208053] confd_mgr[3273]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1127.260311] confd_mgr[3273]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1127.330765] confd_mgr[3273]: ConfdHA Not supported command CONFIRM <NL> [ 1127.410653] confd_mgr[3273]: sm_startconfd::p0_ready_dbc <NL> [ 1127.505906] confd_mgr[3273]: Find message SNMP_CLID_CONFIRM <NL> [ 1127.710540] confd_mgr[3273]: PROCESS_VALHDLR has not registered yet. <NL> [ 1127.787496] confd_mgr[3273]: sm_startconfd::p0_not_ready <NL> [ 1128.024469] confd_mgr[3273]: Find message SNMP_CLID_CONFIRM <NL> [ 1128.025081] confd_mgr[3273]: PROCESS_VALHDLR has not registered yet. <NL> [ 1128.108772] confd_mgr[3273]: leaving: sm_startconfd::wait_for_p0 <NL> [ 1128.186557] confd_mgr[3273]: entering: sm_startconfd::wait_for_p0 <NL> [ 1128.187239] confd_mgr[3273]: PROCESS_VALHDLR has not registered yet. <NL> [ 1128.274968] confd_mgr[3273]: Timer /ConfdAT|wait_for_p0 already created <NL> [ 1128.595642] confd_mgr[3273]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [ 1128.794458] confd_mgr[3273]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [ 1129.025694] confd_mgr[3273]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [ 1129.135841] snmp_clid[5131]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [ 1148.418170] python3[5076]: [.420] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [ 1148.551628] python3[5076]: [.526] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [ 1148.664518] python3[5076]: [.655] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [ 1148.918213] python3[5076]: [.920] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [ 1148.971174] python3[5076]: [.973] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [ 1149.111447] python3[5076]: [.051] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [ 1149.220860] python3[5076]: [.189] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [ 1149.345354] python3[5076]: [.314] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [ 1149.415715] python3[5076]: [.418] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation"}
{"timestamp_utc": "2024-07-31T08:31:24.555Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:24 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:24 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:29.792Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:29 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:29 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:34.752Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:34 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:36.407Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:34 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:40.028Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:39 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:39 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:45.385Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:44 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:44 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:49.547Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:49 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:49.801Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:49 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:55.100Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:54 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:54 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:00.489Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:59 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:31:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:59 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:04.704Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:04 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:04.976Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:32:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:04 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:10.217Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:09 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:32:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:09 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:15.460Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46501, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:14 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp85.fnc.net.local:46501\" SSHException('Error reading SSH protocol banner',) <NL> # 03:32:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp85.fnc.net.local', port 46485, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:15 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp85.fnc.net.local:46485\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:19.625Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:18 exec-job-tree INFO: process_list_cl::wait: queue EMPTY <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::wait: TIMEOUT: check who timed out <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::wait: TIMEOUT: timeout job tree \"n01.p09.s01.startup (p)\" <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p01.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p03.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (executing) type \"command\": timeout (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (executing) type \"serial\": timeout (n01.p09.s01.p05.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (executing) type \"command\": timeout (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (executing) type \"serial\": timeout (n01.p09.s01.p07.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 3)        (executing) type \"parallel\": timeout (n01.p09.s01.startup (p)) <NL> # 03:32:18 exec-job-tree INFO: process_cl::send_signal: name \"n01.p09.s01.p05.s02.NE3-main-cli\": send signal Signals.SIGTERM to process group 3782 <NL> # 03:32:18 exec-job-tree INFO: process_cl::send_signal: name \"n01.p09.s01.p07.s02.NE4-main-cli\": send signal Signals.SIGTERM to process group 3817 <NL> # 03:32:18 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\": process 3782 terminated with exitcode -15 <NL> # 03:32:18 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\": process 3817 terminated with exitcode -15 <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"stderr\": DONE"}
{"timestamp_utc": "2024-07-31T08:32:19.626Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:18 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"stdout\": DONE <NL> # 03:32:18 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\": process 3817 terminated with exitcode -15 <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code -15 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": aborting because child #1 was terminated (n01.p09.s01.p07.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p07.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #6 finished with exit_code 1, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 1 children running (n01.p09.s01.startup (p)) <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.s02.NE4-main-cli\", exit_code -15 <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.main-startup (s)\", exit_code 1 <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"stderr\": DONE <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"stdout\": DONE <NL> # 03:32:18 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\": process 3782 terminated with exitcode -15 <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code -15 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": aborting because child #1 was terminated (n01.p09.s01.p05.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p05.main-startup (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #4 finished with exit_code 1, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 3)        (finished) type \"parallel\": finished (n01.p09.s01.startup (p)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 2)      (executing) type \"serial\": child #0 finished with exit_code 1 (n01.p09.start+user (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 2)      (executing) type \"serial\": aborting because child #0 was terminated (n01.p09.start+user (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"serial\": finished (n01.p09.start+user (s)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #8 finished with exit_code 1, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 8 running children to be terminated (n01.all (p)) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p01.NE1-main-console) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p02.NE1-trib1-console) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:32:18 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.s02.NE3-main-cli\", exit_code -15 <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.main-startup (s)\", exit_code 1 <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.startup (p)\", exit_code 1 <NL> # 03:32:18 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.start+user (s)\", exit_code 1 <NL> # 03:32:18 exec-job-tree INFO: process_cl::send_signal: name \"n01.p01.NE1-main-console\": send signal Signals.SIGKILL to process group 3352 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p02.NE1-trib1-console\": send signal Signals.SIGKILL to process group 3353 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": send signal Signals.SIGKILL to process group 3354 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": send signal Signals.SIGKILL to process group 3355 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": send signal Signals.SIGKILL to process group 3356 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": send signal Signals.SIGKILL to process group 3357 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": send signal Signals.SIGKILL to process group 3358 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": send signal Signals.SIGKILL to process group 3359 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3352 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3353 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3354 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3355 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3357 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3359 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p01.NE1-main-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p01.NE1-main-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3352 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p01.NE1-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #0 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 7 running children to be terminated (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p02.NE1-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p01.NE1-main-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p02.NE1-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3353 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3354 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3355 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3357 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3359 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p02.NE1-trib1-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p04.NE2-trib1-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p03.NE2-main-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p03.NE2-main-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3354 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p03.NE2-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #2 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 6 running children to be terminated (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p02.NE1-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p03.NE2-main-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p02.NE1-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3353 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3355 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3357 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3359 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p02.NE1-trib1-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3353 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p02.NE1-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #1 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 5 running children to be terminated (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console)"}
{"timestamp_utc": "2024-07-31T08:32:19.627Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p02.NE1-trib1-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3355 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3357 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3359 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p04.NE2-trib1-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3355 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p04.NE2-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #3 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 4 running children to be terminated (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p04.NE2-trib1-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3357 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3359 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p06.NE3-trib1-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p08.NE4-trib1-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p08.NE4-trib1-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3359 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p08.NE4-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #7 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 3 running children to be terminated (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p08.NE4-trib1-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3357 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p07.NE4-main-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p06.NE3-trib1-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3357 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p06.NE3-trib1-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #5 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 2 running children to be terminated (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p06.NE3-trib1-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p05.NE3-main-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p07.NE4-main-console\", type \"stdout\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3358 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p07.NE4-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #6 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 1 running children to be terminated (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p07.NE4-main-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: name \"n01.p05.NE3-main-console\", type \"stderr\": DONE <NL> # 03:32:19 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3356 terminated with exitcode -9 <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p05.NE3-main-console) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #4 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 1)    (finished) type \"parallel\": finished (n01.all (p)) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 0)  (executing) type \"none\": child #0 finished with exit_code 1 (none) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 0)  (executing) type \"none\": aborting because child #0 did not pass (none) <NL> # 03:32:19 exec-job-tree INFO: job_cl::finish: ( 0)  (finished) type \"none\": finished (none) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p05.NE3-main-console\", exit_code 0 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.all (p)\", exit_code 1 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"none\", exit_code 1 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: start_time 1722413539.2246716 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait:   end_time 1722414739.0311942 <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::wait: done, job(s) ran for 1199.8065226078033 second(s) <NL> # 03:32:19 exec-job-tree INFO: process_list_cl::__exit__: exc_type \"None\" <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  Begin           End             Job Name                                ECode Flags                     Notes <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p01.NE1-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p02.NE1-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p03.NE2-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p04.NE2-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p05.NE3-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p06.NE3-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p07.NE4-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.p08.NE4-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.031245 n01.p09.s01.p01.s01.NE1-main-debug-ssh      0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031246 20240731.032401 n01.p09.s01.p01.s02.NE1-main-cli            0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.032401 n01.p09.s01.p01.main-startup (s)            0 passed                    all children finished <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.031242 n01.p09.s01.p02.NE1-trib1-debug-ssh         0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.031243 n01.p09.s01.p03.s01.NE2-main-debug-ssh      0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031243 20240731.032316 n01.p09.s01.p03.s02.NE2-main-cli            0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.032316 n01.p09.s01.p03.main-startup (s)            0 passed                    all children finished <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.031237 n01.p09.s01.p04.NE2-trib1-debug-ssh         0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.032456 n01.p09.s01.p05.s01.NE3-main-debug-ssh      0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.032456 20240731.033218 n01.p09.s01.p05.s02.NE3-main-cli          -15 FAILED,timeout,terminated None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033218 n01.p09.s01.p05.main-startup (s)            1 FAILED,timeout,terminated all children finished <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.031242 n01.p09.s01.p06.NE3-trib1-debug-ssh         0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.032707 n01.p09.s01.p07.s01.NE4-main-debug-ssh      0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.032707 20240731.033218 n01.p09.s01.p07.s02.NE4-main-cli          -15 FAILED,timeout,terminated None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033218 n01.p09.s01.p07.main-startup (s)            1 FAILED,timeout,terminated all children finished"}
{"timestamp_utc": "2024-07-31T08:32:19.628Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "# 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.031235 n01.p09.s01.p08.NE4-trib1-debug-ssh         0 passed                    None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033218 n01.p09.s01.startup (p)                     1 FAILED,timeout,terminated all children finished <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  None            None            n01.p09.s02.Warrior                      None unexecuted                None <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033218 n01.p09.start+user (s)                      1 FAILED                    all children finished <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 n01.all (p)                                 1 FAILED                    all children finished <NL> # 03:32:19 exec-job-tree INFO: summary_cl::show:  20240731.031218 20240731.033219 none                                        1 FAILED                    all children finished <NL> # 03:32:19 exec-job-tree INFO: main: result 1 <NL> [  713.707891] confd_mgr[5431]: openDdsPorts Input 20240731.033219 stdout:n01.p04.NE2-trib1-console # [  789.305930] ntputils_client.py[1720240731.033219 stdout:n01.p03.NE2-main-console # [  733.019504] zero-touch-boot[5134]: inotify20240731.033219 stdout:n01.p02.NE1-trib1-console # [  821.5100620240731.033219 stdout:n01.p08.NE4-trib1-console # [  760.355987] ntputils_client.py[1740]: b'server 127.1.254.254, stratum 16, of20240731.033219 stdout:n01.p06.NE3-trib1-console # [  20240731.033219 stdout:n01.p05.NE3-main-console # [ 1156.145947] python3[5167]: [.915] valhdlr 139872986765120 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'}20240731.033219 stdout:n01.p07.NE4-main-console # [ 1154.200697] python3[5076]: [.202] valhdlr 139715158787904 callbackhdlr:252 Done register callpoint pip3-virtualenv-install-and-execute-cmd: ERROR: failed executing: \"exec-job-tree\" \"--timeout\" \"28800\" \"--job-begin-parallel\" \"--name\" \"all (p)\" \"--job-begin-command\" \"--name\" \"NE1-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46535\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46521\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46519\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46505\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46503\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46489\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46487\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46473\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"start+user (s)\" \"--parallel-siblings-terminate-on-my-completion\" \"--job-begin-parallel\" \"--name\" \"startup (p)\" \"--timeout\" \"1200\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE1-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46534\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46533\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46520\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE2-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46518\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46517\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46504\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE3-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46502\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46501\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46488\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE4-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46486\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46485\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp85.fnc.net.local\" \"--port\" \"46472\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"Warrior\" \"--cmd-begin\" \"run_init\" \"--runinit_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\" \"--services_env\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json\" \"--work_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155\" \"-v\" \"-e\" \"warrior\" \"--test_engine_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\" \"--test_engine\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-end\" <NL> pip3-virtualenv-install-and-execute-cmd: removing VIRTUALENV_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\" <NL> pip3-virtualenv-install-and-execute-cmd: done \"1\" <NL> # 03:32:19 ntp-wait-for-devices INFO: main: result 1 <NL> # 03:32:19 tfwk-exec-test-agent INFO: main: caught exception CalledProcessError(1, ['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json', '--cmd-end', '--job-end']) <NL> # 03:32:19 tfwk-exec-test-agent INFO: main: finally block: caught_exception_flag True <NL> # 03:32:19 tfwk-exec-test-agent INFO: main: args_obj.teardown_topology_action 'teardown-always' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main: teardown_topology_flag True <NL> # 03:32:19 tfwk-exec-test-agent INFO: main: - current exec status info: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   topology_active_flag=True <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   topology_state='running' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   topology info for work dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155': <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     topology_tag_name: ['DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1'] <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     topology_pre_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json'] <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     topology_post_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json'] <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:main' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:trib1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": {"}
{"timestamp_utc": "2024-07-31T08:32:19.629Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:main' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:trib1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:main' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:trib1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:main' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:trib1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:32:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:32:19 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-teardown', '-v', '-v', '--ntp-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json', '--no-backup-shared-store'] <NL> # 03:32:19 ntp-topology-teardown INFO: args: { <NL> \"backup_shared_store_flag\": false, <NL> \"ntp_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json\", <NL> \"shared_store_backup_fname\": null, <NL> \"show_container_logs_flag\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:32:19 ntp-topology-teardown INFO: main: ===== ===== starting cleanup ===== ===== <NL> # 03:32:19 ntp-topology-teardown INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json', '--action', 'delete']"}
{"timestamp_utc": "2024-07-31T08:32:19.630Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:19 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace' <NL> # 03:32:19 ntp-topology INFO: main: starting action 'delete'"}
{"timestamp_utc": "2024-07-31T08:32:20.201Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:19 ntp-topology INFO: terminate_containers_command: - terminating container main command processes: <NL> # 03:32:19 ntp-topology INFO: get_container_env_exec_command: network_topology_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology <NL> # 03:32:19 ntp-topology INFO: exec_cmd: ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/preStop.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/preStop.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-delete']"}
{"timestamp_utc": "2024-07-31T08:32:20.456Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:20 ntp-topology INFO: wait_for_containers_command_status: - waiting max 300s for container_logs_command_status_fname files: <NL> # 03:32:20 ntp-topology INFO: wait_for_containers_command_status:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json' <NL> # 03:32:20 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:20 ntp-topology INFO: wait_for_containers_command_status: 0.000s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:21.379Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:21 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:21 ntp-topology INFO: wait_for_containers_command_status: 1.000s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:22.304Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:22 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:22 ntp-topology INFO: wait_for_containers_command_status: 2.001s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:23.228Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:23 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:23 ntp-topology INFO: wait_for_containers_command_status: 3.002s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:24.657Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:24 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:24 ntp-topology INFO: wait_for_containers_command_status: 4.003s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:25.248Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:25 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:25 ntp-topology INFO: wait_for_containers_command_status: 5.004s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:26.608Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:26 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:26 ntp-topology INFO: wait_for_containers_command_status: 6.005s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:27.531Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:27 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:27 ntp-topology INFO: wait_for_containers_command_status: 7.006s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:28.455Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:28 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:28 ntp-topology INFO: wait_for_containers_command_status: 8.007s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:29.381Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:29 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:29 ntp-topology INFO: wait_for_containers_command_status: 9.008s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:30.373Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:30 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:30 ntp-topology INFO: wait_for_containers_command_status: 10.009s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:31.299Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:31 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:31 ntp-topology INFO: wait_for_containers_command_status: 11.010s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:32.320Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:32 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:32:32 ntp-topology INFO: wait_for_containers_command_status: 12.011s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:32:33.264Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:33 ntp-topology INFO: wait_for_containers_command_status: status for fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/command.status.json': { <NL> \"exit_code\": 0 <NL> } <NL> # 03:32:33 ntp-topology INFO: wait_for_containers_preStop_status: - waiting max 300s for container_logs_preStop_status_fname files: <NL> # 03:32:33 ntp-topology INFO: wait_for_containers_preStop_status:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-logs/topology-group-device-group-type-qemu-01/preStop.status.json' <NL> # 03:32:33 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'ps', '--all', '--no-trunc', '--format', '{{.ID}}:{{.Names}}']"}
{"timestamp_utc": "2024-07-31T08:32:33.519Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:33 ntp-topology INFO: docker_command: stdout: 705632a475a76c7662b6e21f55491756d3f457fa3bf9b4170b3dbed9312e5f62:boring_fermi <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 478d795c0930dd26d4eb42f5c00f4043f0ff43e29fd3a43881b7b42c83e2ba53:friendly_sinoussi <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 2c096a3370374347c4e73d8c168c67097697f16daf734957b69eb460e6e0ac38:relaxed_mirzakhani <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 290c1ce839886005b764f71436f4027540592b1696fc2f244a74a2fff4fd1b25:ecstatic_noether <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: dab065a3c69a556486f246f8f3e0074880bbb3e840edd82995cef9d59c928966:compassionate_dubinsky <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 344bae3c1df97038ea6b570e7ab396457431611fd3e4eb38de66e6b7b18fb561:gifted_brahmagupta <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: b92c97b75fcf1f1d8ff2ec5ec17ed94c805a61cebdb34531df4be2db7b5a784e:distracted_lalande <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 54cc36252f88287f849c155fb9742e3ecd7fa72da2fac62e65078d4ab3dcb876:wizardly_wilson <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 0b5313c4265f600b74b0f6774f8b853e621fb49226aae53f7c0c717093b3c845:keen_thompson <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 427eedd4fa79e036c3732a45f878925d3d5c8c5534d7ac17fff9fa27908c1d6f:modest_wilson <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: b89e0890ddb34239c6111afe965d4b342584ecab2a20b733db6ee716108b5854:elegant_aryabhata <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 9abee2e59e98d873aa6e324910a47216b5234b326a25ca72c282d8293b702a38:eager_austin <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: a4d0a42193f1794c2444f251386960605917f3058447fc737732e30f995ab535:inspiring_sammet <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: c196ed2e90fc9e11d13260218980364811d3d16511d40502a9e066477cee0364:affectionate_golick <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14:agitated_pare <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: a60c81e010e505685c0da3de47e0e97e49c4bc14876516538940519c7634c717:stupefied_swanson <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 3fdd0c5e1b955824da8097fa9244db3a4bbcd115b13843484ed18c23f0b6fb49:nostalgic_elion <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: f55e2e65976d10637b98201966a61261110b18f6e381305f614e498f42001839:jolly_hamilton <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 37dae71598f5ec1bf5fee4cdbbca084bb24d8a31a440f87e975a037f09479c2d:upbeat_swirles <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: e8bb3967c597fc2d01282f4f6362a47d4717d4d2dc1c13665dae7383667d977a:confident_curie <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 4381447fe83d451689d8d9c861179a17b0041a12e6a5d222a3feb309210fa83d:trusting_euler <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 5b81cfed569dc97a3d59271cf8717674aa3c81cd17830c22c9ccbbe2af050f52:serene_nobel <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 0bbde0e5ed030f5b52389ba86d2e8116037a3cf1b65b8d5f757e688b8e146179:eloquent_easley <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 41b851c21ff7f93ecb2614f34bb917418f57ffdfa500e13df9ec7db60c777c75:silly_pare <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: e7d795c05cb40a5e474ce01182ede95337e3fc41c899dc503214043ca43cf51b:eloquent_wiles <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 375231c1097c8342fe0ad9bc23015a7bf0fc9755f10fc726be73914bb217cf1e:romantic_lamarr <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: b2f5ec436818c75cefd2b86d9869f1762bb18e9828411959626a0a219f6757bd:adoring_shockley <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: afb60eaaf7803165d261c7f83fdb6325213209de5a255c021eddb40fcf0dcf09:practical_ardinghelli <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 57f074560fb45d6a3d65f66111f0f551bbeb463add1b5048d8177e6c96ae632d:gifted_davinci <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 6ba56926f82f0d506ca2d06162905b7b26c64d2e4c96dc10a739b49a4b8f431a:heuristic_almeida <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: b76483999a8cbc2ed23fe975737a337df2aa8c3d1390ba07c20a59c982289c07:silly_swanson <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: e2c38f7471e3910ecd0c3b90f68a6232485b874cb1972768d217d95418e99e4e:keen_minsky <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 255dbb035dd7a06129b8d62c2476a875427002f7812850107bfedfaa162b9a4a:awesome_liskov <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: dd566f2f8b9fa77cb74d8339d0980248ae36530d8fd4720af8edef7a4b4c4564:heuristic_euler <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 704e7796186be1587f5b26caf303371c1791b408b8b52c7a723c250de611aa15:vibrant_leakey <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: a06e023f97399427ceff6d84a5f0f6175b6cb0d79e2d3e64b9e11b4ac88f5b38:vigilant_bassi <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 29cc358c00330174ce0ae3aff2f19813e3bff1816f0f911beaf05545711cc21c:vigilant_leavitt <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: a174b08504c9c97e7b9e43dbd25de52d3d6cc60fd540bc459597c4cfc1d6e808:nervous_knuth <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: e08afc0b16cce8399f437e0293895204953e95f68995867f4088f4936ba6d027:quizzical_chandrasekhar <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: b2540543e6cec954dd75aeab4a8afe12c72cdb040c3aad549c627588853ead4b:clever_shockley <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 07e987129db3423dea79a2203322ec5ed847da6694f83163286f1b910930de4f:confident_wiles <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 2697c1a4d3b43c350690bc10f266500590c4f11bee50e55286002edfb1a9053d:blissful_noether <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 29ebd23f3789a815ab7e84a500f83c3984507c028c21a428504c80f8b4574964:affectionate_almeida <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: dfc76cf16876f708a1e55ae7fb7f485533f82d76ceeaa867bb64ac488c0a002a:hopeful_mahavira <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 382793f71ef4116cd9ab0bcba9892701ca09660014214655096d3d065c32b274:optimistic_snyder <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: c2183928bf15627731ed71d89dd21d3f3d897a5fa017185b672915a903163f2e:practical_hugle <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 66b9ff6928aaab43815a610c217ed6777536321bb40f0118313dcaba2235f109:vigilant_einstein <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: eff6a97458e45b5a2cf3ff670b18bb2ca5306635eeaf2925689f8e3305c81a2f:silly_poincare <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: cfba76122e691872712ee2cc7a6b86235e15478326031078ad9f244e1e4e3202:suspicious_ritchie <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 1f45c10ecd443940b0d4b54ad580147111da86db9e3cec496355288fe536601d:priceless_shannon <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 9988fb0fa8fe4e4b694df874b3914f0d81c4a63f0de4555b608125566aa49d0d:eloquent_pasteur <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: fd00b16fdcda497ed2876c7db0b9b652f8adf24c2c030f1d27f6a6854f9d9d11:confident_rosalind <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: fe42c22633e38e7099233ee9f72bcf557768497eba4df20e126ea338ca902e29:confident_perlman <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: e40ebf9c2fbd581eb7d559127174da4701645bd2f160396b3dd4c471eca978b1:boring_joliot <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: db2407dbcb597675296f75baa3a84e638f74db0184456e78b1b3ce971758192d:jovial_austin <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: ea28b89d0a7d1547c726e96aa395bc39d2c799a39913fb4bdf8ba8bba0dcf827:quirky_albattani <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: da8e4c2acd642337c0eb98c1fde89744c44ecfa2bf518317198d176643297b2e:wonderful_yonath <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: ec9b8f0547528b72e1419dfd7960f258972c2c1f04eca34decb7aa43558d1b19:dazzling_easley <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 7361c9164c2538515f2650abef4d42329fe38c6914bc2e50d64af14a783bf156:brave_northcutt <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 41d54a4210b2cb74214b3f40a9426c1a54d656d0fda6721c55e783c7facc2d30:adoring_swartz"}
{"timestamp_utc": "2024-07-31T08:32:33.520Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:33 ntp-topology INFO: docker_command: stdout: 988bcbb25ba98025cce7c2f086ce6d7e4d426794d12713396fdaf353fe6aa46e:distracted_curran <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 797b41a493917804c60c922e17f3a45a1a7d3de8a4ed4376b0cb993c86dcd501:goofy_darwin <NL> # 03:32:33 ntp-topology INFO: docker_command: stdout: 9a0171d4f4ff3268dfa3960918ae5402bee6f10118450962d8e08d5acc2e8378:jovial_kilby <NL> # 03:32:33 ntp-topology INFO: delete_single_docker_container: docker_container_name agitated_pare <NL> # 03:32:33 ntp-topology INFO: delete_single_docker_container: docker_container_id 875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14 <NL> # 03:32:33 ntp-topology INFO: delete_single_docker_container: delete Docker container \"875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14(agitated_pare)\" (delete an existing container) <NL> # 03:32:33 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'stop', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14']"}
{"timestamp_utc": "2024-07-31T08:32:48.609Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:32:45 ntp-topology INFO: docker_command: stdout: 875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14 <NL> # 03:32:45 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'rm', '--force', '875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14'] <NL> # 03:32:46 ntp-topology INFO: docker_command: stdout: 875e59d3f20d3e3db3325049047efd590a78aa4b775fcb078ad6af1dfa680b14 <NL> # 03:32:46 ntp-topology INFO: handle_delete_phase_1: show_container_logs_setting 'on-error-only' <NL> # 03:32:46 ntp-topology INFO: main: completed action 'delete' <NL> # 03:32:46 ntp-topology INFO: done <NL> # 03:32:46 ntp-topology-teardown INFO: main: removing container_workspace_basedir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace' <NL> # 03:32:46 ntp-topology-teardown INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e/container-workspace'] <NL> # 03:32:47 ntp-topology-teardown INFO: main: removing shared_store_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e' <NL> # 03:32:47 ntp-topology-teardown INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/ntp-workdir.tag.20240731030823.01a244d88e5f46ac91c706ee6879b59e'] <NL> # 03:32:47 ntp-topology-teardown INFO: main: ===== ===== done cleanup ===== ===== <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 4635, in <module> <NL> main(args_obj=args_obj) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 1329, in main <NL> exec_cmd(command) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 40, in exec_cmd <NL> raise subprocess.CalledProcessError(result, command) <NL> subprocess.CalledProcessError: Command '['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030823.pid-155/test_engine_args.json', '--cmd-end', '--job-end']' returned non-zero exit status 1. <NL> ci-job-info: job returned result \"1\" <NL> ci-job-info: end_job: 1 <NL> ci-job-info: end_artifact_job: ----- ----- ----- ----- ----- <NL> ci-job-info: end_artifact_job: 20240731.033248: ending job with status \"FAILED\" <NL> ci-job-info: end_artifact_job: saving ci-data directory \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/ci-data\" into \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/json-nt-ddcn-4-node-natRedistribute-napt.ci-data\" <NL> ./ <NL> ./manifest.json <NL> ./project-info-status.json <NL> ./gitscm-info.json <NL> ./data.json <NL> ./project-info-extended.json <NL> ./project-info.json <NL> ./project-info-complete.json"}
{"timestamp_utc": "2024-07-31T08:32:50.504Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info-recipe-repo.json <NL> end_job: Wed Jul 31 03:32:50 CDT 2024 <NL> ci-job-info: ended on Wed Jul 31 03:32:50 CDT 2024 <NL> ci-get-archive-artifacts: failed executing command:  \"ci-job-info\" \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml\" <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 107, in <module> <NL> main(args=arg_dict) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 68, in main <NL> subprocess.run(command_list, check=True) <NL> File \"/usr/lib64/python3.6/subprocess.py\", line 438, in run <NL> output=stdout, stderr=stderr)"}
{"timestamp_utc": "2024-07-31T08:32:50.505Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "subprocess.CalledProcessError: Command '['ci-get-archive-artifacts', '--project-info-basename', 'project-info.json', '--project-info-extended-basename', 'project-info-extended.json', '--', 'ci-job-info', 'ci-project-sanity-tfwk', '--', '--testcases-project-name', 'fss3', '--', '--test-engine', 'Warrior', '--topology-tag-name', 'DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1', '--define-attr-defaults', 'machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute', '--define-instance-attr', 'NE1/main', 'shelf-num=1', '--define-instance-attr', 'NE1/main', 'image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2', '--define-instance-attr', 'NE1/trib1', 'shelf-num=2', '--define-instance-attr', 'NE1/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE2/main', 'shelf-num=1', '--define-instance-attr', 'NE2/main', 'image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2', '--define-instance-attr', 'NE2/trib1', 'shelf-num=2', '--define-instance-attr', 'NE2/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE3/main', 'shelf-num=200', '--define-instance-attr', 'NE3/main', 'image-name=fss-aggr-image-validation-T,image-info-config-name=main', '--define-instance-attr', 'NE3/trib1', 'shelf-num=1', '--define-instance-attr', 'NE3/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE4/main', 'shelf-num=200', '--define-instance-attr', 'NE4/main', 'image-name=fss-aggr-image-validation-T,image-info-config-name=main', '--define-instance-attr', 'NE4/trib1', 'shelf-num=1', '--define-instance-attr', 'NE4/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--add-instance', 'NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1', '--device-wait-startup-timeout', '1200', '--test-engine-begin', '--no_logger', '--test-engine-end', '--', 'warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44_PT.xml']' returned non-zero exit status 1. <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 107, in <module> <NL> main(args=arg_dict) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 68, in main <NL> subprocess.run(command_list, check=True) <NL> File \"/usr/lib64/python3.6/subprocess.py\", line 438, in run <NL> output=stdout, stderr=stderr) <NL> subprocess.CalledProcessError: Command '['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/continuous-integration/continuous-integration-common/bin/ci-setup-and-execute', 'ci-execute-json-command-list', '--command-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/jenkins-job-command-list.json']' returned non-zero exit status 1."}
{"timestamp_utc": "2024-07-31T08:32:50.510Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv"}
{"timestamp_utc": "2024-07-31T08:32:50.511Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:32:50.520Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:32:50.793Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker stop a60c81e010e505685c0da3de47e0e97e49c4bc14876516538940519c7634c717"}
{"timestamp_utc": "2024-07-31T08:32:52.270Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "a60c81e010e505685c0da3de47e0e97e49c4bc14876516538940519c7634c717 <NL> + docker rm -f --volumes a60c81e010e505685c0da3de47e0e97e49c4bc14876516538940519c7634c717 <NL> a60c81e010e505685c0da3de47e0e97e49c4bc14876516538940519c7634c717"}
{"timestamp_utc": "2024-07-31T08:32:52.275Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:32:52.281Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:32:52.289Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:32:52.296Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:32:52.305Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> pipeline_execute: Execute stage: catch section of try block: currentBuild.result 'SUCCESS' <NL> pipeline_execute: Execute stage: catch section of try block: exception: hudson.AbortException: script returned exit code 1 <NL> [Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:32:52.312Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:32:52.320Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage"}
{"timestamp_utc": "2024-07-31T08:32:52.321Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (Cleanup)"}
{"timestamp_utc": "2024-07-31T08:32:52.328Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv"}
{"timestamp_utc": "2024-07-31T08:32:52.329Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:32:52.336Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:32:52.607Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +x <NL> ci-job-post-build-cleanup: ----- /bin/docker ps -a <NL> CONTAINER ID        IMAGE                                                    COMMAND                  CREATED              STATUS              PORTS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        NAMES <NL> 705632a475a7        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About a minute ago   Up About a minute   22/tcp, 0.0.0.0:46982->5000/tcp, 0.0.0.0:46981->5001/tcp, 0.0.0.0:46980->5002/tcp, 0.0.0.0:46979->5003/tcp, 0.0.0.0:46978->5004/tcp, 0.0.0.0:33132->5005/udp, 0.0.0.0:46977->5006/tcp, 0.0.0.0:46976->5007/tcp, 0.0.0.0:46975->5008/tcp, 0.0.0.0:46974->5009/tcp, 0.0.0.0:46973->5010/tcp, 0.0.0.0:46972->5011/tcp, 0.0.0.0:46971->5012/tcp, 0.0.0.0:46970->5013/tcp, 0.0.0.0:46969->5014/tcp, 0.0.0.0:46968->5015/tcp, 0.0.0.0:46967->5016/tcp, 0.0.0.0:46966->5017/tcp, 0.0.0.0:46965->5018/tcp, 0.0.0.0:46964->5019/tcp, 0.0.0.0:46963->5020/tcp, 0.0.0.0:46962->5021/tcp, 0.0.0.0:33131->5022/udp, 0.0.0.0:46961->5023/tcp, 0.0.0.0:46960->5024/tcp, 0.0.0.0:46959->5025/tcp, 0.0.0.0:46958->5026/tcp, 0.0.0.0:46957->5027/tcp, 0.0.0.0:46956->5028/tcp, 0.0.0.0:46955->5029/tcp, 0.0.0.0:46954->5030/tcp, 0.0.0.0:46953->5031/tcp, 0.0.0.0:46952->5032/tcp, 0.0.0.0:46951->5033/tcp, 0.0.0.0:46950->5034/tcp, 0.0.0.0:46949->5035/tcp, 0.0.0.0:46948->5036/tcp, 0.0.0.0:46947->5037/tcp, 0.0.0.0:46946->5038/tcp, 0.0.0.0:33130->5039/udp, 0.0.0.0:46945->5040/tcp, 0.0.0.0:46944->5041/tcp, 0.0.0.0:46943->5042/tcp, 0.0.0.0:46942->5043/tcp, 0.0.0.0:46941->5044/tcp, 0.0.0.0:46940->5045/tcp, 0.0.0.0:46939->5046/tcp, 0.0.0.0:46938->5047/tcp, 0.0.0.0:46937->5048/tcp, 0.0.0.0:46936->5049/tcp, 0.0.0.0:46935->5050/tcp, 0.0.0.0:46934->5051/tcp, 0.0.0.0:46933->5052/tcp, 0.0.0.0:46932->5053/tcp, 0.0.0.0:46931->5054/tcp, 0.0.0.0:46930->5055/tcp, 0.0.0.0:33129->5056/udp, 0.0.0.0:46929->5057/tcp, 0.0.0.0:46928->5058/tcp, 0.0.0.0:46927->5059/tcp, 0.0.0.0:46926->5060/tcp, 0.0.0.0:46925->5061/tcp, 0.0.0.0:46924->5062/tcp, 0.0.0.0:46923->5063/tcp, 0.0.0.0:46922->5064/tcp, 0.0.0.0:46921->5065/tcp, 0.0.0.0:46920->5066/tcp, 0.0.0.0:46919->5067/tcp   boring_fermi <NL> 478d795c0930        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 minutes ago        Up 2 minutes        22/tcp, 0.0.0.0:46918->5000/tcp, 0.0.0.0:46917->5001/tcp, 0.0.0.0:46916->5002/tcp, 0.0.0.0:46915->5003/tcp, 0.0.0.0:46914->5004/tcp, 0.0.0.0:33128->5005/udp, 0.0.0.0:46913->5006/tcp, 0.0.0.0:46912->5007/tcp, 0.0.0.0:46911->5008/tcp, 0.0.0.0:46910->5009/tcp, 0.0.0.0:46909->5010/tcp, 0.0.0.0:46908->5011/tcp, 0.0.0.0:46907->5012/tcp, 0.0.0.0:46906->5013/tcp, 0.0.0.0:46905->5014/tcp, 0.0.0.0:46904->5015/tcp, 0.0.0.0:46903->5016/tcp, 0.0.0.0:46902->5017/tcp, 0.0.0.0:46901->5018/tcp, 0.0.0.0:46900->5019/tcp, 0.0.0.0:46899->5020/tcp, 0.0.0.0:46898->5021/tcp, 0.0.0.0:33127->5022/udp, 0.0.0.0:46897->5023/tcp, 0.0.0.0:46896->5024/tcp, 0.0.0.0:46895->5025/tcp, 0.0.0.0:46894->5026/tcp, 0.0.0.0:46893->5027/tcp, 0.0.0.0:46888->5028/tcp, 0.0.0.0:46886->5029/tcp, 0.0.0.0:46884->5030/tcp, 0.0.0.0:46883->5031/tcp, 0.0.0.0:46881->5032/tcp, 0.0.0.0:46879->5033/tcp, 0.0.0.0:46877->5034/tcp, 0.0.0.0:46875->5035/tcp, 0.0.0.0:46873->5036/tcp, 0.0.0.0:46871->5037/tcp, 0.0.0.0:46869->5038/tcp, 0.0.0.0:33125->5039/udp, 0.0.0.0:46866->5040/tcp, 0.0.0.0:46864->5041/tcp, 0.0.0.0:46862->5042/tcp, 0.0.0.0:46860->5043/tcp, 0.0.0.0:46858->5044/tcp, 0.0.0.0:46856->5045/tcp, 0.0.0.0:46854->5046/tcp, 0.0.0.0:46852->5047/tcp, 0.0.0.0:46851->5048/tcp, 0.0.0.0:46849->5049/tcp, 0.0.0.0:46847->5050/tcp, 0.0.0.0:46845->5051/tcp, 0.0.0.0:46843->5052/tcp, 0.0.0.0:46841->5053/tcp, 0.0.0.0:46839->5054/tcp, 0.0.0.0:46837->5055/tcp, 0.0.0.0:33123->5056/udp, 0.0.0.0:46834->5057/tcp, 0.0.0.0:46832->5058/tcp, 0.0.0.0:46830->5059/tcp, 0.0.0.0:46828->5060/tcp, 0.0.0.0:46826->5061/tcp, 0.0.0.0:46824->5062/tcp, 0.0.0.0:46822->5063/tcp, 0.0.0.0:46820->5064/tcp, 0.0.0.0:46819->5065/tcp, 0.0.0.0:46817->5066/tcp, 0.0.0.0:46815->5067/tcp   friendly_sinoussi <NL> 2c096a337037        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 minutes ago        Up 2 minutes        22/tcp, 0.0.0.0:46892->5000/tcp, 0.0.0.0:46891->5001/tcp, 0.0.0.0:46889->5002/tcp, 0.0.0.0:46887->5003/tcp, 0.0.0.0:46885->5004/tcp, 0.0.0.0:33126->5005/udp, 0.0.0.0:46882->5006/tcp, 0.0.0.0:46880->5007/tcp, 0.0.0.0:46878->5008/tcp, 0.0.0.0:46876->5009/tcp, 0.0.0.0:46874->5010/tcp, 0.0.0.0:46872->5011/tcp, 0.0.0.0:46870->5012/tcp, 0.0.0.0:46868->5013/tcp, 0.0.0.0:46867->5014/tcp, 0.0.0.0:46865->5015/tcp, 0.0.0.0:46863->5016/tcp, 0.0.0.0:46861->5017/tcp, 0.0.0.0:46859->5018/tcp, 0.0.0.0:46857->5019/tcp, 0.0.0.0:46855->5020/tcp, 0.0.0.0:46853->5021/tcp, 0.0.0.0:33124->5022/udp, 0.0.0.0:46850->5023/tcp, 0.0.0.0:46848->5024/tcp, 0.0.0.0:46846->5025/tcp, 0.0.0.0:46844->5026/tcp, 0.0.0.0:46842->5027/tcp, 0.0.0.0:46840->5028/tcp, 0.0.0.0:46838->5029/tcp, 0.0.0.0:46836->5030/tcp, 0.0.0.0:46835->5031/tcp, 0.0.0.0:46833->5032/tcp, 0.0.0.0:46831->5033/tcp, 0.0.0.0:46829->5034/tcp, 0.0.0.0:46827->5035/tcp, 0.0.0.0:46825->5036/tcp, 0.0.0.0:46823->5037/tcp, 0.0.0.0:46821->5038/tcp, 0.0.0.0:33122->5039/udp, 0.0.0.0:46818->5040/tcp, 0.0.0.0:46816->5041/tcp, 0.0.0.0:46814->5042/tcp, 0.0.0.0:46813->5043/tcp, 0.0.0.0:46812->5044/tcp, 0.0.0.0:46811->5045/tcp, 0.0.0.0:46810->5046/tcp, 0.0.0.0:46809->5047/tcp, 0.0.0.0:46808->5048/tcp, 0.0.0.0:46807->5049/tcp, 0.0.0.0:46806->5050/tcp, 0.0.0.0:46805->5051/tcp, 0.0.0.0:46804->5052/tcp, 0.0.0.0:46803->5053/tcp, 0.0.0.0:46802->5054/tcp, 0.0.0.0:46801->5055/tcp, 0.0.0.0:33121->5056/udp, 0.0.0.0:46800->5057/tcp, 0.0.0.0:46799->5058/tcp, 0.0.0.0:46798->5059/tcp, 0.0.0.0:46797->5060/tcp, 0.0.0.0:46796->5061/tcp, 0.0.0.0:46795->5062/tcp, 0.0.0.0:46794->5063/tcp, 0.0.0.0:46793->5064/tcp, 0.0.0.0:46792->5065/tcp, 0.0.0.0:46791->5066/tcp, 0.0.0.0:46790->5067/tcp   relaxed_mirzakhani <NL> 290c1ce83988        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 minutes ago        Up 3 minutes        0.0.0.0:46789->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ecstatic_noether <NL> dab065a3c69a        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   4 minutes ago        Up 4 minutes        0.0.0.0:46788->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        compassionate_dubinsky <NL> 344bae3c1df9        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   4 minutes ago        Up 4 minutes        0.0.0.0:46787->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        gifted_brahmagupta"}
{"timestamp_utc": "2024-07-31T08:32:52.608Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "b92c97b75fcf        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   5 minutes ago        Up 5 minutes        22/tcp, 0.0.0.0:46786->5000/tcp, 0.0.0.0:46785->5001/tcp, 0.0.0.0:46784->5002/tcp, 0.0.0.0:46783->5003/tcp, 0.0.0.0:46782->5004/tcp, 0.0.0.0:33120->5005/udp, 0.0.0.0:46781->5006/tcp, 0.0.0.0:46780->5007/tcp, 0.0.0.0:46779->5008/tcp, 0.0.0.0:46778->5009/tcp, 0.0.0.0:46777->5010/tcp, 0.0.0.0:46776->5011/tcp, 0.0.0.0:46775->5012/tcp, 0.0.0.0:46774->5013/tcp, 0.0.0.0:46773->5014/tcp, 0.0.0.0:46772->5015/tcp, 0.0.0.0:46771->5016/tcp, 0.0.0.0:46770->5017/tcp, 0.0.0.0:46769->5018/tcp, 0.0.0.0:46768->5019/tcp, 0.0.0.0:46767->5020/tcp, 0.0.0.0:46766->5021/tcp, 0.0.0.0:33119->5022/udp, 0.0.0.0:46765->5023/tcp, 0.0.0.0:46764->5024/tcp, 0.0.0.0:46763->5025/tcp, 0.0.0.0:46762->5026/tcp, 0.0.0.0:46761->5027/tcp, 0.0.0.0:46760->5028/tcp, 0.0.0.0:46759->5029/tcp, 0.0.0.0:46758->5030/tcp, 0.0.0.0:46757->5031/tcp, 0.0.0.0:46756->5032/tcp, 0.0.0.0:46755->5033/tcp, 0.0.0.0:46754->5034/tcp, 0.0.0.0:46753->5035/tcp, 0.0.0.0:46752->5036/tcp, 0.0.0.0:46751->5037/tcp, 0.0.0.0:46750->5038/tcp, 0.0.0.0:33118->5039/udp, 0.0.0.0:46749->5040/tcp, 0.0.0.0:46748->5041/tcp, 0.0.0.0:46747->5042/tcp, 0.0.0.0:46746->5043/tcp, 0.0.0.0:46745->5044/tcp, 0.0.0.0:46744->5045/tcp, 0.0.0.0:46743->5046/tcp, 0.0.0.0:46742->5047/tcp, 0.0.0.0:46741->5048/tcp, 0.0.0.0:46740->5049/tcp, 0.0.0.0:46739->5050/tcp, 0.0.0.0:46738->5051/tcp, 0.0.0.0:46737->5052/tcp, 0.0.0.0:46736->5053/tcp, 0.0.0.0:46735->5054/tcp, 0.0.0.0:46734->5055/tcp, 0.0.0.0:33117->5056/udp, 0.0.0.0:46733->5057/tcp, 0.0.0.0:46732->5058/tcp, 0.0.0.0:46731->5059/tcp, 0.0.0.0:46730->5060/tcp, 0.0.0.0:46729->5061/tcp, 0.0.0.0:46728->5062/tcp, 0.0.0.0:46727->5063/tcp, 0.0.0.0:46726->5064/tcp, 0.0.0.0:46725->5065/tcp, 0.0.0.0:46724->5066/tcp, 0.0.0.0:46723->5067/tcp   distracted_lalande <NL> 54cc36252f88        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   7 minutes ago        Up 6 minutes        0.0.0.0:46721->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        wizardly_wilson <NL> 0b5313c4265f        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   7 minutes ago        Up 7 minutes        22/tcp, 0.0.0.0:46720->5000/tcp, 0.0.0.0:46719->5001/tcp, 0.0.0.0:46718->5002/tcp, 0.0.0.0:46717->5003/tcp, 0.0.0.0:46716->5004/tcp, 0.0.0.0:33116->5005/udp, 0.0.0.0:46715->5006/tcp, 0.0.0.0:46714->5007/tcp, 0.0.0.0:46713->5008/tcp, 0.0.0.0:46712->5009/tcp, 0.0.0.0:46711->5010/tcp, 0.0.0.0:46710->5011/tcp, 0.0.0.0:46709->5012/tcp, 0.0.0.0:46708->5013/tcp, 0.0.0.0:46707->5014/tcp, 0.0.0.0:46706->5015/tcp, 0.0.0.0:46705->5016/tcp, 0.0.0.0:46704->5017/tcp, 0.0.0.0:46703->5018/tcp, 0.0.0.0:46702->5019/tcp, 0.0.0.0:46701->5020/tcp, 0.0.0.0:46700->5021/tcp, 0.0.0.0:33115->5022/udp, 0.0.0.0:46699->5023/tcp, 0.0.0.0:46698->5024/tcp, 0.0.0.0:46697->5025/tcp, 0.0.0.0:46696->5026/tcp, 0.0.0.0:46695->5027/tcp, 0.0.0.0:46694->5028/tcp, 0.0.0.0:46693->5029/tcp, 0.0.0.0:46692->5030/tcp, 0.0.0.0:46691->5031/tcp, 0.0.0.0:46690->5032/tcp, 0.0.0.0:46689->5033/tcp, 0.0.0.0:46688->5034/tcp, 0.0.0.0:46687->5035/tcp, 0.0.0.0:46686->5036/tcp, 0.0.0.0:46685->5037/tcp, 0.0.0.0:46684->5038/tcp, 0.0.0.0:33114->5039/udp, 0.0.0.0:46683->5040/tcp, 0.0.0.0:46682->5041/tcp, 0.0.0.0:46681->5042/tcp, 0.0.0.0:46680->5043/tcp, 0.0.0.0:46679->5044/tcp, 0.0.0.0:46678->5045/tcp, 0.0.0.0:46677->5046/tcp, 0.0.0.0:46676->5047/tcp, 0.0.0.0:46675->5048/tcp, 0.0.0.0:46674->5049/tcp, 0.0.0.0:46673->5050/tcp, 0.0.0.0:46672->5051/tcp, 0.0.0.0:46671->5052/tcp, 0.0.0.0:46670->5053/tcp, 0.0.0.0:46669->5054/tcp, 0.0.0.0:46668->5055/tcp, 0.0.0.0:33113->5056/udp, 0.0.0.0:46667->5057/tcp, 0.0.0.0:46666->5058/tcp, 0.0.0.0:46665->5059/tcp, 0.0.0.0:46664->5060/tcp, 0.0.0.0:46663->5061/tcp, 0.0.0.0:46661->5062/tcp, 0.0.0.0:46659->5063/tcp, 0.0.0.0:46658->5064/tcp, 0.0.0.0:46657->5065/tcp, 0.0.0.0:46656->5066/tcp, 0.0.0.0:46655->5067/tcp   keen_thompson <NL> 427eedd4fa79        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   9 minutes ago        Up 9 minutes        0.0.0.0:46654->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        modest_wilson <NL> b89e0890ddb3        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   18 minutes ago       Up 18 minutes       22/tcp, 0.0.0.0:46653->5000/tcp, 0.0.0.0:46652->5001/tcp, 0.0.0.0:46651->5002/tcp, 0.0.0.0:46650->5003/tcp, 0.0.0.0:46649->5004/tcp, 0.0.0.0:33112->5005/udp, 0.0.0.0:46648->5006/tcp, 0.0.0.0:46647->5007/tcp, 0.0.0.0:46646->5008/tcp, 0.0.0.0:46645->5009/tcp, 0.0.0.0:46644->5010/tcp, 0.0.0.0:46643->5011/tcp, 0.0.0.0:46642->5012/tcp, 0.0.0.0:46641->5013/tcp, 0.0.0.0:46640->5014/tcp, 0.0.0.0:46639->5015/tcp, 0.0.0.0:46638->5016/tcp, 0.0.0.0:46637->5017/tcp, 0.0.0.0:46636->5018/tcp, 0.0.0.0:46635->5019/tcp, 0.0.0.0:46634->5020/tcp, 0.0.0.0:46633->5021/tcp, 0.0.0.0:33111->5022/udp, 0.0.0.0:46632->5023/tcp, 0.0.0.0:46631->5024/tcp, 0.0.0.0:46630->5025/tcp, 0.0.0.0:46629->5026/tcp, 0.0.0.0:46628->5027/tcp, 0.0.0.0:46627->5028/tcp, 0.0.0.0:46626->5029/tcp, 0.0.0.0:46625->5030/tcp, 0.0.0.0:46624->5031/tcp, 0.0.0.0:46623->5032/tcp, 0.0.0.0:46622->5033/tcp, 0.0.0.0:46621->5034/tcp, 0.0.0.0:46620->5035/tcp, 0.0.0.0:46619->5036/tcp, 0.0.0.0:46618->5037/tcp, 0.0.0.0:46617->5038/tcp, 0.0.0.0:33110->5039/udp, 0.0.0.0:46616->5040/tcp, 0.0.0.0:46615->5041/tcp, 0.0.0.0:46614->5042/tcp, 0.0.0.0:46613->5043/tcp, 0.0.0.0:46612->5044/tcp, 0.0.0.0:46611->5045/tcp, 0.0.0.0:46610->5046/tcp, 0.0.0.0:46609->5047/tcp, 0.0.0.0:46608->5048/tcp, 0.0.0.0:46607->5049/tcp, 0.0.0.0:46606->5050/tcp, 0.0.0.0:46605->5051/tcp, 0.0.0.0:46604->5052/tcp, 0.0.0.0:46603->5053/tcp, 0.0.0.0:46602->5054/tcp, 0.0.0.0:46601->5055/tcp, 0.0.0.0:33109->5056/udp, 0.0.0.0:46600->5057/tcp, 0.0.0.0:46599->5058/tcp, 0.0.0.0:46598->5059/tcp, 0.0.0.0:46597->5060/tcp, 0.0.0.0:46596->5061/tcp, 0.0.0.0:46595->5062/tcp, 0.0.0.0:46594->5063/tcp, 0.0.0.0:46593->5064/tcp, 0.0.0.0:46592->5065/tcp, 0.0.0.0:46591->5066/tcp, 0.0.0.0:46590->5067/tcp   elegant_aryabhata <NL> 9abee2e59e98        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   20 minutes ago       Up 20 minutes       0.0.0.0:46589->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        eager_austin"}
{"timestamp_utc": "2024-07-31T08:32:52.609Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "a4d0a42193f1        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   22 minutes ago       Up 21 minutes       22/tcp, 0.0.0.0:46587->5000/tcp, 0.0.0.0:46586->5001/tcp, 0.0.0.0:46585->5002/tcp, 0.0.0.0:46584->5003/tcp, 0.0.0.0:46583->5004/tcp, 0.0.0.0:33108->5005/udp, 0.0.0.0:46581->5006/tcp, 0.0.0.0:46580->5007/tcp, 0.0.0.0:46579->5008/tcp, 0.0.0.0:46578->5009/tcp, 0.0.0.0:46577->5010/tcp, 0.0.0.0:46576->5011/tcp, 0.0.0.0:46575->5012/tcp, 0.0.0.0:46574->5013/tcp, 0.0.0.0:46573->5014/tcp, 0.0.0.0:46572->5015/tcp, 0.0.0.0:46571->5016/tcp, 0.0.0.0:46570->5017/tcp, 0.0.0.0:46569->5018/tcp, 0.0.0.0:46568->5019/tcp, 0.0.0.0:46567->5020/tcp, 0.0.0.0:46566->5021/tcp, 0.0.0.0:33107->5022/udp, 0.0.0.0:46565->5023/tcp, 0.0.0.0:46564->5024/tcp, 0.0.0.0:46563->5025/tcp, 0.0.0.0:46562->5026/tcp, 0.0.0.0:46561->5027/tcp, 0.0.0.0:46560->5028/tcp, 0.0.0.0:46559->5029/tcp, 0.0.0.0:46558->5030/tcp, 0.0.0.0:46557->5031/tcp, 0.0.0.0:46556->5032/tcp, 0.0.0.0:46555->5033/tcp, 0.0.0.0:46554->5034/tcp, 0.0.0.0:46553->5035/tcp, 0.0.0.0:46552->5036/tcp, 0.0.0.0:46551->5037/tcp, 0.0.0.0:46550->5038/tcp, 0.0.0.0:33106->5039/udp, 0.0.0.0:46549->5040/tcp, 0.0.0.0:46548->5041/tcp, 0.0.0.0:46547->5042/tcp, 0.0.0.0:46546->5043/tcp, 0.0.0.0:46545->5044/tcp, 0.0.0.0:46544->5045/tcp, 0.0.0.0:46543->5046/tcp, 0.0.0.0:46542->5047/tcp, 0.0.0.0:46541->5048/tcp, 0.0.0.0:46539->5049/tcp, 0.0.0.0:46537->5050/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                            inspiring_sammet <NL> c196ed2e90fc        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   23 minutes ago       Up 23 minutes       0.0.0.0:46536->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        affectionate_golick <NL> 3fdd0c5e1b95        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   30 minutes ago       Up 30 minutes       22/tcp, 0.0.0.0:46470->5000/tcp, 0.0.0.0:46469->5001/tcp, 0.0.0.0:46468->5002/tcp, 0.0.0.0:46467->5003/tcp, 0.0.0.0:46466->5004/tcp, 0.0.0.0:46465->5005/tcp, 0.0.0.0:46464->5006/tcp, 0.0.0.0:46463->5007/tcp, 0.0.0.0:46462->5008/tcp, 0.0.0.0:46461->5009/tcp, 0.0.0.0:46460->5010/tcp, 0.0.0.0:46459->5011/tcp, 0.0.0.0:46458->5012/tcp, 0.0.0.0:46457->5013/tcp, 0.0.0.0:46456->5014/tcp, 0.0.0.0:46455->5015/tcp, 0.0.0.0:46454->5016/tcp, 0.0.0.0:46453->5017/tcp, 0.0.0.0:46452->5018/tcp, 0.0.0.0:46451->5019/tcp, 0.0.0.0:46450->5020/tcp, 0.0.0.0:46449->5021/tcp, 0.0.0.0:46448->5022/tcp, 0.0.0.0:46447->5023/tcp, 0.0.0.0:46446->5024/tcp, 0.0.0.0:46445->5025/tcp, 0.0.0.0:46444->5026/tcp, 0.0.0.0:46443->5027/tcp, 0.0.0.0:46442->5028/tcp, 0.0.0.0:46441->5029/tcp, 0.0.0.0:46440->5030/tcp, 0.0.0.0:46439->5031/tcp, 0.0.0.0:46438->5032/tcp, 0.0.0.0:46437->5033/tcp, 0.0.0.0:46436->5034/tcp, 0.0.0.0:46435->5035/tcp, 0.0.0.0:46434->5036/tcp, 0.0.0.0:46433->5037/tcp, 0.0.0.0:46432->5038/tcp, 0.0.0.0:46431->5039/tcp, 0.0.0.0:46430->5040/tcp, 0.0.0.0:46429->5041/tcp, 0.0.0.0:46428->5042/tcp, 0.0.0.0:46427->5043/tcp, 0.0.0.0:46425->5044/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  nostalgic_elion <NL> f55e2e65976d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   30 minutes ago       Up 30 minutes       22/tcp, 0.0.0.0:46424->5000/tcp, 0.0.0.0:46423->5001/tcp, 0.0.0.0:46422->5002/tcp, 0.0.0.0:46421->5003/tcp, 0.0.0.0:46420->5004/tcp, 0.0.0.0:46419->5005/tcp, 0.0.0.0:46418->5006/tcp, 0.0.0.0:46417->5007/tcp, 0.0.0.0:46416->5008/tcp, 0.0.0.0:46415->5009/tcp, 0.0.0.0:46414->5010/tcp, 0.0.0.0:46413->5011/tcp, 0.0.0.0:46412->5012/tcp, 0.0.0.0:46411->5013/tcp, 0.0.0.0:46410->5014/tcp, 0.0.0.0:46409->5015/tcp, 0.0.0.0:46408->5016/tcp, 0.0.0.0:46407->5017/tcp, 0.0.0.0:46406->5018/tcp, 0.0.0.0:46405->5019/tcp, 0.0.0.0:46404->5020/tcp, 0.0.0.0:46403->5021/tcp, 0.0.0.0:46402->5022/tcp, 0.0.0.0:46401->5023/tcp, 0.0.0.0:46400->5024/tcp, 0.0.0.0:46399->5025/tcp, 0.0.0.0:46398->5026/tcp, 0.0.0.0:46397->5027/tcp, 0.0.0.0:46396->5028/tcp, 0.0.0.0:46395->5029/tcp, 0.0.0.0:46394->5030/tcp, 0.0.0.0:46393->5031/tcp, 0.0.0.0:46392->5032/tcp, 0.0.0.0:46391->5033/tcp, 0.0.0.0:46390->5034/tcp, 0.0.0.0:46389->5035/tcp, 0.0.0.0:46388->5036/tcp, 0.0.0.0:46387->5037/tcp, 0.0.0.0:46386->5038/tcp, 0.0.0.0:46385->5039/tcp, 0.0.0.0:46384->5040/tcp, 0.0.0.0:46383->5041/tcp, 0.0.0.0:46382->5042/tcp, 0.0.0.0:46381->5043/tcp, 0.0.0.0:46380->5044/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  jolly_hamilton <NL> 37dae71598f5        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   31 minutes ago       Up 31 minutes       0.0.0.0:46379->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        upbeat_swirles <NL> e8bb3967c597        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   31 minutes ago       Up 31 minutes       0.0.0.0:46378->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        confident_curie <NL> 4381447fe83d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   50 minutes ago       Up 50 minutes       22/tcp, 0.0.0.0:46307->5000/tcp, 0.0.0.0:46306->5001/tcp, 0.0.0.0:46305->5002/tcp, 0.0.0.0:46304->5003/tcp, 0.0.0.0:46303->5004/tcp, 0.0.0.0:46302->5005/tcp, 0.0.0.0:46301->5006/tcp, 0.0.0.0:46300->5007/tcp, 0.0.0.0:46299->5008/tcp, 0.0.0.0:46298->5009/tcp, 0.0.0.0:46297->5010/tcp, 0.0.0.0:46296->5011/tcp, 0.0.0.0:46295->5012/tcp, 0.0.0.0:46294->5013/tcp, 0.0.0.0:46293->5014/tcp, 0.0.0.0:46292->5015/tcp, 0.0.0.0:46291->5016/tcp, 0.0.0.0:46290->5017/tcp, 0.0.0.0:46289->5018/tcp, 0.0.0.0:46288->5019/tcp, 0.0.0.0:46287->5020/tcp, 0.0.0.0:46286->5021/tcp, 0.0.0.0:46285->5022/tcp, 0.0.0.0:46284->5023/tcp, 0.0.0.0:46283->5024/tcp, 0.0.0.0:46282->5025/tcp, 0.0.0.0:46281->5026/tcp, 0.0.0.0:46280->5027/tcp, 0.0.0.0:46279->5028/tcp, 0.0.0.0:46278->5029/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         trusting_euler"}
{"timestamp_utc": "2024-07-31T08:32:52.610Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "5b81cfed569d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   52 minutes ago       Up 52 minutes       0.0.0.0:46277->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        serene_nobel <NL> 0bbde0e5ed03        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   52 minutes ago       Up 52 minutes       22/tcp, 0.0.0.0:46276->5000/tcp, 0.0.0.0:46275->5001/tcp, 0.0.0.0:46274->5002/tcp, 0.0.0.0:46273->5003/tcp, 0.0.0.0:46272->5004/tcp, 0.0.0.0:46271->5005/tcp, 0.0.0.0:46270->5006/tcp, 0.0.0.0:46269->5007/tcp, 0.0.0.0:46268->5008/tcp, 0.0.0.0:46267->5009/tcp, 0.0.0.0:46266->5010/tcp, 0.0.0.0:46265->5011/tcp, 0.0.0.0:46264->5012/tcp, 0.0.0.0:46263->5013/tcp, 0.0.0.0:46262->5014/tcp, 0.0.0.0:46261->5015/tcp, 0.0.0.0:46260->5016/tcp, 0.0.0.0:46259->5017/tcp, 0.0.0.0:46258->5018/tcp, 0.0.0.0:46257->5019/tcp, 0.0.0.0:46256->5020/tcp, 0.0.0.0:46255->5021/tcp, 0.0.0.0:46254->5022/tcp, 0.0.0.0:46253->5023/tcp, 0.0.0.0:46252->5024/tcp, 0.0.0.0:46251->5025/tcp, 0.0.0.0:46250->5026/tcp, 0.0.0.0:46249->5027/tcp, 0.0.0.0:46248->5028/tcp, 0.0.0.0:46247->5029/tcp, 0.0.0.0:46246->5030/tcp, 0.0.0.0:46245->5031/tcp, 0.0.0.0:46244->5032/tcp, 0.0.0.0:46243->5033/tcp, 0.0.0.0:46242->5034/tcp, 0.0.0.0:46241->5035/tcp, 0.0.0.0:46240->5036/tcp, 0.0.0.0:46239->5037/tcp, 0.0.0.0:46238->5038/tcp, 0.0.0.0:46237->5039/tcp, 0.0.0.0:46236->5040/tcp, 0.0.0.0:46235->5041/tcp, 0.0.0.0:46234->5042/tcp, 0.0.0.0:46233->5043/tcp, 0.0.0.0:46232->5044/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  eloquent_easley <NL> 41b851c21ff7        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   54 minutes ago       Up 54 minutes       0.0.0.0:46231->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        silly_pare <NL> e7d795c05cb4        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago    Up About an hour    22/tcp, 0.0.0.0:46230->5000/tcp, 0.0.0.0:46229->5001/tcp, 0.0.0.0:46228->5002/tcp, 0.0.0.0:46227->5003/tcp, 0.0.0.0:46225->5004/tcp, 0.0.0.0:46224->5005/tcp, 0.0.0.0:46223->5006/tcp, 0.0.0.0:46222->5007/tcp, 0.0.0.0:46221->5008/tcp, 0.0.0.0:46220->5009/tcp, 0.0.0.0:46219->5010/tcp, 0.0.0.0:46218->5011/tcp, 0.0.0.0:46217->5012/tcp, 0.0.0.0:46216->5013/tcp, 0.0.0.0:46215->5014/tcp, 0.0.0.0:46214->5015/tcp, 0.0.0.0:46213->5016/tcp, 0.0.0.0:46212->5017/tcp, 0.0.0.0:46211->5018/tcp, 0.0.0.0:46210->5019/tcp, 0.0.0.0:46209->5020/tcp, 0.0.0.0:46208->5021/tcp, 0.0.0.0:46207->5022/tcp, 0.0.0.0:46206->5023/tcp, 0.0.0.0:46205->5024/tcp, 0.0.0.0:46204->5025/tcp, 0.0.0.0:46203->5026/tcp, 0.0.0.0:46202->5027/tcp, 0.0.0.0:46201->5028/tcp, 0.0.0.0:46200->5029/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         eloquent_wiles <NL> 375231c1097c        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago    Up About an hour    0.0.0.0:46199->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        romantic_lamarr <NL> b2f5ec436818        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago    Up About an hour    22/tcp, 0.0.0.0:46198->5000/tcp, 0.0.0.0:46197->5001/tcp, 0.0.0.0:46196->5002/tcp, 0.0.0.0:46195->5003/tcp, 0.0.0.0:46194->5004/tcp, 0.0.0.0:46193->5005/tcp, 0.0.0.0:46192->5006/tcp, 0.0.0.0:46190->5007/tcp, 0.0.0.0:46188->5008/tcp, 0.0.0.0:46186->5009/tcp, 0.0.0.0:46184->5010/tcp, 0.0.0.0:46182->5011/tcp, 0.0.0.0:46180->5012/tcp, 0.0.0.0:46178->5013/tcp, 0.0.0.0:46176->5014/tcp, 0.0.0.0:46174->5015/tcp, 0.0.0.0:46172->5016/tcp, 0.0.0.0:46170->5017/tcp, 0.0.0.0:46168->5018/tcp, 0.0.0.0:46166->5019/tcp, 0.0.0.0:46164->5020/tcp, 0.0.0.0:46162->5021/tcp, 0.0.0.0:46160->5022/tcp, 0.0.0.0:46158->5023/tcp, 0.0.0.0:46156->5024/tcp, 0.0.0.0:46154->5025/tcp, 0.0.0.0:46152->5026/tcp, 0.0.0.0:46150->5027/tcp, 0.0.0.0:46146->5028/tcp, 0.0.0.0:46144->5029/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         adoring_shockley"}
{"timestamp_utc": "2024-07-31T08:32:52.611Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "afb60eaaf780        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago    Up About an hour    0.0.0.0:46136->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        practical_ardinghelli <NL> 57f074560fb4        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago    Up About an hour    22/tcp, 0.0.0.0:46135->5000/tcp, 0.0.0.0:46134->5001/tcp, 0.0.0.0:46133->5002/tcp, 0.0.0.0:46132->5003/tcp, 0.0.0.0:46131->5004/tcp, 0.0.0.0:46130->5005/tcp, 0.0.0.0:46129->5006/tcp, 0.0.0.0:46128->5007/tcp, 0.0.0.0:46127->5008/tcp, 0.0.0.0:46126->5009/tcp, 0.0.0.0:46125->5010/tcp, 0.0.0.0:46124->5011/tcp, 0.0.0.0:46123->5012/tcp, 0.0.0.0:46122->5013/tcp, 0.0.0.0:46121->5014/tcp, 0.0.0.0:46120->5015/tcp, 0.0.0.0:46119->5016/tcp, 0.0.0.0:46118->5017/tcp, 0.0.0.0:46117->5018/tcp, 0.0.0.0:46116->5019/tcp, 0.0.0.0:46115->5020/tcp, 0.0.0.0:46114->5021/tcp, 0.0.0.0:46113->5022/tcp, 0.0.0.0:46112->5023/tcp, 0.0.0.0:46111->5024/tcp, 0.0.0.0:46110->5025/tcp, 0.0.0.0:46109->5026/tcp, 0.0.0.0:46108->5027/tcp, 0.0.0.0:46107->5028/tcp, 0.0.0.0:46106->5029/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         gifted_davinci <NL> 6ba56926f82f        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago    Up About an hour    0.0.0.0:46105->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        heuristic_almeida <NL> b76483999a8c        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   2 hours ago          Up 2 hours          0.0.0.0:45899->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        silly_swanson <NL> e2c38f7471e3        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   2 hours ago          Up 2 hours          22/tcp, 0.0.0.0:45804->5000/tcp, 0.0.0.0:45803->5001/tcp, 0.0.0.0:45801->5002/tcp, 0.0.0.0:45800->5003/tcp, 0.0.0.0:45799->5004/tcp, 0.0.0.0:45798->5005/tcp, 0.0.0.0:45797->5006/tcp, 0.0.0.0:45796->5007/tcp, 0.0.0.0:45795->5008/tcp, 0.0.0.0:45794->5009/tcp, 0.0.0.0:45793->5010/tcp, 0.0.0.0:45792->5011/tcp, 0.0.0.0:45791->5012/tcp, 0.0.0.0:45790->5013/tcp, 0.0.0.0:45789->5014/tcp, 0.0.0.0:45788->5015/tcp, 0.0.0.0:45787->5016/tcp, 0.0.0.0:45786->5017/tcp, 0.0.0.0:45785->5018/tcp, 0.0.0.0:45784->5019/tcp, 0.0.0.0:45783->5020/tcp, 0.0.0.0:45782->5021/tcp, 0.0.0.0:45781->5022/tcp, 0.0.0.0:45780->5023/tcp, 0.0.0.0:45779->5024/tcp, 0.0.0.0:45778->5025/tcp, 0.0.0.0:45777->5026/tcp, 0.0.0.0:45776->5027/tcp, 0.0.0.0:45775->5028/tcp, 0.0.0.0:45774->5029/tcp, 0.0.0.0:45773->5030/tcp, 0.0.0.0:45772->5031/tcp, 0.0.0.0:45771->5032/tcp, 0.0.0.0:45770->5033/tcp, 0.0.0.0:45769->5034/tcp, 0.0.0.0:45768->5035/tcp, 0.0.0.0:45767->5036/tcp, 0.0.0.0:45766->5037/tcp, 0.0.0.0:45765->5038/tcp, 0.0.0.0:45764->5039/tcp, 0.0.0.0:45763->5040/tcp, 0.0.0.0:45762->5041/tcp, 0.0.0.0:45761->5042/tcp, 0.0.0.0:45760->5043/tcp, 0.0.0.0:45759->5044/tcp, 0.0.0.0:45758->5045/tcp, 0.0.0.0:45757->5046/tcp, 0.0.0.0:45756->5047/tcp, 0.0.0.0:45755->5048/tcp, 0.0.0.0:45754->5049/tcp, 0.0.0.0:45753->5050/tcp, 0.0.0.0:45752->5051/tcp, 0.0.0.0:45751->5052/tcp, 0.0.0.0:45750->5053/tcp, 0.0.0.0:45749->5054/tcp, 0.0.0.0:45748->5055/tcp, 0.0.0.0:45747->5056/tcp, 0.0.0.0:45746->5057/tcp, 0.0.0.0:45745->5058/tcp, 0.0.0.0:45744->5059/tcp                                                                                                                                                                                                           keen_minsky <NL> 255dbb035dd7        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   2 hours ago          Up 2 hours          0.0.0.0:45743->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        awesome_liskov <NL> dd566f2f8b9f        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45600->5000/tcp, 0.0.0.0:45599->5001/tcp, 0.0.0.0:45598->5002/tcp, 0.0.0.0:45597->5003/tcp, 0.0.0.0:45596->5004/tcp, 0.0.0.0:45595->5005/tcp, 0.0.0.0:45594->5006/tcp, 0.0.0.0:45593->5007/tcp, 0.0.0.0:45592->5008/tcp, 0.0.0.0:45591->5009/tcp, 0.0.0.0:45590->5010/tcp, 0.0.0.0:45589->5011/tcp, 0.0.0.0:45588->5012/tcp, 0.0.0.0:45587->5013/tcp, 0.0.0.0:45586->5014/tcp, 0.0.0.0:45585->5015/tcp, 0.0.0.0:45584->5016/tcp, 0.0.0.0:45583->5017/tcp, 0.0.0.0:45582->5018/tcp, 0.0.0.0:45581->5019/tcp, 0.0.0.0:45580->5020/tcp, 0.0.0.0:45579->5021/tcp, 0.0.0.0:45578->5022/tcp, 0.0.0.0:45577->5023/tcp, 0.0.0.0:45576->5024/tcp, 0.0.0.0:45575->5025/tcp, 0.0.0.0:45574->5026/tcp, 0.0.0.0:45573->5027/tcp, 0.0.0.0:45572->5028/tcp, 0.0.0.0:45570->5029/tcp, 0.0.0.0:45568->5030/tcp, 0.0.0.0:45566->5031/tcp, 0.0.0.0:45564->5032/tcp, 0.0.0.0:45562->5033/tcp, 0.0.0.0:45560->5034/tcp, 0.0.0.0:45558->5035/tcp, 0.0.0.0:45556->5036/tcp, 0.0.0.0:45554->5037/tcp, 0.0.0.0:45552->5038/tcp, 0.0.0.0:45550->5039/tcp, 0.0.0.0:45548->5040/tcp, 0.0.0.0:45546->5041/tcp, 0.0.0.0:45544->5042/tcp, 0.0.0.0:45542->5043/tcp, 0.0.0.0:45540->5044/tcp, 0.0.0.0:45538->5045/tcp, 0.0.0.0:45536->5046/tcp, 0.0.0.0:45534->5047/tcp, 0.0.0.0:45532->5048/tcp, 0.0.0.0:45530->5049/tcp, 0.0.0.0:45528->5050/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                            heuristic_euler <NL> 704e7796186b        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45571->5000/tcp, 0.0.0.0:45569->5001/tcp, 0.0.0.0:45567->5002/tcp, 0.0.0.0:45565->5003/tcp, 0.0.0.0:45563->5004/tcp, 0.0.0.0:45561->5005/tcp, 0.0.0.0:45559->5006/tcp, 0.0.0.0:45557->5007/tcp, 0.0.0.0:45555->5008/tcp, 0.0.0.0:45553->5009/tcp, 0.0.0.0:45551->5010/tcp, 0.0.0.0:45549->5011/tcp, 0.0.0.0:45547->5012/tcp, 0.0.0.0:45545->5013/tcp, 0.0.0.0:45543->5014/tcp, 0.0.0.0:45541->5015/tcp, 0.0.0.0:45539->5016/tcp, 0.0.0.0:45537->5017/tcp, 0.0.0.0:45535->5018/tcp, 0.0.0.0:45533->5019/tcp, 0.0.0.0:45531->5020/tcp, 0.0.0.0:45529->5021/tcp, 0.0.0.0:45527->5022/tcp, 0.0.0.0:45526->5023/tcp, 0.0.0.0:45525->5024/tcp, 0.0.0.0:45524->5025/tcp, 0.0.0.0:45523->5026/tcp, 0.0.0.0:45522->5027/tcp, 0.0.0.0:45521->5028/tcp, 0.0.0.0:45520->5029/tcp, 0.0.0.0:45519->5030/tcp, 0.0.0.0:45518->5031/tcp, 0.0.0.0:45517->5032/tcp, 0.0.0.0:45516->5033/tcp, 0.0.0.0:45515->5034/tcp, 0.0.0.0:45514->5035/tcp, 0.0.0.0:45513->5036/tcp, 0.0.0.0:45512->5037/tcp, 0.0.0.0:45511->5038/tcp, 0.0.0.0:45510->5039/tcp, 0.0.0.0:45509->5040/tcp, 0.0.0.0:45508->5041/tcp, 0.0.0.0:45507->5042/tcp, 0.0.0.0:45506->5043/tcp, 0.0.0.0:45505->5044/tcp, 0.0.0.0:45504->5045/tcp, 0.0.0.0:45503->5046/tcp, 0.0.0.0:45502->5047/tcp, 0.0.0.0:45501->5048/tcp, 0.0.0.0:45500->5049/tcp, 0.0.0.0:45498->5050/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                            vibrant_leakey <NL> a06e023f9739        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45451->5000/tcp, 0.0.0.0:45449->5001/tcp, 0.0.0.0:45446->5002/tcp, 0.0.0.0:45443->5003/tcp, 0.0.0.0:45440->5004/tcp, 0.0.0.0:45438->5005/tcp, 0.0.0.0:45436->5006/tcp, 0.0.0.0:45433->5007/tcp, 0.0.0.0:45430->5008/tcp, 0.0.0.0:45427->5009/tcp, 0.0.0.0:45424->5010/tcp, 0.0.0.0:45421->5011/tcp, 0.0.0.0:45415->5012/tcp, 0.0.0.0:45412->5013/tcp, 0.0.0.0:45409->5014/tcp, 0.0.0.0:45406->5015/tcp, 0.0.0.0:45402->5016/tcp, 0.0.0.0:45397->5017/tcp, 0.0.0.0:45392->5018/tcp, 0.0.0.0:45387->5019/tcp, 0.0.0.0:45382->5020/tcp, 0.0.0.0:45377->5021/tcp, 0.0.0.0:45372->5022/tcp, 0.0.0.0:45367->5023/tcp, 0.0.0.0:45362->5024/tcp, 0.0.0.0:45357->5025/tcp, 0.0.0.0:45352->5026/tcp, 0.0.0.0:45347->5027/tcp, 0.0.0.0:45342->5028/tcp, 0.0.0.0:45337->5029/tcp, 0.0.0.0:45332->5030/tcp, 0.0.0.0:45327->5031/tcp, 0.0.0.0:45322->5032/tcp, 0.0.0.0:45317->5033/tcp, 0.0.0.0:45312->5034/tcp, 0.0.0.0:45307->5035/tcp, 0.0.0.0:45303->5036/tcp, 0.0.0.0:45299->5037/tcp, 0.0.0.0:45295->5038/tcp, 0.0.0.0:45291->5039/tcp, 0.0.0.0:45287->5040/tcp, 0.0.0.0:45283->5041/tcp, 0.0.0.0:45279->5042/tcp, 0.0.0.0:45275->5043/tcp, 0.0.0.0:45271->5044/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  vigilant_bassi"}
{"timestamp_utc": "2024-07-31T08:32:52.612Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "29cc358c0033        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45404->5000/tcp, 0.0.0.0:45399->5001/tcp, 0.0.0.0:45394->5002/tcp, 0.0.0.0:45389->5003/tcp, 0.0.0.0:45384->5004/tcp, 0.0.0.0:45379->5005/tcp, 0.0.0.0:45374->5006/tcp, 0.0.0.0:45369->5007/tcp, 0.0.0.0:45364->5008/tcp, 0.0.0.0:45359->5009/tcp, 0.0.0.0:45354->5010/tcp, 0.0.0.0:45349->5011/tcp, 0.0.0.0:45344->5012/tcp, 0.0.0.0:45339->5013/tcp, 0.0.0.0:45334->5014/tcp, 0.0.0.0:45329->5015/tcp, 0.0.0.0:45324->5016/tcp, 0.0.0.0:45319->5017/tcp, 0.0.0.0:45314->5018/tcp, 0.0.0.0:45309->5019/tcp, 0.0.0.0:45304->5020/tcp, 0.0.0.0:45300->5021/tcp, 0.0.0.0:45296->5022/tcp, 0.0.0.0:45292->5023/tcp, 0.0.0.0:45288->5024/tcp, 0.0.0.0:45284->5025/tcp, 0.0.0.0:45280->5026/tcp, 0.0.0.0:45276->5027/tcp, 0.0.0.0:45272->5028/tcp, 0.0.0.0:45268->5029/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         vigilant_leavitt <NL> a174b08504c9        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45401->5000/tcp, 0.0.0.0:45396->5001/tcp, 0.0.0.0:45391->5002/tcp, 0.0.0.0:45386->5003/tcp, 0.0.0.0:45381->5004/tcp, 0.0.0.0:45376->5005/tcp, 0.0.0.0:45371->5006/tcp, 0.0.0.0:45366->5007/tcp, 0.0.0.0:45361->5008/tcp, 0.0.0.0:45356->5009/tcp, 0.0.0.0:45351->5010/tcp, 0.0.0.0:45346->5011/tcp, 0.0.0.0:45341->5012/tcp, 0.0.0.0:45336->5013/tcp, 0.0.0.0:45331->5014/tcp, 0.0.0.0:45326->5015/tcp, 0.0.0.0:45321->5016/tcp, 0.0.0.0:45316->5017/tcp, 0.0.0.0:45311->5018/tcp, 0.0.0.0:45306->5019/tcp, 0.0.0.0:45294->5020/tcp, 0.0.0.0:45290->5021/tcp, 0.0.0.0:45286->5022/tcp, 0.0.0.0:45282->5023/tcp, 0.0.0.0:45278->5024/tcp, 0.0.0.0:45274->5025/tcp, 0.0.0.0:45270->5026/tcp, 0.0.0.0:45267->5027/tcp, 0.0.0.0:45266->5028/tcp, 0.0.0.0:45265->5029/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         nervous_knuth <NL> e08afc0b16cc        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45448->5000/tcp, 0.0.0.0:45445->5001/tcp, 0.0.0.0:45442->5002/tcp, 0.0.0.0:45439->5003/tcp, 0.0.0.0:45437->5004/tcp, 0.0.0.0:45435->5005/tcp, 0.0.0.0:45432->5006/tcp, 0.0.0.0:45429->5007/tcp, 0.0.0.0:45426->5008/tcp, 0.0.0.0:45423->5009/tcp, 0.0.0.0:45420->5010/tcp, 0.0.0.0:45417->5011/tcp, 0.0.0.0:45414->5012/tcp, 0.0.0.0:45411->5013/tcp, 0.0.0.0:45408->5014/tcp, 0.0.0.0:45405->5015/tcp, 0.0.0.0:45400->5016/tcp, 0.0.0.0:45395->5017/tcp, 0.0.0.0:45390->5018/tcp, 0.0.0.0:45385->5019/tcp, 0.0.0.0:45380->5020/tcp, 0.0.0.0:45375->5021/tcp, 0.0.0.0:45370->5022/tcp, 0.0.0.0:45365->5023/tcp, 0.0.0.0:45360->5024/tcp, 0.0.0.0:45355->5025/tcp, 0.0.0.0:45350->5026/tcp, 0.0.0.0:45345->5027/tcp, 0.0.0.0:45340->5028/tcp, 0.0.0.0:45335->5029/tcp, 0.0.0.0:45330->5030/tcp, 0.0.0.0:45325->5031/tcp, 0.0.0.0:45320->5032/tcp, 0.0.0.0:45315->5033/tcp, 0.0.0.0:45310->5034/tcp, 0.0.0.0:45305->5035/tcp, 0.0.0.0:45301->5036/tcp, 0.0.0.0:45297->5037/tcp, 0.0.0.0:45293->5038/tcp, 0.0.0.0:45289->5039/tcp, 0.0.0.0:45285->5040/tcp, 0.0.0.0:45281->5041/tcp, 0.0.0.0:45277->5042/tcp, 0.0.0.0:45273->5043/tcp, 0.0.0.0:45269->5044/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  quizzical_chandrasekhar <NL> b2540543e6ce        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:45263->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        clever_shockley <NL> 07e987129db3        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:45262->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        confident_wiles <NL> 2697c1a4d3b4        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:45259->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        blissful_noether <NL> 29ebd23f3789        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:45258->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        affectionate_almeida <NL> dfc76cf16876        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:45257->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        hopeful_mahavira"}
{"timestamp_utc": "2024-07-31T08:32:52.613Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "382793f71ef4        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:45255->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        optimistic_snyder <NL> c2183928bf15        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45254->5000/tcp, 0.0.0.0:45253->5001/tcp, 0.0.0.0:45252->5002/tcp, 0.0.0.0:45251->5003/tcp, 0.0.0.0:45250->5004/tcp, 0.0.0.0:45249->5005/tcp, 0.0.0.0:45248->5006/tcp, 0.0.0.0:45247->5007/tcp, 0.0.0.0:45246->5008/tcp, 0.0.0.0:45245->5009/tcp, 0.0.0.0:45244->5010/tcp, 0.0.0.0:45243->5011/tcp, 0.0.0.0:45242->5012/tcp, 0.0.0.0:45241->5013/tcp, 0.0.0.0:45239->5014/tcp, 0.0.0.0:45236->5015/tcp, 0.0.0.0:45233->5016/tcp, 0.0.0.0:45230->5017/tcp, 0.0.0.0:45227->5018/tcp, 0.0.0.0:45224->5019/tcp, 0.0.0.0:45221->5020/tcp, 0.0.0.0:45217->5021/tcp, 0.0.0.0:45213->5022/tcp, 0.0.0.0:45209->5023/tcp, 0.0.0.0:45205->5024/tcp, 0.0.0.0:45201->5025/tcp, 0.0.0.0:45197->5026/tcp, 0.0.0.0:45193->5027/tcp, 0.0.0.0:45188->5028/tcp, 0.0.0.0:45183->5029/tcp, 0.0.0.0:45178->5030/tcp, 0.0.0.0:45173->5031/tcp, 0.0.0.0:45168->5032/tcp, 0.0.0.0:45163->5033/tcp, 0.0.0.0:45158->5034/tcp, 0.0.0.0:45153->5035/tcp, 0.0.0.0:45148->5036/tcp, 0.0.0.0:45142->5037/tcp, 0.0.0.0:45134->5038/tcp, 0.0.0.0:45126->5039/tcp, 0.0.0.0:45118->5040/tcp, 0.0.0.0:45110->5041/tcp, 0.0.0.0:45102->5042/tcp, 0.0.0.0:45094->5043/tcp, 0.0.0.0:45086->5044/tcp, 0.0.0.0:45078->5045/tcp, 0.0.0.0:45070->5046/tcp, 0.0.0.0:45062->5047/tcp, 0.0.0.0:45054->5048/tcp, 0.0.0.0:45046->5049/tcp, 0.0.0.0:45038->5050/tcp, 0.0.0.0:45030->5051/tcp                                                                                                                                                                                                                                                                                                                                                                                                                   practical_hugle <NL> 66b9ff6928aa        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45237->5000/tcp, 0.0.0.0:45234->5001/tcp, 0.0.0.0:45231->5002/tcp, 0.0.0.0:45228->5003/tcp, 0.0.0.0:45225->5004/tcp, 0.0.0.0:45222->5005/tcp, 0.0.0.0:45219->5006/tcp, 0.0.0.0:45215->5007/tcp, 0.0.0.0:45211->5008/tcp, 0.0.0.0:45207->5009/tcp, 0.0.0.0:45203->5010/tcp, 0.0.0.0:45199->5011/tcp, 0.0.0.0:45195->5012/tcp, 0.0.0.0:45190->5013/tcp, 0.0.0.0:45185->5014/tcp, 0.0.0.0:45180->5015/tcp, 0.0.0.0:45175->5016/tcp, 0.0.0.0:45170->5017/tcp, 0.0.0.0:45165->5018/tcp, 0.0.0.0:45160->5019/tcp, 0.0.0.0:45155->5020/tcp, 0.0.0.0:45150->5021/tcp, 0.0.0.0:45145->5022/tcp, 0.0.0.0:45139->5023/tcp, 0.0.0.0:45131->5024/tcp, 0.0.0.0:45123->5025/tcp, 0.0.0.0:45115->5026/tcp, 0.0.0.0:45107->5027/tcp, 0.0.0.0:45099->5028/tcp, 0.0.0.0:45091->5029/tcp, 0.0.0.0:45083->5030/tcp, 0.0.0.0:45075->5031/tcp, 0.0.0.0:45067->5032/tcp, 0.0.0.0:45059->5033/tcp, 0.0.0.0:45051->5034/tcp, 0.0.0.0:45043->5035/tcp, 0.0.0.0:45035->5036/tcp, 0.0.0.0:45027->5037/tcp, 0.0.0.0:45021->5038/tcp, 0.0.0.0:45014->5039/tcp, 0.0.0.0:45007->5040/tcp, 0.0.0.0:45000->5041/tcp, 0.0.0.0:44993->5042/tcp, 0.0.0.0:44986->5043/tcp, 0.0.0.0:44979->5044/tcp, 0.0.0.0:44972->5045/tcp, 0.0.0.0:44966->5046/tcp, 0.0.0.0:44960->5047/tcp, 0.0.0.0:44954->5048/tcp, 0.0.0.0:44948->5049/tcp, 0.0.0.0:44942->5050/tcp, 0.0.0.0:44936->5051/tcp                                                                                                                                                                                                                                                                                                                                                                                                                   vigilant_einstein <NL> eff6a97458e4        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:45136->5000/tcp, 0.0.0.0:45128->5001/tcp, 0.0.0.0:45120->5002/tcp, 0.0.0.0:45112->5003/tcp, 0.0.0.0:45104->5004/tcp, 0.0.0.0:45096->5005/tcp, 0.0.0.0:45088->5006/tcp, 0.0.0.0:45080->5007/tcp, 0.0.0.0:45072->5008/tcp, 0.0.0.0:45064->5009/tcp, 0.0.0.0:45056->5010/tcp, 0.0.0.0:45048->5011/tcp, 0.0.0.0:45040->5012/tcp, 0.0.0.0:45032->5013/tcp, 0.0.0.0:45024->5014/tcp, 0.0.0.0:45018->5015/tcp, 0.0.0.0:45011->5016/tcp, 0.0.0.0:45004->5017/tcp, 0.0.0.0:44997->5018/tcp, 0.0.0.0:44990->5019/tcp, 0.0.0.0:44983->5020/tcp, 0.0.0.0:44976->5021/tcp, 0.0.0.0:44970->5022/tcp, 0.0.0.0:44964->5023/tcp, 0.0.0.0:44958->5024/tcp, 0.0.0.0:44952->5025/tcp, 0.0.0.0:44946->5026/tcp, 0.0.0.0:44940->5027/tcp, 0.0.0.0:44934->5028/tcp, 0.0.0.0:44930->5029/tcp, 0.0.0.0:44926->5030/tcp, 0.0.0.0:44922->5031/tcp, 0.0.0.0:44918->5032/tcp, 0.0.0.0:44914->5033/tcp, 0.0.0.0:44910->5034/tcp, 0.0.0.0:44906->5035/tcp, 0.0.0.0:44902->5036/tcp, 0.0.0.0:44898->5037/tcp, 0.0.0.0:44894->5038/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        silly_poincare <NL> cfba76122e69        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          22/tcp, 0.0.0.0:44678->5000/tcp, 0.0.0.0:44671->5001/tcp, 0.0.0.0:44664->5002/tcp, 0.0.0.0:44657->5003/tcp, 0.0.0.0:44650->5004/tcp, 0.0.0.0:44643->5005/tcp, 0.0.0.0:44637->5006/tcp, 0.0.0.0:44631->5007/tcp, 0.0.0.0:44626->5008/tcp, 0.0.0.0:44621->5009/tcp, 0.0.0.0:44616->5010/tcp, 0.0.0.0:44611->5011/tcp, 0.0.0.0:44606->5012/tcp, 0.0.0.0:44601->5013/tcp, 0.0.0.0:44596->5014/tcp, 0.0.0.0:44591->5015/tcp, 0.0.0.0:44586->5016/tcp, 0.0.0.0:44581->5017/tcp, 0.0.0.0:44576->5018/tcp, 0.0.0.0:44571->5019/tcp, 0.0.0.0:44566->5020/tcp, 0.0.0.0:44561->5021/tcp, 0.0.0.0:44556->5022/tcp, 0.0.0.0:44551->5023/tcp, 0.0.0.0:44546->5024/tcp, 0.0.0.0:44542->5025/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             suspicious_ritchie <NL> 1f45c10ecd44        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:44538->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        priceless_shannon <NL> 9988fb0fa8fe        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:44537->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        eloquent_pasteur <NL> fd00b16fdcda        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:44525->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        confident_rosalind <NL> fe42c22633e3        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:44524->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        confident_perlman"}
{"timestamp_utc": "2024-07-31T08:32:52.614Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "e40ebf9c2fbd        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago          Up 3 hours          0.0.0.0:44515->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        boring_joliot <NL> db2407dbcb59        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   20 hours ago         Up 20 hours         22/tcp, 0.0.0.0:44513->5000/tcp, 0.0.0.0:44512->5001/tcp, 0.0.0.0:44511->5002/tcp, 0.0.0.0:44510->5003/tcp, 0.0.0.0:44509->5004/tcp, 0.0.0.0:33101->5005/udp, 0.0.0.0:44508->5006/tcp, 0.0.0.0:44507->5007/tcp, 0.0.0.0:44506->5008/tcp, 0.0.0.0:44505->5009/tcp, 0.0.0.0:44504->5010/tcp, 0.0.0.0:44503->5011/tcp, 0.0.0.0:44502->5012/tcp, 0.0.0.0:44501->5013/tcp, 0.0.0.0:44500->5014/tcp, 0.0.0.0:44499->5015/tcp, 0.0.0.0:44498->5016/tcp, 0.0.0.0:44497->5017/tcp, 0.0.0.0:44496->5018/tcp, 0.0.0.0:44495->5019/tcp, 0.0.0.0:44494->5020/tcp, 0.0.0.0:44493->5021/tcp, 0.0.0.0:33100->5022/udp, 0.0.0.0:44492->5023/tcp, 0.0.0.0:44491->5024/tcp, 0.0.0.0:44490->5025/tcp, 0.0.0.0:44489->5026/tcp, 0.0.0.0:44488->5027/tcp, 0.0.0.0:44487->5028/tcp, 0.0.0.0:44486->5029/tcp, 0.0.0.0:44485->5030/tcp, 0.0.0.0:44484->5031/tcp, 0.0.0.0:44483->5032/tcp, 0.0.0.0:44482->5033/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     jovial_austin <NL> ea28b89d0a7d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   20 hours ago         Up 20 hours         22/tcp, 0.0.0.0:44195->5000/tcp, 0.0.0.0:44194->5001/tcp, 0.0.0.0:44193->5002/tcp, 0.0.0.0:44192->5003/tcp, 0.0.0.0:44191->5004/tcp, 0.0.0.0:33081->5005/udp, 0.0.0.0:44190->5006/tcp, 0.0.0.0:44189->5007/tcp, 0.0.0.0:44188->5008/tcp, 0.0.0.0:44187->5009/tcp, 0.0.0.0:44186->5010/tcp, 0.0.0.0:44185->5011/tcp, 0.0.0.0:44184->5012/tcp, 0.0.0.0:44183->5013/tcp, 0.0.0.0:44182->5014/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                quirky_albattani <NL> da8e4c2acd64        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   24 hours ago         Up 24 hours         22/tcp, 0.0.0.0:43504->5000/tcp, 0.0.0.0:43503->5001/tcp, 0.0.0.0:43502->5002/tcp, 0.0.0.0:43501->5003/tcp, 0.0.0.0:43500->5004/tcp, 0.0.0.0:43499->5005/tcp, 0.0.0.0:33043->5006/udp, 0.0.0.0:43498->5007/tcp, 0.0.0.0:43497->5008/tcp, 0.0.0.0:43496->5009/tcp, 0.0.0.0:43495->5010/tcp, 0.0.0.0:43494->5011/tcp, 0.0.0.0:43493->5012/tcp, 0.0.0.0:43492->5013/tcp, 0.0.0.0:43491->5014/tcp, 0.0.0.0:43490->5015/tcp, 0.0.0.0:43489->5016/tcp, 0.0.0.0:43488->5017/tcp, 0.0.0.0:43487->5018/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            wonderful_yonath <NL> ec9b8f054752        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   29 hours ago         Up 29 hours         22/tcp, 0.0.0.0:43293->5000/tcp, 0.0.0.0:43292->5001/tcp, 0.0.0.0:43291->5002/tcp, 0.0.0.0:43290->5003/tcp, 0.0.0.0:43289->5004/tcp, 0.0.0.0:43288->5005/tcp, 0.0.0.0:43287->5006/tcp, 0.0.0.0:43285->5007/tcp, 0.0.0.0:43283->5008/tcp, 0.0.0.0:43281->5009/tcp, 0.0.0.0:43279->5010/tcp, 0.0.0.0:43277->5011/tcp, 0.0.0.0:43275->5012/tcp, 0.0.0.0:43273->5013/tcp, 0.0.0.0:43271->5014/tcp, 0.0.0.0:43269->5015/tcp, 0.0.0.0:43267->5016/tcp, 0.0.0.0:43265->5017/tcp, 0.0.0.0:43263->5018/tcp, 0.0.0.0:43261->5019/tcp, 0.0.0.0:43259->5020/tcp, 0.0.0.0:43257->5021/tcp, 0.0.0.0:43255->5022/tcp, 0.0.0.0:43253->5023/tcp, 0.0.0.0:43251->5024/tcp, 0.0.0.0:43249->5025/tcp, 0.0.0.0:43247->5026/tcp, 0.0.0.0:43245->5027/tcp, 0.0.0.0:43243->5028/tcp, 0.0.0.0:43239->5029/tcp, 0.0.0.0:43235->5030/tcp, 0.0.0.0:43231->5031/tcp, 0.0.0.0:43227->5032/tcp, 0.0.0.0:43222->5033/tcp, 0.0.0.0:43217->5034/tcp, 0.0.0.0:43212->5035/tcp, 0.0.0.0:43206->5036/tcp, 0.0.0.0:43200->5037/tcp, 0.0.0.0:43194->5038/tcp, 0.0.0.0:43188->5039/tcp, 0.0.0.0:43182->5040/tcp, 0.0.0.0:43176->5041/tcp, 0.0.0.0:43170->5042/tcp, 0.0.0.0:43164->5043/tcp, 0.0.0.0:43158->5044/tcp, 0.0.0.0:43152->5045/tcp, 0.0.0.0:43145->5046/tcp, 0.0.0.0:43138->5047/tcp, 0.0.0.0:43128->5048/tcp, 0.0.0.0:43118->5049/tcp, 0.0.0.0:43107->5050/tcp, 0.0.0.0:43096->5051/tcp                                                                                                                                                                                                                                                                                                                                                                                                                   dazzling_easley <NL> 7361c9164c25        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   29 hours ago         Up 29 hours         22/tcp, 0.0.0.0:43286->5000/tcp, 0.0.0.0:43284->5001/tcp, 0.0.0.0:43282->5002/tcp, 0.0.0.0:43280->5003/tcp, 0.0.0.0:43278->5004/tcp, 0.0.0.0:43276->5005/tcp, 0.0.0.0:43274->5006/tcp, 0.0.0.0:43272->5007/tcp, 0.0.0.0:43270->5008/tcp, 0.0.0.0:43268->5009/tcp, 0.0.0.0:43266->5010/tcp, 0.0.0.0:43264->5011/tcp, 0.0.0.0:43262->5012/tcp, 0.0.0.0:43260->5013/tcp, 0.0.0.0:43258->5014/tcp, 0.0.0.0:43256->5015/tcp, 0.0.0.0:43254->5016/tcp, 0.0.0.0:43252->5017/tcp, 0.0.0.0:43250->5018/tcp, 0.0.0.0:43248->5019/tcp, 0.0.0.0:43246->5020/tcp, 0.0.0.0:43244->5021/tcp, 0.0.0.0:43240->5022/tcp, 0.0.0.0:43236->5023/tcp, 0.0.0.0:43232->5024/tcp, 0.0.0.0:43228->5025/tcp, 0.0.0.0:43223->5026/tcp, 0.0.0.0:43218->5027/tcp, 0.0.0.0:43213->5028/tcp, 0.0.0.0:43207->5029/tcp, 0.0.0.0:43201->5030/tcp, 0.0.0.0:43195->5031/tcp, 0.0.0.0:43189->5032/tcp, 0.0.0.0:43183->5033/tcp, 0.0.0.0:43177->5034/tcp, 0.0.0.0:43171->5035/tcp, 0.0.0.0:43165->5036/tcp, 0.0.0.0:43159->5037/tcp, 0.0.0.0:43153->5038/tcp, 0.0.0.0:43147->5039/tcp, 0.0.0.0:43140->5040/tcp, 0.0.0.0:43130->5041/tcp, 0.0.0.0:43120->5042/tcp, 0.0.0.0:43110->5043/tcp, 0.0.0.0:43099->5044/tcp, 0.0.0.0:43088->5045/tcp, 0.0.0.0:43078->5046/tcp, 0.0.0.0:43068->5047/tcp, 0.0.0.0:43058->5048/tcp, 0.0.0.0:43048->5049/tcp, 0.0.0.0:43038->5050/tcp, 0.0.0.0:43028->5051/tcp                                                                                                                                                                                                                                                                                                                                                                                                                   brave_northcutt <NL> 41d54a4210b2        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   29 hours ago         Up 29 hours         22/tcp, 0.0.0.0:42785->5000/tcp, 0.0.0.0:42784->5001/tcp, 0.0.0.0:42783->5002/tcp, 0.0.0.0:42782->5003/tcp, 0.0.0.0:42781->5004/tcp, 0.0.0.0:42780->5005/tcp, 0.0.0.0:42779->5006/tcp, 0.0.0.0:42778->5007/tcp, 0.0.0.0:42777->5008/tcp, 0.0.0.0:42776->5009/tcp, 0.0.0.0:42775->5010/tcp, 0.0.0.0:42774->5011/tcp, 0.0.0.0:42773->5012/tcp, 0.0.0.0:42772->5013/tcp, 0.0.0.0:42771->5014/tcp, 0.0.0.0:42770->5015/tcp, 0.0.0.0:42769->5016/tcp, 0.0.0.0:42768->5017/tcp, 0.0.0.0:42767->5018/tcp, 0.0.0.0:42766->5019/tcp, 0.0.0.0:42765->5020/tcp, 0.0.0.0:42764->5021/tcp, 0.0.0.0:42763->5022/tcp, 0.0.0.0:42762->5023/tcp, 0.0.0.0:42761->5024/tcp, 0.0.0.0:42760->5025/tcp, 0.0.0.0:42759->5026/tcp, 0.0.0.0:42758->5027/tcp, 0.0.0.0:42757->5028/tcp, 0.0.0.0:42756->5029/tcp, 0.0.0.0:42755->5030/tcp, 0.0.0.0:42754->5031/tcp, 0.0.0.0:42753->5032/tcp, 0.0.0.0:42752->5033/tcp, 0.0.0.0:42751->5034/tcp, 0.0.0.0:42750->5035/tcp, 0.0.0.0:42749->5036/tcp, 0.0.0.0:42748->5037/tcp, 0.0.0.0:42747->5038/tcp, 0.0.0.0:42746->5039/tcp, 0.0.0.0:42745->5040/tcp, 0.0.0.0:42744->5041/tcp, 0.0.0.0:42743->5042/tcp, 0.0.0.0:42742->5043/tcp, 0.0.0.0:42740->5044/tcp, 0.0.0.0:42739->5045/tcp, 0.0.0.0:42738->5046/tcp, 0.0.0.0:42737->5047/tcp, 0.0.0.0:42736->5048/tcp, 0.0.0.0:42735->5049/tcp, 0.0.0.0:42734->5050/tcp, 0.0.0.0:42733->5051/tcp                                                                                                                                                                                                                                                                                                                                                                                                                   adoring_swartz <NL> 988bcbb25ba9        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   29 hours ago         Up 29 hours         22/tcp, 0.0.0.0:42555->5000/tcp, 0.0.0.0:42552->5001/tcp, 0.0.0.0:42549->5002/tcp, 0.0.0.0:42546->5003/tcp, 0.0.0.0:42543->5004/tcp, 0.0.0.0:42540->5005/tcp, 0.0.0.0:42537->5006/tcp, 0.0.0.0:42534->5007/tcp, 0.0.0.0:42531->5008/tcp, 0.0.0.0:42527->5009/tcp, 0.0.0.0:42523->5010/tcp, 0.0.0.0:42518->5011/tcp, 0.0.0.0:42514->5012/tcp, 0.0.0.0:42510->5013/tcp, 0.0.0.0:42506->5014/tcp, 0.0.0.0:42502->5015/tcp, 0.0.0.0:42499->5016/tcp, 0.0.0.0:42496->5017/tcp, 0.0.0.0:42493->5018/tcp, 0.0.0.0:42490->5019/tcp, 0.0.0.0:42488->5020/tcp, 0.0.0.0:42486->5021/tcp, 0.0.0.0:42484->5022/tcp, 0.0.0.0:42482->5023/tcp, 0.0.0.0:42480->5024/tcp, 0.0.0.0:42478->5025/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             distracted_curran <NL> 797b41a49391        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   31 hours ago         Up 31 hours         22/tcp, 0.0.0.0:42153->5000/tcp, 0.0.0.0:42151->5001/tcp, 0.0.0.0:42149->5002/tcp, 0.0.0.0:42147->5003/tcp, 0.0.0.0:42145->5004/tcp, 0.0.0.0:42143->5005/tcp, 0.0.0.0:42141->5006/tcp, 0.0.0.0:42139->5007/tcp, 0.0.0.0:42137->5008/tcp, 0.0.0.0:42135->5009/tcp, 0.0.0.0:42133->5010/tcp, 0.0.0.0:42131->5011/tcp, 0.0.0.0:42129->5012/tcp, 0.0.0.0:42127->5013/tcp, 0.0.0.0:42125->5014/tcp, 0.0.0.0:42123->5015/tcp, 0.0.0.0:42121->5016/tcp, 0.0.0.0:42119->5017/tcp, 0.0.0.0:42117->5018/tcp, 0.0.0.0:42115->5019/tcp, 0.0.0.0:42113->5020/tcp, 0.0.0.0:42111->5021/tcp, 0.0.0.0:42109->5022/tcp, 0.0.0.0:42107->5023/tcp, 0.0.0.0:42105->5024/tcp, 0.0.0.0:42103->5025/tcp, 0.0.0.0:42101->5026/tcp, 0.0.0.0:42099->5027/tcp, 0.0.0.0:42097->5028/tcp, 0.0.0.0:42095->5029/tcp, 0.0.0.0:42093->5030/tcp, 0.0.0.0:42091->5031/tcp, 0.0.0.0:42089->5032/tcp, 0.0.0.0:42087->5033/tcp, 0.0.0.0:42084->5034/tcp, 0.0.0.0:42081->5035/tcp, 0.0.0.0:42078->5036/tcp, 0.0.0.0:42075->5037/tcp, 0.0.0.0:42072->5038/tcp, 0.0.0.0:42069->5039/tcp, 0.0.0.0:42066->5040/tcp, 0.0.0.0:42063->5041/tcp, 0.0.0.0:42060->5042/tcp, 0.0.0.0:42057->5043/tcp, 0.0.0.0:42054->5044/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  goofy_darwin"}
{"timestamp_utc": "2024-07-31T08:32:52.615Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "9a0171d4f4ff        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   35 hours ago         Up 35 hours         22/tcp, 0.0.0.0:42030->5000/tcp, 0.0.0.0:42027->5001/tcp, 0.0.0.0:42024->5002/tcp, 0.0.0.0:42021->5003/tcp, 0.0.0.0:42017->5004/tcp, 0.0.0.0:42013->5005/tcp, 0.0.0.0:42009->5006/tcp, 0.0.0.0:42005->5007/tcp, 0.0.0.0:42001->5008/tcp, 0.0.0.0:41997->5009/tcp, 0.0.0.0:41993->5010/tcp, 0.0.0.0:41989->5011/tcp, 0.0.0.0:41985->5012/tcp, 0.0.0.0:41981->5013/tcp, 0.0.0.0:41977->5014/tcp, 0.0.0.0:41973->5015/tcp, 0.0.0.0:41969->5016/tcp, 0.0.0.0:41965->5017/tcp, 0.0.0.0:41961->5018/tcp, 0.0.0.0:41957->5019/tcp, 0.0.0.0:41953->5020/tcp, 0.0.0.0:41949->5021/tcp, 0.0.0.0:41945->5022/tcp, 0.0.0.0:41941->5023/tcp, 0.0.0.0:41937->5024/tcp, 0.0.0.0:41933->5025/tcp, 0.0.0.0:41929->5026/tcp, 0.0.0.0:41925->5027/tcp, 0.0.0.0:41921->5028/tcp, 0.0.0.0:41917->5029/tcp, 0.0.0.0:41913->5030/tcp, 0.0.0.0:41909->5031/tcp, 0.0.0.0:41905->5032/tcp, 0.0.0.0:41901->5033/tcp, 0.0.0.0:41897->5034/tcp, 0.0.0.0:41893->5035/tcp, 0.0.0.0:41889->5036/tcp, 0.0.0.0:41885->5037/tcp, 0.0.0.0:41881->5038/tcp, 0.0.0.0:41877->5039/tcp, 0.0.0.0:41873->5040/tcp, 0.0.0.0:41869->5041/tcp, 0.0.0.0:41865->5042/tcp, 0.0.0.0:41862->5043/tcp, 0.0.0.0:41860->5044/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  jovial_kilby <NL> ci-job-post-build-cleanup: ----- ci-resource-tracker -v -v -v --del-all <NL> # DEBUG 2024-07-31 03:32:52,580 ci-resource-tracker: arg_dict: { <NL> \"action\": \"del-all\", <NL> \"command\": null, <NL> \"data_fname\": null, <NL> \"force_flag\": false, <NL> \"hostname\": null, <NL> \"type\": null, <NL> \"verbosity\": 3 <NL> } <NL> # DEBUG 2024-07-31 03:32:52,581 ci-resource-tracker: data_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/ci-data/ci-resource-tracker.json\" <NL> # INFO 2024-07-31 03:32:52,581 ci-resource-tracker: action_del_all: current_hostname \"rtxoialp85.fnc.net.local\" <NL> # INFO 2024-07-31 03:32:52,581 ci-resource-tracker: action_del_all: nothing to do, data file not there: \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/ci-data/ci-resource-tracker.json\" <NL> ci-job-post-build-cleanup: exit_code \"0\""}
{"timestamp_utc": "2024-07-31T08:32:52.624Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:32:52.635Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:32:52.642Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:32:52.649Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:32:52.656Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:32:52.663Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // timeout"}
{"timestamp_utc": "2024-07-31T08:32:52.670Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] archive"}
{"timestamp_utc": "2024-07-31T08:32:52.672Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "The archive step is deprecated, please use archiveArtifacts instead."}
{"timestamp_utc": "2024-07-31T08:32:59.631Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:32:59.641Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:32:59.921Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.003/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-napt/7/node.003/node-info.json"}
{"timestamp_utc": "2024-07-31T08:32:59.926Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:32:59.933Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T08:32:59.943Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T08:32:59.944Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pipeline_execute: currentBuild.result 'FAILURE' <NL> ===== ===== ===== ===== ===== <NL> [Pipeline] End of Pipeline"}
{"timestamp_utc": "2024-07-31T08:33:00.195Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Finished: FAILURE"}
