{"timestamp_utc": "2024-07-31T05:08:29.943Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Started by upstream project \"project/fss3/ci-regression\" build number 2999 <NL> originally caused by: <NL> Started by user Meenakshisundaram, Balaji (BMEENAKS)"}
{"timestamp_utc": "2024-07-31T05:08:29.989Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] Start of Pipeline"}
{"timestamp_utc": "2024-07-31T05:08:29.995Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] library"}
{"timestamp_utc": "2024-07-31T05:08:29.997Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Loading library cic-shared-library@project_latest <NL> Attempting to resolve project_latest from remote references... <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:08:30.067Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3' <NL> > git ls-remote -- ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:08:30.377Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Found match: refs/tags/project_latest revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a <NL> Resolving tag commit... (remote references may be a lightweight tag or an annotated tag)"}
{"timestamp_utc": "2024-07-31T05:10:08.561Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git rev-parse --resolve-git-dir /atldata/jenkins/caches/git-81d7c0835bf8496255df022a875c0e23/.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:08.641Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Setting origin to ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git config remote.origin.url ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:08.733Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching origin... <NL> Fetching upstream changes from origin <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:08.936Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3'"}
{"timestamp_utc": "2024-07-31T05:10:08.937Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git config --get remote.origin.url # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:08.993Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git fetch --tags --force --progress -- origin +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:10.720Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git rev-parse refs/tags/project_latest^{commit} # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:10.919Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Resolved tag project_latest revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a"}
{"timestamp_utc": "2024-07-31T05:10:10.920Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "The recommended git tool is: git <NL> Warning: CredentialId \"jenkins\" could not be found."}
{"timestamp_utc": "2024-07-31T05:10:10.921Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Cloning the remote Git repository <NL> Cloning with configured refspecs honoured and with tags <NL> Cloning repository ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git init /atldata/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44_libs/e62eae340757e7d61d5116e39951ef47814af05333dabd029e21d997a41ab976 # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:11.078Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching upstream changes from ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:11.199Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3' <NL> > git fetch --tags --force --progress -- ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:25.112Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git config remote.origin.url ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:25.193Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git config --add remote.origin.fetch +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:25.318Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Avoid second fetch <NL> Checking out Revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a (project_latest) <NL> > git config core.sparsecheckout # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:25.488Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git checkout -f 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:25.867Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Commit message: \"saving manifest for tag project_cd1474\""}
{"timestamp_utc": "2024-07-31T05:10:26.545Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false <NL> [Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:26.668Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp73 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44"}
{"timestamp_utc": "2024-07-31T05:10:26.669Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T05:10:26.673Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:26.951Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.001 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.001"}
{"timestamp_utc": "2024-07-31T05:10:26.959Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:26.962Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:27.441Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.001/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.001/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:27.450Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T05:10:27.486Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:27.771Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git bootstrap-repo-subdir <NL> Cloning into 'bootstrap-repo-subdir'..."}
{"timestamp_utc": "2024-07-31T05:10:28.028Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name"}
{"timestamp_utc": "2024-07-31T05:10:28.036Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:28.342Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (bootstrap-repo-subdir/jenkins/bootstrap-pipeline.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:28.345Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:28.348Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:28.353Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:28.358Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:28.637Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.001/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.001/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:28.642Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:28.645Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T05:10:28.722Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false"}
{"timestamp_utc": "2024-07-31T05:10:28.731Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:28.853Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp73 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44 <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T05:10:28.858Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:29.149Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.002 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.002"}
{"timestamp_utc": "2024-07-31T05:10:29.160Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:29.167Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:29.452Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.002/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.002/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:29.460Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T05:10:29.461Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:29.733Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44"}
{"timestamp_utc": "2024-07-31T05:10:29.739Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T05:10:29.746Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> ===== parameter values: ===== <NL> PIPELINE_JOB_NAME                  \"json-nt-ddcn-4-node-natRedistribute-nat44\" <NL> PIPELINE_JOB_FULL_NAME             \"project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44\" <NL> PIPELINE_JOB_PROJECT_FOLDER_NAME   \"fss3\" <NL> RECIPE_REPO_BASE_JOB_NAME          null <NL> (dflt) PROJECT_NAME                       \"fss3\" <NL> (dflt) RECIPE_REPO_NAME                   null <NL> (user) CI_BASE_BRANCH_NAME                \"fss3\" <NL> (user) NETWORK_TOPOLOGY_BRANCH_NAME       \"ntp_latest\" <NL> (user) CI_SUBMODULE_BRANCH_NAME           \"project_latest\" <NL> (user) PROJECT_INFO_BRANCH_NAME           \"master_cd23138\" <NL> (user) GROOVY_SCRIPT_NAME                 \"continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy\" <NL> ===== ===== ===== ===== ====="}
{"timestamp_utc": "2024-07-31T05:10:29.747Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:30.022Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ git clone --branch fss3 --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration.git continuous-integration <NL> Cloning into 'continuous-integration'... <NL> + rm -rf continuous-integration/continuous-integration-common <NL> + cd continuous-integration <NL> + git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git continuous-integration-common <NL> Cloning into 'continuous-integration-common'..."}
{"timestamp_utc": "2024-07-31T05:10:30.587Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd continuous-integration-common <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf repo <NL> + git clone --branch master --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/repo.git repo <NL> Cloning into 'repo'..."}
{"timestamp_utc": "2024-07-31T05:10:30.842Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cd repo <NL> + rm -rf .git <NL> + cd .."}
{"timestamp_utc": "2024-07-31T05:10:30.847Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:31.487Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:31.494Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:31.509Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:31.518Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:31.711Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.utilities.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:31.718Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:31.724Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:31.731Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:31.786Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.user_input.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:31.792Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:31.798Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:31.805Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:32.448Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.json_pipeline.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:32.456Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:32.465Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:32.475Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:32.901Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.gitscm.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:32.929Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:32.935Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:32.951Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:32.972Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:33.245Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.002/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.002/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:33.251Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:33.257Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T05:10:33.281Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> PIPELINE_JOB_NAME                 \"json-nt-ddcn-4-node-natRedistribute-nat44\" <NL> PIPELINE_JOB_FULL_NAME            \"project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44\" <NL> PIPELINE_JOB_PROJECT_FOLDER_NAME  \"fss3\" <NL> PROJECT_NAME                      \"fss3\" <NL> CI_BASE_BRANCH_NAME               \"fss3\" <NL> CI_SUBMODULE_BRANCH_NAME          \"project_latest\" <NL> CI_BUILD_URL                      \"\" <NL> CI_JOB_PARENT_ARTIFACT_INFO_FNAME \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\" <NL> GROOVY_SCRIPT_NAME                \"continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy\" <NL> JPARAM_JOB_JSON_STRING            \"{\"job_type\":\"explicit\",\"job_timeout_unit\":\"HOURS\",\"job_timeout_amount\":6,\"job_propagate_flag\":true,\"job_template\":\"ci-pipeline-job.xml\",\"disable_flag.ci-release-recipe-repo\":true,\"disable_flag.ci-review\":true,\"disable_flag.ci-release-project\":true,\"job_command_list\":[\"ci-project-sanity-tfwk\",\"--\",\"--testcases-project-name\",\"fss3\",\"--\",\"--test-engine\",\"Warrior\",\"--topology-tag-name\",\"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\",\"--define-attr-defaults\",\"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\",\"--define-instance-attr\",\"NE1/main\",\"shelf-num=1\",\"--define-instance-attr\",\"NE1/main\",\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\",\"--define-instance-attr\",\"NE1/trib1\",\"shelf-num=2\",\"--define-instance-attr\",\"NE1/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE2/main\",\"shelf-num=1\",\"--define-instance-attr\",\"NE2/main\",\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\",\"--define-instance-attr\",\"NE2/trib1\",\"shelf-num=2\",\"--define-instance-attr\",\"NE2/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE3/main\",\"shelf-num=200\",\"--define-instance-attr\",\"NE3/main\",\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\",\"--define-instance-attr\",\"NE3/trib1\",\"shelf-num=1\",\"--define-instance-attr\",\"NE3/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE4/main\",\"shelf-num=200\",\"--define-instance-attr\",\"NE4/main\",\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\",\"--define-instance-attr\",\"NE4/trib1\",\"shelf-num=1\",\"--define-instance-attr\",\"NE4/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--add-instance\",\"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\",\"--device-wait-startup-timeout\",\"1200\",\"--test-engine-begin\",\"--no_logger\",\"--test-engine-end\",\"--\",\"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml\"],\"disable_flag.ci-update-manifest\":true,\"job_name\":\"nt-ddcn-4-node-natRedistribute-nat44\",\"job_quiet_period\":0,\"job_docker_container_flag\":true,\"job_wait_flag\":true,\"job_failure_handling\":\"pipeline-failure\",\"job_unstash_flag\":true,\"disable_flag.ci-update-manifest-recipe-repo\":true,\"disable_flag.ci-review-recipe-repo\":true,\"job_agent\":\"regression-sanity-docker\",\"previous_job_method\":\"previous-job\",\"job_stash_flag\":true,\"job_label\":\"nt-ddcn-4-node-natRedistribute-nat44\",\"job_docker_container_info\":null,\"job_kubernetes_info\":null,\"job_command_prefix\":[\"ci-get-archive-artifacts\",\"--project-info-basename\",\"project-info.json\",\"--project-info-extended-basename\",\"project-info-extended.json\",\"--\",\"ci-job-info\"],\"logstash_flag\":false,\"parent_info\":{\"jenkins_master\":\"jenkins.fnc.fujitsu.com\",\"jenkins_job_BUILD_URL\":\"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\",\"jenkins_job_full_name\":\"project/fss3/ci-regression\",\"jenkins_job_name\":\"ci-regression\",\"jenkins_job_build_number\":2999,\"jenkins_job_full_build_name\":\"project/fss3/ci-regression/2999\"},\"parent_pipeline_context_info\":{\"pipeline_type\":\"ci-regression\",\"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\":\"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\"}}\" <NL> json_text: { <NL> \"job_type\": \"explicit\", <NL> \"job_timeout_unit\": \"HOURS\", <NL> \"job_timeout_amount\": 6, <NL> \"logstash_flag\": false, <NL> \"job_propagate_flag\": true, <NL> \"job_template\": \"ci-pipeline-job.xml\", <NL> \"job_quiet_period\": 0, <NL> \"job_docker_container_flag\": true, <NL> \"disable_flag.ci-update-manifest-recipe-repo\": true, <NL> \"previous_job_method\": \"previous-job\", <NL> \"job_docker_container_info\": null, <NL> \"job_stash_flag\": true, <NL> \"parent_info\": { <NL> \"jenkins_job_build_number\": 2999, <NL> \"jenkins_job_full_name\": \"project/fss3/ci-regression\", <NL> \"jenkins_job_name\": \"ci-regression\", <NL> \"jenkins_job_full_build_name\": \"project/fss3/ci-regression/2999\", <NL> \"jenkins_master\": \"jenkins.fnc.fujitsu.com\", <NL> \"jenkins_job_BUILD_URL\": \"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\" <NL> }, <NL> \"job_label\": \"nt-ddcn-4-node-natRedistribute-nat44\", <NL> \"job_command_prefix\": [ <NL> \"ci-get-archive-artifacts\", <NL> \"--project-info-basename\", <NL> \"project-info.json\", <NL> \"--project-info-extended-basename\", <NL> \"project-info-extended.json\", <NL> \"--\", <NL> \"ci-job-info\" <NL> ], <NL> \"disable_flag.ci-release-recipe-repo\": true, <NL> \"disable_flag.ci-review\": true, <NL> \"disable_flag.ci-release-project\": true, <NL> \"job_command_list\": [ <NL> \"ci-project-sanity-tfwk\", <NL> \"--\", <NL> \"--testcases-project-name\", <NL> \"fss3\", <NL> \"--\", <NL> \"--test-engine\", <NL> \"Warrior\", <NL> \"--topology-tag-name\", <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\", <NL> \"--define-attr-defaults\", <NL> \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--add-instance\", <NL> \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\", <NL> \"--device-wait-startup-timeout\", <NL> \"1200\", <NL> \"--test-engine-begin\", <NL> \"--no_logger\", <NL> \"--test-engine-end\", <NL> \"--\", <NL> \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml\" <NL> ], <NL> \"job_kubernetes_info\": null, <NL> \"disable_flag.ci-update-manifest\": true, <NL> \"job_name\": \"nt-ddcn-4-node-natRedistribute-nat44\", <NL> \"job_wait_flag\": true, <NL> \"job_failure_handling\": \"pipeline-failure\", <NL> \"job_unstash_flag\": true, <NL> \"parent_pipeline_context_info\": { <NL> \"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\", <NL> \"pipeline_type\": \"ci-regression\" <NL> }, <NL> \"disable_flag.ci-review-recipe-repo\": true, <NL> \"job_agent\": \"regression-sanity-docker\" <NL> }"}
{"timestamp_utc": "2024-07-31T05:10:33.303Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T05:10:33.304Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pipeline_init: currentBuild.result 'SUCCESS' <NL> ===== ===== ===== ===== ====="}
{"timestamp_utc": "2024-07-31T05:10:33.320Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false"}
{"timestamp_utc": "2024-07-31T05:10:33.328Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:48.336Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Still waiting to schedule task"}
{"timestamp_utc": "2024-07-31T05:10:48.337Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Waiting for next available executor on \u2018regression-sanity-docker\u2019"}
{"timestamp_utc": "2024-07-31T08:06:44.027Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp79 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44 <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:44.038Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:44.353Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.003 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.003"}
{"timestamp_utc": "2024-07-31T08:06:44.362Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:44.370Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:44.642Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.003/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.003/node-info.json"}
{"timestamp_utc": "2024-07-31T08:06:44.649Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage"}
{"timestamp_utc": "2024-07-31T08:06:44.650Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (Init)"}
{"timestamp_utc": "2024-07-31T08:06:44.657Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] timeout <NL> Timeout set to expire in 1 hr 0 min <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:44.665Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:44.666Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:44.941Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44"}
{"timestamp_utc": "2024-07-31T08:06:44.949Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T08:06:44.957Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:06:44.963Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // timeout"}
{"timestamp_utc": "2024-07-31T08:06:44.969Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:06:44.975Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:06:44.982Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] timeout"}
{"timestamp_utc": "2024-07-31T08:06:44.983Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Timeout set to expire in 6 hr 0 min <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:44.990Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:44.991Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:45.277Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "++ hostname <NL> ++ hostname -i <NL> + echo '{ \"hostname\": \"rtxoialp79\", \"hostip\": \"167.254.217.189\" }' <NL> + cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/hostname.json <NL> { \"hostname\": \"rtxoialp79\", \"hostip\": \"167.254.217.189\" }"}
{"timestamp_utc": "2024-07-31T08:06:45.283Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] readFile"}
{"timestamp_utc": "2024-07-31T08:06:45.291Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> host_info_name_dict: { <NL> \"hostname\": \"rtxoialp79\", <NL> \"hostip\": \"167.254.217.189\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:06:45.301Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:45.312Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:45.313Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage"}
{"timestamp_utc": "2024-07-31T08:06:45.314Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (Execute)"}
{"timestamp_utc": "2024-07-31T08:06:45.320Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:45.321Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:45.591Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44"}
{"timestamp_utc": "2024-07-31T08:06:45.596Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T08:06:45.603Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:45.612Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:45.619Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:45.627Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:45.634Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T08:06:45.635Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "running_in_k8s_flag: false"}
{"timestamp_utc": "2024-07-31T08:06:45.641Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:45.674Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:45.751Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] isUnix"}
{"timestamp_utc": "2024-07-31T08:06:45.752Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:45.760Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:46.030Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker pull harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest <NL> Trying to pull repository harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build ... <NL> latest: Pulling from harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build <NL> Digest: sha256:f649c9d54a8d0322e20c4524897fb6d43164df14359f965f27d7fedcf395eb95 <NL> Status: Image is up to date for harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:06:46.290Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:06:46.298Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:06:46.307Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] isUnix"}
{"timestamp_utc": "2024-07-31T08:06:46.314Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:46.585Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker run -d --privileged --user root --cap-add NET_ADMIN --cap-add SYS_ADMIN --device /dev/kvm:/dev/kvm --device /dev/net/tun:/dev/net/tun --device /dev/vhost-net:/dev/vhost-net --publish :22 --workdir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44 --detach --volume /var/run/docker.sock:/var/run/docker.sock --volume /proj/bitbake:/proj/bitbake:shared --volume /proj/artifacts:/proj/artifacts:shared --volume /repo:/repo:ro,shared --volume /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44:shared harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:06:48.485Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:48.764Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ hostname <NL> rtxoialp79 <NL> + pwd <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44 <NL> + id"}
{"timestamp_utc": "2024-07-31T08:06:49.325Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "uid=51016(jenkins) gid=50063(common) groups=50063(common),36(kvm),990(dockerroot),548600513(domain users),548601197(9949 atp's-r),548601199(itgcd01),548601201(ontblan - prjfiles-r),548606239(qdc-c),548612341(106admin),548619018(itgfile3_marketing-r),548619025(itgfile3_procq_r),548619027(itgfile3_qdc-c),548619031(itgfile3_rel-r),548619037(itgfile3_svcq_r),548619041(itgfile3_tpubs-dvt$-r),548619046(itgfile3_tpubs-users),548619089(itgfile4_antivirus-r),548619106(itgfile4_corpq_r),548619129(itgfile4_fns_bp - r),548619134(itgfile4_fns-busmodel-r),548619154(itgfile4_markmfg-r),548619161(itgfile4_naprojects-c),548619164(itgfile4_net ops - r),548619167(itgfile4_networkdev_dev),548619170(itgfile4_networkdoc_prod-r),548619177(itgfile4_oracle-r),548619186(itgfile4_priso9001 - r),548619203(itgfile4_sapsuperusers-r),548619209(itgfile4_siebel docs - r),548619211(itgfile4_siebelitg-s),548619214(itgfile4_software-r),548619216(itgfile4_sw-iso9002-r),548619223(itgfile4_tech_ops-r),548619238(itgfile4_xeroxps-r),548619566(netval3admin),548619568(tsc_users),548650281(rchnetapp2_mobile_newsletters-r),548657500(rchnetapp2_coursera_sdn-002_r),548658825(rchfile2_techserv_r),548664859(fnc.engftp),548671195(g05_qdc_share_c),548671198(rtxnasop01_lr_toolkit-r),548671199(rtxnasop01_lr_output-c),548674493(mxl1400dhc-w10-admins),548677213(rtxnasop01_qdc-c) <NL> + '[' '!' -d continuous-integration ']' <NL> + git clone --branch fss3 --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration.git continuous-integration <NL> Cloning into 'continuous-integration'..."}
{"timestamp_utc": "2024-07-31T08:06:49.582Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ rm -rf continuous-integration/continuous-integration-common <NL> + cd continuous-integration <NL> + git log -1 <NL> + '[' '!' -d continuous-integration-common ']' <NL> + git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git continuous-integration-common <NL> Cloning into 'continuous-integration-common'..."}
{"timestamp_utc": "2024-07-31T08:06:49.837Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd continuous-integration-common <NL> + git log -1 <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf .git <NL> + cd .. <NL> + '[' '!' -d network-topology ']' <NL> + git clone --branch ntp_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/network-topology.git network-topology <NL> Cloning into 'network-topology'..."}
{"timestamp_utc": "2024-07-31T08:06:50.093Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '9dd57f75190f0d255e5fd5a19408ee684d8e30fb'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd network-topology <NL> + git log -1 <NL> + rm -rf .git <NL> + cd .. <NL> + '[' '!' -d repo ']' <NL> + git clone --branch master --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/repo.git repo <NL> Cloning into 'repo'..."}
{"timestamp_utc": "2024-07-31T08:06:50.352Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cd repo <NL> + rm -rf .git <NL> + cd .. <NL> + set +xe <NL> -- show continuous-integration/version.txt <NL> commit 46d558a518beb700cd21573f2815e8a9d270df94 <NL> Author: pmadiraj <pavankumar.madirajukeshavaraju@us.fujitsu.com> <NL> Date:   Thu Sep 19 09:40:06 2019 -0500"}
{"timestamp_utc": "2024-07-31T08:06:50.353Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "add missing recipe repo groovy links <NL> -- show continuous-integration/continuous-integration-common/version.txt <NL> commit 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a <NL> Author: Jenkins <jenkins_noreply@fnc.fujitsu.com> <NL> Date:   Tue Jul 30 04:49:43 2024 -0500 <NL> saving manifest for tag project_cd1474 <NL> -- show network-topology/version.txt <NL> commit 9dd57f75190f0d255e5fd5a19408ee684d8e30fb <NL> Author: Parween, Sagufta <sparween@localhost> <NL> Date:   Thu Jul 25 00:09:36 2024 -0500 <NL> saving manifest for tag ntp_cd118 <NL> -- done <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/jenkins-job-command-list.json <NL> [ <NL> \"ci-get-archive-artifacts\", <NL> \"--project-info-basename\", <NL> \"project-info.json\", <NL> \"--project-info-extended-basename\", <NL> \"project-info-extended.json\", <NL> \"--\", <NL> \"ci-job-info\", <NL> \"ci-project-sanity-tfwk\", <NL> \"--\", <NL> \"--testcases-project-name\", <NL> \"fss3\", <NL> \"--\", <NL> \"--test-engine\", <NL> \"Warrior\", <NL> \"--topology-tag-name\", <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\", <NL> \"--define-attr-defaults\", <NL> \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--add-instance\", <NL> \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\", <NL> \"--device-wait-startup-timeout\", <NL> \"1200\", <NL> \"--test-engine-begin\", <NL> \"--no_logger\", <NL> \"--test-engine-end\", <NL> \"--\", <NL> \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml\" <NL> ] <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/jenkins-job-environment-map.json <NL> { <NL> \"CI_BASE_BRANCH_NAME\": \"fss3\", <NL> \"CI_SUBMODULE_BRANCH_NAME\": \"project_latest\", <NL> \"PROJECT_INFO_BRANCH_NAME\": \"master_cd23138\", <NL> \"NETWORK_TOPOLOGY_BRANCH_NAME\": \"ntp_latest\", <NL> \"CI_BUILD_URL\": \"\", <NL> \"CI_JOB_PARENT_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\", <NL> \"JPARAM_JOB_JSON_STRING\": \"{\\\"job_type\\\":\\\"explicit\\\",\\\"job_timeout_unit\\\":\\\"HOURS\\\",\\\"job_timeout_amount\\\":6,\\\"job_propagate_flag\\\":true,\\\"job_template\\\":\\\"ci-pipeline-job.xml\\\",\\\"disable_flag.ci-release-recipe-repo\\\":true,\\\"disable_flag.ci-review\\\":true,\\\"disable_flag.ci-release-project\\\":true,\\\"job_command_list\\\":[\\\"ci-project-sanity-tfwk\\\",\\\"--\\\",\\\"--testcases-project-name\\\",\\\"fss3\\\",\\\"--\\\",\\\"--test-engine\\\",\\\"Warrior\\\",\\\"--topology-tag-name\\\",\\\"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\\\",\\\"--define-attr-defaults\\\",\\\"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\\\",\\\"--define-instance-attr\\\",\\\"NE1/main\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE1/main\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE1/trib1\\\",\\\"shelf-num=2\\\",\\\"--define-instance-attr\\\",\\\"NE1/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE2/main\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE2/main\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE2/trib1\\\",\\\"shelf-num=2\\\",\\\"--define-instance-attr\\\",\\\"NE2/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE3/main\\\",\\\"shelf-num=200\\\",\\\"--define-instance-attr\\\",\\\"NE3/main\\\",\\\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\\\",\\\"--define-instance-attr\\\",\\\"NE3/trib1\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE3/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE4/main\\\",\\\"shelf-num=200\\\",\\\"--define-instance-attr\\\",\\\"NE4/main\\\",\\\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\\\",\\\"--define-instance-attr\\\",\\\"NE4/trib1\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE4/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--add-instance\\\",\\\"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\\\",\\\"--device-wait-startup-timeout\\\",\\\"1200\\\",\\\"--test-engine-begin\\\",\\\"--no_logger\\\",\\\"--test-engine-end\\\",\\\"--\\\",\\\"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml\\\"],\\\"disable_flag.ci-update-manifest\\\":true,\\\"job_name\\\":\\\"nt-ddcn-4-node-natRedistribute-nat44\\\",\\\"job_quiet_period\\\":0,\\\"job_docker_container_flag\\\":true,\\\"job_wait_flag\\\":true,\\\"job_failure_handling\\\":\\\"pipeline-failure\\\",\\\"job_unstash_flag\\\":true,\\\"disable_flag.ci-update-manifest-recipe-repo\\\":true,\\\"disable_flag.ci-review-recipe-repo\\\":true,\\\"job_agent\\\":\\\"regression-sanity-docker\\\",\\\"previous_job_method\\\":\\\"previous-job\\\",\\\"job_stash_flag\\\":true,\\\"job_label\\\":\\\"nt-ddcn-4-node-natRedistribute-nat44\\\",\\\"job_docker_container_info\\\":null,\\\"job_kubernetes_info\\\":null,\\\"job_command_prefix\\\":[\\\"ci-get-archive-artifacts\\\",\\\"--project-info-basename\\\",\\\"project-info.json\\\",\\\"--project-info-extended-basename\\\",\\\"project-info-extended.json\\\",\\\"--\\\",\\\"ci-job-info\\\"],\\\"logstash_flag\\\":false,\\\"parent_info\\\":{\\\"jenkins_master\\\":\\\"jenkins.fnc.fujitsu.com\\\",\\\"jenkins_job_BUILD_URL\\\":\\\"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\\\",\\\"jenkins_job_full_name\\\":\\\"project/fss3/ci-regression\\\",\\\"jenkins_job_name\\\":\\\"ci-regression\\\",\\\"jenkins_job_build_number\\\":2999,\\\"jenkins_job_full_build_name\\\":\\\"project/fss3/ci-regression/2999\\\"},\\\"parent_pipeline_context_info\\\":{\\\"pipeline_type\\\":\\\"ci-regression\\\",\\\"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\\\":\\\"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\\\"}}\", <NL> \"BUILD_NUMBER\": \"7\", <NL> \"CI_JENKINS_EXECUTOR_HOSTNAME\": \"rtxoialp79\", <NL> \"CI_JENKINS_EXECUTOR_HOSTIP\": \"167.254.217.189\", <NL> \"WORKSPACE\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44\", <NL> \"JOB_NAME\": \"project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44\", <NL> \"LANG\": \"en_US.UTF-8\", <NL> \"PARENT_PIPELINE_CONTEXT_INFO_MAP_JSON_FNAME\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/parent-pipeline-context-info-map.json\" <NL> } <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/parent-pipeline-context-info-map.json <NL> { <NL> \"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\", <NL> \"pipeline_type\": \"ci-regression\" <NL> } <NL> == done <NL> user jenkins <NL> container.id ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c"}
{"timestamp_utc": "2024-07-31T08:06:51.290Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ exec ci-execute-json-command-list --command-json-fname /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/jenkins-job-command-list.json"}
{"timestamp_utc": "2024-07-31T08:06:51.544Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-get-archive-artifacts: creating local_data_dir \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/ci-data\" <NL> ci-get-archive-artifacts: started with parent info from CI_JOB_PARENT_ARTIFACT_INFO_FNAME \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\" <NL> ci-get-archive-artifacts: copying ci-data files from CI_JOB_ARTIFACT_CI_DATA_DIR \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.ci-data\" into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/ci-data\""}
{"timestamp_utc": "2024-07-31T08:06:51.801Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./ <NL> ./manifest.json <NL> ./project-info-status.json <NL> ./gitscm-info.json <NL> ./data.json <NL> ./project-info-extended.json <NL> ./project-info.json <NL> ./project-info-complete.json"}
{"timestamp_utc": "2024-07-31T08:06:55.086Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info-recipe-repo.json <NL> ci-get-archive-artifacts: pwd \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44\" <NL> ci-get-archive-artifacts: calling command:  \"ci-job-info\" \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml\" <NL> ci-job-info: started on Wed Jul 31 03:06:54 CDT 2024 <NL> start_job: Wed Jul 31 03:06:54 CDT 2024"}
{"timestamp_utc": "2024-07-31T08:06:55.342Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_subsequent_job <NL> ci-job-info: start_subsequent_job: ----- ----- ----- ----- -----"}
{"timestamp_utc": "2024-07-31T08:06:56.267Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_job: save existing info file into what will be the parent info file /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/data.parent.json"}
{"timestamp_utc": "2024-07-31T08:06:58.160Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_job: ----- ----- ----- ----- ----- <NL> ci-job-info: calling command: \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml\" <NL> ci-project-sanity-tfwk: starting"}
{"timestamp_utc": "2024-07-31T08:06:58.415Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ '[' 0 -eq 0 ']' <NL> + echo 'ci-project-sanity-tfwk: not setting up workspace' <NL> ci-project-sanity-tfwk: not setting up workspace <NL> + rm -rf /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts <NL> + mkdir -p /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts <NL> + '[' 0 -eq 1 ']' <NL> + cd /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts <NL> + '[' 67 -le 0 ']' <NL> + ci-project-sanity-tfwk.py --testcases-project-name fss3 -- --test-engine Warrior --topology-tag-name DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1 --define-attr-defaults machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute --define-instance-attr NE1/main shelf-num=1 --define-instance-attr NE1/main image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2 --define-instance-attr NE1/trib1 shelf-num=2 --define-instance-attr NE1/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE2/main shelf-num=1 --define-instance-attr NE2/main image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2 --define-instance-attr NE2/trib1 shelf-num=2 --define-instance-attr NE2/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE3/main shelf-num=200 --define-instance-attr NE3/main image-name=fss-aggr-image-validation-T,image-info-config-name=main --define-instance-attr NE3/trib1 shelf-num=1 --define-instance-attr NE3/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE4/main shelf-num=200 --define-instance-attr NE4/main image-name=fss-aggr-image-validation-T,image-info-config-name=main --define-instance-attr NE4/trib1 shelf-num=1 --define-instance-attr NE4/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --add-instance NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1 --device-wait-startup-timeout 1200 --test-engine-begin --no_logger --test-engine-end -- warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml"}
{"timestamp_utc": "2024-07-31T08:06:59.341Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Fetching project \"manifests\" <NL> Cloning into 'manifests'..."}
{"timestamp_utc": "2024-07-31T08:06:59.598Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "remote: Enumerating objects: 22649, done.\u001b[K"}
{"timestamp_utc": "2025-05-23T14:11:15.058Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "remote: Total 22649 (delta 3951), reused 100 (delta 98), pack-reused 17567\u001b[K"}
{"timestamp_utc": "2024-07-31T08:07:01.096Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch fss3 set up to track remote branch fss3 from origin. <NL> Switched to a new branch 'fss3'"}
{"timestamp_utc": "2024-07-31T08:07:01.351Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://bitbucket.fnc.fujitsu.com:7999/iprepo/testcase-manifests <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date."}
{"timestamp_utc": "2024-07-31T08:07:01.607Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# manifest_filename \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/.repo/manifests/default.xml\""}
{"timestamp_utc": "2024-07-31T08:07:01.865Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching project \"test_framework\" <NL> Warning: Permanently added '[rtx-swtl-git.fnc.net.local]:7999' (RSA) to the list of known hosts."}
{"timestamp_utc": "2024-07-31T08:07:09.951Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'tfwk_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c5a96c8... saving manifest for tag tfwk_cd101 <NL> Fetching project \"test_framework/network-topology\" <NL> Note: checking out 'ntp_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 9dd57f7... saving manifest for tag ntp_cd118 <NL> Fetching project \"test_framework/network-topology-data\" <NL> Note: checking out 'ntpd_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c580e72... saving manifest for tag ntpd_cd28 <NL> Fetching project \"test_framework/common_tools\""}
{"timestamp_utc": "2024-07-31T08:07:11.347Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'common-tools_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 6617d9d... saving manifest for tag common-tools_cd30 <NL> Fetching project \"test_framework/warrior-testcases/common\""}
{"timestamp_utc": "2024-07-31T08:07:12.274Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch DEVOPS-415_hw_sanity_tc_py3 set up to track remote branch DEVOPS-415_hw_sanity_tc_py3 from origin. <NL> Switched to a new branch 'DEVOPS-415_hw_sanity_tc_py3' <NL> Fetching project \"test_framework/testcase-config\""}
{"timestamp_utc": "2024-07-31T08:07:12.529Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch fss3 set up to track remote branch fss3 from origin. <NL> Switched to a new branch 'fss3'"}
{"timestamp_utc": "2024-07-31T08:07:12.784Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://rtx-swtl-git.fnc.net.local:7999/iprepo/testcase-config <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date. <NL> Fetching project \"test_framework/warrior-testcases/1finity\""}
{"timestamp_utc": "2024-07-31T08:07:24.958Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-tseries_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 93cf8df... Pull request #1586: L1TC-2668-increasing-rang-for-pm-value <NL> Fetching project \"test_framework/warrior-testcases/trp_base\""}
{"timestamp_utc": "2024-07-31T08:07:26.321Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-trp_base_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 0e5f339... Pull request #19: TRPBASE-1278 changed auto-negotiation disabled <NL> Fetching project \"test_framework/warrior-testcases/dcn\""}
{"timestamp_utc": "2024-07-31T08:07:44.370Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Checking out files:  47% (5966/12577) <NL> Checking out files:  48% (6037/12577) <NL> Checking out files:  49% (6163/12577) <NL> Checking out files:  50% (6289/12577) <NL> Checking out files:  51% (6415/12577) <NL> Checking out files:  52% (6541/12577) <NL> Checking out files:  53% (6666/12577) <NL> Checking out files:  54% (6792/12577) <NL> Checking out files:  55% (6918/12577) <NL> Checking out files:  56% (7044/12577) <NL> Checking out files:  57% (7169/12577) <NL> Checking out files:  58% (7295/12577) <NL> Checking out files:  59% (7421/12577) <NL> Checking out files:  60% (7547/12577) <NL> Checking out files:  61% (7672/12577) <NL> Checking out files:  62% (7798/12577) <NL> Checking out files:  63% (7924/12577) <NL> Checking out files:  64% (8050/12577) <NL> Checking out files:  65% (8176/12577) <NL> Checking out files:  66% (8301/12577) <NL> Checking out files:  67% (8427/12577) <NL> Checking out files:  68% (8553/12577) <NL> Checking out files:  69% (8679/12577) <NL> Checking out files:  70% (8804/12577) <NL> Checking out files:  71% (8930/12577) <NL> Checking out files:  72% (9056/12577) <NL> Checking out files:  73% (9182/12577) <NL> Checking out files:  74% (9307/12577) <NL> Checking out files:  75% (9433/12577) <NL> Checking out files:  76% (9559/12577) <NL> Checking out files:  77% (9685/12577) <NL> Checking out files:  78% (9811/12577) <NL> Checking out files:  79% (9936/12577) <NL> Checking out files:  80% (10062/12577) <NL> Checking out files:  81% (10188/12577) <NL> Checking out files:  82% (10314/12577) <NL> Checking out files:  83% (10439/12577) <NL> Checking out files:  83% (10449/12577) <NL> Checking out files:  84% (10565/12577) <NL> Checking out files:  85% (10691/12577) <NL> Checking out files:  86% (10817/12577) <NL> Checking out files:  87% (10942/12577) <NL> Checking out files:  88% (11068/12577) <NL> Checking out files:  89% (11194/12577) <NL> Checking out files:  90% (11320/12577) <NL> Checking out files:  91% (11446/12577) <NL> Checking out files:  92% (11571/12577) <NL> Checking out files:  93% (11697/12577) <NL> Checking out files:  94% (11823/12577) <NL> Checking out files:  95% (11949/12577) <NL> Checking out files:  96% (12074/12577) <NL> Checking out files:  97% (12200/12577) <NL> Checking out files:  98% (12326/12577) <NL> Checking out files:  99% (12452/12577) <NL> Checking out files: 100% (12577/12577) <NL> Checking out files: 100% (12577/12577), done. <NL> Note: checking out 'proj-fss3-recipe-dcn_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 2dbf363... Pull request #579: DCN-10811 remove the dhcp process chcek <NL> Fetching project \"test_framework/warrior-testcases/snmp\""}
{"timestamp_utc": "2024-07-31T08:07:44.625Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-snmp_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name"}
{"timestamp_utc": "2024-07-31T08:07:44.626Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 1c1d5c5... Pull request #63: FSS2SNMP-914 reduce TAT of SNMP L jobs <NL> Fetching project \"test_framework/warrior-testcases/ops\""}
{"timestamp_utc": "2024-07-31T08:07:51.199Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-ops_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c8e9ba9... Pull request #170: OPS-8964: Updated the client IP after Kubernetes server patching <NL> Fetching project \"test_framework/pycit-testcases/cit/lseries_test_cases\""}
{"timestamp_utc": "2024-07-31T08:07:52.565Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-lseries_test_cases_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at ce78bba... PF-9776 rdm-service check after mcu-p reboot <NL> Fetching project \"test_framework/pycit-testcases/cit/cit_l1cc\""}
{"timestamp_utc": "2024-07-31T08:07:52.822Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-cit_l1cc_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 3801263... Pull request #80: L1TC-2661 restore-profile-attr-testcases-commented <NL> Fetching project \"test_framework/warrior-keywords/ops_1finity\""}
{"timestamp_utc": "2024-07-31T08:07:54.189Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-ops_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at b90c727... Pull request #9: OPS-7896 <NL> Fetching project \"test_framework/warrior-keywords/snmp_1finity\""}
{"timestamp_utc": "2024-07-31T08:07:55.555Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-snmp_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at d00ee1e... Pull request #1: OPS-7722 <NL> Fetching project \"test_framework/robot-testcases/webui_automation-py3\""}
{"timestamp_utc": "2024-07-31T08:08:00.818Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-webui_automation-py3_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at f9b2864... Pull request #9: FSSFWK-8781: Initial commit #1. <NL> Fetching project \"test_framework/warrior-keywords/dcn_1finity\" <NL> Note: checking out 'proj-fss3-recipe-dcn_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 8ea07fa... Pull request #21: DCN-10811 increase the retry and correct the renew sed cmd <NL> Fetching project \"test_framework/warrior-testcases/openconfig-t\""}
{"timestamp_utc": "2024-07-31T08:08:01.380Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-openconfig-t_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c0f0ec8... Pull request #27: OPCG-323 <NL> Fetching project \"test_framework/warrior-keywords/kw_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:03.271Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-kw_1finity_latest_passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at e873a09... FSSVSW-1166 update pip conf file <NL> Fetching project \"test_framework/warrior-keywords/onefinity\""}
{"timestamp_utc": "2024-07-31T08:08:05.160Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-onefinity_latest_passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 93ebd8e... Pull request #60: Made the input text case insensitive for not-allowed <NL> Fetching project \"test_framework/robot_core\""}
{"timestamp_utc": "2024-07-31T08:08:05.723Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'robot-core_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 5b56560... HOTFIX: Fix refactoring mistake (used 'alias' kwarg instead of 'session_name') <NL> Fetching project \"test_framework/robot_tests\""}
{"timestamp_utc": "2024-07-31T08:08:06.286Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-robot_tests_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name"}
{"timestamp_utc": "2024-07-31T08:08:06.287Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 6adf37a... Pull request #143: RF-733 update for 24.2 changes <NL> Fetching project \"test_framework/warrior-testcases/owb_lseries_att\""}
{"timestamp_utc": "2024-07-31T08:08:07.651Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-owb_lseries_att_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 78dd82a... Pull request #199: OWBSW-2496"}
{"timestamp_utc": "2024-07-31T08:08:07.907Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# manifest_filename \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/.repo/manifests/default.xml\" <NL> Fetching project \"test_framework\" <NL> HEAD is now at c5a96c8... saving manifest for tag tfwk_cd101 <NL> Fetching project \"test_framework/network-topology\""}
{"timestamp_utc": "2024-07-31T08:08:08.163Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 9dd57f7... saving manifest for tag ntp_cd118 <NL> Fetching project \"test_framework/network-topology-data\""}
{"timestamp_utc": "2024-07-31T08:08:08.418Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c580e72... saving manifest for tag ntpd_cd28 <NL> Fetching project \"test_framework/common_tools\""}
{"timestamp_utc": "2024-07-31T08:08:08.675Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 6617d9d... saving manifest for tag common-tools_cd30 <NL> Fetching project \"test_framework/warrior-testcases/common\""}
{"timestamp_utc": "2024-07-31T08:08:08.942Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Already on 'DEVOPS-415_hw_sanity_tc_py3' <NL> Fetching project \"test_framework/testcase-config\""}
{"timestamp_utc": "2024-07-31T08:08:09.197Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://rtx-swtl-git.fnc.net.local:7999/iprepo/testcase-config <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date. <NL> Fetching project \"test_framework/warrior-testcases/1finity\""}
{"timestamp_utc": "2024-07-31T08:08:10.125Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 93cf8df... Pull request #1586: L1TC-2668-increasing-rang-for-pm-value <NL> Fetching project \"test_framework/warrior-testcases/trp_base\" <NL> HEAD is now at 0e5f339... Pull request #19: TRPBASE-1278 changed auto-negotiation disabled <NL> Fetching project \"test_framework/warrior-testcases/dcn\""}
{"timestamp_utc": "2024-07-31T08:08:12.012Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 2dbf363... Pull request #579: DCN-10811 remove the dhcp process chcek <NL> Fetching project \"test_framework/warrior-testcases/snmp\""}
{"timestamp_utc": "2024-07-31T08:08:12.268Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 1c1d5c5... Pull request #63: FSS2SNMP-914 reduce TAT of SNMP L jobs <NL> Fetching project \"test_framework/warrior-testcases/ops\""}
{"timestamp_utc": "2024-07-31T08:08:13.225Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c8e9ba9... Pull request #170: OPS-8964: Updated the client IP after Kubernetes server patching <NL> Fetching project \"test_framework/pycit-testcases/cit/lseries_test_cases\""}
{"timestamp_utc": "2024-07-31T08:08:13.481Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at ce78bba... PF-9776 rdm-service check after mcu-p reboot <NL> Fetching project \"test_framework/pycit-testcases/cit/cit_l1cc\""}
{"timestamp_utc": "2024-07-31T08:08:13.737Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 3801263... Pull request #80: L1TC-2661 restore-profile-attr-testcases-commented <NL> Fetching project \"test_framework/warrior-keywords/ops_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:13.993Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at b90c727... Pull request #9: OPS-7896 <NL> Fetching project \"test_framework/warrior-keywords/snmp_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:14.249Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at d00ee1e... Pull request #1: OPS-7722 <NL> Fetching project \"test_framework/robot-testcases/webui_automation-py3\""}
{"timestamp_utc": "2024-07-31T08:08:14.504Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at f9b2864... Pull request #9: FSSFWK-8781: Initial commit #1. <NL> Fetching project \"test_framework/warrior-keywords/dcn_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:14.760Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 8ea07fa... Pull request #21: DCN-10811 increase the retry and correct the renew sed cmd <NL> Fetching project \"test_framework/warrior-testcases/openconfig-t\" <NL> HEAD is now at c0f0ec8... Pull request #27: OPCG-323 <NL> Fetching project \"test_framework/warrior-keywords/kw_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:15.321Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at e873a09... FSSVSW-1166 update pip conf file <NL> Fetching project \"test_framework/warrior-keywords/onefinity\""}
{"timestamp_utc": "2024-07-31T08:08:15.577Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 93ebd8e... Pull request #60: Made the input text case insensitive for not-allowed <NL> Fetching project \"test_framework/robot_core\""}
{"timestamp_utc": "2024-07-31T08:08:15.833Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 5b56560... HOTFIX: Fix refactoring mistake (used 'alias' kwarg instead of 'session_name') <NL> Fetching project \"test_framework/robot_tests\""}
{"timestamp_utc": "2024-07-31T08:08:16.089Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 6adf37a... Pull request #143: RF-733 update for 24.2 changes <NL> Fetching project \"test_framework/warrior-testcases/owb_lseries_att\""}
{"timestamp_utc": "2024-07-31T08:08:16.344Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 78dd82a... Pull request #199: OWBSW-2496"}
{"timestamp_utc": "2024-07-31T08:08:16.345Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# fnc-init-test-env: TEST_FRAMEWORK_ROOT_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework\" <NL> ntpd-setup.sh: NETWORK_TOPOLOGY_DATA_ROOT_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data\""}
{"timestamp_utc": "2024-07-31T08:08:17.708Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:17 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__before_variables') <NL> # 03:08:17 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__variables') <NL> # 03:08:17 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__normal') <NL> # 03:08:17 tfwk-exec-test-agent INFO: args_derived_cl.add_topology_tag_name: arg_item_obj: { <NL> \"def_item_obj\": { <NL> \"const\": false, <NL> \"default\": null, <NL> \"dest\": \"discard_topology_tag_name\", <NL> \"input_type\": \"text\", <NL> \"name\": \"--topology-tag-name\", <NL> \"nargs\": 2, <NL> \"phase\": \"phase__normal\", <NL> \"required\": false, <NL> \"set_attributes_func\": \"<bound method args_derived_cl.add_topology_tag_name of <__main__.args_derived_cl object at 0x7f6799eea8d0>>\", <NL> \"subtype\": null, <NL> \"type\": \"list\" <NL> }, <NL> \"item_list\": [ <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" <NL> ] <NL> } <NL> # 03:08:17 tfwk-exec-test-agent INFO: get_topology_tag_pre_and_post_file_lists: - checking topology_tag_name 'DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1' <NL> # 03:08:17 tfwk-exec-test-agent INFO: get_topology_tag_pre_and_post_file_lists:   topology_tag_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags' <NL> # 03:08:17 tfwk-exec-test-agent INFO: add_from_testcase_group_config_fname: testcase_group_config_fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/conf/local-config.json' <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148'] <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir'] <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json'] <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-setup', '-v', '-v', '--work-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '--pid', '148', '--shared-store-tag', 'tag', '--out-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json'] <NL> # 03:08:17 ntp-topology-setup INFO: args: { <NL> \"container_local_base_dir\": null, <NL> \"out_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"parent_hostip\": null, <NL> \"parent_hostname\": null, <NL> \"pid\": \"148\", <NL> \"script_dir\": null, <NL> \"shared_store_base_dir\": null, <NL> \"shared_store_tag\": \"tag\", <NL> \"shared_store_type\": null, <NL> \"topology_options\": null, <NL> \"topology_type\": null, <NL> \"verbosity\": 2, <NL> \"work_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\", <NL> \"work_dir_tag\": null, <NL> \"work_dir_type\": null <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:18.635Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/docker: stdout b'/bin/docker\\n'"}
{"timestamp_utc": "2024-07-31T08:08:18.890Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:18 ntp-topology-setup INFO: get_have_docker_flag: sudo /bin/docker info --format {{.ID}}: stdout b'3NT7:U5OP:3EXF:HCMW:43ZR:PVZQ:L754:MIXL:ZLQU:ZPQ7:QM27:VKE2\\n'"}
{"timestamp_utc": "2024-07-31T08:08:18.891Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:18 ntp-topology-setup INFO: get_in_docker_container_flag: /proc/1/cgroup: '12:memory:/system.slice/docker-ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c.scope\\n'"}
{"timestamp_utc": "2024-07-31T08:08:19.147Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/podman: stderr b'sudo: /bin/podman: command not found\\n' <NL> # 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/podman: returncode 1 <NL> # 03:08:18 ntp-topology-setup INFO: get_in_kubernetes_flag: KUBERNETES_SERVICE_HOST None <NL> # 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /usr/local/bin/vmmng_interface.py: stderr b'sudo: /usr/local/bin/vmmng_interface.py: command not found\\n' <NL> # 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /usr/local/bin/vmmng_interface.py: returncode 1 <NL> # 03:08:18 ntp-topology-setup INFO: main: have_docker_flag True <NL> # 03:08:18 ntp-topology-setup INFO: main: have_docker_socket_flag True <NL> # 03:08:18 ntp-topology-setup INFO: main: in_docker_container_flag True <NL> # 03:08:18 ntp-topology-setup INFO: main: have_podman_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: have_podman_socket_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: in_podman_container_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: in_kubernetes_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: have_sudo_vmmng_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: defaulting topology_type to 'single' <NL> # 03:08:18 ntp-topology-setup INFO: get_network_topology_tag: shared_store_tag = tag <NL> # 03:08:18 ntp-topology-setup INFO: get_network_topology_tag: network_topology_tag  'tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01' (len 51) <NL> # 03:08:18 ntp-topology-setup INFO: main: shared_store_mount_dir        '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01' <NL> # 03:08:18 ntp-topology-setup INFO: main: shared_store_dir              '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01' <NL> # 03:08:18 ntp-topology-setup INFO: main: container_workspace_basedir   '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace' <NL> # 03:08:18 ntp-topology-setup INFO: main: container_logs_basedir        '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs' <NL> # 03:08:18 ntp-topology-setup INFO: main: container_local_base_dir      None <NL> # 03:08:18 ntp-topology-setup INFO: main: container_fake_local_base_dir None (fake can only be used when using remote store) <NL> # 03:08:18 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01'] <NL> # 03:08:18 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace'] <NL> # 03:08:18 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs']"}
{"timestamp_utc": "2024-07-31T08:08:19.148Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:18 ntp-topology-setup INFO: exec_cmd: ['chmod', 'a+rwx', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs'] <NL> # 03:08:18 ntp-topology-setup INFO: ntp_info_cl.write_json_dict: ntp_info_obj into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json': { <NL> \"_NETWORK_TOPOLOGY_TAG\": \"tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> \"_SHARED_STORE_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> \"_TOPOLOGY_TYPE\": \"container-docker-single\" <NL> } <NL> # 03:08:18 ntp-topology-setup INFO: shared_store_info_cl.write_json_dict: shared_store_info_dict into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json': { <NL> \"REMOTE_STORE_FLAG\": false, <NL> \"SHARED_STORE_MOUNT_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> \"UNIQUE_SHARED_SUBDIR\": \"ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\" <NL> } <NL> # 03:08:18 tfwk-exec-test-agent INFO: main: begin: calling set_attributes() to perform the delayed evaluation <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__delayed') <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE1/device:main' <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json'"}
{"timestamp_utc": "2024-07-31T08:08:19.409Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ci-get-pipeline-image-location-info', '--project-name', '{#project_name#}', '--project-label', '{#project_label#}', '--branch-name', '{#branch_name#}', '--regression-group', '{#regression_group#}', '--machine-name', '{#machine_name#}', '--image-name', '{#image_name#}']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: {  \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\" } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_cl.get_image_location_info_dict: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"2\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\","}
{"timestamp_utc": "2024-07-31T08:08:19.410Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE2/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"2\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip'"}
{"timestamp_utc": "2024-07-31T08:08:19.411Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE3/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"shelf-num\": \"200\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-aggr-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T': product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": {"}
{"timestamp_utc": "2024-07-31T08:08:19.412Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"name\": \"network-element:NE3/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE4/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"shelf-num\": \"200\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-aggr-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T': product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\" <NL> } <NL> }, <NL> \"child_list\": ["}
{"timestamp_utc": "2024-07-31T08:08:19.413Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: end: calling set_attributes() to perform the delayed evaluation <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.non_explicit_instance_context_add: define_instance_attr_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"2\" <NL> } <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"2\" <NL> } <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"200\" <NL> } <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"200\" <NL> } <NL> }, <NL> \"network-element:NE4/device:trib1\": { <NL> \"name\": \"network-element:NE4/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\", <NL> \"network-element:NE4/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-attr\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.non_explicit_instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\" <NL> }, <NL> \"network-element:NE4/device:trib1\": { <NL> \"name\": \"network-element:NE4/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\", <NL> \"network-element:NE4/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: ntp_topology_run: [ <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE1/device:main\", <NL> \"main-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE1/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE1/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE1/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE1/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE1/device:trib1\", <NL> \"trib-L1-OTSG2\","}
{"timestamp_utc": "2024-07-31T08:08:19.414Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE1/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE1/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE1/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE1/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE2/device:main\", <NL> \"main-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE2/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE2/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE2/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE2/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE2/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE2/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE2/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE2/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE2/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE3/device:main\", <NL> \"main\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE3/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE3/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE3/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE3/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE3/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE3/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE3/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE3/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE3/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE4/device:main\", <NL> \"main\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE4/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE4/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE4/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE4/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE4/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE4/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE4/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE4/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE4/device:trib1\" <NL> ] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: - new exec status info: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   topology_active_flag=False <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   topology_state='initializing' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   topology info for work dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148': <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     topology_tag_name: ['DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1'] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     topology_pre_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json'] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     topology_post_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json'] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     }"}
{"timestamp_utc": "2024-07-31T08:08:19.415Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: args_obj.execute_wait_for_devices_flag True <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: local_exec_test_agent_flag True (defaulted from args_obj.execute_wait_for_devices_flag)"}
{"timestamp_utc": "2024-07-31T08:08:19.416Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-run.py', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--services-legacy-env-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json', '--services-env-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--image-info-configuration-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-configuration.json', '--ntp-topology-pre-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--ntp-topology-post-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--parent-hostname', 'rtxoialp79', '--parent-hostip', '167.254.217.189', '--ntp-instance-context-image-info-config-name', 'network-element:NE1/device:main', 'main-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE1/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE1/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE1/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE1/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE1/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE1/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE1/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE1/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}', '--ntp-instance-context-add', 'network-element:NE1/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE2/device:main', 'main-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE2/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE2/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE2/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE2/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE2/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE2/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE2/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE2/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}', '--ntp-instance-context-add', 'network-element:NE2/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE3/device:main', 'main', '--ntp-instance-context-image-location-type', 'network-element:NE3/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE3/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE3/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}', '--ntp-instance-context-add', 'network-element:NE3/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE3/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE3/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE3/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE3/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE3/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE4/device:main', 'main', '--ntp-instance-context-image-location-type', 'network-element:NE4/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE4/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE4/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}', '--ntp-instance-context-add', 'network-element:NE4/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE4/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE4/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE4/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE4/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE4/device:trib1']"}
{"timestamp_utc": "2024-07-31T08:08:19.673Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 ntp-topology-run.py INFO: main: { <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"_instance_context_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE1/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE1/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE2/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE2/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE3/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE3/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE4/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         },"}
{"timestamp_utc": "2024-07-31T08:08:19.674Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE4/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         } <NL> # 03:08:19 ntp-topology-run.py INFO: main:     }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"_instance_context_list\": [ <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:trib1\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:trib1\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:trib1\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:     ], <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"_ntp_topology_obj_list\": [ <NL> # 03:08:19 ntp-topology-run.py INFO: main:         { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"--ntp-topology-pre-fname\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"value\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"--ntp-topology-post-fname\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"value\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         } <NL> # 03:08:19 ntp-topology-run.py INFO: main:     ], <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"abort_before_create_flag\": false, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"create_image_info_from_tag_command\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"get_image_location_info_command\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"image_info_configuration_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-configuration.json\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"ntp_topology_tag_dir\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"parent_hostip\": \"167.254.217.189\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"parent_hostname\": \"rtxoialp79\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_env_bash_fname\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_env_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_global_host_info_flag\": true, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_legacy_env_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_ntp_json_fname\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"show_topology_flag\": true, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_flag\": false, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_image_info_path\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_kernel_path\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_rootfs_path\": null <NL> # 03:08:19 ntp-topology-run.py INFO: main: } <NL> # 03:08:19 ntp-topology-run.py INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/image-info'] <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file: - input_topology_json_fname_list: <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file:   item '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json' <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file: - input_topology_post_json_fname_list: <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file:   item '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json' <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lmp referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:osc2 referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:osc2 from referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lmp referencing network:lmp"}
{"timestamp_utc": "2024-07-31T08:08:19.675Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:osc2 referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:osc2 from referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lmp referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:osc2 referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:osc2 from referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lmp referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:osc2 referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:osc2 from referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: operating_system_cl.get_current_operating_system_tag: PRETTY_NAME 'CentOS Linux 7 (Core)', ID 'centos', MAJOR_VERSION_ID '7' <NL> # 03:08:19 ntp-topology-run.py INFO: create_dynamic_defaults: operating_system_tag 'rhel-7' <NL> # 03:08:19 ntp-topology-run.py INFO: add_dynamic_defaults_for_qemu_defs: qemu_command None <NL> # 03:08:19 ntp-topology-run.py INFO: add_dynamic_defaults_for_docker_defs: docker_image_name None <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE1/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE2/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE3/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE4/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.instance.create_instance_new: \"definitions:instance-configure\" <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.definitions_instance_configure.instance_configure_cl.write_amend_file: saved amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json' <NL> # 03:08:19 ntp-topology-run.py INFO: exec_cmd: ['rm', '-f', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json'] <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE1/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main-L1-OTSG2' <NL> # 03:08:19 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE1/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'main-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:20.239Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE1/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null,"}
{"timestamp_utc": "2024-07-31T08:08:20.240Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE1/device:main\" <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE1/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE1/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main-L1-OTSG2' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"08-qemu-main-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"main-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE1/device.main/data/qemu <NL> network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE1/device.main/data/qemu/cdrom <NL> network-element.NE1/device.main/data/qemu/cdrom/image <NL> network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json"}
{"timestamp_utc": "2024-07-31T08:08:20.496Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\" <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:08:20.497Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE1/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE1/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE1/device:trib1\" <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE1/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json']"}
{"timestamp_utc": "2024-07-31T08:08:20.753Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE1/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE1/device.trib1/data/qemu <NL> network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE1/device.trib1/data/qemu/cdrom <NL> network-element.NE1/device.trib1/data/qemu/cdrom/image <NL> network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\" <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE2/device:main' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main-L1-OTSG2' <NL> # 03:08:20 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE2/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'main-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:21.010Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE2/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE2/device:main\" <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE2/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE2/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main-L1-OTSG2' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"08-qemu-main-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"main-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE2/device.main/data/qemu <NL> network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE2/device.main/data/qemu/cdrom <NL> network-element.NE2/device.main/data/qemu/cdrom/image <NL> network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\" <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:08:21.011Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE2/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:21.266Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\","}
{"timestamp_utc": "2024-07-31T08:08:21.267Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE2/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE2/device:trib1\" <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE2/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE2/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE2/device.trib1/data/qemu <NL> network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE2/device.trib1/data/qemu/cdrom <NL> network-element.NE2/device.trib1/data/qemu/cdrom/image <NL> network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\""}
{"timestamp_utc": "2024-07-31T08:08:21.523Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE3/device:main' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main' <NL> # 03:08:21 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE3/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--image-info-configuration-name', 'main'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"instance_context\": \"network-element:NE3/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\","}
{"timestamp_utc": "2024-07-31T08:08:21.524Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE3/device:main\" <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 18:00   cdrom/image/' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2568482816  07-26-2024 17:57   cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    32881  07-26-2024 17:58   cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE3/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json']"}
{"timestamp_utc": "2024-07-31T08:08:21.779Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> inflating: network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE3/device.main/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 32881 Jul 26 17:58 fss-aggr-image-validation-T-qemux86-64.image-info.json'"}
{"timestamp_utc": "2024-07-31T08:08:21.780Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json': ['main-BDC2-C200', 'main_prot-BDC2-C200', 'main', 'main_prot'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"03-qemu-main-image-config-values.json\" <NL> ], <NL> \"configuration-name\": \"main\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE3/device.main/data/qemu <NL> network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> network-element.NE3/device.main/data/qemu/cdrom <NL> network-element.NE3/device.main/data/qemu/cdrom/image <NL> network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\" <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2' <NL> # 03:08:21 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE3/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:22.036Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE3/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE3/device:trib1\" <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE3/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE3/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .'"}
{"timestamp_utc": "2024-07-31T08:08:22.037Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE3/device.trib1/data/qemu <NL> network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE3/device.trib1/data/qemu/cdrom <NL> network-element.NE3/device.trib1/data/qemu/cdrom/image <NL> network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\" <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE4/device:main' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main' <NL> # 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE4/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--image-info-configuration-name', 'main']"}
{"timestamp_utc": "2024-07-31T08:08:22.293Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"instance_context\": \"network-element:NE4/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": ["}
{"timestamp_utc": "2024-07-31T08:08:22.294Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE4/device:main\" <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 18:00   cdrom/image/' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2568482816  07-26-2024 17:57   cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    32881  07-26-2024 17:58   cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE4/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> inflating: network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE4/device.main/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 32881 Jul 26 17:58 fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json': ['main-BDC2-C200', 'main_prot-BDC2-C200', 'main', 'main_prot'] <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"03-qemu-main-image-config-values.json\" <NL> ], <NL> \"configuration-name\": \"main\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE4/device.main/data/qemu <NL> network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> network-element.NE4/device.main/data/qemu/cdrom <NL> network-element.NE4/device.main/data/qemu/cdrom/image <NL> network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json"}
{"timestamp_utc": "2024-07-31T08:08:22.550Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\" <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2' <NL> # 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--instance-context', 'network-element:NE4/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:22.811Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE4/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE4/device:trib1\" <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE4/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom'"}
{"timestamp_utc": "2024-07-31T08:08:22.812Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE4/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE4/device.trib1/data/qemu <NL> network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE4/device.trib1/data/qemu/cdrom <NL> network-element.NE4/device.trib1/data/qemu/cdrom/image <NL> network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\" <NL> # 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['cat', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json'] <NL> [ <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"1\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"1\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE1\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": {"}
{"timestamp_utc": "2024-07-31T08:08:22.813Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ],"}
{"timestamp_utc": "2024-07-31T08:08:22.814Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"rootfs_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.815Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE1\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\","}
{"timestamp_utc": "2024-07-31T08:08:22.816Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"1\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"1\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE2\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:22.817Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.818Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE2\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\","}
{"timestamp_utc": "2024-07-31T08:08:22.819Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.820Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"{#cpu_model#}\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"cpu_model\\\": \\\"qemu64\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"redundancyMode\\\": \\\"WORK\\\", \\\"serialNum\\\": \\\"12345\\\", \\\"shelfNumber\\\": \\\"200\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"200\\\", \\\"smp\\\": \\\"1\\\", \\\"unitCode\\\": \\\"0xc200\\\", \\\"unitName\\\": \\\"BDC2-C200\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE3\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.821Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\""}
{"timestamp_utc": "2024-07-31T08:08:22.822Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "}, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE3\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\","}
{"timestamp_utc": "2024-07-31T08:08:22.823Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"{#cpu_model#}\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"cpu_model\\\": \\\"qemu64\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"redundancyMode\\\": \\\"WORK\\\", \\\"serialNum\\\": \\\"12345\\\", \\\"shelfNumber\\\": \\\"200\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"200\\\", \\\"smp\\\": \\\"1\\\", \\\"unitCode\\\": \\\"0xc200\\\", \\\"unitName\\\": \\\"BDC2-C200\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE4\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:22.824Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "} <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": {"}
{"timestamp_utc": "2024-07-31T08:08:22.825Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\","}
{"timestamp_utc": "2024-07-31T08:08:22.826Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE4\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:22.827Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "]# 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['ntp-amend-for-qemu', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json', '--out-mode', 'create', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json']"}
{"timestamp_utc": "2024-07-31T08:08:23.082Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-amend-for-qemu INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\","}
{"timestamp_utc": "2024-07-31T08:08:23.083Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json\", <NL> \"out_mode\": \"create\", <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:23 ntp-amend-for-qemu INFO: handle_phase_1: - begin <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE1/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE1/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:trib1/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE2/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE2/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:trib1/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE3/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE3/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:trib1/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE4/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE4/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:trib1/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE1/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE1/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE2/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE2/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE3/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE3/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE4/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE4/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: handle_phase_1: -----"}
{"timestamp_utc": "2024-07-31T08:08:23.084Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-topology-run.py INFO: exec_cmd: ['ntp-amend-for-docker-containers', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json', '--out-mode', 'append', '--topology-tag', 'tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01', '--topology-type', 'container-docker-single', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json']"}
{"timestamp_utc": "2024-07-31T08:08:23.339Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json\", <NL> \"out_mode\": \"append\", <NL> \"topology_tag\": \"tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> \"topology_type\": \"container-docker-single\", <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: topology_definitions_cl.__init__: new_topology_type \"container-docker-single\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: topology_definitions_cl.__init__: new termination-signal 15(SIGTERM)"}
{"timestamp_utc": "2024-07-31T08:08:23.598Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: main: topology_type \"container-docker-single\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE1/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE1/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE2/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE2/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE3/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE3/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE4/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE4/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: create_group_instances: <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_new: \"definitions:topology/device_group:group-device-group-type-qemu-01\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: create_group_instances: get_instance_dict: { <NL> \"instance_info\": { <NL> \"group_type\": \"device-group-type-qemu\", <NL> \"instance_action\": \"create-new\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"topology\", <NL> \"instance_type\": \"definitions\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"group-device-group-type-qemu-01\", <NL> \"instance_type\": \"device_group\" <NL> } <NL> } <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main\" (ref \"network-element:NE1/device:main\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1\" (ref \"network-element:NE1/device:trib1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main\" (ref \"network-element:NE2/device:main\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1\" (ref \"network-element:NE2/device:trib1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main\" (ref \"network-element:NE3/device:main\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1\" (ref \"network-element:NE3/device:trib1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main\" (ref \"network-element:NE4/device:main\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1\" (ref \"network-element:NE4/device:trib1\")"}
{"timestamp_utc": "2024-07-31T08:08:23.599Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: create_default_docker_bridge_networks: <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_new: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-console\" (ref \"network-element:NE1/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-debug-ssh\" (ref \"network-element:NE1/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-cli\" (ref \"network-element:NE1/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-netconf\" (ref \"network-element:NE1/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gnmi\" (ref \"network-element:NE1/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-snmp\" (ref \"network-element:NE1/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-webui\" (ref \"network-element:NE1/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-https\" (ref \"network-element:NE1/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-zmq\" (ref \"network-element:NE1/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb\" (ref \"network-element:NE1/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb-ops-additional\" (ref \"network-element:NE1/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ospl\" (ref \"network-element:NE1/device:main/service:ospl\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ftp\" (ref \"network-element:NE1/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-sftp\" (ref \"network-element:NE1/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-telnet\" (ref \"network-element:NE1/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-console\" (ref \"network-element:NE1/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-debug-ssh\" (ref \"network-element:NE1/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-console\" (ref \"network-element:NE2/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-debug-ssh\" (ref \"network-element:NE2/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-cli\" (ref \"network-element:NE2/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\")"}
{"timestamp_utc": "2024-07-31T08:08:23.600Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-netconf\" (ref \"network-element:NE2/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gnmi\" (ref \"network-element:NE2/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-snmp\" (ref \"network-element:NE2/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-webui\" (ref \"network-element:NE2/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-https\" (ref \"network-element:NE2/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-zmq\" (ref \"network-element:NE2/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb\" (ref \"network-element:NE2/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb-ops-additional\" (ref \"network-element:NE2/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ospl\" (ref \"network-element:NE2/device:main/service:ospl\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ftp\" (ref \"network-element:NE2/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-sftp\" (ref \"network-element:NE2/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-telnet\" (ref \"network-element:NE2/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-console\" (ref \"network-element:NE2/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-debug-ssh\" (ref \"network-element:NE2/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-console\" (ref \"network-element:NE3/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-debug-ssh\" (ref \"network-element:NE3/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-cli\" (ref \"network-element:NE3/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-netconf\" (ref \"network-element:NE3/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gnmi\" (ref \"network-element:NE3/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-snmp\" (ref \"network-element:NE3/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-webui\" (ref \"network-element:NE3/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-https\" (ref \"network-element:NE3/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-zmq\" (ref \"network-element:NE3/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb\" (ref \"network-element:NE3/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb-ops-additional\" (ref \"network-element:NE3/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ospl\" (ref \"network-element:NE3/device:main/service:ospl\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ftp\" (ref \"network-element:NE3/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-sftp\" (ref \"network-element:NE3/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-telnet\" (ref \"network-element:NE3/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\")"}
{"timestamp_utc": "2024-07-31T08:08:23.601Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-console\" (ref \"network-element:NE3/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-debug-ssh\" (ref \"network-element:NE3/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-console\" (ref \"network-element:NE4/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-debug-ssh\" (ref \"network-element:NE4/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-cli\" (ref \"network-element:NE4/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-netconf\" (ref \"network-element:NE4/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gnmi\" (ref \"network-element:NE4/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-snmp\" (ref \"network-element:NE4/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-webui\" (ref \"network-element:NE4/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-https\" (ref \"network-element:NE4/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-zmq\" (ref \"network-element:NE4/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb\" (ref \"network-element:NE4/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb-ops-additional\" (ref \"network-element:NE4/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ospl\" (ref \"network-element:NE4/device:main/service:ospl\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ftp\" (ref \"network-element:NE4/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-sftp\" (ref \"network-element:NE4/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-telnet\" (ref \"network-element:NE4/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-console\" (ref \"network-element:NE4/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-debug-ssh\" (ref \"network-element:NE4/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: begin <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge', network_type 'external' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc1', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lmp', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lcn1', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lcn2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE1/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc1-2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc2-2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE2/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE3/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE4/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   external: resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     this is the container's default docker bridge network, do not create again <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id None"}
{"timestamp_utc": "2024-07-31T08:08:23.602Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1\" (ref \"network:osc1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp\" (ref \"network:lmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1\" (ref \"network:lcn1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2\" (ref \"network:lcn2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan\" (ref \"network-element:NE1/network:ilan\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2\" (ref \"network:osc2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2\" (ref \"network:osc1-2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2\" (ref \"network:osc2-2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan\" (ref \"network-element:NE2/network:ilan\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan\" (ref \"network-element:NE3/network:ilan\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan\" (ref \"network-element:NE4/network:ilan\")"}
{"timestamp_utc": "2024-07-31T08:08:23.603Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show: networks by group <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id None <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show: groups by network <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id None <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lcn2"}
{"timestamp_utc": "2024-07-31T08:08:23.604Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-topology-run.py INFO: exec_cmd: ['ntp-update-instance-sequence-numbers', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json', '--out-mode', 'append', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json']"}
{"timestamp_utc": "2024-07-31T08:08:23.860Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-update-instance-sequence-numbers INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json\", <NL> \"out_mode\": \"append\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:24.120Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: ----- collecting existing counts <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: ----- setting new counts <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:docker-container\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:docker-container\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"definitions:docker-network\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"definitions:docker-network\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"definitions:instance-configure\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"definitions:instance-configure\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"definitions:instance-defaults\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"definitions:instance-defaults\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"definitions:kubernetes-cluster\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"definitions:kubernetes-cluster\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"definitions:qemu-configuration\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"definitions:qemu-configuration\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"definitions:topology\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"definitions:topology\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network:osc1-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network:osc1-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network:osc2-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network:osc2-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.121Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE1/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.122Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 61\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 62\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 63\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 64\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 65\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 66\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 67\": create-new instance_context_absolute_id \"network-element:NE1/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 68\": create-new instance_context_absolute_id \"network-element:NE2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 69\": create-new instance_context_absolute_id \"network-element:NE2/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE2/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 70\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 71\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 72\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 73\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 74\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 75\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 76\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 77\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 78\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 79\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 80\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 81\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 82\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 83\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 84\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.123Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 85\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 86\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 87\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 88\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 89\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 90\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 91\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 92\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 93\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 94\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 95\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 96\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 97\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 98\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 99\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"100\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"101\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"102\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"103\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"104\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"105\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"106\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"107\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"108\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"109\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"110\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"111\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"112\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"113\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"114\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"115\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"116\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.124Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"117\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"118\": create-new instance_context_absolute_id \"network-element:NE2/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE2/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"119\": create-new instance_context_absolute_id \"network-element:NE3\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE3\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"120\": create-new instance_context_absolute_id \"network-element:NE3/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE3/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"121\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"122\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"123\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"124\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"125\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"126\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"127\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"128\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"129\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"130\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"131\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"132\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"133\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"134\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"135\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"136\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"137\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"138\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"139\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"140\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"141\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"142\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"143\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"144\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"145\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.125Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"146\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"147\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"148\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"149\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"150\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"151\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"152\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"153\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"154\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"155\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"156\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"157\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"158\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"159\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"160\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"161\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"162\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"163\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"164\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"165\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"166\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"167\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"168\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"169\": create-new instance_context_absolute_id \"network-element:NE3/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE3/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"170\": create-new instance_context_absolute_id \"network-element:NE4\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE4\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"171\": create-new instance_context_absolute_id \"network-element:NE4/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE4/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"172\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"173\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"174\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"175\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"176\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"177\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"178\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"179\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.126Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"180\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"181\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"182\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"183\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"184\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"185\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"186\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"187\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"188\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"189\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"190\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"191\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"192\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"193\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"194\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"195\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"196\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"197\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"198\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 61\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"199\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"200\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 62\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"201\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"202\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 63\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"203\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"204\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 64\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"205\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"206\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 65\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"207\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"208\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 66\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"209\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"210\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"211\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"212\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"213\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc1\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.127Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"214\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"215\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"216\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"217\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 67\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"218\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 68\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"219\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"220\": create-new instance_context_absolute_id \"network-element:NE4/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE4/network:ilan\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.383Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-json-flist', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--use-relative-path', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json'] <NL> # 03:08:24 ntp-create-json-flist INFO: arg_dict: { <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json\" <NL> ], <NL> \"use_absolute_path_flag\": false, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:24 ntp-create-json-flist DEBUG: json_flist ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/topology-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/docker-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/kubernetes-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/qemu-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/data/instance-defaults-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-01-dynamic-defaults.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-02-config.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-03-user.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/amend-04-setup.json'] <NL> # 03:08:24 ntp-create-json-flist DEBUG: flist_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\" <NL> # 03:08:24 ntp-create-json-flist DEBUG: workspace_root_dir \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace\" <NL> # 03:08:24 ntp-create-json-flist DEBUG: flist_fpath \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\""}
{"timestamp_utc": "2024-07-31T08:08:32.464Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:31 ntp-topology-run.py INFO: exec_cmd: ['ntp-get-image-info-configuration-json', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--image-info-configuration-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-configuration.json'] <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration: container_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:32 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-docker-containers', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--container-parent-hostip', '167.254.217.189', '--container-parent-hostname', 'rtxoialp79']"}
{"timestamp_utc": "2024-07-31T08:08:32.725Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:32 ntp-configure-docker-containers INFO: arg_dict: { <NL> \"container_parent_hostip\": \"167.254.217.189\", <NL> \"container_parent_hostname\": \"rtxoialp79\", <NL> \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:32.992Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:32 ntp-configure-docker-containers INFO: save_amend_changes: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.docker-container/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:32 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE1/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:33.247Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE1/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:33 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:33.503Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE1/device:main\" <NL> # 03:08:33 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:33 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE1/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:33.758Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE1/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:33 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"2\", <NL> \"simulatedShelf\": \"2\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:34.014Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE1/device:trib1\" <NL> # 03:08:33 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:33 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE2/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}'] <NL> # 03:08:33 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE2/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:33 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:34.575Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:34 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE2/device:main\" <NL> # 03:08:34 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:34 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE2/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}'] <NL> # 03:08:34 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE2/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:34 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"2\", <NL> \"simulatedShelf\": \"2\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:34.831Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:34 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE2/device:trib1\" <NL> # 03:08:34 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:34 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE3/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:35.086Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:34 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE3/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:34 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"200\", <NL> \"simulatedShelf\": \"200\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:35.342Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:35 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE3/device:main\" <NL> # 03:08:35 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:35 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE3/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:35.597Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:35 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE3/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:35 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:35.854Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:35 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE3/device:trib1\" <NL> # 03:08:35 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:35 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE4/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:36.110Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:35 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE4/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:35 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"200\", <NL> \"simulatedShelf\": \"200\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:36.365Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:36 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE4/device:main\" <NL> # 03:08:36 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:36 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE4/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}'] <NL> # 03:08:36 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE4/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:36 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:36.926Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:36 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE4/device:trib1\" <NL> # 03:08:36 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:36 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json', '--action', 'prepare']"}
{"timestamp_utc": "2024-07-31T08:08:37.181Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:36 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace' <NL> # 03:08:36 ntp-topology INFO: main: starting action 'prepare'"}
{"timestamp_utc": "2024-07-31T08:08:37.439Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5000 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5000:None for 'network-element:NE1/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5000 for network-element:NE1/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5001 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5001:6022 for 'network-element:NE1/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5001 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5002 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5002:22 for 'network-element:NE1/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5002 for network-element:NE1/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE1/device:main/service:cli"}
{"timestamp_utc": "2024-07-31T08:08:37.440Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5003 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5003:830 for 'network-element:NE1/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5003 for network-element:NE1/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE1/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5004 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5004:6030 for 'network-element:NE1/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5004 for network-element:NE1/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE1/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5005 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5005:161/udp for 'network-element:NE1/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5005 for network-element:NE1/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE1/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5006 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5006:80 for 'network-element:NE1/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5006 for network-element:NE1/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE1/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5007 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5007:443 for 'network-element:NE1/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5007 for network-element:NE1/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE1/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5008 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5008:5555 for 'network-element:NE1/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5008 for network-element:NE1/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE1/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5009 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5009:10000 for 'network-element:NE1/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5009 for network-element:NE1/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE1/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5010 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5010:32767 for 'network-element:NE1/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5010 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5011 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5011:50000 for 'network-element:NE1/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5011 for network-element:NE1/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE1/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5012 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5012:21 for 'network-element:NE1/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5012 for network-element:NE1/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE1/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5013 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5013:2202 for 'network-element:NE1/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5013 for network-element:NE1/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE1/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5014 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5014:23 for 'network-element:NE1/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5014 for network-element:NE1/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE1/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5015 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5015:None for 'network-element:NE1/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5015 for network-element:NE1/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5016 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5016:6022 for 'network-element:NE1/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5016 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json'"}
{"timestamp_utc": "2024-07-31T08:08:37.441Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5017 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5017:None for 'network-element:NE2/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5017 for network-element:NE2/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5018 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5018:6022 for 'network-element:NE2/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5018 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5019 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5019:22 for 'network-element:NE2/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5019 for network-element:NE2/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE2/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5020 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5020:830 for 'network-element:NE2/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5020 for network-element:NE2/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE2/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5021 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5021:6030 for 'network-element:NE2/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5021 for network-element:NE2/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE2/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5022 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5022:161/udp for 'network-element:NE2/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5022 for network-element:NE2/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE2/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5023 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5023:80 for 'network-element:NE2/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5023 for network-element:NE2/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE2/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5024 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5024:443 for 'network-element:NE2/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5024 for network-element:NE2/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE2/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5025 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5025:5555 for 'network-element:NE2/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5025 for network-element:NE2/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE2/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5026 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5026:10000 for 'network-element:NE2/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5026 for network-element:NE2/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE2/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5027 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5027:32767 for 'network-element:NE2/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5027 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5028 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5028:50000 for 'network-element:NE2/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5028 for network-element:NE2/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE2/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5029 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5029:21 for 'network-element:NE2/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5029 for network-element:NE2/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE2/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5030 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5030:2202 for 'network-element:NE2/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5030 for network-element:NE2/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE2/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5031 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5031:23 for 'network-element:NE2/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5031 for network-element:NE2/device:main/service:telnet"}
{"timestamp_utc": "2024-07-31T08:08:37.442Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE2/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5032 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5032:None for 'network-element:NE2/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5032 for network-element:NE2/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5033 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5033:6022 for 'network-element:NE2/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5033 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5034 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5034:None for 'network-element:NE3/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5034 for network-element:NE3/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5035 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5035:6022 for 'network-element:NE3/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5035 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5036 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5036:22 for 'network-element:NE3/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5036 for network-element:NE3/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE3/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5037 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5037:830 for 'network-element:NE3/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5037 for network-element:NE3/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE3/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5038 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5038:6030 for 'network-element:NE3/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5038 for network-element:NE3/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE3/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5039 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5039:161/udp for 'network-element:NE3/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5039 for network-element:NE3/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE3/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5040 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5040:80 for 'network-element:NE3/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5040 for network-element:NE3/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE3/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5041 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5041:443 for 'network-element:NE3/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5041 for network-element:NE3/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE3/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5042 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5042:5555 for 'network-element:NE3/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5042 for network-element:NE3/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE3/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5043 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5043:10000 for 'network-element:NE3/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5043 for network-element:NE3/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE3/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5044 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5044:32767 for 'network-element:NE3/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5044 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5045 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5045:50000 for 'network-element:NE3/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5045 for network-element:NE3/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE3/device:main/service:ospl"}
{"timestamp_utc": "2024-07-31T08:08:37.443Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5046 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5046:21 for 'network-element:NE3/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5046 for network-element:NE3/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE3/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5047 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5047:2202 for 'network-element:NE3/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5047 for network-element:NE3/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE3/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5048 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5048:23 for 'network-element:NE3/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5048 for network-element:NE3/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE3/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5049 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5049:None for 'network-element:NE3/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5049 for network-element:NE3/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5050 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5050:6022 for 'network-element:NE3/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5050 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5051 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5051:None for 'network-element:NE4/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5051 for network-element:NE4/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5052 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5052:6022 for 'network-element:NE4/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5052 for network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5053 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5053:22 for 'network-element:NE4/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5053 for network-element:NE4/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE4/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5054 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5054:830 for 'network-element:NE4/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5054 for network-element:NE4/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE4/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5055 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5055:6030 for 'network-element:NE4/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5055 for network-element:NE4/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE4/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5056 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5056:161/udp for 'network-element:NE4/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5056 for network-element:NE4/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE4/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5057 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5057:80 for 'network-element:NE4/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5057 for network-element:NE4/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE4/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5058 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5058:443 for 'network-element:NE4/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5058 for network-element:NE4/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE4/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5059 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5059:5555 for 'network-element:NE4/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5059 for network-element:NE4/device:main/service:zmq"}
{"timestamp_utc": "2024-07-31T08:08:37.444Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE4/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5060 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5060:10000 for 'network-element:NE4/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5060 for network-element:NE4/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE4/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5061 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5061:32767 for 'network-element:NE4/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5061 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5062 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5062:50000 for 'network-element:NE4/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5062 for network-element:NE4/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE4/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5063 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5063:21 for 'network-element:NE4/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5063 for network-element:NE4/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE4/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5064 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5064:2202 for 'network-element:NE4/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5064 for network-element:NE4/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE4/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5065 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5065:23 for 'network-element:NE4/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5065 for network-element:NE4/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE4/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5066 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5066:None for 'network-element:NE4/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5066 for network-element:NE4/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5067 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5067:6022 for 'network-element:NE4/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5067 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: handle_prepare_networks: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type external <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name eth0 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text a00000 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 9 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0002\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0002\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE1-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 10 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 3 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None"}
{"timestamp_utc": "2024-07-31T08:08:37.445Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0003\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0003\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE2-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 11 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 4 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0004\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0004\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE3-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 12 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 5 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0005\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0005\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE4-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 6 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0006\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0006\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 3 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 7 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0007\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0007\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 4 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 8 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0008\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0008\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 5 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 9 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0009\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0009\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 6 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 10 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000a\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000a\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc1-2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 7 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 11 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc2"}
{"timestamp_utc": "2024-07-31T08:08:37.446Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000b\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000b\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 8 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 12 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000c\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000c\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc2-2/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:38.015Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:main'"}
{"timestamp_utc": "2024-07-31T08:08:38.016Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: prepare_devices: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE1/device:main\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\""}
{"timestamp_utc": "2024-07-31T08:08:38.017Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "}, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5000:None for service \"network-element:NE1/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5001:6022 for service \"network-element:NE1/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5002:22 for service \"network-element:NE1/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5003:830 for service \"network-element:NE1/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5004:6030 for service \"network-element:NE1/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5005:161/udp for service \"network-element:NE1/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5006:80 for service \"network-element:NE1/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5007:443 for service \"network-element:NE1/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5008:5555 for service \"network-element:NE1/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5009:10000 for service \"network-element:NE1/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5010:32767 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5011:50000 for service \"network-element:NE1/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5012:21 for service \"network-element:NE1/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5013:2202 for service \"network-element:NE1/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5014:23 for service \"network-element:NE1/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:01' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5000:None (network-element:NE1/device:main/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5001:6022 (network-element:NE1/device:main/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5002:22 (network-element:NE1/device:main/service:cli)"}
{"timestamp_utc": "2024-07-31T08:08:38.018Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5003:830 (network-element:NE1/device:main/service:netconf) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5004:6030 (network-element:NE1/device:main/service:gnmi) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5005:161 (network-element:NE1/device:main/service:snmp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5006:80 (network-element:NE1/device:main/service:webui) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5007:443 (network-element:NE1/device:main/service:https) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5008:5555 (network-element:NE1/device:main/service:zmq) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5009:10000 (network-element:NE1/device:main/service:gdb) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5010:32767 (network-element:NE1/device:main/service:gdb-ops-additional) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5011:50000 (network-element:NE1/device:main/service:ospl) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5012:21 (network-element:NE1/device:main/service:ftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5013:2202 (network-element:NE1/device:main/service:sftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5014:23 (network-element:NE1/device:main/service:telnet) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5001-:6022,hostfwd=tcp::5002-:22,hostfwd=tcp::5003-:830,hostfwd=tcp::5004-:6030,hostfwd=udp::5005-:161,hostfwd=tcp::5006-:80,hostfwd=tcp::5007-:443,hostfwd=tcp::5008-:5555,hostfwd=tcp::5009-:10000,hostfwd=tcp::5010-:32767,hostfwd=tcp::5011-:50000,hostfwd=tcp::5012-:21,hostfwd=tcp::5013-:2202,hostfwd=tcp::5014-:23\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:06' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0006,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:06\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp'"}
{"timestamp_utc": "2024-07-31T08:08:38.019Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:05' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0005,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:05\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:03' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0003,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:03\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:04' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-0004,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:04\""}
{"timestamp_utc": "2024-07-31T08:08:38.020Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE1/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0002' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:02' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0002,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:02\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:07' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0007,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:07\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5000 for network-element:NE1/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0006\", <NL> \"up\""}
{"timestamp_utc": "2024-07-31T08:08:38.021Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0005\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0003\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0004\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0002\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0007\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\","}
{"timestamp_utc": "2024-07-31T08:08:38.022Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0006\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0005\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0003\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0004\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:ilan\""}
{"timestamp_utc": "2024-07-31T08:08:38.023Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0002\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0007\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5001-:6022,hostfwd=tcp::5002-:22,hostfwd=tcp::5003-:830,hostfwd=tcp::5004-:6030,hostfwd=udp::5005-:161,hostfwd=tcp::5006-:80,hostfwd=tcp::5007-:443,hostfwd=tcp::5008-:5555,hostfwd=tcp::5009-:10000,hostfwd=tcp::5010-:32767,hostfwd=tcp::5011-:50000,hostfwd=tcp::5012-:21,hostfwd=tcp::5013-:2202,hostfwd=tcp::5014-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0006,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:06\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0005,script=no,downscript=no\","}
{"timestamp_utc": "2024-07-31T08:08:38.024Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:05\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0003,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:03\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-0004,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:04\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0002,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:02\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0007,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:07\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5000, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE1/device:trib1\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\""}
{"timestamp_utc": "2024-07-31T08:08:38.025Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "} <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5015:None for service \"network-element:NE1/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5016:6022 for service \"network-element:NE1/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:08' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5015:None (network-element:NE1/device:trib1/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5016:6022 (network-element:NE1/device:trib1/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5016-:6022\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE1/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0002' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:09' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0009,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:09\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-000a,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:0a\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-000b,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:0b\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:38.026Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5015 for network-element:NE1/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0009\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0009\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\","}
{"timestamp_utc": "2024-07-31T08:08:38.027Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5016-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0009,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:09\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-000a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:0a\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-000b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:0b\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5015, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE2/device:main\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\","}
{"timestamp_utc": "2024-07-31T08:08:38.028Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5017:None for service \"network-element:NE2/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5018:6022 for service \"network-element:NE2/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5019:22 for service \"network-element:NE2/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5020:830 for service \"network-element:NE2/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5021:6030 for service \"network-element:NE2/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5022:161/udp for service \"network-element:NE2/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5023:80 for service \"network-element:NE2/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5024:443 for service \"network-element:NE2/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5025:5555 for service \"network-element:NE2/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5026:10000 for service \"network-element:NE2/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5027:32767 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5028:50000 for service \"network-element:NE2/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5029:21 for service \"network-element:NE2/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5030:2202 for service \"network-element:NE2/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5031:23 for service \"network-element:NE2/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5017:None (network-element:NE2/device:main/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5018:6022 (network-element:NE2/device:main/service:debug-ssh)"}
{"timestamp_utc": "2024-07-31T08:08:38.029Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5019:22 (network-element:NE2/device:main/service:cli) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5020:830 (network-element:NE2/device:main/service:netconf) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5021:6030 (network-element:NE2/device:main/service:gnmi) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5022:161 (network-element:NE2/device:main/service:snmp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5023:80 (network-element:NE2/device:main/service:webui) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5024:443 (network-element:NE2/device:main/service:https) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5025:5555 (network-element:NE2/device:main/service:zmq) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5026:10000 (network-element:NE2/device:main/service:gdb) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5027:32767 (network-element:NE2/device:main/service:gdb-ops-additional) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5028:50000 (network-element:NE2/device:main/service:ospl) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5029:21 (network-element:NE2/device:main/service:ftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5030:2202 (network-element:NE2/device:main/service:sftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5031:23 (network-element:NE2/device:main/service:telnet) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5018-:6022,hostfwd=tcp::5019-:22,hostfwd=tcp::5020-:830,hostfwd=tcp::5021-:6030,hostfwd=udp::5022-:161,hostfwd=tcp::5023-:80,hostfwd=tcp::5024-:443,hostfwd=tcp::5025-:5555,hostfwd=tcp::5026-:10000,hostfwd=tcp::5027-:32767,hostfwd=tcp::5028-:50000,hostfwd=tcp::5029-:21,hostfwd=tcp::5030-:2202,hostfwd=tcp::5031-:23\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:11' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0011,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:11\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:10' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0010,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:10\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0e' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-000e,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:0e\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2'"}
{"timestamp_utc": "2024-07-31T08:08:38.030Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0f' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-000f,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:0f\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE2/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0003' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0d' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-000d,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:0d\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:12' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0012,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:12\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5017 for network-element:NE2/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0011\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\","}
{"timestamp_utc": "2024-07-31T08:08:38.031Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"set\", <NL> \"tap-0010\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000e\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000f\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000d\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0012\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0011\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0010\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\""}
{"timestamp_utc": "2024-07-31T08:08:38.032Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000e\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000f\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000d\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0012\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5018-:6022,hostfwd=tcp::5019-:22,hostfwd=tcp::5020-:830,hostfwd=tcp::5021-:6030,hostfwd=udp::5022-:161,hostfwd=tcp::5023-:80,hostfwd=tcp::5024-:443,hostfwd=tcp::5025-:5555,hostfwd=tcp::5026-:10000,hostfwd=tcp::5027-:32767,hostfwd=tcp::5028-:50000,hostfwd=tcp::5029-:21,hostfwd=tcp::5030-:2202,hostfwd=tcp::5031-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0011,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:11\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0010,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:10\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-000e,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:0e\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-000f,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:0f\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-000d,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:0d\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0012,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:12\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null,"}
{"timestamp_utc": "2024-07-31T08:08:38.033Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5017, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE2/device:trib1\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5032:None for service \"network-element:NE2/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5033:6022 for service \"network-element:NE2/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\""}
{"timestamp_utc": "2024-07-31T08:08:38.034Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:13' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5032:None (network-element:NE2/device:trib1/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5033:6022 (network-element:NE2/device:trib1/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5033-:6022\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE2/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0003' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:14' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0014,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:14\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:15' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0015,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:15\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:16' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0016,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:16\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value {"}
{"timestamp_utc": "2024-07-31T08:08:38.035Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5032 for network-element:NE2/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0014\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0015\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0016\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0014\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0015\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\","}
{"timestamp_utc": "2024-07-31T08:08:38.036Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"tap-0016\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5033-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0014,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:14\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0015,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:15\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0016,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:16\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5032, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE3/device:main\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\","}
{"timestamp_utc": "2024-07-31T08:08:38.037Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5034:None for service \"network-element:NE3/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5035:6022 for service \"network-element:NE3/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5036:22 for service \"network-element:NE3/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5037:830 for service \"network-element:NE3/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5038:6030 for service \"network-element:NE3/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5039:161/udp for service \"network-element:NE3/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5040:80 for service \"network-element:NE3/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5041:443 for service \"network-element:NE3/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5042:5555 for service \"network-element:NE3/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5043:10000 for service \"network-element:NE3/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5044:32767 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5045:50000 for service \"network-element:NE3/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5046:21 for service \"network-element:NE3/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5047:2202 for service \"network-element:NE3/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5048:23 for service \"network-element:NE3/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:17' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5034:None (network-element:NE3/device:main/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5035:6022 (network-element:NE3/device:main/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5036:22 (network-element:NE3/device:main/service:cli) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5037:830 (network-element:NE3/device:main/service:netconf) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5038:6030 (network-element:NE3/device:main/service:gnmi) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5039:161 (network-element:NE3/device:main/service:snmp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5040:80 (network-element:NE3/device:main/service:webui) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5041:443 (network-element:NE3/device:main/service:https) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5042:5555 (network-element:NE3/device:main/service:zmq) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5043:10000 (network-element:NE3/device:main/service:gdb) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5044:32767 (network-element:NE3/device:main/service:gdb-ops-additional) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5045:50000 (network-element:NE3/device:main/service:ospl) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5046:21 (network-element:NE3/device:main/service:ftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5047:2202 (network-element:NE3/device:main/service:sftp)"}
{"timestamp_utc": "2024-07-31T08:08:38.038Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5048:23 (network-element:NE3/device:main/service:telnet) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5035-:6022,hostfwd=tcp::5036-:22,hostfwd=tcp::5037-:830,hostfwd=tcp::5038-:6030,hostfwd=udp::5039-:161,hostfwd=tcp::5040-:80,hostfwd=tcp::5041-:443,hostfwd=tcp::5042-:5555,hostfwd=tcp::5043-:10000,hostfwd=tcp::5044-:32767,hostfwd=tcp::5045-:50000,hostfwd=tcp::5046-:21,hostfwd=tcp::5047-:2202,hostfwd=tcp::5048-:23\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-001c,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:1c\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-001b,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:1b\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:19' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0019,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:19\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-001a,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:1a\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE3/network:ilan'"}
{"timestamp_utc": "2024-07-31T08:08:38.039Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0004' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:18' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0018,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:18\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1d' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-001d,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:1d\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5034 for network-element:NE3/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001c\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\","}
{"timestamp_utc": "2024-07-31T08:08:38.040Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0019\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0018\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001d\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001c\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0019\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> ["}
{"timestamp_utc": "2024-07-31T08:08:38.041Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0018\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001d\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5035-:6022,hostfwd=tcp::5036-:22,hostfwd=tcp::5037-:830,hostfwd=tcp::5038-:6030,hostfwd=udp::5039-:161,hostfwd=tcp::5040-:80,hostfwd=tcp::5041-:443,hostfwd=tcp::5042-:5555,hostfwd=tcp::5043-:10000,hostfwd=tcp::5044-:32767,hostfwd=tcp::5045-:50000,hostfwd=tcp::5046-:21,hostfwd=tcp::5047-:2202,hostfwd=tcp::5048-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-001c,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:1c\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-001b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:1b\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0019,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:19\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-001a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:1a\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0018,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:18\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-001d,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:1d\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5034, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE3/device:trib1\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\","}
{"timestamp_utc": "2024-07-31T08:08:38.042Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5049:None for service \"network-element:NE3/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5050:6022 for service \"network-element:NE3/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1e' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5049:None (network-element:NE3/device:trib1/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5050:6022 (network-element:NE3/device:trib1/service:debug-ssh)"}
{"timestamp_utc": "2024-07-31T08:08:38.043Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5050-:6022\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE3/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0004' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1f' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-001f,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:1f\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:20' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0020,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:20\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:21' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0021,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:21\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5049 for network-element:NE3/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001f\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\","}
{"timestamp_utc": "2024-07-31T08:08:38.044Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0020\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0021\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001f\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0020\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0021\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\","}
{"timestamp_utc": "2024-07-31T08:08:38.045Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5050-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-001f,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:1f\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0020,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:20\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0021,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:21\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5049, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE4/device:main\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ],"}
{"timestamp_utc": "2024-07-31T08:08:38.046Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"rootfs_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5051:None for service \"network-element:NE4/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5052:6022 for service \"network-element:NE4/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5053:22 for service \"network-element:NE4/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5054:830 for service \"network-element:NE4/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5055:6030 for service \"network-element:NE4/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5056:161/udp for service \"network-element:NE4/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5057:80 for service \"network-element:NE4/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5058:443 for service \"network-element:NE4/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5059:5555 for service \"network-element:NE4/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5060:10000 for service \"network-element:NE4/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5061:32767 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5062:50000 for service \"network-element:NE4/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5063:21 for service \"network-element:NE4/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5064:2202 for service \"network-element:NE4/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5065:23 for service \"network-element:NE4/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:22' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5051:None (network-element:NE4/device:main/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5052:6022 (network-element:NE4/device:main/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5053:22 (network-element:NE4/device:main/service:cli) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5054:830 (network-element:NE4/device:main/service:netconf) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5055:6030 (network-element:NE4/device:main/service:gnmi) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5056:161 (network-element:NE4/device:main/service:snmp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5057:80 (network-element:NE4/device:main/service:webui) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5058:443 (network-element:NE4/device:main/service:https) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5059:5555 (network-element:NE4/device:main/service:zmq) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5060:10000 (network-element:NE4/device:main/service:gdb) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5061:32767 (network-element:NE4/device:main/service:gdb-ops-additional) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5062:50000 (network-element:NE4/device:main/service:ospl) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5063:21 (network-element:NE4/device:main/service:ftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5064:2202 (network-element:NE4/device:main/service:sftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5065:23 (network-element:NE4/device:main/service:telnet) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5052-:6022,hostfwd=tcp::5053-:22,hostfwd=tcp::5054-:830,hostfwd=tcp::5055-:6030,hostfwd=udp::5056-:161,hostfwd=tcp::5057-:80,hostfwd=tcp::5058-:443,hostfwd=tcp::5059-:5555,hostfwd=tcp::5060-:10000,hostfwd=tcp::5061-:32767,hostfwd=tcp::5062-:50000,hostfwd=tcp::5063-:21,hostfwd=tcp::5064-:2202,hostfwd=tcp::5065-:23\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1'"}
{"timestamp_utc": "2024-07-31T08:08:38.047Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:27' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0027,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:27\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:26' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0026,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:26\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:24' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0024,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:24\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:25' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-0025,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:25\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE4/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0005' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:23' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0023,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:23\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None"}
{"timestamp_utc": "2024-07-31T08:08:38.048Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:28' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0028,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:28\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   found ports None:5051 for network-element:NE4/device:main/service:console <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\""}
{"timestamp_utc": "2024-07-31T08:08:38.305Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0027\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0026\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0024\", <NL> \"up\" <NL> ], <NL> ["}
{"timestamp_utc": "2024-07-31T08:08:38.306Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0025\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0023\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0028\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0027\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0026\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0024\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\","}
{"timestamp_utc": "2024-07-31T08:08:38.307Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"tap-0025\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0023\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0028\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5052-:6022,hostfwd=tcp::5053-:22,hostfwd=tcp::5054-:830,hostfwd=tcp::5055-:6030,hostfwd=udp::5056-:161,hostfwd=tcp::5057-:80,hostfwd=tcp::5058-:443,hostfwd=tcp::5059-:5555,hostfwd=tcp::5060-:10000,hostfwd=tcp::5061-:32767,hostfwd=tcp::5062-:50000,hostfwd=tcp::5063-:21,hostfwd=tcp::5064-:2202,hostfwd=tcp::5065-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0027,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:27\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0026,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:26\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0024,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:24\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-0025,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:25\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0023,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:23\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0028,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:28\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5051, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE4/device:trib1\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:38.308Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "{ <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5066:None for service \"network-element:NE4/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5067:6022 for service \"network-element:NE4/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:29' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5066:None (network-element:NE4/device:trib1/service:console) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5067:6022 (network-element:NE4/device:trib1/service:debug-ssh) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5067-:6022\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0005' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2a' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-002a,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:2a\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2b' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-002b,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:2b\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:38.309Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2c' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-002c,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:2c\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   found ports None:5066 for network-element:NE4/device:trib1/service:console <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002c\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002c\", <NL> \"down\""}
{"timestamp_utc": "2024-07-31T08:08:38.310Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5067-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-002a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:2a\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-002b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:2b\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-002c,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:2c\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5066, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_devices:   saved device_group amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: main: completed action 'prepare' <NL> # 03:08:38 ntp-topology INFO: done <NL> # 03:08:38 ntp-topology-run.py INFO: exec_cmd: ['ntp-show-current-topology', '-v', '-v', '--sort-instances', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json']"}
{"timestamp_utc": "2024-07-31T08:08:38.873Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 0) None      : <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:docker-container <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:docker-network <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:instance-configure <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:instance-defaults <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:kubernetes-cluster <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:qemu-configuration <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:topology <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc1-2"}
{"timestamp_utc": "2024-07-31T08:08:38.874Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-sftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-webui <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-sftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-webui <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-sftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-webui"}
{"timestamp_utc": "2024-07-31T08:08:38.875Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-sftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-webui <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge"}
{"timestamp_utc": "2024-07-31T08:08:38.876Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:telnet/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port"}
{"timestamp_utc": "2024-07-31T08:08:38.877Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:telnet/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE3 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lmp"}
{"timestamp_utc": "2024-07-31T08:08:38.878Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:telnet/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE4"}
{"timestamp_utc": "2024-07-31T08:08:38.879Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:telnet/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/service:debug-ssh/network:bridge"}
{"timestamp_utc": "2024-07-31T08:08:38.880Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ----- ----- ----- ----- ----- <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan : 'network-element:NE1/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan : 'network-element:NE2/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan : 'network-element:NE3/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan : 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1     : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2     : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp      : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1     : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2     : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:ilan/network:ilan                      : 'network-element:NE1/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE1/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:ilan/network:ilan                      : 'network-element:NE2/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE2/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:ilan/network:ilan                      : 'network-element:NE3/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE3/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2'"}
{"timestamp_utc": "2024-07-31T08:08:38.881Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:ilan/network:ilan                      : 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json', '--action', 'create']"}
{"timestamp_utc": "2024-07-31T08:08:39.136Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace' <NL> # 03:08:38 ntp-topology INFO: main: starting action 'create'"}
{"timestamp_utc": "2024-07-31T08:08:40.061Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-topology INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01'] <NL> # 03:08:39 ntp-topology INFO: exec_cmd: ['chmod', 'a+rwx', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01'] <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: parent_hostname rtxoialp79 <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: parent_hostip 167.254.217.189 <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_context_names topology-group-device-group-type-qemu-01 <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01"}
{"timestamp_utc": "2024-07-31T08:08:40.062Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_type device-group-type-qemu <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge', network_type 'external', default_docker_bridge_network_flag True <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   container_network_name_list [] <NL> # 03:08:39 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'pull', 'harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest'] <NL> # 03:08:39 ntp-topology INFO: docker_command: stdout: Trying to pull repository harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build ... <NL> # 03:08:40 ntp-topology INFO: docker_command: stdout: latest: Pulling from harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build <NL> # 03:08:40 ntp-topology INFO: docker_command: stdout: Digest: sha256:f649c9d54a8d0322e20c4524897fb6d43164df14359f965f27d7fedcf395eb95 <NL> # 03:08:40 ntp-topology INFO: docker_command: stdout: Status: Image is up to date for harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:08:40.318Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5000 for service \"network-element:NE1/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5001 for service \"network-element:NE1/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5002 for service \"network-element:NE1/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5003 for service \"network-element:NE1/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5004 for service \"network-element:NE1/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5005/udp for service \"network-element:NE1/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5006 for service \"network-element:NE1/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5007 for service \"network-element:NE1/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5008 for service \"network-element:NE1/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5009 for service \"network-element:NE1/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5010 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5011 for service \"network-element:NE1/device:main/service:ospl\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5012 for service \"network-element:NE1/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5013 for service \"network-element:NE1/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5014 for service \"network-element:NE1/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5015 for service \"network-element:NE1/device:trib1/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5016 for service \"network-element:NE1/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5017 for service \"network-element:NE2/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5018 for service \"network-element:NE2/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5019 for service \"network-element:NE2/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5020 for service \"network-element:NE2/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5021 for service \"network-element:NE2/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5022/udp for service \"network-element:NE2/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5023 for service \"network-element:NE2/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5024 for service \"network-element:NE2/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5025 for service \"network-element:NE2/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5026 for service \"network-element:NE2/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5027 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5028 for service \"network-element:NE2/device:main/service:ospl\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5029 for service \"network-element:NE2/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5030 for service \"network-element:NE2/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5031 for service \"network-element:NE2/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5032 for service \"network-element:NE2/device:trib1/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5033 for service \"network-element:NE2/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5034 for service \"network-element:NE3/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5035 for service \"network-element:NE3/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5036 for service \"network-element:NE3/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5037 for service \"network-element:NE3/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5038 for service \"network-element:NE3/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5039/udp for service \"network-element:NE3/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5040 for service \"network-element:NE3/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5041 for service \"network-element:NE3/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5042 for service \"network-element:NE3/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5043 for service \"network-element:NE3/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5044 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5045 for service \"network-element:NE3/device:main/service:ospl\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5046 for service \"network-element:NE3/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5047 for service \"network-element:NE3/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5048 for service \"network-element:NE3/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5049 for service \"network-element:NE3/device:trib1/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5050 for service \"network-element:NE3/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5051 for service \"network-element:NE4/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5052 for service \"network-element:NE4/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5053 for service \"network-element:NE4/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5054 for service \"network-element:NE4/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5055 for service \"network-element:NE4/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5056/udp for service \"network-element:NE4/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5057 for service \"network-element:NE4/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5058 for service \"network-element:NE4/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5059 for service \"network-element:NE4/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5060 for service \"network-element:NE4/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5061 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5062 for service \"network-element:NE4/device:main/service:ospl\""}
{"timestamp_utc": "2024-07-31T08:08:40.319Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5063 for service \"network-element:NE4/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5064 for service \"network-element:NE4/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5065 for service \"network-element:NE4/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5066 for service \"network-element:NE4/device:trib1/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5067 for service \"network-element:NE4/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'create', '--privileged', '--user', 'root', '--device', '/dev/kvm:/dev/kvm', '--device', '/dev/net/tun:/dev/net/tun', '--device', '/dev/vhost-net:/dev/vhost-net', '--volume', '/proj/artifacts:/proj/artifacts:ro,shared', '--volume', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01', '--volume', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology:ro', '--publish', ':5000', '--publish', ':5001', '--publish', ':5002', '--publish', ':5003', '--publish', ':5004', '--publish', ':5005/udp', '--publish', ':5006', '--publish', ':5007', '--publish', ':5008', '--publish', ':5009', '--publish', ':5010', '--publish', ':5011', '--publish', ':5012', '--publish', ':5013', '--publish', ':5014', '--publish', ':5015', '--publish', ':5016', '--publish', ':5017', '--publish', ':5018', '--publish', ':5019', '--publish', ':5020', '--publish', ':5021', '--publish', ':5022/udp', '--publish', ':5023', '--publish', ':5024', '--publish', ':5025', '--publish', ':5026', '--publish', ':5027', '--publish', ':5028', '--publish', ':5029', '--publish', ':5030', '--publish', ':5031', '--publish', ':5032', '--publish', ':5033', '--publish', ':5034', '--publish', ':5035', '--publish', ':5036', '--publish', ':5037', '--publish', ':5038', '--publish', ':5039/udp', '--publish', ':5040', '--publish', ':5041', '--publish', ':5042', '--publish', ':5043', '--publish', ':5044', '--publish', ':5045', '--publish', ':5046', '--publish', ':5047', '--publish', ':5048', '--publish', ':5049', '--publish', ':5050', '--publish', ':5051', '--publish', ':5052', '--publish', ':5053', '--publish', ':5054', '--publish', ':5055', '--publish', ':5056/udp', '--publish', ':5057', '--publish', ':5058', '--publish', ':5059', '--publish', ':5060', '--publish', ':5061', '--publish', ':5062', '--publish', ':5063', '--publish', ':5064', '--publish', ':5065', '--publish', ':5066', '--publish', ':5067', 'harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest']"}
{"timestamp_utc": "2024-07-31T08:08:42.205Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: docker_command: stdout: 13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52 <NL> # 03:08:42 ntp-topology INFO: create_single_docker_container: create: \"13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52\" <NL> # 03:08:42 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'start', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52']"}
{"timestamp_utc": "2024-07-31T08:08:52.178Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_command: stdout: 13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: running ['sudo', '/bin/docker', 'inspect', '--type', 'container', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52'] <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout: [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Id\": \"13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Created\": \"2024-07-31T08:08:40.280090497Z\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Path\": \"/usr/bin/tini\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Args\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"--\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"/usr/sbin/sshd\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"-D\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"State\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Status\": \"running\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Running\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Paused\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Restarting\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OOMKilled\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Dead\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Pid\": 24976, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ExitCode\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Error\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"StartedAt\": \"2024-07-31T08:08:51.026339963Z\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"FinishedAt\": \"0001-01-01T00:00:00Z\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Image\": \"sha256:e6ab72684bf033e695847013b10678ea3fd26f1eb52d6ad59f865602619223ab\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"ResolvConfPath\": \"/var/lib/docker/containers/13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52/resolv.conf\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"HostnamePath\": \"/var/lib/docker/containers/13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52/hostname\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"HostsPath\": \"/var/lib/docker/containers/13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52/hosts\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"LogPath\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Name\": \"/quirky_brattain\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"RestartCount\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Driver\": \"devicemapper\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"MountLabel\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"ProcessLabel\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"AppArmorProfile\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"ExecIDs\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"HostConfig\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Binds\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/proj/artifacts:/proj/artifacts:ro,shared\","}
{"timestamp_utc": "2024-07-31T08:08:52.179Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology:ro\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ContainerIDFile\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"LogConfig\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"journald\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Config\": {} <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"NetworkMode\": \"default\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PortBindings\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\""}
{"timestamp_utc": "2024-07-31T08:08:52.180Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": ["}
{"timestamp_utc": "2024-07-31T08:08:52.181Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\","}
{"timestamp_utc": "2024-07-31T08:08:52.182Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ] <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"RestartPolicy\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Name\": \"no\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"MaximumRetryCount\": 0 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AutoRemove\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"VolumeDriver\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"VolumesFrom\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CapAdd\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CapDrop\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Dns\": [], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"DnsOptions\": [], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"DnsSearch\": [], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ExtraHosts\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"GroupAdd\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IpcMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Cgroup\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Links\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OomScoreAdj\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PidMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Privileged\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PublishAllPorts\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ReadonlyRootfs\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SecurityOpt\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"label=disable\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"UTSMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"UsernsMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ShmSize\": 67108864, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Runtime\": \"docker-runc\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ConsoleSize\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 0 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Isolation\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuShares\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Memory\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"NanoCpus\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CgroupParent\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioWeight\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioWeightDevice\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceReadBps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceWriteBps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceReadIOps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceWriteIOps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuPeriod\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuQuota\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuRealtimePeriod\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuRealtimeRuntime\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpusetCpus\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpusetMems\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Devices\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/kvm\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/kvm\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/net/tun\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/net/tun\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/vhost-net\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/vhost-net\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"DiskQuota\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"KernelMemory\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MemoryReservation\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MemorySwap\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MemorySwappiness\": -1, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OomKillDisable\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PidsLimit\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Ulimits\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuCount\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuPercent\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IOMaximumIOps\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IOMaximumBandwidth\": 0 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"GraphDriver\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Name\": \"devicemapper\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Data\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"DeviceId\": \"35462\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"DeviceName\": \"docker-253:0-2235604-4ad1e270717c218f32e1401d5597ee30e9affc77ca52305c38de9af17b36ce12\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"DeviceSize\": \"10737418240\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Mounts\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"rprivate\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"ro\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"rprivate\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/proj/artifacts\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/proj/artifacts\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"ro,shared\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"shared\""}
{"timestamp_utc": "2024-07-31T08:08:52.183Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Config\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Hostname\": \"13e8e1ceb73f\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Domainname\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"User\": \"root\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStdin\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStdout\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStderr\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ExposedPorts\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"22/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": {} <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Tty\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OpenStdin\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"StdinOnce\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Env\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"HOME=/home/jenkins\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"LC_ALL=en_US.UTF-8\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"LANG=en_US.UTF-8\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Cmd\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/usr/sbin/sshd\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"-D\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Image\": \"harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Volumes\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"WorkingDir\": \"/home/jenkins\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Entrypoint\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/usr/bin/tini\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"--\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OnBuild\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Labels\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"io.buildah.version\": \"1.31.3\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.build-date\": \"20201113\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.license\": \"GPLv2\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.name\": \"CentOS Base Image\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.schema-version\": \"1.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.vendor\": \"CentOS\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.created\": \"2020-11-13 00:00:00+00:00\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.licenses\": \"GPL-2.0-only\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.title\": \"CentOS Base Image\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.vendor\": \"CentOS\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"NetworkSettings\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Bridge\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SandboxID\": \"d0d375d334269501c648e7a9019ab87ef0dbc1805800b739b00eab7257009c6a\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"HairpinMode\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"LinkLocalIPv6Address\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"LinkLocalIPv6PrefixLen\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Ports\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"22/tcp\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37315\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\","}
{"timestamp_utc": "2024-07-31T08:08:52.184Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37313\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37311\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37309\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37307\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32842\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37304\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37302\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37300\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37298\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37296\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37294\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37292\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37290\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37288\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37286\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37285\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37283\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37281\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37279\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37277\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37275\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32840\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37272\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\","}
{"timestamp_utc": "2024-07-31T08:08:52.185Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37270\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37268\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37264\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37262\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37260\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37258\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37256\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37254\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37253\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37251\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37249\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37247\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37245\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37243\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37241\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32838\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37238\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37236\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37234\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37232\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37230\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37228\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37226\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37224\""}
{"timestamp_utc": "2024-07-31T08:08:52.186Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37222\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37221\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37219\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37217\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37215\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37213\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37211\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37209\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32836\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37206\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37204\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37202\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37200\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37199\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37198\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37197\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37196\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37195\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37194\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37193\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ] <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             },"}
{"timestamp_utc": "2024-07-31T08:08:52.187Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SandboxKey\": \"/var/run/docker/netns/d0d375d33426\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SecondaryIPAddresses\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SecondaryIPv6Addresses\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"EndpointID\": \"76a565ce8d354f779c992bdbb5819e76a23c1b97332915613095a91b99065242\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Gateway\": \"172.17.0.1\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"GlobalIPv6Address\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"GlobalIPv6PrefixLen\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IPAddress\": \"172.17.0.9\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IPPrefixLen\": 16, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IPv6Gateway\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MacAddress\": \"02:42:ac:11:00:09\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Networks\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"bridge\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPAMConfig\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"Links\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"Aliases\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"NetworkID\": \"4a45b0ef4cf13bd98e537829e6df02da9e283ef3232ced2d12f8023a8079d589\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"EndpointID\": \"76a565ce8d354f779c992bdbb5819e76a23c1b97332915613095a91b99065242\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"Gateway\": \"172.17.0.1\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPAddress\": \"172.17.0.9\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPPrefixLen\": 16, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPv6Gateway\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"GlobalIPv6Address\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"GlobalIPv6PrefixLen\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"MacAddress\": \"02:42:ac:11:00:09\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout: ] <NL> # 03:08:51 ntp-topology INFO: create_single_docker_container: created actual_container_id \"13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52\"(name \"quirky_brattain\") for requested name \"topology-group-device-group-type-qemu-01\" <NL> # 03:08:51 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   saved container amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', 'quirky_brattain'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5048/tcp -> 0.0.0.0:37222 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5008/tcp -> 0.0.0.0:37300 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5035/tcp -> 0.0.0.0:37247 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5057/tcp -> 0.0.0.0:37206 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5059/tcp -> 0.0.0.0:37202 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5032/tcp -> 0.0.0.0:37253 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5010/tcp -> 0.0.0.0:37296 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5013/tcp -> 0.0.0.0:37290 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5036/tcp -> 0.0.0.0:37245 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5046/tcp -> 0.0.0.0:37226 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5058/tcp -> 0.0.0.0:37204 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5003/tcp -> 0.0.0.0:37309 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5037/tcp -> 0.0.0.0:37243 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5038/tcp -> 0.0.0.0:37241 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5044/tcp -> 0.0.0.0:37230 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5045/tcp -> 0.0.0.0:37228 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5053/tcp -> 0.0.0.0:37213 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5061/tcp -> 0.0.0.0:37199 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5012/tcp -> 0.0.0.0:37292 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5050/tcp -> 0.0.0.0:37219 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5022/udp -> 0.0.0.0:32840 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5019/tcp -> 0.0.0.0:37279 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5028/tcp -> 0.0.0.0:37260 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5042/tcp -> 0.0.0.0:37234 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5056/udp -> 0.0.0.0:32836 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5063/tcp -> 0.0.0.0:37197 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5006/tcp -> 0.0.0.0:37304 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5011/tcp -> 0.0.0.0:37294 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5014/tcp -> 0.0.0.0:37288 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5004/tcp -> 0.0.0.0:37307 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5054/tcp -> 0.0.0.0:37211 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5024/tcp -> 0.0.0.0:37270 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5031/tcp -> 0.0.0.0:37254 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5060/tcp -> 0.0.0.0:37200 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5005/udp -> 0.0.0.0:32842 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5026/tcp -> 0.0.0.0:37264 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5034/tcp -> 0.0.0.0:37249 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5049/tcp -> 0.0.0.0:37221 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5051/tcp -> 0.0.0.0:37217 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5064/tcp -> 0.0.0.0:37196 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5020/tcp -> 0.0.0.0:37277 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5017/tcp -> 0.0.0.0:37283 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5021/tcp -> 0.0.0.0:37275 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5033/tcp -> 0.0.0.0:37251 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5043/tcp -> 0.0.0.0:37232 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5009/tcp -> 0.0.0.0:37298 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5016/tcp -> 0.0.0.0:37285 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5018/tcp -> 0.0.0.0:37281 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5047/tcp -> 0.0.0.0:37224 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5065/tcp -> 0.0.0.0:37195 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5007/tcp -> 0.0.0.0:37302 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5029/tcp -> 0.0.0.0:37258 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5030/tcp -> 0.0.0.0:37256 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5039/udp -> 0.0.0.0:32838 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5041/tcp -> 0.0.0.0:37236 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5055/tcp -> 0.0.0.0:37209 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5001/tcp -> 0.0.0.0:37313 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5062/tcp -> 0.0.0.0:37198 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5066/tcp -> 0.0.0.0:37194 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5025/tcp -> 0.0.0.0:37268 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5000/tcp -> 0.0.0.0:37315 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5002/tcp -> 0.0.0.0:37311 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5015/tcp -> 0.0.0.0:37286 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5023/tcp -> 0.0.0.0:37272 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5027/tcp -> 0.0.0.0:37262 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5040/tcp -> 0.0.0.0:37238 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5052/tcp -> 0.0.0.0:37215 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5067/tcp -> 0.0.0.0:37193 <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5000'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37315 <NL> # 03:08:51 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37315 for service \"network-element:NE1/device:main/service:console\" <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5001'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37313 <NL> # 03:08:51 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37313 for service \"network-element:NE1/device:main/service:debug-ssh\" <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5002'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37311 <NL> # 03:08:51 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37311 for service \"network-element:NE1/device:main/service:cli\" <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5003'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37309 <NL> # 03:08:51 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37309 for service \"network-element:NE1/device:main/service:netconf\" <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5004'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37307 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37307 for service \"network-element:NE1/device:main/service:gnmi\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5005/udp']"}
{"timestamp_utc": "2024-07-31T08:08:52.443Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32842 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32842 for service \"network-element:NE1/device:main/service:snmp\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5006'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37304 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37304 for service \"network-element:NE1/device:main/service:webui\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5007']"}
{"timestamp_utc": "2024-07-31T08:08:53.003Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37302 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37302 for service \"network-element:NE1/device:main/service:https\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5008'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37300"}
{"timestamp_utc": "2024-07-31T08:08:53.004Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37300 for service \"network-element:NE1/device:main/service:zmq\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5009']"}
{"timestamp_utc": "2024-07-31T08:08:53.259Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37298 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37298 for service \"network-element:NE1/device:main/service:gdb\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5010']"}
{"timestamp_utc": "2024-07-31T08:08:53.514Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37296 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37296 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5011'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37294 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37294 for service \"network-element:NE1/device:main/service:ospl\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5012']"}
{"timestamp_utc": "2024-07-31T08:08:53.769Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37292 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37292 for service \"network-element:NE1/device:main/service:ftp\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5013'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37290 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37290 for service \"network-element:NE1/device:main/service:sftp\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5014'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37288 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37288 for service \"network-element:NE1/device:main/service:telnet\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5015']"}
{"timestamp_utc": "2024-07-31T08:08:54.024Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37286 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37286 for service \"network-element:NE1/device:trib1/service:console\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5016'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37285 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37285 for service \"network-element:NE1/device:trib1/service:debug-ssh\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5017'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37283 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37283 for service \"network-element:NE2/device:main/service:console\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5018']"}
{"timestamp_utc": "2024-07-31T08:08:54.280Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37281 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37281 for service \"network-element:NE2/device:main/service:debug-ssh\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5019'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37279 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37279 for service \"network-element:NE2/device:main/service:cli\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5020'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37277 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37277 for service \"network-element:NE2/device:main/service:netconf\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5021']"}
{"timestamp_utc": "2024-07-31T08:08:54.535Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37275 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37275 for service \"network-element:NE2/device:main/service:gnmi\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5022/udp']"}
{"timestamp_utc": "2024-07-31T08:08:54.791Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32840 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32840 for service \"network-element:NE2/device:main/service:snmp\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5023'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37272 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37272 for service \"network-element:NE2/device:main/service:webui\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5024']"}
{"timestamp_utc": "2024-07-31T08:08:55.047Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37270 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37270 for service \"network-element:NE2/device:main/service:https\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5025'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37268 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37268 for service \"network-element:NE2/device:main/service:zmq\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5026']"}
{"timestamp_utc": "2024-07-31T08:08:55.304Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37264 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37264 for service \"network-element:NE2/device:main/service:gdb\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5027']"}
{"timestamp_utc": "2024-07-31T08:08:55.560Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37262 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37262 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5028'] <NL> # 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37260 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37260 for service \"network-element:NE2/device:main/service:ospl\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5029']"}
{"timestamp_utc": "2024-07-31T08:08:55.852Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37258 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37258 for service \"network-element:NE2/device:main/service:ftp\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5030'] <NL> # 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37256 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37256 for service \"network-element:NE2/device:main/service:sftp\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5031'] <NL> # 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37254 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37254 for service \"network-element:NE2/device:main/service:telnet\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5032']"}
{"timestamp_utc": "2024-07-31T08:08:56.108Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37253 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37253 for service \"network-element:NE2/device:trib1/service:console\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5033']"}
{"timestamp_utc": "2024-07-31T08:08:56.364Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37251 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37251 for service \"network-element:NE2/device:trib1/service:debug-ssh\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5034'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37249 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37249 for service \"network-element:NE3/device:main/service:console\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5035'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37247 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37247 for service \"network-element:NE3/device:main/service:debug-ssh\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5036']"}
{"timestamp_utc": "2024-07-31T08:08:56.620Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37245 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37245 for service \"network-element:NE3/device:main/service:cli\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5037'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37243 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37243 for service \"network-element:NE3/device:main/service:netconf\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5038']"}
{"timestamp_utc": "2024-07-31T08:08:56.875Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37241 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37241 for service \"network-element:NE3/device:main/service:gnmi\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5039/udp']"}
{"timestamp_utc": "2024-07-31T08:08:57.130Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32838 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32838 for service \"network-element:NE3/device:main/service:snmp\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5040'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37238 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37238 for service \"network-element:NE3/device:main/service:webui\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5041'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37236 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37236 for service \"network-element:NE3/device:main/service:https\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5042']"}
{"timestamp_utc": "2024-07-31T08:08:57.386Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37234 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37234 for service \"network-element:NE3/device:main/service:zmq\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5043']"}
{"timestamp_utc": "2024-07-31T08:08:57.643Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37232 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37232 for service \"network-element:NE3/device:main/service:gdb\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5044'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37230 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37230 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5045'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37228 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37228 for service \"network-element:NE3/device:main/service:ospl\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5046']"}
{"timestamp_utc": "2024-07-31T08:08:57.900Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37226 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37226 for service \"network-element:NE3/device:main/service:ftp\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5047'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37224 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37224 for service \"network-element:NE3/device:main/service:sftp\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5048']"}
{"timestamp_utc": "2024-07-31T08:08:58.155Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37222 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37222 for service \"network-element:NE3/device:main/service:telnet\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5049'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37221 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37221 for service \"network-element:NE3/device:trib1/service:console\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5050'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37219 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37219 for service \"network-element:NE3/device:trib1/service:debug-ssh\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5051']"}
{"timestamp_utc": "2024-07-31T08:08:58.411Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37217 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37217 for service \"network-element:NE4/device:main/service:console\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5052'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37215 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37215 for service \"network-element:NE4/device:main/service:debug-ssh\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5053']"}
{"timestamp_utc": "2024-07-31T08:08:58.667Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37213 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37213 for service \"network-element:NE4/device:main/service:cli\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5054'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37211 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37211 for service \"network-element:NE4/device:main/service:netconf\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5055']"}
{"timestamp_utc": "2024-07-31T08:08:58.923Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37209 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37209 for service \"network-element:NE4/device:main/service:gnmi\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5056/udp'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32836 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32836 for service \"network-element:NE4/device:main/service:snmp\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5057']"}
{"timestamp_utc": "2024-07-31T08:08:59.188Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37206 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37206 for service \"network-element:NE4/device:main/service:webui\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5058']"}
{"timestamp_utc": "2024-07-31T08:08:59.449Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37204 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37204 for service \"network-element:NE4/device:main/service:https\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5059']"}
{"timestamp_utc": "2024-07-31T08:08:59.704Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37202 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37202 for service \"network-element:NE4/device:main/service:zmq\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5060'] <NL> # 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37200 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37200 for service \"network-element:NE4/device:main/service:gdb\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5061'] <NL> # 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37199"}
{"timestamp_utc": "2024-07-31T08:08:59.705Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37199 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5062']"}
{"timestamp_utc": "2024-07-31T08:08:59.961Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37198 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37198 for service \"network-element:NE4/device:main/service:ospl\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5063']"}
{"timestamp_utc": "2024-07-31T08:09:00.218Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37197 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37197 for service \"network-element:NE4/device:main/service:ftp\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5064'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37196 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37196 for service \"network-element:NE4/device:main/service:sftp\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5065'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37195 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37195 for service \"network-element:NE4/device:main/service:telnet\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5066']"}
{"timestamp_utc": "2024-07-31T08:09:00.475Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37194 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37194 for service \"network-element:NE4/device:trib1/service:console\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '5067'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37193 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37193 for service \"network-element:NE4/device:trib1/service:debug-ssh\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37315 for network-element:NE1/device:main/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37313 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37311 for network-element:NE1/device:main/service:cli <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37309 for network-element:NE1/device:main/service:netconf <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37307 for network-element:NE1/device:main/service:gnmi <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32842 for network-element:NE1/device:main/service:snmp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37304 for network-element:NE1/device:main/service:webui <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37302 for network-element:NE1/device:main/service:https"}
{"timestamp_utc": "2024-07-31T08:09:00.476Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37300 for network-element:NE1/device:main/service:zmq <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37298 for network-element:NE1/device:main/service:gdb <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37296 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37294 for network-element:NE1/device:main/service:ospl <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37292 for network-element:NE1/device:main/service:ftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37290 for network-element:NE1/device:main/service:sftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37288 for network-element:NE1/device:main/service:telnet <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37286 for network-element:NE1/device:trib1/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37285 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189"}
{"timestamp_utc": "2024-07-31T08:09:00.735Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37283 for network-element:NE2/device:main/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37281 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37279 for network-element:NE2/device:main/service:cli <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37277 for network-element:NE2/device:main/service:netconf <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37275 for network-element:NE2/device:main/service:gnmi <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32840 for network-element:NE2/device:main/service:snmp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37272 for network-element:NE2/device:main/service:webui <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37270 for network-element:NE2/device:main/service:https <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37268 for network-element:NE2/device:main/service:zmq <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189"}
{"timestamp_utc": "2024-07-31T08:09:00.736Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37264 for network-element:NE2/device:main/service:gdb <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37262 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37260 for network-element:NE2/device:main/service:ospl <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37258 for network-element:NE2/device:main/service:ftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37256 for network-element:NE2/device:main/service:sftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37254 for network-element:NE2/device:main/service:telnet <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37253 for network-element:NE2/device:trib1/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37251 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37249 for network-element:NE3/device:main/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37247 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37245 for network-element:NE3/device:main/service:cli <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37243 for network-element:NE3/device:main/service:netconf <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37241 for network-element:NE3/device:main/service:gnmi <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189"}
{"timestamp_utc": "2024-07-31T08:09:00.737Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32838 for network-element:NE3/device:main/service:snmp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37238 for network-element:NE3/device:main/service:webui <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37236 for network-element:NE3/device:main/service:https <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37234 for network-element:NE3/device:main/service:zmq <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37232 for network-element:NE3/device:main/service:gdb <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37230 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37228 for network-element:NE3/device:main/service:ospl <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37226 for network-element:NE3/device:main/service:ftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37224 for network-element:NE3/device:main/service:sftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37222 for network-element:NE3/device:main/service:telnet <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37221 for network-element:NE3/device:trib1/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37219 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37217 for network-element:NE4/device:main/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37215 for network-element:NE4/device:main/service:debug-ssh"}
{"timestamp_utc": "2024-07-31T08:09:00.738Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37213 for network-element:NE4/device:main/service:cli <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37211 for network-element:NE4/device:main/service:netconf <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37209 for network-element:NE4/device:main/service:gnmi <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32836 for network-element:NE4/device:main/service:snmp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37206 for network-element:NE4/device:main/service:webui <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37204 for network-element:NE4/device:main/service:https <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37202 for network-element:NE4/device:main/service:zmq <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37200 for network-element:NE4/device:main/service:gdb <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37199 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37198 for network-element:NE4/device:main/service:ospl <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37197 for network-element:NE4/device:main/service:ftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37196 for network-element:NE4/device:main/service:sftp <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37195 for network-element:NE4/device:main/service:telnet <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json'"}
{"timestamp_utc": "2024-07-31T08:09:00.739Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37194 for network-element:NE4/device:trib1/service:console <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37193 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:09:00 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:00 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:00 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: container_logs_command_log_fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.log' <NL> # 03:09:00 ntp-topology INFO: get_container_env_exec_command: network_topology_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology <NL> # 03:09:00 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: start_command ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-create'] <NL> # 03:09:00 ntp-topology INFO: create_container_log_fname: name='command' type='created'): fname_data_dict { <NL> \"status_text\": \"from handle_remote_create_in_new_device_group_containers\" <NL> } <NL> # 03:09:00 ntp-topology INFO: exec_cmd: ['mv', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.created.tmp', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.created'] <NL> # 03:09:00 ntp-topology INFO: exec_cmd: ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-create']"}
{"timestamp_utc": "2024-07-31T08:09:01.301Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: wait_for_containers_command_started: - waiting max 600s for container_logs_command_started_fname files: <NL> # 03:09:01 ntp-topology INFO: wait_for_containers_command_started:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.started' <NL> # 03:09:01 ntp-topology INFO: wait_for_containers_command_started: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.started'] <NL> # 03:09:01 ntp-topology INFO: wait_for_containers_command_started: 0.000s of 600.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:02.229Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:02 ntp-topology INFO: wait_for_containers_command_started: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.started'] <NL> # 03:09:02 ntp-topology INFO: wait_for_containers_command_started: 1.001s of 600.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:03.156Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized: - waiting max 1800s for container_logs_command_initialized_fname files: <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized' <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error' <NL> # 03:09:03 ntp-topology INFO: ntp.retry.group_list_cl.show: json_list: [ <NL> { <NL> \"all_of_file_list\": [ <NL> [ <NL> \"initialized\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized\" <NL> ] <NL> ], <NL> \"any_of_file_list\": [ <NL> [ <NL> \"error\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error\" <NL> ] <NL> ], <NL> \"group_name\": \"topology-group-device-group-type-qemu-01\" <NL> } <NL> ] <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized: 0.000s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:04.523Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:04 ntp-topology INFO: wait_for_containers_command_initialized: 1.001s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:05.451Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:05 ntp-topology INFO: wait_for_containers_command_initialized: 2.002s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:06.380Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:06 ntp-topology INFO: wait_for_containers_command_initialized: 3.003s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:07.318Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:07 ntp-topology INFO: wait_for_containers_command_initialized: 4.005s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:08.245Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:08 ntp-topology INFO: wait_for_containers_command_initialized: 5.006s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:09.173Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:09 ntp-topology INFO: wait_for_containers_command_initialized: 6.007s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:10.545Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:10 ntp-topology INFO: wait_for_containers_command_initialized: 7.008s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:11.478Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized: 8.009s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:12.408Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:12 ntp-topology INFO: wait_for_containers_command_initialized: 9.010s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:13.336Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:13 ntp-topology INFO: wait_for_containers_command_initialized: 10.011s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:14.264Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:14 ntp-topology INFO: wait_for_containers_command_initialized: 11.012s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:15.191Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:15 ntp-topology INFO: wait_for_containers_command_initialized: 12.013s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:16.557Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:16 ntp-topology INFO: wait_for_containers_command_initialized: 13.014s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:17.483Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:17 ntp-topology INFO: wait_for_containers_command_initialized: 14.015s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:18.411Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:18 ntp-topology INFO: wait_for_containers_command_initialized: 15.016s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:19.339Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:19 ntp-topology INFO: wait_for_containers_command_initialized: 16.017s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:20.266Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:20 ntp-topology INFO: wait_for_containers_command_initialized: 17.018s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:21.195Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:21 ntp-topology INFO: wait_for_containers_command_initialized: 18.019s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:22.588Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:22 ntp-topology INFO: wait_for_containers_command_initialized: 19.020s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:23.515Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:23 ntp-topology INFO: wait_for_containers_command_initialized: 20.021s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:24.443Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:24 ntp-topology INFO: wait_for_containers_command_initialized: 21.022s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:25.370Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:25 ntp-topology INFO: wait_for_containers_command_initialized: 22.023s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:26.296Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:26 ntp-topology INFO: wait_for_containers_command_initialized: 23.024s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:27.225Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:27 ntp-topology INFO: wait_for_containers_command_initialized: 24.025s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:28.588Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:28 ntp-topology INFO: wait_for_containers_command_initialized: 25.026s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:29.513Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:29 ntp-topology INFO: wait_for_containers_command_initialized: 26.027s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:30.439Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:30 ntp-topology INFO: wait_for_containers_command_initialized: 27.028s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:31.366Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:31 ntp-topology INFO: wait_for_containers_command_initialized: 28.029s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:32.294Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:32 ntp-topology INFO: wait_for_containers_command_initialized: 29.030s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:33.220Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:33 ntp-topology INFO: wait_for_containers_command_initialized: 30.032s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:34.600Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:34 ntp-topology INFO: wait_for_containers_command_initialized: 31.033s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:35.526Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:35 ntp-topology INFO: wait_for_containers_command_initialized: 32.034s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:36.452Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:36 ntp-topology INFO: wait_for_containers_command_initialized: 33.035s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:37.379Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:37 ntp-topology INFO: wait_for_containers_command_initialized: 34.036s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:38.305Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:38 ntp-topology INFO: wait_for_containers_command_initialized: 35.037s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:39.230Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:39 ntp-topology INFO: wait_for_containers_command_initialized: 36.038s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:40.592Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:40 ntp-topology INFO: wait_for_containers_command_initialized: 37.039s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:41.519Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:41 ntp-topology INFO: wait_for_containers_command_initialized: 38.040s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:42.445Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:42 ntp-topology INFO: wait_for_containers_command_initialized: 39.041s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:43.373Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:43 ntp-topology INFO: wait_for_containers_command_initialized: 40.042s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:44.298Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:44 ntp-topology INFO: wait_for_containers_command_initialized: 41.043s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:45.223Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:45 ntp-topology INFO: wait_for_containers_command_initialized: 42.044s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:46.593Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:46 ntp-topology INFO: wait_for_containers_command_initialized: 43.045s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:47.521Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:47 ntp-topology INFO: wait_for_containers_command_initialized: 44.046s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:48.446Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:48 ntp-topology INFO: wait_for_containers_command_initialized: 45.052s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:49.371Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:49 ntp-topology INFO: wait_for_containers_command_initialized: 46.053s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:50.314Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:50 ntp-topology INFO: wait_for_containers_command_initialized: 47.054s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:51.239Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:51 ntp-topology INFO: wait_for_containers_command_initialized: 48.055s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:52.603Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:52 ntp-topology INFO: wait_for_containers_command_initialized: 49.056s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:53.530Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:53 ntp-topology INFO: wait_for_containers_command_initialized: 50.057s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:54.456Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:54 ntp-topology INFO: wait_for_containers_command_initialized: 51.058s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:55.382Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:55 ntp-topology INFO: wait_for_containers_command_initialized: 52.059s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:56.308Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:56 ntp-topology INFO: wait_for_containers_command_initialized: 53.060s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:57.234Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:57 ntp-topology INFO: wait_for_containers_command_initialized: 54.061s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:58.598Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:58 ntp-topology INFO: wait_for_containers_command_initialized: 55.062s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:59.524Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:09:59.525Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:59 ntp-topology INFO: wait_for_containers_command_initialized: 56.063s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:00.456Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:00 ntp-topology INFO: wait_for_containers_command_initialized: 57.064s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:01.385Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:01 ntp-topology INFO: wait_for_containers_command_initialized: 58.065s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:02.313Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:02 ntp-topology INFO: wait_for_containers_command_initialized: 59.066s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:03.240Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:03 ntp-topology INFO: wait_for_containers_command_initialized: 60.067s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:04.604Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:04 ntp-topology INFO: wait_for_containers_command_initialized: 61.068s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:05.532Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:05 ntp-topology INFO: wait_for_containers_command_initialized: 62.069s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:06.459Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:06 ntp-topology INFO: wait_for_containers_command_initialized: 63.070s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:07.429Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:07 ntp-topology INFO: wait_for_containers_command_initialized: 64.071s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:08.355Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:08 ntp-topology INFO: wait_for_containers_command_initialized: 65.072s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:09.282Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:09 ntp-topology INFO: wait_for_containers_command_initialized: 66.073s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:10.646Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:10 ntp-topology INFO: wait_for_containers_command_initialized: 67.074s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:11.577Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:11 ntp-topology INFO: wait_for_containers_command_initialized: 68.075s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:12.502Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:12 ntp-topology INFO: wait_for_containers_command_initialized: 69.076s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:13.448Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:13 ntp-topology INFO: wait_for_containers_command_initialized: 70.077s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:14.375Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:14 ntp-topology INFO: wait_for_containers_command_initialized: 71.078s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:15.346Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:15 ntp-topology INFO: wait_for_containers_command_initialized: 72.079s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:16.275Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:16 ntp-topology INFO: wait_for_containers_command_initialized: 73.080s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:17.640Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:17 ntp-topology INFO: wait_for_containers_command_initialized: 74.081s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:18.567Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:18 ntp-topology INFO: wait_for_containers_command_initialized: 75.082s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:19.501Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:19 ntp-topology INFO: wait_for_containers_command_initialized: 76.083s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:20.429Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:20 ntp-topology INFO: wait_for_containers_command_initialized: 77.084s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:21.355Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:21 ntp-topology INFO: wait_for_containers_command_initialized: 78.085s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:22.282Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:22 ntp-topology INFO: wait_for_containers_command_initialized: 79.086s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:23.665Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:23 ntp-topology INFO: wait_for_containers_command_initialized: 80.087s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:24.593Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:24 ntp-topology INFO: wait_for_containers_command_initialized: 81.088s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:25.521Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:25 ntp-topology INFO: wait_for_containers_command_initialized: 82.089s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:26.446Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:26 ntp-topology INFO: wait_for_containers_command_initialized: 83.090s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:27.372Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:27 ntp-topology INFO: wait_for_containers_command_initialized: 84.091s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:28.310Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:28 ntp-topology INFO: wait_for_containers_command_initialized: 85.092s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:29.675Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:29 ntp-topology INFO: wait_for_containers_command_initialized: 86.093s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:30.602Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:30 ntp-topology INFO: wait_for_containers_command_initialized: 87.094s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:31.529Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:31 ntp-topology INFO: wait_for_containers_command_initialized: 88.095s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:32.471Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:32 ntp-topology INFO: wait_for_containers_command_initialized: 89.096s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:33.400Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:33 ntp-topology INFO: wait_for_containers_command_initialized: 90.097s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:34.325Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:34 ntp-topology INFO: wait_for_containers_command_initialized: 91.098s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:35.273Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:35 ntp-topology INFO: wait_for_containers_command_initialized: 92.099s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:36.639Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:36 ntp-topology INFO: wait_for_containers_command_initialized: 93.101s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:37.566Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:37 ntp-topology INFO: wait_for_containers_command_initialized: 94.102s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:38.492Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:38 ntp-topology INFO: wait_for_containers_command_initialized: 95.103s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:39.419Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:39 ntp-topology INFO: wait_for_containers_command_initialized: 96.104s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:40.345Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:40 ntp-topology INFO: wait_for_containers_command_initialized: 97.105s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:41.272Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:41 ntp-topology INFO: wait_for_containers_command_initialized: 98.106s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:42.637Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:42 ntp-topology INFO: wait_for_containers_command_initialized: 99.107s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:43.563Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:43 ntp-topology INFO: wait_for_containers_command_initialized: 100.108s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:44.489Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:44 ntp-topology INFO: wait_for_containers_command_initialized: 101.109s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:45.415Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:45 ntp-topology INFO: wait_for_containers_command_initialized: 102.110s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:46.343Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:46 ntp-topology INFO: wait_for_containers_command_initialized: 103.111s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:47.271Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:47 ntp-topology INFO: wait_for_containers_command_initialized: 104.112s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:48.637Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:48 ntp-topology INFO: wait_for_containers_command_initialized: 105.113s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:49.563Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:49 ntp-topology INFO: wait_for_containers_command_initialized: 106.114s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:50.490Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:50 ntp-topology INFO: wait_for_containers_command_initialized: 107.115s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:51.418Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:51 ntp-topology INFO: wait_for_containers_command_initialized: 108.116s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:52.348Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:52 ntp-topology INFO: wait_for_containers_command_initialized: 109.117s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:53.275Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:53 ntp-topology INFO: wait_for_containers_command_initialized: 110.118s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:54.642Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:54 ntp-topology INFO: wait_for_containers_command_initialized: 111.119s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:55.571Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:55 ntp-topology INFO: wait_for_containers_command_initialized: 112.120s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:56.500Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:56 ntp-topology INFO: wait_for_containers_command_initialized: 113.122s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:57.429Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:57 ntp-topology INFO: wait_for_containers_command_initialized: 114.123s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:58.356Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:58 ntp-topology INFO: wait_for_containers_command_initialized: 115.124s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:59.285Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:59 ntp-topology INFO: wait_for_containers_command_initialized: 116.125s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:00.650Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:00 ntp-topology INFO: wait_for_containers_command_initialized: 117.126s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:01.578Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:01 ntp-topology INFO: wait_for_containers_command_initialized: 118.127s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:02.509Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:02 ntp-topology INFO: wait_for_containers_command_initialized: 119.128s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:03.436Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:03 ntp-topology INFO: wait_for_containers_command_initialized: 120.129s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:04.363Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:04 ntp-topology INFO: wait_for_containers_command_initialized: 121.130s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:05.294Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:05 ntp-topology INFO: wait_for_containers_command_initialized: 122.131s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:06.679Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:06 ntp-topology INFO: wait_for_containers_command_initialized: 123.132s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:07.608Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:07 ntp-topology INFO: wait_for_containers_command_initialized: 124.133s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:08.535Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:08 ntp-topology INFO: wait_for_containers_command_initialized: 125.134s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:09.462Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:09 ntp-topology INFO: wait_for_containers_command_initialized: 126.135s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:10.395Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:10 ntp-topology INFO: wait_for_containers_command_initialized: 127.136s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:11.324Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:11 ntp-topology INFO: wait_for_containers_command_initialized: 128.137s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:12.692Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:12 ntp-topology INFO: wait_for_containers_command_initialized: 129.138s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:13.618Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:13 ntp-topology INFO: wait_for_containers_command_initialized: 130.139s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:14.575Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:14 ntp-topology INFO: wait_for_containers_command_initialized: 131.140s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:15.503Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:15 ntp-topology INFO: wait_for_containers_command_initialized: 132.141s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:16.430Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:16 ntp-topology INFO: wait_for_containers_command_initialized: 133.142s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:17.356Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:11:17.357Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:17 ntp-topology INFO: wait_for_containers_command_initialized: 134.143s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:18.336Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:18 ntp-topology INFO: wait_for_containers_command_initialized: 135.144s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:19.699Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:19 ntp-topology INFO: wait_for_containers_command_initialized: 136.145s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:20.627Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:20 ntp-topology INFO: wait_for_containers_command_initialized: 137.146s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:21.578Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:21 ntp-topology INFO: wait_for_containers_command_initialized: 138.147s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:22.504Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:22 ntp-topology INFO: wait_for_containers_command_initialized: 139.149s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:23.431Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:11:23.432Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:23 ntp-topology INFO: wait_for_containers_command_initialized: 140.151s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:24.359Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:24 ntp-topology INFO: wait_for_containers_command_initialized: 141.152s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:25.725Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:25 ntp-topology INFO: wait_for_containers_command_initialized: 142.153s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:26.651Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:26 ntp-topology INFO: wait_for_containers_command_initialized: 143.154s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:27.579Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:27 ntp-topology INFO: wait_for_containers_command_initialized: 144.155s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:28.507Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:28 ntp-topology INFO: wait_for_containers_command_initialized: 145.157s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:29.434Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:29 ntp-topology INFO: wait_for_containers_command_initialized: 146.158s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:30.360Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:30 ntp-topology INFO: wait_for_containers_command_initialized: 147.159s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:31.726Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:31 ntp-topology INFO: wait_for_containers_command_initialized: 148.160s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:32.653Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:32 ntp-topology INFO: wait_for_containers_command_initialized: 149.161s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:33.579Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:33 ntp-topology INFO: wait_for_containers_command_initialized: 150.162s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:34.522Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:34 ntp-topology INFO: wait_for_containers_command_initialized: 151.163s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:35.450Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:35 ntp-topology INFO: wait_for_containers_command_initialized: 152.164s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:36.376Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:36 ntp-topology INFO: wait_for_containers_command_initialized: 153.165s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:37.740Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:37 ntp-topology INFO: wait_for_containers_command_initialized: 154.166s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:38.329Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:38 ntp-topology INFO: wait_for_containers_command_initialized: 155.167s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:39.693Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:39 ntp-topology INFO: wait_for_containers_command_initialized: 156.168s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:40.622Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:40 ntp-topology INFO: wait_for_containers_command_initialized: 157.169s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:41.553Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:41 ntp-topology INFO: wait_for_containers_command_initialized: 158.170s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:42.481Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:42 ntp-topology INFO: wait_for_containers_command_initialized: 159.171s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:43.410Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:43 ntp-topology INFO: wait_for_containers_command_initialized: 160.172s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:44.337Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:44 ntp-topology INFO: wait_for_containers_command_initialized: 161.173s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:45.699Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:45 ntp-topology INFO: wait_for_containers_command_initialized: 162.174s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:46.626Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:46 ntp-topology INFO: wait_for_containers_command_initialized: 163.175s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:47.553Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:47 ntp-topology INFO: wait_for_containers_command_initialized: 164.176s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:48.482Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:48 ntp-topology INFO: wait_for_containers_command_initialized: 165.177s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:49.429Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:49 ntp-topology INFO: wait_for_containers_command_initialized: 166.179s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:50.376Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:50 ntp-topology INFO: wait_for_containers_command_initialized: 167.180s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:51.745Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:51 ntp-topology INFO: wait_for_containers_command_initialized: 168.181s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:52.674Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:52 ntp-topology INFO: wait_for_containers_command_initialized: 169.182s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:53.616Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:53 ntp-topology INFO: wait_for_containers_command_initialized: 170.183s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:54.545Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:54 ntp-topology INFO: wait_for_containers_command_initialized: 171.184s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:55.477Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:55 ntp-topology INFO: wait_for_containers_command_initialized: 172.185s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:56.422Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:56 ntp-topology INFO: wait_for_containers_command_initialized: 173.186s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:57.353Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:57 ntp-topology INFO: wait_for_containers_command_initialized: 174.187s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:58.721Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:58 ntp-topology INFO: wait_for_containers_command_initialized: 175.188s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:59.652Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:59 ntp-topology INFO: wait_for_containers_command_initialized: 176.189s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:00.582Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:00 ntp-topology INFO: wait_for_containers_command_initialized: 177.190s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:01.512Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_command_initialized: 178.191s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:02.441Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:02 ntp-topology INFO: wait_for_containers_command_initialized: 179.192s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:03.371Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:03 ntp-topology INFO: wait_for_containers_command_initialized: 180.193s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:04.735Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:04 ntp-topology INFO: wait_for_containers_command_initialized: 181.194s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:05.664Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:05 ntp-topology INFO: wait_for_containers_command_initialized: 182.195s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:06.592Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:06 ntp-topology INFO: wait_for_containers_command_initialized: 183.196s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:07.521Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:07 ntp-topology INFO: wait_for_containers_command_initialized: 184.197s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:08.450Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:08 ntp-topology INFO: wait_for_containers_command_initialized: 185.198s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:09.378Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:09 ntp-topology INFO: wait_for_containers_command_initialized: 186.199s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:10.745Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:12:10.746Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:10 ntp-topology INFO: wait_for_containers_command_initialized: 187.200s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:11.673Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:11 ntp-topology INFO: wait_for_containers_command_initialized: 188.201s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:12.600Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:12 ntp-topology INFO: wait_for_containers_command_initialized: 189.202s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:13.527Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:13 ntp-topology INFO: wait_for_containers_command_initialized: 190.203s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:14.468Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:14 ntp-topology INFO: wait_for_containers_command_initialized: 191.204s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:15.396Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:15 ntp-topology INFO: wait_for_containers_command_initialized: 192.206s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:16.761Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:16 ntp-topology INFO: wait_for_containers_command_initialized: 193.207s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:17.742Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:17 ntp-topology INFO: wait_for_containers_command_initialized: 194.208s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:18.670Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:18 ntp-topology INFO: wait_for_containers_command_initialized: 195.209s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:19.597Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:19 ntp-topology INFO: wait_for_containers_command_initialized: 196.210s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:20.523Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:20 ntp-topology INFO: wait_for_containers_command_initialized: 197.211s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:21.492Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:21 ntp-topology INFO: wait_for_containers_command_initialized: 198.212s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:22.454Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:22 ntp-topology INFO: wait_for_containers_command_initialized: 199.213s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:23.382Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:23 ntp-topology INFO: wait_for_containers_command_initialized: 200.214s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:24.749Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:24 ntp-topology INFO: wait_for_containers_command_initialized: 201.215s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:25.710Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:25 ntp-topology INFO: wait_for_containers_command_initialized: 202.216s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:26.637Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:26 ntp-topology INFO: wait_for_containers_command_initialized: 203.217s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:27.566Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:27 ntp-topology INFO: wait_for_containers_command_initialized: 204.218s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:28.499Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:28 ntp-topology INFO: wait_for_containers_command_initialized: 205.219s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:29.426Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:29 ntp-topology INFO: wait_for_containers_command_initialized: 206.220s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:30.793Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:30 ntp-topology INFO: wait_for_containers_command_initialized: 207.222s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:31.721Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:31 ntp-topology INFO: wait_for_containers_command_initialized: 208.227s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:32.649Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:32 ntp-topology INFO: wait_for_containers_command_initialized: 209.228s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:33.575Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:33 ntp-topology INFO: wait_for_containers_command_initialized: 210.229s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:34.501Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:34 ntp-topology INFO: wait_for_containers_command_initialized: 211.230s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:35.428Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:35 ntp-topology INFO: wait_for_containers_command_initialized: 212.231s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:36.418Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:36 ntp-topology INFO: wait_for_containers_command_initialized: 213.232s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:37.782Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:37 ntp-topology INFO: wait_for_containers_command_initialized: 214.233s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:38.709Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:38 ntp-topology INFO: wait_for_containers_command_initialized: 215.234s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:39.637Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:39 ntp-topology INFO: wait_for_containers_command_initialized: 216.236s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:40.563Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:40 ntp-topology INFO: wait_for_containers_command_initialized: 217.237s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:41.491Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:41 ntp-topology INFO: wait_for_containers_command_initialized: 218.238s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:42.419Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:42 ntp-topology INFO: wait_for_containers_command_initialized: ntp_container_name 'topology-group-device-group-type-qemu-01': error_file_present_flag False <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: - waiting max 1800s for socket daemon files, if we have any <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: container_workspace_basedir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace' <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error' <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: socket_daemon_info_list: [ <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE1/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE1/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE2/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE2/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE3/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE3/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE4/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE4/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> ] <NL> # 03:12:42 ntp-topology INFO: ntp.retry.group_list_cl.show: json_list: [ <NL> { <NL> \"all_of_file_list\": [ <NL> [ <NL> \"socket-daemon-info:network-element:NE1/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE1/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE2/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE2/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE3/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE3/device:trib1\","}
{"timestamp_utc": "2024-07-31T08:12:42.420Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE4/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE4/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ] <NL> ], <NL> \"any_of_file_list\": [ <NL> [ <NL> \"error\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error\" <NL> ] <NL> ], <NL> \"group_name\": \"topology-group-device-group-type-qemu-01\" <NL> } <NL> ] <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: 0.000s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:43.784Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:43 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:43 ntp-topology INFO: wait_for_containers_socket_deamon_info: 1.001s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:44.712Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:44 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:44 ntp-topology INFO: wait_for_containers_socket_deamon_info: 2.002s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:45.641Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:45 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:45 ntp-topology INFO: wait_for_containers_socket_deamon_info: 3.003s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:46.568Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:46 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:46 ntp-topology INFO: wait_for_containers_socket_deamon_info: 4.004s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:47.495Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: 5.005s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:48.421Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': error_file_present_flag False <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE1/device:main': command_code 0 <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE1/device:trib1': command_code 0 <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE2/device:main': command_code 0 <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE2/device:trib1': command_code 0 <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE3/device:main': command_code 0 <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE3/device:trib1': command_code 0 <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE4/device:main': command_code 0 <NL> # 03:12:48 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE4/device:trib1': command_code 0 <NL> # 03:12:48 ntp-topology INFO: main: completed action 'create' <NL> # 03:12:48 ntp-topology INFO: done"}
{"timestamp_utc": "2024-07-31T08:12:48.676Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json', '--action', 'request-remote-create']"}
{"timestamp_utc": "2024-07-31T08:12:49.242Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace' <NL> # 03:12:49 ntp-topology INFO: main: starting action 'request-remote-create' <NL> # 03:12:49 ntp-topology INFO: main: completed action 'request-remote-create' <NL> # 03:12:49 ntp-topology INFO: done <NL> # 03:12:49 ntp-topology-run.py INFO: exec_cmd: ['ntp-get-service-details', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace/topology-flist.json', '--out-format', 'json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/services-ntp.852.json']"}
{"timestamp_utc": "2024-07-31T08:12:49.855Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main'"}
{"timestamp_utc": "2024-07-31T08:12:49.856Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:cli' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:netconf' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gnmi' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:snmp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:webui' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:https' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:zmq' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gdb' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gdb-ops-additional' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:ospl' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:ftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:sftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:telnet' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:trib1/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:trib1/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:cli' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:netconf' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gnmi' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:snmp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:webui' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:https' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:zmq' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gdb' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gdb-ops-additional' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:ospl' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:ftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:sftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:telnet' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:trib1/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:trib1/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:cli' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:netconf' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gnmi' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:snmp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:webui' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:https' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:zmq' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gdb' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gdb-ops-additional' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:ospl' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:ftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:sftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:telnet' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:trib1/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:trib1/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:cli' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:netconf' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gnmi' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:snmp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:webui' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:https' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:zmq' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gdb' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gdb-ops-additional' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:ospl' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:ftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:sftp' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:telnet' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:trib1/service:console' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:trib1/service:debug-ssh' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:netconf', device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:49.857Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37315:5000:None for network-element:NE1/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37313:5001:6022 for network-element:NE1/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:49.858Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37311:5002:22 for network-element:NE1/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37309:5003:830 for network-element:NE1/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37307:5004:6030 for network-element:NE1/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32842:5005:161/udp for network-element:NE1/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37304:5006:80 for network-element:NE1/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37302:5007:443 for network-element:NE1/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37300:5008:5555 for network-element:NE1/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37298:5009:10000 for network-element:NE1/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37296:5010:32767 for network-element:NE1/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37294:5011:50000 for network-element:NE1/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37292:5012:21 for network-element:NE1/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37290:5013:2202 for network-element:NE1/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37288:5014:23 for network-element:NE1/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37286:5015:None for network-element:NE1/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37285:5016:6022 for network-element:NE1/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37283:5017:None for network-element:NE2/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37281:5018:6022 for network-element:NE2/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37279:5019:22 for network-element:NE2/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37277:5020:830 for network-element:NE2/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37275:5021:6030 for network-element:NE2/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32840:5022:161/udp for network-element:NE2/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37272:5023:80 for network-element:NE2/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37270:5024:443 for network-element:NE2/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37268:5025:5555 for network-element:NE2/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37264:5026:10000 for network-element:NE2/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37262:5027:32767 for network-element:NE2/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37260:5028:50000 for network-element:NE2/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37258:5029:21 for network-element:NE2/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37256:5030:2202 for network-element:NE2/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37254:5031:23 for network-element:NE2/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37253:5032:None for network-element:NE2/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37251:5033:6022 for network-element:NE2/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37249:5034:None for network-element:NE3/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37247:5035:6022 for network-element:NE3/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37245:5036:22 for network-element:NE3/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37243:5037:830 for network-element:NE3/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37241:5038:6030 for network-element:NE3/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32838:5039:161/udp for network-element:NE3/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37238:5040:80 for network-element:NE3/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37236:5041:443 for network-element:NE3/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37234:5042:5555 for network-element:NE3/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37232:5043:10000 for network-element:NE3/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37230:5044:32767 for network-element:NE3/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37228:5045:50000 for network-element:NE3/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37226:5046:21 for network-element:NE3/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37224:5047:2202 for network-element:NE3/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37222:5048:23 for network-element:NE3/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37221:5049:None for network-element:NE3/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37219:5050:6022 for network-element:NE3/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37217:5051:None for network-element:NE4/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37215:5052:6022 for network-element:NE4/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37213:5053:22 for network-element:NE4/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37211:5054:830 for network-element:NE4/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37209:5055:6030 for network-element:NE4/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32836:5056:161/udp for network-element:NE4/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37206:5057:80 for network-element:NE4/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37204:5058:443 for network-element:NE4/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37202:5059:5555 for network-element:NE4/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37200:5060:10000 for network-element:NE4/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37199:5061:32767 for network-element:NE4/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37198:5062:50000 for network-element:NE4/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37197:5063:21 for network-element:NE4/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37196:5064:2202 for network-element:NE4/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37195:5065:23 for network-element:NE4/device:main/service:telnet, device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:49.859Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37194:5066:None for network-element:NE4/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37193:5067:6022 for network-element:NE4/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:49 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-legacy-service-info-environment', '-v', '-v', '--service-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/services-ntp.852.json', '--environment-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json', '--map-service-name', 'debug-ssh', 'dip']"}
{"timestamp_utc": "2024-07-31T08:12:50.124Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-create-legacy-service-info-environment INFO: arg_dict: { <NL> \"environment_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json\", <NL> \"global_host_info_flag\": true, <NL> \"map_service_name\": [ <NL> [ <NL> \"debug-ssh\", <NL> \"dip\" <NL> ] <NL> ], <NL> \"service_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/services-ntp.852.json\", <NL> \"verbosity\": 2 <NL> } <NL> create-service-info-environment-json: service_info_json_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/services-ntp.852.json\" <NL> create-service-info-environment-json: environment_json_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json\" <NL> # 03:12:49 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-service-info-environment', '-v', '-v', '--input-file', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/services-ntp.852.json', '--output-file', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--output-format', 'json'] <NL> # 03:12:49 ntp-create-service-info-environment INFO: Called with arguments: Namespace(input_file='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/services-ntp.852.json', output_file='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', output_format='json', verbosity=2) <NL> # 03:12:49 ntp-create-service-info-environment DEBUG: Writing: /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json <NL> # 03:12:49 ntp-topology-run.py INFO: exec_cmd: ['rm', '-f', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/services-ntp.852.json'] <NL> # 03:12:50 ntp-topology-run.py INFO: done <NL> # 03:12:50 tfwk-exec-test-agent INFO: create_autop_json_fname: device_list: [] <NL> # 03:12:50 tfwk-exec-test-agent INFO: create_autop_json_fname: saving device_list into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-autop.json' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs: - from fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'HOSTIP'='167.254.217.189'"}
{"timestamp_utc": "2024-07-31T08:12:50.381Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_PORT'=37311 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_PORT'=37315 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_PORT'=37313 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_PORT'=37292 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_PORT'=37296 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_PORT'=37298 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_PORT'=37307 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_PORT'=37302 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_PORT'=37309 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_PORT'=37294 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_PORT'=37290 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_PORT'=32842 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_PORT'=37288 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_PORT'=37304 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_PORT'=37300 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_PORT'=37286 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_PORT'=37285 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_PORT'=37279 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_PORT'=37283 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_PORT'=37281 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_PORT'=37258 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_PORT'=37262 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_PORT'=37264 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_PORT'=37275 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_PORT'=37270"}
{"timestamp_utc": "2024-07-31T08:12:50.382Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_PORT'=37277 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_PORT'=37260 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_PORT'=37256 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_PORT'=32840 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_PORT'=37254 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_PORT'=37272 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_PORT'=37268 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_PORT'=37253 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_PORT'=37251 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_PORT'=37245 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_PORT'=37249 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_PORT'=37247 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_PORT'=37226 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_PORT'=37230 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_PORT'=37232 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_PORT'=37241 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_PORT'=37236 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_PORT'=37243 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_PORT'=37228 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_PORT'=37224 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_PORT'=32838 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_PORT'=37222 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_PORT'=37238 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_PORT'=37234 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_PORT'=37221 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_PORT'=37219 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_PORT'=37213 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_PORT'=37217 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_PORT'=37215 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_PORT'=37197 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_PORT'=37199 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_PORT'=37200 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_PORT'=37209 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_HOSTIP'='167.254.217.189'"}
{"timestamp_utc": "2024-07-31T08:12:50.383Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_PORT'=37204 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_PORT'=37211 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_PORT'=37198 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_PORT'=37196 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_PORT'=32836 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_PORT'=37195 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_PORT'=37206 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_PORT'=37202 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_PORT'=37194 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_PORT'=37193 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs: - from fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli'=37311 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console'=37315 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh'=37313 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp'=37292 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb'=37298 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional'=37296 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi'=37307 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https'=37302 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf'=37309 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl'=37294 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp'=37290 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp'=32842 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet'=37288 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui'=37304 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq'=37300 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console'=37286 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh'=37285 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli'=37279 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console'=37283 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh'=37281 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp'=37258 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb'=37264 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional'=37262 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi'=37275 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi_hostip'='167.254.217.189'"}
{"timestamp_utc": "2024-07-31T08:12:50.384Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https'=37270 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf'=37277 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl'=37260 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp'=37256 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp'=32840 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet'=37254 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui'=37272 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq'=37268 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console'=37253 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh'=37251 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli'=37245 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console'=37249 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh'=37247 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp'=37226 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb'=37232 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional'=37230 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi'=37241 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https'=37236 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf'=37243 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl'=37228 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp'=37224 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp'=32838 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet'=37222 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui'=37238 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq'=37234 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console'=37221 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh'=37219 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli'=37213 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console'=37217 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh'=37215 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp'=37197 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb'=37200 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional'=37199 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional_hostname'='rtxoialp79'"}
{"timestamp_utc": "2024-07-31T08:12:50.385Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi'=37209 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https'=37204 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf'=37211 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl'=37198 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp'=37196 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp'=32836 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet'=37195 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui'=37206 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq'=37202 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console'=37194 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh'=37193 <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_hostip'='167.254.217.189' <NL> # 03:12:50 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_hostname'='rtxoialp79' <NL> # 03:12:50 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test-engine-output-dir'] <NL> # 03:12:50 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json', '--cmd-end', '--job-end'] <NL> # 03:12:50 ntp-wait-for-devices INFO: arg_dict: { <NL> \"autop_json_fname\": null, <NL> \"autop_processing\": null, <NL> \"flist_fname\": null, <NL> \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"overall_timeout\": 28800, <NL> \"startup_timeout\": \"1200\", <NL> \"trailer_command\": [ <NL> \"--\", <NL> \"--job-begin-command\", <NL> \"--name\", <NL> \"Warrior\", <NL> \"--cmd-begin\", <NL> \"run_init\", <NL> \"--runinit_venv_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\", <NL> \"--services_env\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\", <NL> \"--work_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\", <NL> \"-v\", <NL> \"-e\", <NL> \"warrior\", <NL> \"--test_engine_venv_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\", <NL> \"--test_engine\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json\", <NL> \"--cmd-end\", <NL> \"--job-end\" <NL> ], <NL> \"verbosity\": 2, <NL> \"virtualenv_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\", <NL> \"wait_period\": null, <NL> \"wait_time\": null <NL> } <NL> # 03:12:50 ntp-wait-for-devices INFO: main: ntp_info_obj: { <NL> \"_NETWORK_TOPOLOGY_TAG\": \"tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> \"_SHARED_STORE_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01\", <NL> \"_TOPOLOGY_TYPE\": \"container-docker-single\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:12:50.949Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-console\": [rtxoialp79] 37315 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-debug-ssh\": [rtxoialp79] 37313 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-cli\": [rtxoialp79] 37311 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-cli\": [rtxoialp79] 37311 <NL> # 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE1-trib1-console\": [rtxoialp79] 37286 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None"}
{"timestamp_utc": "2024-07-31T08:12:50.950Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE1-trib1-debug-ssh\": [rtxoialp79] 37285 <NL> # 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-console\": [rtxoialp79] 37283 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-debug-ssh\": [rtxoialp79] 37281 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-cli\": [rtxoialp79] 37279 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-cli\": [rtxoialp79] 37279 <NL> # 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE2-trib1-console\": [rtxoialp79] 37253 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE2-trib1-debug-ssh\": [rtxoialp79] 37251 <NL> # 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-console\": [rtxoialp79] 37249 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-debug-ssh\": [rtxoialp79] 37247 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-cli\": [rtxoialp79] 37245 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-cli\": [rtxoialp79] 37245 <NL> # 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE3-trib1-console\": [rtxoialp79] 37221 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE3-trib1-debug-ssh\": [rtxoialp79] 37219 <NL> # 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-console\": [rtxoialp79] 37217 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-debug-ssh\": [rtxoialp79] 37215 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-cli\": [rtxoialp79] 37213 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-cli\": [rtxoialp79] 37213 <NL> # 03:12:50 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE4-trib1-console\": [rtxoialp79] 37194 <NL> # 03:12:50 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:50 ntp-wait-for-devices INFO: main:     take job_name \"NE4-trib1-debug-ssh\": [rtxoialp79] 37193 <NL> pip3-virtualenv-install-and-execute-cmd: installing into VIRTUALENV_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\" <NL> pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"venv\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\""}
{"timestamp_utc": "2024-07-31T08:13:00.895Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"ensurepip\""}
{"timestamp_utc": "2024-07-31T08:13:02.832Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Requirement already satisfied: setuptools in ./.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib/python3.6/site-packages <NL> Requirement already satisfied: pip in ./.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib/python3.6/site-packages <NL> pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"pip\" \"install\" \"--upgrade\" \"pip\""}
{"timestamp_utc": "2024-07-31T08:13:04.197Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Collecting pip"}
{"timestamp_utc": "2024-07-31T08:13:04.454Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hInstalling collected packages: pip <NL> Found existing installation: pip 9.0.3"}
{"timestamp_utc": "2024-07-31T08:13:05.015Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Uninstalling pip-9.0.3:"}
{"timestamp_utc": "2024-07-31T08:13:05.271Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Successfully uninstalled pip-9.0.3"}
{"timestamp_utc": "2024-07-31T08:13:07.163Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Successfully installed pip-21.3.1 <NL> \u001b[33mYou are using pip version 21.3.1, however version 24.2 is available. <NL> You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m <NL> pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"pip\" \"install\" \"paramiko\""}
{"timestamp_utc": "2024-07-31T08:13:08.091Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Looking in indexes: https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/simple"}
{"timestamp_utc": "2024-07-31T08:13:08.347Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Collecting paramiko"}
{"timestamp_utc": "2024-07-31T08:13:08.603Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/ad/50/8792484502c8141c20c996b802fefa8435a9c018a2bb440a06b172782118/paramiko-3.4.0-py3-none-any.whl (225 kB)"}
{"timestamp_utc": "2024-07-31T08:13:08.860Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hCollecting bcrypt>=3.2 <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/aa/48/fd2b197a9741fa790ba0b88a9b10b5e88e62ff5cf3e1bc96d8354d7ce613/bcrypt-4.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (593 kB)"}
{"timestamp_utc": "2024-07-31T08:13:09.117Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\u001b[?25hCollecting pynacl>=1.5"}
{"timestamp_utc": "2024-07-31T08:13:11.008Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\u001b[?25hCollecting cryptography>=3.3"}
{"timestamp_utc": "2024-07-31T08:13:12.378Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hCollecting cffi>=1.12 <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/3a/12/d6066828014b9ccb2bbb8e1d9dc28872d20669b65aeb4a86806a0757813f/cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB) <NL> \u001b[?25hCollecting pycparser <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/62/d5/5f610ebe421e85889f2e55e33b7f9a6795bd982198517d912eb1c76e1a53/pycparser-2.21-py2.py3-none-any.whl (118 kB)"}
{"timestamp_utc": "2024-07-31T08:13:12.635Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hInstalling collected packages: pycparser, cffi, pynacl, cryptography, bcrypt, paramiko"}
{"timestamp_utc": "2024-07-31T08:13:14.000Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Successfully installed bcrypt-4.0.1 cffi-1.15.1 cryptography-40.0.2 paramiko-3.4.0 pycparser-2.21 pynacl-1.5.0"}
{"timestamp_utc": "2024-07-31T08:13:14.257Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: execute: \"exec-job-tree --timeout 28800 --job-begin-parallel --name all (p) --job-begin-command --name NE1-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37315 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE1-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37286 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE2-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37283 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE2-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37253 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE3-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37249 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE3-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37221 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE4-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37217 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE4-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37194 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-serial --name start+user (s) --parallel-siblings-terminate-on-my-completion --job-begin-parallel --name startup (p) --timeout 1200 --job-begin-serial --name main-startup (s) --job-begin-command --name NE1-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37313 --delay 5 --cmd-end --job-end --job-begin-command --name NE1-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37311 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE1-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37285 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE2-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37281 --delay 5 --cmd-end --job-end --job-begin-command --name NE2-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37279 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE2-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37251 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE3-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37247 --delay 5 --cmd-end --job-end --job-begin-command --name NE3-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37245 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE3-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37219 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE4-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37215 --delay 5 --cmd-end --job-end --job-begin-command --name NE4-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37213 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE4-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37193 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name Warrior --cmd-begin run_init --runinit_venv_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir --services_env /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json --work_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148 -v -e warrior --test_engine_venv_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir --test_engine /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json --cmd-end --job-end --job-end --job-end\""}
{"timestamp_utc": "2024-07-31T08:13:14.258Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"exec-job-tree\" \"--timeout\" \"28800\" \"--job-begin-parallel\" \"--name\" \"all (p)\" \"--job-begin-command\" \"--name\" \"NE1-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37315\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37286\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37283\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37253\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37249\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37221\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37217\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37194\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"start+user (s)\" \"--parallel-siblings-terminate-on-my-completion\" \"--job-begin-parallel\" \"--name\" \"startup (p)\" \"--timeout\" \"1200\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE1-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37313\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37311\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37285\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE2-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37281\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37279\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37251\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE3-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37247\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37245\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37219\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE4-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37215\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37213\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37193\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"Warrior\" \"--cmd-begin\" \"run_init\" \"--runinit_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\" \"--services_env\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\" \"--work_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\" \"-v\" \"-e\" \"warrior\" \"--test_engine_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\" \"--test_engine\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-end\""}
{"timestamp_utc": "2024-07-31T08:13:14.515Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:14 exec-job-tree INFO: parse_arguments: ( 0) arg timeout=\"28800\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 0) \"--job-begin-parallel\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   arg name=\"all (p)\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE1-main-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\""}
{"timestamp_utc": "2024-07-31T08:13:14.516Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37315', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE1-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37286', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE2-main-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37283', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE2-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37253', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE3-main-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37249', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE3-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37221', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE4-main-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37217', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE4-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37194', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-serial\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"start+user (s)\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-begin-parallel\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       arg name=\"startup (p)\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       arg timeout=\"1200\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE1-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37313', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE1-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37311', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE1-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37285', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE2-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37281', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE2-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37279', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE2-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37251', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE3-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37247', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE3-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37245', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE3-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37219', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE4-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37215', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE4-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37213', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE4-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37193', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-begin-command\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       arg name=\"Warrior\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       command ['run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json'] <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-end\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 0){ <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 0)  type \"none\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 0)  name \"none\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 0)  child_index None <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 0)  option \"timeout\" = \"28800\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 1)  { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 1)    type \"parallel\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 1)    name \"n01.all (p)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 1)    child_index 0"}
{"timestamp_utc": "2024-07-31T08:13:14.517Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:14 exec-job-tree INFO: job_cl::show: ##( 1)    option \"name\" = \"all (p)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p01.NE1-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 0 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE1-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37315', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p02.NE1-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 1 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE1-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37286', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p03.NE2-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 2 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE2-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37283', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p04.NE2-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 3 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE2-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37253', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p05.NE3-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 4 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE3-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37249', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p06.NE3-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 5 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE3-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37221', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p07.NE4-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 6 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE4-main-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37217', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p08.NE4-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 7 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE4-trib1-console\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37194', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p09.start+user (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 8 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"start+user (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)      { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        type \"parallel\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        name \"n01.p09.s01.startup (p)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        child_index 0 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        option \"name\" = \"startup (p)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        option \"timeout\" = \"1200\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p01.main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 0 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE1-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37313', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p01.s02.NE1-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE1-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37311', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 1 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE1-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37285', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p03.main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 2 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE2-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37281', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p03.s02.NE2-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE2-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37279', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 3 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE2-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37251', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p05.main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 4 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\""}
{"timestamp_utc": "2024-07-31T08:13:14.518Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE3-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37247', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p05.s02.NE3-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE3-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37245', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 5 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE3-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37219', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p07.main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 6 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE4-main-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37215', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p07.s02.NE4-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE4-main-cli\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37213', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 7 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE4-trib1-debug-ssh\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37193', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)      } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)      { <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        type \"command\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        name \"n01.p09.s02.Warrior\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        child_index 1 <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        option \"name\" = \"Warrior\" <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)        command ['run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 3)      } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 1)  } <NL> # 03:13:14 exec-job-tree INFO: job_cl::show: ##( 0)} <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::__enter__ <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37315', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p01.NE1-main-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p01.NE1-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37315', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p01.NE1-main-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37286', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p02.NE1-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p02.NE1-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37286', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p02.NE1-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37283', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p03.NE2-main-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p03.NE2-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37283', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p03.NE2-main-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37253', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p04.NE2-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p04.NE2-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37253', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p04.NE2-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37249', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p05.NE3-main-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p05.NE3-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37249', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p05.NE3-main-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37221', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p06.NE3-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p06.NE3-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37221', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p06.NE3-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37217', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p07.NE4-main-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p07.NE4-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37217', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p07.NE4-main-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37194', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p08.NE4-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p08.NE4-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37194', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p08.NE4-trib1-console) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37313', '--delay', '5'] (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37313', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37285', '--delay', '5'] (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37285', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37281', '--delay', '5'] (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37281', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37251', '--delay', '5'] (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37251', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37247', '--delay', '5'] (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37247', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37219', '--delay', '5'] (n01.p09.s01.p06.NE3-trib1-debug-ssh)"}
{"timestamp_utc": "2024-07-31T08:13:14.519Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37219', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37215', '--delay', '5'] (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37215', '--delay', '5'] <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37193', '--delay', '5'] (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37193', '--delay', '5']"}
{"timestamp_utc": "2024-07-31T08:13:14.775Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:14 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 3)        (executing) type \"parallel\": started 8 children (n01.p09.s01.startup (p)) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"serial\": started child #0 (n01.p09.start+user (s)) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 1)    (executing) type \"parallel\": started 9 children (n01.all (p)) <NL> # 03:13:14 exec-job-tree INFO: job_cl::start:  ( 0)  (executing) type \"none\": started child #0 (none) <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p01.NE1-main-console\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p02.NE1-trib1-console\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p03.NE2-main-console\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p04.NE2-trib1-console\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p05.NE3-main-console\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p06.NE3-trib1-console\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p07.NE4-main-console\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p08.NE4-trib1-console\", type \"command\""}
{"timestamp_utc": "2024-07-31T08:13:15.032Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "# 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.main-startup (s)\", type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.main-startup (s)\", type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.main-startup (s)\", type \"serial\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"command\" <NL> # 03:13:14 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.main-startup (s)\", type \"serial\" <NL> # 03:13:15 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"command\" <NL> # 03:13:15 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.startup (p)\", type \"parallel\" <NL> # 03:13:15 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.start+user (s)\", type \"serial\" <NL> # 03:13:15 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.all (p)\", type \"parallel\" <NL> # 03:13:15 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"none\", type \"none\" <NL> # 03:13:15 exec-job-tree INFO: process_list_cl::wait: begin, timeout 28800.0 <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37217; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37217 <NL> (process:691): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 5a54001, primary cpu clock <NL> [    0.000000] kvm-clock: using sched offset of 4665513025 cycles <NL> [    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000021] tsc: Detected 2095.076 MHz processor <NL> [    0.019362] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.019457] x86/PAT: PAT not supported by the CPU. <NL> [    0.019470] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC"}
{"timestamp_utc": "2024-07-31T08:13:15.033Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[    0.057276] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.057387] check: Scanning 1 areas for low memory corruption <NL> [    0.057672] ACPI: Early table checksum verification disabled <NL> [    0.057700] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.057713] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.057729] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.057740] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.057747] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.057754] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.057761] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.057768] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.057775] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.057778] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.057780] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.057782] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.057785] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.057787] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.057863] Zone ranges: <NL> [    0.057865]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.057868]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.057871]   Normal   empty <NL> [    0.057874] Movable zone start for each node <NL> [    0.057876] Early memory node ranges <NL> [    0.057878]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.057881]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.057884] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.058387] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.058416] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.071124] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.089792] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.089817] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.089862] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.089868] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.089872] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.089874] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.089884] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.089886] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.089899] Using ACPI (MADT) for SMP configuration information <NL> [    0.089902] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.089911] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.089950] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.089953] Booting paravirtualized kernel on KVM <NL> [    0.089958] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.089973] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.090754] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.090801] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.090811] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.090815] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.091276] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.091371] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.091479] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.095272] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.095348] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.095359] Kernel/User page tables isolation: enabled <NL> [    0.095396] ftrace: allocating 47967 entries in 188 pages <NL> [    0.306382] ftrace: allocated 188 pages with 5 groups <NL> [    0.306580] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.306583] rcu: \tRCU event tracing is enabled. <NL> [    0.306585] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.306588] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.306592] \tRude variant of Tasks RCU enabled. <NL> [    0.306594] \tTracing variant of Tasks RCU enabled. <NL> [    0.306597] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.306600] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.330269] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.360795] Console: colour VGA+ 80x25 <NL> [    0.751925] printk: console [ttyS0] enabled <NL> [    0.752497] ACPI: Core revision 20200925 <NL> [    0.757268] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.765034] APIC: Switch to symmetric I/O mode setup <NL> [    0.767358] x2apic enabled <NL> [    0.769844] Switched APIC routing to physical x2apic. <NL> [    0.777724] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.780029] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.789732] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.790881] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.791736] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.792516] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.792739] Spectre V2 : Mitigation: Retpolines <NL> [    0.793319] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.793737] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.794736] Speculative Store Bypass: Vulnerable <NL> [    0.795735] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.796735] MMIO Stale Data: Unknown: No mitigations <NL> [    0.797738] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.834969] Freeing SMP alternatives memory: 48K <NL> [    0.835754] pid_max: default: 32768 minimum: 301 <NL> [    0.836771] LSM: Security Framework initializing <NL> [    0.838751] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.839777] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear)"}
{"timestamp_utc": "2024-07-31T08:13:15.303Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[    0.867759] APIC calibration not consistent with PM-Timer: 107ms instead of 100ms <NL> [    0.868729] APIC delta adjusted to PM-Timer: 6250097 (6696059) <NL> [    0.868788] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.870822] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.873871] rcu: Hierarchical SRCU implementation. <NL> [    0.875292] smp: Bringing up secondary CPUs ... <NL> [    0.876082] x86: Booting SMP configuration: <NL> [    0.876733] .... node  #0, CPUs:      #1 <NL> [    0.449676] kvm-clock: cpu 1, msr 5a54041, secondary cpu clock <NL> [    0.449676] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.882807] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.891144]  #2 <NL> [    0.449676] kvm-clock: cpu 2, msr 5a54081, secondary cpu clock <NL> [    0.449676] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.897768] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    0.906187]  #3 <NL> [    0.449676] kvm-clock: cpu 3, msr 5a540c1, secondary cpu clock <NL> [    0.449676] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.910809] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    0.911752] smp: Brought up 1 node, 4 CPUs <NL> [    0.912740] smpboot: Max logical packages: 4 <NL> [    0.913758] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    0.928876] devtmpfs: initialized <NL> [    0.932771] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.933745] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.935797] pinctrl core: initialized pinctrl subsystem <NL> [    0.939247] NET: Registered protocol family 16 <NL> [    0.941051] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.941052] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.942754] cpuidle: using governor menu <NL> [    0.944843] ACPI: bus type PCI registered <NL> [    0.946855] PCI: Using configuration type 1 for base access <NL> [    0.951371] Kprobes globally optimized <NL> [    1.099735] raid6: sse2x4   gen()  4120 MB/s <NL> [    1.116738] raid6: sse2x4   xor()  2542 MB/s <NL> [    1.134743] raid6: sse2x2   gen()  4281 MB/s <NL> [    1.152736] raid6: sse2x2   xor()  2969 MB/s <NL> [    1.170737] raid6: sse2x1   gen()  4135 MB/s <NL> [    1.188739] raid6: sse2x1   xor()  2783 MB/s <NL> [    1.189736] raid6: using algorithm sse2x2 gen() 4281 MB/s <NL> [    1.190736] raid6: .... xor() 2969 MB/s, rmw enabled <NL> [    1.191738] raid6: using intx1 recovery algorithm <NL> [    1.192826] ACPI: Added _OSI(Module Device) <NL> [    1.193736] ACPI: Added _OSI(Processor Device) <NL> [    1.194735] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.195735] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.196737] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.197736] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.198733] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.202409] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.204989] ACPI: Interpreter enabled <NL> [    1.205754] ACPI: (supports S0 S3 S5) <NL> [    1.206733] ACPI: Using IOAPIC for interrupt routing <NL> [    1.207764] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.209017] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.214499] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.214747] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.215751] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.216891] PCI host bridge to bus 0000:00 <NL> [    1.217421] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.217743] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.218737] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.219743] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.220734] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.221742] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.222743] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.223740] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.224795] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.227276] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100"}
{"timestamp_utc": "2024-07-31T08:13:15.304Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[    1.229787] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.235738] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.238594] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.238740] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.239740] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.240736] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.242953] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.244337] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.244747] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.246092] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.248784] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.252786] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.263785] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.266249] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.268567] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.270739] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.280592] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.282112] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.284739] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.287739] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.297740] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.299971] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.302739] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.305739] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.315739] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.317770] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.320739] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.323738] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.333738] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.335899] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.338739] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.341741] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.354217] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.354930] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.355898] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.356859] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.357829] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.359957] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.360729] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.360742] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.361733] vgaarb: loaded <NL> [    1.364762] SCSI subsystem initialized <NL> [    1.367821] ACPI: bus type USB registered <NL> [    1.368427] usbcore: registered new interface driver usbfs <NL> [    1.368759] usbcore: registered new interface driver hub <NL> [    1.369752] usbcore: registered new device driver usb <NL> [    1.370769] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.371399] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.371751] PTP clock support registered <NL> [    1.374233] Bluetooth: Core ver 2.22 <NL> [    1.374769] NET: Registered protocol family 31 <NL> [    1.375732] Bluetooth: HCI device and connection manager initialized <NL> [    1.376744] Bluetooth: HCI socket layer initialized <NL> [    1.377392] Bluetooth: L2CAP socket layer initialized <NL> [    1.377762] Bluetooth: SCO socket layer initialized <NL> [    1.379789] PCI: Using ACPI for IRQ routing <NL> [    1.381037] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.381771] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.382736] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.393759] clocksource: Switched to clocksource kvm-clock <NL> [    2.305252] pnp: PnP ACPI init <NL> [    2.315414] pnp: PnP ACPI: found 7 devices <NL> [    2.351247] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.379109] NET: Registered protocol family 2 <NL> [    2.391341] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    2.409863] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    2.429344] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.430458] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    2.431552] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    2.432608] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.450546] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.452286] NET: Registered protocol family 1 <NL> [    2.524946] RPC: Registered named UNIX socket transport module. <NL> [    2.526503] RPC: Registered udp transport module. <NL> [    2.527269] RPC: Registered tcp transport module. <NL> [    2.528244] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.535984] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.537848] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.564806] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.565612] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.566408] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.567200] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.568078] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    2.575049] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.575805] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.576553] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.577400] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.579967] PCI: CLS 0 bytes, default 64 <NL> [    2.580746] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.608803] check: Scanning for low memory corruption every 60 seconds <NL> [    2.610137] Initialise system trusted keyrings <NL> [    2.610891] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.633152] NFS: Registering the id_resolver key type <NL> [    2.633841] Key type id_resolver registered <NL> [    2.634375] Key type id_legacy registered <NL> [    2.638448] Key type cifs.idmap registered <NL> [    2.644807] 9p: Installing v9fs 9p2000 file system support <NL> [    2.645699] xor: measuring software checksum speed <NL> [    2.647437]    prefetch64-sse  :  9410 MB/sec <NL> [    2.649493]    generic_sse     :  6935 MB/sec <NL> [    2.650099] xor: using function: prefetch64-sse (9410 MB/sec) <NL> [    2.655339] Key type asymmetric registered <NL> [    2.655910] Asymmetric key parser 'x509' registered <NL> [    2.656546] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.694789] io scheduler mq-deadline registered <NL> [    2.695398] io scheduler kyber registered <NL> [    2.701064] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.710896] ACPI: Power Button [PWRF] <NL> [    2.731068] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.732724] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.750406] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.752251] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.753382] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A"}
{"timestamp_utc": "2024-07-31T08:13:15.305Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[    2.765662] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.772813] Linux agpgart interface v0.103 <NL> [    2.775218] ACPI: bus type drm_connector registered <NL> [    2.846376] brd: module loaded <NL> [    2.867358] loop: module loaded <NL> [    2.879656] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.903422] vda: detected capacity change from 0 to 2576215040 <NL> [    2.947340] Uniform Multi-Platform E-IDE driver <NL> [    2.958203] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.978920] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.990092] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.990092] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.992615]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.993210]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    4.285868] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.914912] hdc: MWDMA2 mode selected <NL> [    4.915596] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.916254] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.917063] ide-gd driver 1.18 <NL> [    4.920362] e100: Intel(R) PRO/100 Network Driver <NL> [    4.920998] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.921731] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.922348] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.655416] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.662950] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.664359] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    6.603805] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:2a <NL> [    6.605462] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.606887] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    7.282377] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:2b <NL> [    7.292336] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    7.298304] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    8.115575] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:2c <NL> [    8.128663] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    8.139457] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    8.149417] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    8.150940] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    8.158458] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    8.169266] PPP generic driver version 2.4.2 <NL> [    8.171806] PPP BSD Compression module registered <NL> [    8.172431] PPP Deflate Compression module registered <NL> [    8.173091] NET: Registered protocol family 24 <NL> [    8.173673] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    8.174882] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    8.181836] SLIP linefill/keepalive option. <NL> [    8.182390] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    8.183233] ehci-pci: EHCI PCI platform driver <NL> [    8.183851] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    8.184641] ohci-pci: OHCI PCI platform driver <NL> [    8.185236] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    8.193336] usbcore: registered new interface driver usb-storage <NL> [    8.194169] usbcore: registered new interface driver usbserial_generic <NL> [    8.195135] usbserial: USB Serial support registered for generic <NL> [    8.196074] usbcore: registered new interface driver ftdi_sio <NL> [    8.202965] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    8.203954] usbcore: registered new interface driver pl2303 <NL> [    8.204742] usbserial: USB Serial support registered for pl2303 <NL> [    8.205575] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    8.213396] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    8.214126] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    8.218762] mousedev: PS/2 mouse device common for all mice <NL> [    8.224173] rtc_cmos 00:00: RTC can wake from S4 <NL> [    8.225818] rtc_cmos 00:00: registered as rtc0 <NL> [    8.231270] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:02 UTC (1722413582) <NL> [    8.232881] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    8.239877] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    8.246993] intel_pstate: CPU model not supported <NL> [    8.248464] sdhci: Secure Digital Host Controller Interface driver <NL> [    8.249926] sdhci: Copyright(c) Pierre Ossman <NL> [    8.251063] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    8.252184] usbcore: registered new interface driver usbhid <NL> [    8.253151] usbhid: USB HID core driver <NL> [    8.253748] u32 classifier <NL> [    8.254220]     input device check on <NL> [    8.254737]     Actions configured <NL> [    8.255707] xt_time: kernel timezone is -0000 <NL> [    8.257667] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    8.260744] gre: GRE over IPv4 demultiplexor driver <NL> [    8.261364] ip_gre: GRE over IPv4 tunneling driver <NL> [    8.262726] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    8.263788] NET: Registered protocol family 10 <NL> [    8.263821] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    8.279395] Segment Routing with IPv6 <NL> [    8.280062] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    8.281221] ip6_gre: GRE over IPv6 tunneling driver <NL> [    8.289403] NET: Registered protocol family 17 <NL> [    8.290452] Bridge firewalling registered <NL> [    8.291485] 8021q: 802.1Q VLAN Support v1.8 <NL> [    8.292325] 9pnet: Installing 9P2000 support <NL> [    8.293039] Key type dns_resolver registered <NL> [    8.295800] NET: Registered protocol family 40 <NL> [    8.307823] IPI shorthand broadcast: enabled <NL> [    8.308424] sched_clock: Marking stable (7859056412, 448676095)->(9805557809, -1497825302) <NL> [    8.309574] registered taskstats version 1 <NL> [    8.310122] Loading compiled-in X.509 certificates <NL> [    8.344324] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    8.347659] Key type .fscrypt registered <NL> [    8.348258] Key type fscrypt-provisioning registered <NL> [    8.350645] Btrfs loaded, crc32c=crc32c-generic <NL> [    8.365253] Key type encrypted registered <NL> [    8.365989] printk: console [netcon0] enabled <NL> [    8.366567] netconsole: network logging started <NL> [    8.881699] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    8.887180] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    8.893043] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    8.902870] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    8.989849] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    8.990724] IP-Config: Failed to open gretap0 <NL> [    8.991285] IP-Config: Failed to open erspan0 <NL> [    9.001781] Sending DHCP requests . <NL> [   10.929296] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.931721] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.941583] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   10.942575] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   10.993250] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX"}
{"timestamp_utc": "2024-07-31T08:13:15.306Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   10.994746] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   10.997430] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.018315] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   11.766755] ., OK <NL> [   11.775120] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   11.776003] IP-Config: Complete: <NL> [   11.776407]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   11.777594]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   11.780233]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   11.780234]      nameserver0=10.0.2.3 <NL> [   12.019585] md: Waiting for all devices to be available before autodetect <NL> [   12.030816] md: If you don't use raid, use raid=noautodetect <NL> [   12.046753] md: Autodetecting RAID arrays. <NL> [   12.054324] md: autorun ... <NL> [   12.062466] md: ... autorun DONE. <NL> [   12.064909] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   12.112766] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   12.119057] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   12.126837] devtmpfs: mounted <NL> [   12.155603] Freeing unused kernel image (initmem) memory: 1964K <NL> [   12.164808] Write protecting the kernel read-only data: 22528k <NL> [   12.173397] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   12.190962] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   12.191928] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   12.492769] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   12.509419] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   12.674914] #####FSS INIT: Running on host <NL> [   12.915048] #####FSS INIT: FSS system init pre startup script <NL> [   12.984461] random: python3: uninitialized urandom read (24 bytes read) <NL> [   15.591755] random: crng init done <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37194; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37194 <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37315; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37221; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37315 <NL> (process:686): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 4da54001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 3928299849 cycles <NL> [    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000020] tsc: Detected 2095.076 MHz processor <NL> [    0.001948] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.002035] x86/PAT: PAT not supported by the CPU. <NL> [    0.002046] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.002062] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.013483] found SMP MP-table at [mem 0x000f6380-0x000f638f] <NL> [    0.013590] check: Scanning 1 areas for low memory corruption <NL> [    0.014411] ACPI: Early table checksum verification disabled <NL> [    0.014437] ACPI: RSDP 0x00000000000F61D0 000014 (v00 BOCHS ) <NL> [    0.014450] ACPI: RSDT 0x00000000BFFFFBC1 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.014466] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.014476] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.014484] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.014490] ACPI: SSDT 0x00000000BFFFF234 0008DD (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.014497] ACPI: APIC 0x00000000BFFFFB11 000078 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.014505] ACPI: HPET 0x00000000BFFFFB89 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001)"}
{"timestamp_utc": "2024-07-31T08:13:15.307Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[    0.014512] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.014514] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.014516] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.014519] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffb10] <NL> [    0.014521] ACPI: Reserving APIC table memory at [mem 0xbffffb11-0xbffffb88] <NL> [    0.014523] ACPI: Reserving HPET table memory at [mem 0xbffffb89-0xbffffbc0] <NL> [    0.014600] Zone ranges: <NL> [    0.014603]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.014606]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.014610]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.014613] Movable zone start for each node <NL> [    0.014615] Early memory node ranges <NL> [    0.014617]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.014620]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.014622]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.014626] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.015105] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.015140] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.037849] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.038486] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.038506] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.038552] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.038558] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.038562] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.038564] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.038573] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.038575] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.038587] Using ACPI (MADT) for SMP configuration information <NL> [    0.038591] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.038599] smpboot: Allowing 1 CPUs, 0 hotplug CPUs <NL> [    0.038638] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.038641] Booting paravirtualized kernel on KVM <NL> [    0.038647] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.038662] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:1 nr_node_ids:1 <NL> [    0.039318] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u2097152 <NL> [    0.039362] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.039371] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.039375] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.040908] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.041467] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.041517] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.071616] Memory: 4026940K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 166696K reserved, 0K cma-reserved) <NL> [    0.071681] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1 <NL> [    0.071693] Kernel/User page tables isolation: enabled <NL> [    0.071730] ftrace: allocating 47967 entries in 188 pages <NL> [    0.124120] ftrace: allocated 188 pages with 5 groups <NL> [    0.124682] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.124685] rcu: \tRCU event tracing is enabled. <NL> [    0.124687] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=1. <NL> [    0.124690] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.124692] \tRude variant of Tasks RCU enabled. <NL> [    0.124693] \tTracing variant of Tasks RCU enabled. <NL> [    0.124695] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.124698] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1 <NL> [    0.131573] NR_IRQS: 4352, nr_irqs: 256, preallocated irqs: 16 <NL> [    0.138082] Console: colour VGA+ 80x25 <NL> [    0.427433] printk: console [ttyS0] enabled <NL> [    0.427997] ACPI: Core revision 20200925 <NL> [    0.428693] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.439289] APIC: Switch to symmetric I/O mode setup <NL> [    0.442592] x2apic enabled <NL> [    0.444596] Switched APIC routing to physical x2apic. <NL> [    0.448843] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.453410] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.454833] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.456971] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.457844] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.458845] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.459838] Spectre V2 : Mitigation: Retpolines <NL> [    0.460835] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.461835] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.462836] Speculative Store Bypass: Vulnerable <NL> [    0.463836] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.464835] MMIO Stale Data: Unknown: No mitigations <NL> [    0.465855] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.508450] Freeing SMP alternatives memory: 48K <NL> [    0.508850] pid_max: default: 32768 minimum: 301 <NL> [    0.509867] LSM: Security Framework initializing <NL> [    0.511407] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.511861] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.616103] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.618032] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.620953] rcu: Hierarchical SRCU implementation. <NL> [    0.622203] smp: Bringing up secondary CPUs ..."}
{"timestamp_utc": "2024-07-31T08:13:15.308Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[    0.622835] smp: Brought up 1 node, 1 CPU <NL> [    0.623353] smpboot: Max logical packages: 1 <NL> [    0.623835] smpboot: Total of 1 processors activated (4190.15 BogoMIPS) <NL> [    0.625202] devtmpfs: initialized <NL> [    0.626891] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.627845] futex hash table entries: 256 (order: 2, 16384 bytes, linear) <NL> [    0.628893] pinctrl core: initialized pinctrl subsystem <NL> [    0.631033] NET: Registered protocol family 16 <NL> [    0.632969] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.632978] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.634410] cpuidle: using governor menu <NL> [    0.635911] ACPI: bus type PCI registered <NL> [    0.637087] PCI: Using configuration type 1 for base access <NL> [    0.641901] Kprobes globally optimized <NL> [    0.755858] raid6: sse2x4   gen()  5354 MB/s <NL> [    0.773851] raid6: sse2x4   xor()  3361 MB/s <NL> [    0.791839] raid6: sse2x2   gen()  4385 MB/s <NL> [    0.808838] raid6: sse2x2   xor()  2831 MB/s <NL> [    0.825839] raid6: sse2x1   gen()  3398 MB/s <NL> [    0.843840] raid6: sse2x1   xor()  2361 MB/s <NL> [    0.844844] raid6: using algorithm sse2x4 gen() 5354 MB/s <NL> [    0.845841] raid6: .... xor() 3361 MB/s, rmw enabled <NL> [    0.846843] raid6: using intx1 recovery algorithm <NL> [    0.848870] ACPI: Added _OSI(Module Device) <NL> [    0.849456] ACPI: Added _OSI(Processor Device) <NL> [    0.849835] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.850489] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.850836] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.851835] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.852842] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.855954] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.859273] ACPI: Interpreter enabled <NL> [    0.859855] ACPI: (supports S0 S3 S5) <NL> [    0.860344] ACPI: Using IOAPIC for interrupt routing <NL> [    0.860862] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.862036] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    0.867490] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    0.867857] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    0.868846] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    0.869972] PCI host bridge to bus 0000:00 <NL> [    0.870509] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    0.870843] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    0.871836] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    0.872836] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    0.873836] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    0.874837] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    0.875847] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    0.876779] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    0.876903] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    0.878962] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    0.881547] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    0.886699] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    0.889309] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    0.889849] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    0.890836] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    0.891837] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    0.894256] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    0.896721] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    0.896867] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    0.899215] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    0.901880] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    0.904877] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    0.915882] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    0.918027] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    0.920838] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    0.923636] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    0.932622] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    0.934176] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    0.936840] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    0.938842] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    0.949654] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    0.950365] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    0.952616] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    0.954841] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    0.964843] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    0.966155] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    0.968841] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    0.971847] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    0.981843] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    0.983152] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    0.985842] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    0.989841] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    0.998843] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.000172] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    1.002842] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.005654] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    1.014844] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.016888] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    1.019845] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    1.022681] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    1.031842] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.034102] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.036842] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    1.039842] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    1.051505] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.052969] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.054003] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.055005] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.055943] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.057979] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.058831] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.058847] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.059837] vgaarb: loaded <NL> [    1.060408] SCSI subsystem initialized <NL> [    1.060999] ACPI: bus type USB registered <NL> [    1.061879] usbcore: registered new interface driver usbfs <NL> [    1.062613] usbcore: registered new interface driver hub <NL> [    1.062849] usbcore: registered new device driver usb <NL> [    1.063861] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.064860] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.066864] PTP clock support registered <NL> [    1.068393] Bluetooth: Core ver 2.22 <NL> [    1.068857] NET: Registered protocol family 31 <NL> [    1.069841] Bluetooth: HCI device and connection manager initialized <NL> [    1.070854] Bluetooth: HCI socket layer initialized <NL> [    1.071859] Bluetooth: L2CAP socket layer initialized"}
{"timestamp_utc": "2024-07-31T08:13:15.309Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[    1.072857] Bluetooth: SCO socket layer initialized <NL> [    1.073976] PCI: Using ACPI for IRQ routing <NL> [    1.076022] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.076867] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.077835] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.082892] clocksource: Switched to clocksource kvm-clock <NL> [    2.005604] pnp: PnP ACPI init <NL> [    2.016282] pnp: PnP ACPI: found 7 devices <NL> [    2.049577] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.073789] NET: Registered protocol family 2 <NL> [    2.091202] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    2.105435] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    2.114777] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    2.120634] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    2.125299] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    2.129217] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.132662] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.136459] NET: Registered protocol family 1 <NL> [    2.139064] RPC: Registered named UNIX socket transport module. <NL> [    2.142189] RPC: Registered udp transport module. <NL> [    2.143080] RPC: Registered tcp transport module. <NL> [    2.143666] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.144483] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.145273] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.146059] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.146814] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.155997] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.158593] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.161693] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    2.165537] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.168386] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.171224] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.175988] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.177150] PCI: CLS 0 bytes, default 64 <NL> [    2.177774] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    2.178614] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    2.191736] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.193153] check: Scanning for low memory corruption every 60 seconds <NL> [    2.194409] Initialise system trusted keyrings <NL> [    2.195128] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    2.201338] NFS: Registering the id_resolver key type <NL> [    2.226543] Key type id_resolver registered <NL> [    2.229293] Key type id_legacy registered <NL> [    2.231987] Key type cifs.idmap registered <NL> [    2.234927] 9p: Installing v9fs 9p2000 file system support <NL> [    2.238041] xor: measuring software checksum speed <NL> [    2.240221]    prefetch64-sse  :  9382 MB/sec <NL> [    2.242238]    generic_sse     :  6787 MB/sec <NL> [    2.256692] xor: using function: prefetch64-sse (9382 MB/sec) <NL> [    2.266918] Key type asymmetric registered <NL> [    2.273028] Asymmetric key parser 'x509' registered <NL> [    2.275564] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.282058] io scheduler mq-deadline registered <NL> [    2.282642] io scheduler kyber registered <NL> [    2.284157] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.303973] ACPI: Power Button [PWRF] <NL> [    2.306896] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    2.319753] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    2.329299] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.343609] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.347429] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.355813] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.360644] Linux agpgart interface v0.103 <NL> [    2.363624] ACPI: bus type drm_connector registered <NL> [    2.491069] brd: module loaded <NL> [    2.501571] loop: module loaded <NL> [    2.506044] virtio_blk virtio0: [vda] 5016568 512-byte logical blocks (2.57 GB/2.39 GiB) <NL> [    2.523544] vda: detected capacity change from 0 to 2568482816 <NL> [    2.545441] Uniform Multi-Platform E-IDE driver <NL> [    2.547067] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.550017] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.556793] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.556793] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.568865]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    2.575568]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    3.819614] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.450999] hdc: MWDMA2 mode selected <NL> [    4.451688] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.452322] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.453090] ide-gd driver 1.18 <NL> [    4.453961] e100: Intel(R) PRO/100 Network Driver <NL> [    4.456155] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.465681] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.469998] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.476827] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    5.166513] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.176736] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.178138] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    5.958277] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:27 <NL> [    5.969333] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.981445] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.681215] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:26 <NL> [    6.686364] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    7.448572] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:24 <NL> [    7.455710] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    8.165256] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:25 <NL> [    8.171553] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    8.789741] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:23 <NL> [    8.791893] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    9.420708] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:28 <NL> [    9.427435] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    9.431171] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    9.433708] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    9.436100] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    9.436785] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    9.437532] PPP generic driver version 2.4.2 <NL> [    9.438172] PPP BSD Compression module registered <NL> [    9.438771] PPP Deflate Compression module registered <NL> [    9.439417] NET: Registered protocol family 24 <NL> [    9.447406] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    9.460711] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    9.464308] SLIP linefill/keepalive option. <NL> [    9.466126] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    9.469520] ehci-pci: EHCI PCI platform driver <NL> [    9.472321] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver"}
{"timestamp_utc": "2024-07-31T08:13:15.310Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[    9.475539] ohci-pci: OHCI PCI platform driver <NL> [    9.480394] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    9.483587] usbcore: registered new interface driver usb-storage <NL> [    9.486644] usbcore: registered new interface driver usbserial_generic <NL> [    9.498364] usbserial: USB Serial support registered for generic <NL> [    9.501504] usbcore: registered new interface driver ftdi_sio <NL> [    9.504273] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    9.507782] usbcore: registered new interface driver pl2303 <NL> [    9.510307] usbserial: USB Serial support registered for pl2303 <NL> [    9.513410] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    9.518178] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    9.529702] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    9.532262] mousedev: PS/2 mouse device common for all mice <NL> [    9.535792] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    9.540813] rtc_cmos 00:00: RTC can wake from S4 <NL> [    9.546279] rtc_cmos 00:00: registered as rtc0 <NL> [    9.562324] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:02 UTC (1722413582) <NL> [    9.567595] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    9.571330] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    9.576407] intel_pstate: CPU model not supported <NL> [    9.579155] sdhci: Secure Digital Host Controller Interface driver <NL> [    9.580222] sdhci: Copyright(c) Pierre Ossman <NL> [    9.580823] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    9.581728] usbcore: registered new interface driver usbhid <NL> [    9.582438] usbhid: USB HID core driver <NL> [    9.585100] u32 classifier <NL> [    9.586036]     input device check on <NL> [    9.587084]     Actions configured <NL> [    9.600501] xt_time: kernel timezone is -0000 <NL> [    9.601161] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.602018] gre: GRE over IPv4 demultiplexor driver <NL> [    9.602643] ip_gre: GRE over IPv4 tunneling driver <NL> [    9.605321] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    9.607459] NET: Registered protocol family 10 <NL> [    9.610618] Segment Routing with IPv6 <NL> [    9.611574] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.612800] ip6_gre: GRE over IPv6 tunneling driver <NL> [    9.613639] NET: Registered protocol family 17 <NL> [    9.614263] Bridge firewalling registered <NL> [    9.614848] 8021q: 802.1Q VLAN Support v1.8 <NL> [    9.615461] 9pnet: Installing 9P2000 support <NL> [    9.616060] Key type dns_resolver registered <NL> [    9.620766] NET: Registered protocol family 40 <NL> [    9.621582] IPI shorthand broadcast: enabled <NL> [    9.622148] sched_clock: Marking stable (9305179022, 316928557)->(10217419421, -595311842) <NL> [    9.623287] registered taskstats version 1 <NL> [    9.623825] Loading compiled-in X.509 certificates <NL> [    9.639377] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    9.640731] Key type .fscrypt registered <NL> [    9.641264] Key type fscrypt-provisioning registered <NL> [    9.642974] Btrfs loaded, crc32c=crc32c-generic <NL> [    9.644224] Key type encrypted registered <NL> [    9.660351] printk: console [netcon0] enabled <NL> [    9.661893] netconsole: network logging started <NL> [   10.170012] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   10.755554] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.772933] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   10.784138] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   10.793610] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   10.813492] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   10.844557] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   10.855702] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   10.867256] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   10.873615] IP-Config: Failed to open gretap0 <NL> [   10.878184] IP-Config: Failed to open erspan0 <NL> [   10.882702] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   10.902667] Sending DHCP requests ., OK <NL> [   10.907545] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   10.915164] IP-Config: Complete: <NL> [   10.918584]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   10.923939]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   10.926730]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   10.926732]      nameserver0=10.0.2.3 <NL> [   11.241544] md: Waiting for all devices to be available before autodetect <NL> [   11.245543] md: If you don't use raid, use raid=noautodetect <NL> [   11.246415] md: Autodetecting RAID arrays. <NL> [   11.246951] md: autorun ... <NL> [   11.247302] md: ... autorun DONE. <NL> [   11.250858] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   11.280196] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   11.284865] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   11.286041] devtmpfs: mounted <NL> [   11.290787] Freeing unused kernel image (initmem) memory: 1964K <NL> [   11.291960] Write protecting the kernel read-only data: 22528k <NL> [   11.304390] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   11.305630] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   11.306483] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   11.551331] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   11.569288] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   11.699791] #####FSS INIT: Running on host <NL> [   11.783508] #####FSS INIT: FSS system init pre startup script <NL> [   11.811362] random: python3: uninitialized urandom read (24 bytes read) <NL> [   13.784974] random: crng init done <NL> [   15.080915] #####FSS INIT: UnitCode:c200  ShelfRole:MAIN <NL> [   15.092492] #####FSS INIT: FSS no slotRole found <NL> [   15.101745] #####FSS INIT: FSS system init get inputs from PSI c200 : MAIN <NL> [   15.114871] #####FSS INIT:PI data: unitCode=c200 Role=MAIN <NL> [   15.142906] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   15.168132] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-C200-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   15.183316] #####FSS INIT:Specific Target File found : /lib/systemd/system/FSS-C200-MAIN.target <NL> [   15.199722] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-C200-MAIN.target <NL> sh: -d: unknown operand <NL> [   15.230779] #####FSS INIT:systemd will take it from here! <NL> [   15.281231] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   15.347058] systemd[1]: Detected virtualization kvm. <NL> [   15.354452] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   15.376313] systemd[1]: Hostname set to <fujitsu>. <NL> [   15.386733] systemd[1]: Initializing machine ID from random generator. <NL> [   15.580783] systemd-sysv-generator[309]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   15.639434] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped"}
{"timestamp_utc": "2024-07-31T08:13:15.311Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[   15.874052] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.904129] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.929440] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.932710] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.955281] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   15.991222] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.013243] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.033172] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.041617] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.067596] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.076766] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.120282] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.143429] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.156748] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.166813] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.178059] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.190496] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.197810] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.214516] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.227419] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.241639] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.257894] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   16.269158] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   16.281820] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.294625] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.306585] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.327684] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.337333] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.344624] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.350195] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.357224] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.365594] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.374550] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.382802] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.385589] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.402030] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.409111] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.440733] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.458733] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.478573] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.489458] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.500042] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.511060] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.522420] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:15.312Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[   16.530412] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.541893] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.551109] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.575154] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   16.609459] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   16.619478] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   16.628626] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   16.638835] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   16.648919] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   16.651426] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   16.659320] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   16.661422] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   16.678379] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   16.680222] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   16.689920] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   16.691349] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   16.726273] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   16.728893] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   16.739413] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   16.753108] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   16.775751] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   16.777518] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   16.802629] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   16.804310] systemd[1]: Listening on udev Control Socket. <NL> [   16.819907] systemd[315]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   16.827787] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   16.846746] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   16.859002] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   16.871821] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   16.895246] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   16.928223] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   16.954925] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   16.969353] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   16.992498] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   17.012067] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   17.042023] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   17.073824] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   17.131561] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   17.191842] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   17.195353] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   17.244271] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   17.262555] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   17.305174] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   17.332322] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   17.334548] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   17.340999] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   17.347316] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   17.355588] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   17.359096] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   17.376171] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   17.460079] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   17.579604] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   17.599561] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   17.608668] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   17.677278] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   17.679098] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   17.710861] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   17.716991] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   17.735154] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   17.736838] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   17.753998] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   17.763312] systemd[1]: Mounting /var/volatile..."}
{"timestamp_utc": "2024-07-31T08:13:15.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   17.799248] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   17.819814] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   17.823061] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   17.827649] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   17.835076] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   17.847860] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   17.852410] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   17.880588] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   17.886069] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   17.896452] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   17.912048] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   17.976504] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   17.980999] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   17.987247] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   17.996771] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   18.000997] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   18.032676] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   18.056025] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   18.087566] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   18.161639] systemd[1]: Finished Load/Save Random Seed. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   18.181021] systemd[1]: First Boot Complete was skipped because of a failed condition check (ConditionFirstBoot=yes). <NL> [   18.200098] systemd[1]: Commit a transient machine-id on disk was skipped because of a failed condition check (ConditionPathIsMountPoint=/etc/machine-id). <NL> [   18.745026] fuse: init (API version 7.32) <NL> [   18.830821] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   18.849160] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   18.914298] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m...[   18.987169] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   19.007923] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   19.066889] systemd[1]: Started Rule-based Manager for Device Events and Files. <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37221 <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37249; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37283; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37283 <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37253; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37249 <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37253 <NL> (process:694): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80 <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 43e54001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 4720895185 cycles"}
{"timestamp_utc": "2024-07-31T08:13:15.314Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000023] tsc: Detected 2095.076 MHz processor <NL> [    0.001449] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.001545] x86/PAT: PAT not supported by the CPU. <NL> [    0.001556] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.001572] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.021073] found SMP MP-table at [mem 0x000f6340-0x000f634f] <NL> [    0.021199] check: Scanning 1 areas for low memory corruption <NL> [    0.022518] ACPI: Early table checksum verification disabled <NL> [    0.022550] ACPI: RSDP 0x00000000000F6110 000014 (v00 BOCHS ) <NL> [    0.022566] ACPI: RSDT 0x00000000BFFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.022583] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.022593] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.022600] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.022606] ACPI: SSDT 0x00000000BFFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.022613] ACPI: APIC 0x00000000BFFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.022621] ACPI: HPET 0x00000000BFFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.026648] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.026654] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.026657] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.026659] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffc33] <NL> [    0.026662] ACPI: Reserving APIC table memory at [mem 0xbffffc34-0xbffffcc3] <NL> [    0.026664] ACPI: Reserving HPET table memory at [mem 0xbffffcc4-0xbffffcfb] <NL> [    0.026783] Zone ranges: <NL> [    0.026786]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.026789]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.026792]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.026795] Movable zone start for each node <NL> [    0.026796] Early memory node ranges <NL> [    0.026799]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.026801]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.026803]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.026806] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.033958] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.033998] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.125310] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.126040] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.126063] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.126110] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.126116] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.126120] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.126123] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.126133] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.126135] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.126148] Using ACPI (MADT) for SMP configuration information <NL> [    0.126151] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.126160] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.126203] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.126206] Booting paravirtualized kernel on KVM <NL> [    0.126213] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.126229] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.127328] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.127379] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.127389] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.127392] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.130164] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.131116] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.131228] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.218799] Memory: 4026256K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 167380K reserved, 0K cma-reserved) <NL> [    0.218902] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.218929] Kernel/User page tables isolation: enabled <NL> [    0.219036] ftrace: allocating 47967 entries in 188 pages <NL> [    0.369903] ftrace: allocated 188 pages with 5 groups <NL> [    0.370347] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.370349] rcu: \tRCU event tracing is enabled. <NL> [    0.370352] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.370355] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.370356] \tRude variant of Tasks RCU enabled. <NL> [    0.370358] \tTracing variant of Tasks RCU enabled. <NL> [    0.370360] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.370363] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.392187] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.435829] Console: colour VGA+ 80x25 <NL> [    0.934504] printk: console [ttyS0] enabled <NL> [    0.935068] ACPI: Core revision 20200925 <NL> [    0.950377] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.951740] APIC: Switch to symmetric I/O mode setup <NL> [    0.952667] x2apic enabled <NL> [    0.953360] Switched APIC routing to physical x2apic. <NL> [    0.970444] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.984089] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.989299] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.990473] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.991305] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.992306] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.993307] Spectre V2 : Mitigation: Retpolines <NL> [    0.994302] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.995303] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.996301] Speculative Store Bypass: Vulnerable <NL> [    0.997302] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.998299] MMIO Stale Data: Unknown: No mitigations <NL> [    0.999304] x86/fpu: x87 FPU will use FXSAVE <NL> [    1.033830] Freeing SMP alternatives memory: 48K <NL> [    1.034322] pid_max: default: 32768 minimum: 301 <NL> [    1.036301] LSM: Security Framework initializing <NL> [    1.038383] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.039395] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.082370] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    1.084395] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    1.085469] rcu: Hierarchical SRCU implementation. <NL> [    1.088359] smp: Bringing up secondary CPUs ... <NL> [    1.089711] x86: Booting SMP configuration: <NL> [    1.090305] .... node  #0, CPUs:      #1 <NL> [    0.581176] kvm-clock: cpu 1, msr 43e54041, secondary cpu clock <NL> [    0.581176] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    1.103357] kvm-guest: stealtime: cpu 1, msr 13bc9b600 <NL> [    1.105699]  #2 <NL> [    0.581176] kvm-clock: cpu 2, msr 43e54081, secondary cpu clock <NL> [    0.581176] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    1.113337] kvm-guest: stealtime: cpu 2, msr 13bd1b600 <NL> [    1.115517]  #3 <NL> [    0.581176] kvm-clock: cpu 3, msr 43e540c1, secondary cpu clock <NL> [    0.581176] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    1.119354] kvm-guest: stealtime: cpu 3, msr 13bd9b600 <NL> [    1.121306] smp: Brought up 1 node, 4 CPUs <NL> [    1.121906] smpboot: Max logical packages: 4 <NL> [    1.122312] smpboot: Total of 4 processors activated (16760.60 BogoMIPS)"}
{"timestamp_utc": "2024-07-31T08:13:15.315Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[    1.134435] devtmpfs: initialized <NL> [    1.135462] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.136307] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    1.137431] pinctrl core: initialized pinctrl subsystem <NL> [    1.142447] NET: Registered protocol family 16 <NL> [    1.143706] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.143708] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.145331] cpuidle: using governor menu <NL> [    1.147399] ACPI: bus type PCI registered <NL> [    1.149313] PCI: Using configuration type 1 for base access <NL> [    1.156456] Kprobes globally optimized <NL> [    1.485313] raid6: sse2x4   gen()  2531 MB/s <NL> [    1.520308] raid6: sse2x4   xor()   887 MB/s <NL> [    1.548315] raid6: sse2x2   gen()  2531 MB/s <NL> [    1.577307] raid6: sse2x2   xor()  2860 MB/s <NL> [    1.622307] raid6: sse2x1   gen()  2065 MB/s <NL> [    1.677321] raid6: sse2x1   xor()  1246 MB/s <NL> [    1.684319] raid6: using algorithm sse2x4 gen() 2531 MB/s <NL> [    1.710310] raid6: .... xor() 887 MB/s, rmw enabled <NL> [    1.715302] raid6: using intx1 recovery algorithm <NL> [    1.723420] ACPI: Added _OSI(Module Device) <NL> [    1.741306] ACPI: Added _OSI(Processor Device) <NL> [    1.746306] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.760306] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.761302] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.762299] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.762983] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.771811] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.791606] ACPI: Interpreter enabled <NL> [    1.796330] ACPI: (supports S0 S3 S5) <NL> [    1.797928] ACPI: Using IOAPIC for interrupt routing <NL> [    1.798337] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.804595] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.823319] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.828327] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.830327] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.834536] PCI host bridge to bus 0000:00 <NL> [    1.838327] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.843315] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.847315] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.849308] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.854315] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.856309] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.858308] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    1.861307] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.863380] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.868372] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.871443] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.881713] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    1.890823] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.899313] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.905315] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.910315] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.914438] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.918346] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.921323] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.923811] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.931316] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.934362] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    1.954370] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    1.962323] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.967310] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    1.979252] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    2.000309] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    2.011757] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    2.023313] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    2.035309] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    2.051310] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    2.054602] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    2.057307] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    2.064311] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    2.072310] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    2.078745] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    2.084308] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    2.089308] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    2.097310] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    2.101708] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    2.104136] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    2.108310] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    2.115131] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    2.116711] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    2.119307] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    2.122308] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    2.132114] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    2.135696] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    2.144154] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    2.149306] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    2.161134] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    2.183799] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    2.189312] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    2.194310] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    2.210947] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    2.213315] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    2.216498] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    2.219504] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    2.222427] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    2.226358] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    2.227295] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    2.231316] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    2.231316] vgaarb: loaded <NL> [    2.234446] SCSI subsystem initialized <NL> [    2.246416] ACPI: bus type USB registered"}
{"timestamp_utc": "2024-07-31T08:13:15.316Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[    2.246416] usbcore: registered new interface driver usbfs <NL> [    2.247357] usbcore: registered new interface driver hub <NL> [    2.247357] usbcore: registered new device driver usb <NL> [    2.248354] pps_core: LinuxPPS API ver. 1 registered <NL> [    2.252308] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    2.254336] PTP clock support registered <NL> [    2.256516] Bluetooth: Core ver 2.22 <NL> [    2.257334] NET: Registered protocol family 31 <NL> [    2.258305] Bluetooth: HCI device and connection manager initialized <NL> [    2.258315] Bluetooth: HCI socket layer initialized <NL> [    2.259329] Bluetooth: L2CAP socket layer initialized <NL> [    2.260313] Bluetooth: SCO socket layer initialized <NL> [    2.263095] PCI: Using ACPI for IRQ routing <NL> [    2.263409] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    2.264333] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    2.264333] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    2.289160] clocksource: Switched to clocksource kvm-clock <NL> [    2.908453] pnp: PnP ACPI init <NL> [    2.916903] pnp: PnP ACPI: found 7 devices <NL> [    2.940704] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.957418] NET: Registered protocol family 2 <NL> [    2.989059] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    3.005035] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    3.013695] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    3.023300] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    3.046723] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    3.070521] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    3.076531] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    3.080607] NET: Registered protocol family 1 <NL> [    3.115703] RPC: Registered named UNIX socket transport module. <NL> [    3.119135] RPC: Registered udp transport module. <NL> [    3.121881] RPC: Registered tcp transport module. <NL> [    3.124079] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    3.127171] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    3.134479] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    3.137487] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    3.140480] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    3.143699] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    3.146590] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    3.153821] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    3.156624] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    3.157368] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    3.158119] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    3.158980] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    3.160142] PCI: CLS 0 bytes, default 64 <NL> [    3.160816] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    3.182246] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    3.186078] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    3.221637] check: Scanning for low memory corruption every 60 seconds <NL> [    3.233893] Initialise system trusted keyrings <NL> [    3.238889] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    3.268516] NFS: Registering the id_resolver key type <NL> [    3.278528] Key type id_resolver registered <NL> [    3.287138] Key type id_legacy registered <NL> [    3.316804] Key type cifs.idmap registered <NL> [    3.322542] 9p: Installing v9fs 9p2000 file system support <NL> [    3.325087] xor: measuring software checksum speed <NL> [    3.327143]    prefetch64-sse  :  9077 MB/sec <NL> [    3.329104]    generic_sse     :  7692 MB/sec <NL> [    3.336417] xor: using function: prefetch64-sse (9077 MB/sec) <NL> [    3.340584] Key type asymmetric registered <NL> [    3.342561] Asymmetric key parser 'x509' registered <NL> [    3.345238] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    3.359010] io scheduler mq-deadline registered <NL> [    3.361707] io scheduler kyber registered <NL> [    3.365075] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    3.379273] ACPI: Power Button [PWRF] <NL> [    3.405853] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    3.411905] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    3.420306] N_HDLC line discipline registered with maxframe=4096 <NL> [    3.426666] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    3.432349] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    3.436744] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    3.441800] Linux agpgart interface v0.103 <NL> [    3.444729] ACPI: bus type drm_connector registered <NL> [    3.460328] brd: module loaded <NL> [    3.471894] loop: module loaded <NL> [    3.481942] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    3.495094] vda: detected capacity change from 0 to 2576215040 <NL> [    3.504825] Uniform Multi-Platform E-IDE driver <NL> [    3.505478] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    3.506439] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    3.507369] legacy IDE will be removed in 2021, please switch to libata <NL> [    3.507369] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    3.509932]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    3.536896]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    4.783473] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    5.441438] hdc: MWDMA2 mode selected <NL> [    5.442167] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    5.442832] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    5.461890] ide-gd driver 1.18 <NL> [    5.476091] e100: Intel(R) PRO/100 Network Driver <NL> [    5.478090] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    5.478896] e1000: Intel(R) PRO/1000 Network Driver <NL> [    5.479530] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.480839] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    6.233115] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    6.250772] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    6.263996] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    6.786136] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:11 <NL> [    6.802333] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.813783] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    7.559762] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:10 <NL> [    7.569637] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    8.012631] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:0e <NL> [    8.019946] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    8.465161] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:0f <NL> [    8.466696] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    8.920708] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:0d <NL> [    8.928318] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    9.381469] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:12 <NL> [    9.382357] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    9.387056] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    9.387706] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    9.388578] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    9.389264] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    9.390051] PPP generic driver version 2.4.2 <NL> [    9.408413] PPP BSD Compression module registered <NL> [    9.409049] PPP Deflate Compression module registered"}
{"timestamp_utc": "2024-07-31T08:13:15.317Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[    9.409722] NET: Registered protocol family 24 <NL> [    9.410385] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    9.418882] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    9.419816] SLIP linefill/keepalive option. <NL> [    9.420609] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    9.421470] ehci-pci: EHCI PCI platform driver <NL> [    9.422097] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    9.422971] ohci-pci: OHCI PCI platform driver <NL> [    9.423581] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    9.424649] usbcore: registered new interface driver usb-storage <NL> [    9.425558] usbcore: registered new interface driver usbserial_generic <NL> [    9.426405] usbserial: USB Serial support registered for generic <NL> [    9.427166] usbcore: registered new interface driver ftdi_sio <NL> [    9.427898] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    9.428999] usbcore: registered new interface driver pl2303 <NL> [    9.429718] usbserial: USB Serial support registered for pl2303 <NL> [    9.430651] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    9.445715] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    9.446494] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    9.447681] mousedev: PS/2 mouse device common for all mice <NL> [    9.457501] rtc_cmos 00:00: RTC can wake from S4 <NL> [    9.473107] rtc_cmos 00:00: registered as rtc0 <NL> [    9.480634] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:03 UTC (1722413583) <NL> [    9.486557] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    9.494975] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    9.496353] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    9.504300] intel_pstate: CPU model not supported <NL> [    9.504342] sdhci: Secure Digital Host Controller Interface driver <NL> [    9.504343] sdhci: Copyright(c) Pierre Ossman <NL> [    9.504389] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    9.504650] usbcore: registered new interface driver usbhid <NL> [    9.504651] usbhid: USB HID core driver <NL> [    9.504728] u32 classifier <NL> [    9.504728]     input device check on <NL> [    9.504729]     Actions configured <NL> [    9.536905] xt_time: kernel timezone is -0000 <NL> [    9.537591] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.538501] gre: GRE over IPv4 demultiplexor driver <NL> [    9.539119] ip_gre: GRE over IPv4 tunneling driver <NL> [    9.545060] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    9.551792] NET: Registered protocol family 10 <NL> [    9.565045] Segment Routing with IPv6 <NL> [    9.570404] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.572677] ip6_gre: GRE over IPv6 tunneling driver <NL> [    9.574586] NET: Registered protocol family 17 <NL> [    9.580102] Bridge firewalling registered <NL> [    9.581462] 8021q: 802.1Q VLAN Support v1.8 <NL> [    9.583776] 9pnet: Installing 9P2000 support <NL> [    9.585670] Key type dns_resolver registered <NL> [    9.591885] NET: Registered protocol family 40 <NL> [    9.594392] IPI shorthand broadcast: enabled <NL> [    9.595049] sched_clock: Marking stable (9014088411, 580176965)->(11250709934, -1656444558) <NL> [    9.606576] registered taskstats version 1 <NL> [    9.607145] Loading compiled-in X.509 certificates <NL> [    9.617793] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    9.630629] Key type .fscrypt registered <NL> [    9.633154] Key type fscrypt-provisioning registered <NL> [    9.640003] Btrfs loaded, crc32c=crc32c-generic <NL> [    9.659647] Key type encrypted registered <NL> [    9.663005] printk: console [netcon0] enabled <NL> [    9.668057] netconsole: network logging started <NL> [   10.301835] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   10.311146] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   10.331883] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   10.345974] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   10.376562] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   10.443591] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   10.452422] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   10.458806] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   10.468468] IP-Config: Failed to open gretap0 <NL> [   10.472763] IP-Config: Failed to open erspan0 <NL> [   10.491479] Sending DHCP requests . <NL> (process:673): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 3f054001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 4452357261 cycles <NL> [    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns"}
{"timestamp_utc": "2024-07-31T08:13:15.318Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[    0.000023] tsc: Detected 2095.076 MHz processor <NL> [    0.002479] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.002573] x86/PAT: PAT not supported by the CPU. <NL> [    0.002584] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.041106] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.041245] check: Scanning 1 areas for low memory corruption <NL> [    0.041471] ACPI: Early table checksum verification disabled <NL> [    0.041502] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.041515] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.041533] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.041545] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.041553] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.041559] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.041567] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.041574] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.041581] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.041584] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.041586] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.041589] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.041591] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.041593] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.041680] Zone ranges: <NL> [    0.041683]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.041687]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.041690]   Normal   empty <NL> [    0.041692] Movable zone start for each node <NL> [    0.041694] Early memory node ranges <NL> [    0.041697]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.041699]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.041703] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.042524] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.042560] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.121472] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.122044] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.122069] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.122114] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.122121] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.122125] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.122127] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.122137] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.122138] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.122149] Using ACPI (MADT) for SMP configuration information <NL> [    0.122152] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.122161] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.122202] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.122205] Booting paravirtualized kernel on KVM <NL> [    0.122221] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.122238] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.133254] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.133314] kvm-guest: stealtime: cpu 0, msr 3fc1b600 <NL> [    0.133327] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.133332] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.133845] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.133992] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.134104] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.156046] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.156129] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.156142] Kernel/User page tables isolation: enabled <NL> [    0.156183] ftrace: allocating 47967 entries in 188 pages <NL> [    0.275676] ftrace: allocated 188 pages with 5 groups <NL> [    0.283688] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.283694] rcu: \tRCU event tracing is enabled. <NL> [    0.283696] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.283699] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.283700] \tRude variant of Tasks RCU enabled. <NL> [    0.283702] \tTracing variant of Tasks RCU enabled. <NL> [    0.283704] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.283706] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.295835] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.314009] Console: colour VGA+ 80x25 <NL> [    0.666081] printk: console [ttyS0] enabled <NL> [    0.666736] ACPI: Core revision 20200925 <NL> [    0.667682] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.669202] APIC: Switch to symmetric I/O mode setup <NL> [    0.670269] x2apic enabled <NL> [    0.670947] Switched APIC routing to physical x2apic. <NL> [    0.685168] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.689711] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.691024] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.692037] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.692737] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.693020] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.693037] Spectre V2 : Mitigation: Retpolines <NL> [    0.693637] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.694020] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.694020] Speculative Store Bypass: Vulnerable <NL> [    0.694044] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.694871] MMIO Stale Data: Unknown: No mitigations <NL> [    0.695020] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.716794] Freeing SMP alternatives memory: 48K <NL> [    0.717054] pid_max: default: 32768 minimum: 301 <NL> [    0.718084] LSM: Security Framework initializing <NL> [    0.720044] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.721039] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.775091] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.776567] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.778157] rcu: Hierarchical SRCU implementation. <NL> [    0.779353] smp: Bringing up secondary CPUs ... <NL> [    0.780150] x86: Booting SMP configuration: <NL> [    0.781034] .... node  #0, CPUs:      #1 <NL> [    0.390210] kvm-clock: cpu 1, msr 3f054041, secondary cpu clock <NL> [    0.390210] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.786091] kvm-guest: stealtime: cpu 1, msr 3fc9b600 <NL> [    0.788264]  #2 <NL> [    0.390210] kvm-clock: cpu 2, msr 3f054081, secondary cpu clock <NL> [    0.390210] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.796074] kvm-guest: stealtime: cpu 2, msr 3fd1b600 <NL> [    0.798240]  #3 <NL> [    0.390210] kvm-clock: cpu 3, msr 3f0540c1, secondary cpu clock <NL> [    0.390210] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.802062] kvm-guest: stealtime: cpu 3, msr 3fd9b600 <NL> [    0.803031] smp: Brought up 1 node, 4 CPUs <NL> [    0.804033] smpboot: Max logical packages: 4 <NL> [    0.804617] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    0.812028] devtmpfs: initialized <NL> [    0.814230] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.815031] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.816084] pinctrl core: initialized pinctrl subsystem <NL> [    0.817449] NET: Registered protocol family 16"}
{"timestamp_utc": "2024-07-31T08:13:15.319Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[    0.818292] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.818294] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.820050] cpuidle: using governor menu <NL> [    0.821631] ACPI: bus type PCI registered <NL> [    0.822164] PCI: Using configuration type 1 for base access <NL> [    0.826343] Kprobes globally optimized <NL> [    0.982508] raid6: sse2x4   gen()  5739 MB/s <NL> [    1.001492] raid6: sse2x4   xor()  3225 MB/s <NL> [    1.023496] raid6: sse2x2   gen()  5239 MB/s <NL> [    1.045496] raid6: sse2x2   xor()  3487 MB/s <NL> [    1.067494] raid6: sse2x1   gen()  5112 MB/s <NL> [    1.088493] raid6: sse2x1   xor()  3208 MB/s <NL> [    1.093028] raid6: using algorithm sse2x4 gen() 5739 MB/s <NL> [    1.099027] raid6: .... xor() 3225 MB/s, rmw enabled <NL> [    1.099027] raid6: using intx1 recovery algorithm <NL> [    1.099732] ACPI: Added _OSI(Module Device) <NL> [    1.099732] ACPI: Added _OSI(Processor Device) <NL> [    1.099732] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.099851] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.099851] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.099851] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.100026] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.100813] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.102162] ACPI: Interpreter enabled <NL> [    1.102162] ACPI: (supports S0 S3 S5) <NL> [    1.102716] ACPI: Using IOAPIC for interrupt routing <NL> [    1.102716] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.103336] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.103835] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.104033] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.104035] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.104203] PCI host bridge to bus 0000:00 <NL> [    1.104203] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.105026] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.106025] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.106025] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.106026] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.106026] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.106026] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.107026] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.107104] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.107526] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.107526] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.110834] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.112482] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.112482] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.112482] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.114025] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.115284] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.115387] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.115387] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.115387] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.117072] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.121069] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.135074] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.136578] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.140028] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.143027] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.153030] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.154120] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.157028] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.158027] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.189042] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.189368] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.189368] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.199031] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.215031] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.217100] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.221032] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.230033] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.253032] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.258393] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.271031] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.280033] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.314378] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.321113] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.326542] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.334195] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.339135] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.344085] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.345020] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.351036] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.355030] vgaarb: loaded <NL> [    1.356247] SCSI subsystem initialized <NL> [    1.358097] ACPI: bus type USB registered <NL> [    1.359080] usbcore: registered new interface driver usbfs <NL> [    1.365029] usbcore: registered new interface driver hub <NL> [    1.369065] usbcore: registered new device driver usb <NL> [    1.373077] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.376029] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.382047] PTP clock support registered <NL> [    1.385572] Bluetooth: Core ver 2.22 <NL> [    1.388047] NET: Registered protocol family 31 <NL> [    1.389026] Bluetooth: HCI device and connection manager initialized <NL> [    1.394042] Bluetooth: HCI socket layer initialized <NL> [    1.396032] Bluetooth: L2CAP socket layer initialized <NL> [    1.398043] Bluetooth: SCO socket layer initialized <NL> [    1.402064] PCI: Using ACPI for IRQ routing <NL> [    1.404366] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.407046] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.409026] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.441272] clocksource: Switched to clocksource kvm-clock <NL> [    1.995817] pnp: PnP ACPI init <NL> [    2.014996] pnp: PnP ACPI: found 7 devices <NL> [    2.064006] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.065303] NET: Registered protocol family 2 <NL> [    2.066022] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    2.074635] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear)"}
{"timestamp_utc": "2024-07-31T08:13:15.320Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[    2.075745] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.076787] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    2.077750] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    2.085263] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.086243] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.087277] NET: Registered protocol family 1 <NL> [    2.125490] RPC: Registered named UNIX socket transport module. <NL> [    2.127266] RPC: Registered udp transport module. <NL> [    2.128052] RPC: Registered tcp transport module. <NL> [    2.128795] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.130986] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.135858] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.136613] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.137375] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.138175] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.138965] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.139857] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    2.140870] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.152196] pci 0000:00:00.0: quirk_passive_release+0x0/0x80 took 11062 usecs <NL> [    2.153109] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.153883] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.154744] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.166063] pci 0000:00:02.0: pci_fixup_video+0x0/0xe0 took 11080 usecs <NL> [    2.167036] PCI: CLS 0 bytes, default 64 <NL> [    2.167772] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.211973] check: Scanning for low memory corruption every 60 seconds <NL> [    2.213558] Initialise system trusted keyrings <NL> [    2.215162] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.231304] NFS: Registering the id_resolver key type <NL> [    2.232073] Key type id_resolver registered <NL> [    2.232629] Key type id_legacy registered <NL> [    2.249188] Key type cifs.idmap registered <NL> [    2.254085] 9p: Installing v9fs 9p2000 file system support <NL> [    2.255000] xor: measuring software checksum speed <NL> [    2.256586]    prefetch64-sse  : 10492 MB/sec <NL> [    2.258284]    generic_sse     :  8989 MB/sec <NL> [    2.258830] xor: using function: prefetch64-sse (10492 MB/sec) <NL> [    2.264492] Key type asymmetric registered <NL> [    2.265009] Asymmetric key parser 'x509' registered <NL> [    2.265687] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.280115] io scheduler mq-deadline registered <NL> [    2.280782] io scheduler kyber registered <NL> [    2.292857] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.311326] ACPI: Power Button [PWRF] <NL> [    2.330705] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.344290] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.356794] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.365601] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.368641] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.377205] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.381502] Linux agpgart interface v0.103 <NL> [    2.384564] ACPI: bus type drm_connector registered <NL> [    2.395766] brd: module loaded <NL> [    2.410374] loop: module loaded <NL> [    2.418186] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.431703] vda: detected capacity change from 0 to 2576215040 <NL> [    2.466097] Uniform Multi-Platform E-IDE driver <NL> [    2.476136] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.503161] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.504236] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.504236] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.518779]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.519375]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    3.796800] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.433016] hdc: MWDMA2 mode selected <NL> [    4.433714] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.434291] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.435055] ide-gd driver 1.18 <NL> [    4.436595] e100: Intel(R) PRO/100 Network Driver <NL> [    4.437145] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.438707] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.439346] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.138913] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.144099] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.145500] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    5.572488] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:14 <NL> [    5.582234] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.583639] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.053605] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:15 <NL> [    6.055848] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.063116] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    6.512792] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:16 <NL> [    6.518880] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.521352] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    6.522486] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    6.524802] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    6.526271] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    6.527572] PPP generic driver version 2.4.2 <NL> [    6.530960] PPP BSD Compression module registered <NL> [    6.532588] PPP Deflate Compression module registered <NL> [    6.534283] NET: Registered protocol family 24 <NL> [    6.539778] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    6.541864] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    6.542892] SLIP linefill/keepalive option. <NL> [    6.543522] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    6.544496] ehci-pci: EHCI PCI platform driver <NL> [    6.545251] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    6.546245] ohci-pci: OHCI PCI platform driver <NL> [    6.546900] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    6.547857] usbcore: registered new interface driver usb-storage <NL> [    6.548657] usbcore: registered new interface driver usbserial_generic <NL> [    6.553642] usbserial: USB Serial support registered for generic <NL> [    6.554513] usbcore: registered new interface driver ftdi_sio <NL> [    6.555347] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    6.556386] usbcore: registered new interface driver pl2303 <NL> [    6.557177] usbserial: USB Serial support registered for pl2303 <NL> [    6.562146] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    6.567319] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    6.568002] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    6.568813] mousedev: PS/2 mouse device common for all mice <NL> [    6.607949] rtc_cmos 00:00: RTC can wake from S4 <NL> [    6.609567] rtc_cmos 00:00: registered as rtc0 <NL> [    6.610830] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    6.612734] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:00 UTC (1722413580) <NL> [    6.613952] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    6.621042] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    6.624385] intel_pstate: CPU model not supported <NL> [    6.626253] sdhci: Secure Digital Host Controller Interface driver <NL> [    6.629304] sdhci: Copyright(c) Pierre Ossman <NL> [    6.632018] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    6.634900] usbcore: registered new interface driver usbhid <NL> [    6.637959] usbhid: USB HID core driver <NL> [    6.639937] u32 classifier"}
{"timestamp_utc": "2024-07-31T08:13:15.321Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[    6.643476]     input device check on <NL> [    6.644528]     Actions configured <NL> [    6.646259] xt_time: kernel timezone is -0000 <NL> [    6.648544] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.650873] gre: GRE over IPv4 demultiplexor driver <NL> [    6.653387] ip_gre: GRE over IPv4 tunneling driver <NL> [    6.666334] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    6.668670] NET: Registered protocol family 10 <NL> [    6.679425] Segment Routing with IPv6 <NL> [    6.680791] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.683591] ip6_gre: GRE over IPv6 tunneling driver <NL> [    6.686337] NET: Registered protocol family 17 <NL> [    6.689279] Bridge firewalling registered <NL> [    6.691780] 8021q: 802.1Q VLAN Support v1.8 <NL> [    6.698081] 9pnet: Installing 9P2000 support <NL> [    6.700565] Key type dns_resolver registered <NL> [    6.707062] NET: Registered protocol family 40 <NL> [    6.717129] IPI shorthand broadcast: enabled <NL> [    6.719765] sched_clock: Marking stable (6330503160, 389210660)->(8192942488, -1473228668) <NL> [    6.723442] registered taskstats version 1 <NL> [    6.725458] Loading compiled-in X.509 certificates <NL> [    6.757511] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    6.769645] Key type .fscrypt registered <NL> [    6.771840] Key type fscrypt-provisioning registered <NL> [    6.774832] Btrfs loaded, crc32c=crc32c-generic <NL> [    6.813079] Key type encrypted registered <NL> [    6.816432] printk: console [netcon0] enabled <NL> [    6.818939] netconsole: network logging started <NL> [    7.413368] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    7.422582] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    7.444565] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    7.468860] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    7.485824] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    7.505456] IP-Config: Failed to open gretap0 <NL> [    7.515440] IP-Config: Failed to open erspan0 <NL> [    7.538078] Sending DHCP requests . <NL> [    9.489574] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.492092] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.500160] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.517765] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [    9.524598] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [    9.531051] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [    9.558211] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.585262] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   10.410192] ., OK <NL> [   10.413416] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   10.419973] IP-Config: Complete: <NL> [   10.425566]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   10.427000]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   10.427734]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   10.427736]      nameserver0=10.0.2.3 <NL> [   10.674682] md: Waiting for all devices to be available before autodetect <NL> [   10.678181] md: If you don't use raid, use raid=noautodetect <NL> [   10.680906] md: Autodetecting RAID arrays. <NL> [   10.683062] md: autorun ... <NL> [   10.684245] md: ... autorun DONE. <NL> [   10.687140] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   10.700726] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   10.711686] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   10.715141] devtmpfs: mounted <NL> [   10.721278] Freeing unused kernel image (initmem) memory: 1964K <NL> [   10.730629] Write protecting the kernel read-only data: 22528k <NL> [   10.737730] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   10.744715] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   10.747260] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   11.381926] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   11.404270] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   11.548551] #####FSS INIT: Running on host <NL> [   11.807936] #####FSS INIT: FSS system init pre startup script <NL> [   11.854455] random: python3: uninitialized urandom read (24 bytes read) <NL> [   14.343552] random: crng init done <NL> [   15.938566] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   15.943758] #####FSS INIT: FSS no slotRole found <NL> [   15.944446] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   15.945384] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   15.966148] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   16.009357] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   16.013626] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   16.021758] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   16.059934] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   16.135474] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   16.156512] systemd[1]: Detected virtualization kvm. <NL> [   16.160389] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   16.181679] systemd[1]: Hostname set to <fujitsu>. <NL> [   16.184876] systemd[1]: Initializing machine ID from random generator. <NL> [   16.297452] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   16.411615] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   16.869424] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.921767] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.974236] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.023492] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.073550] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.104173] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.114007] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.123815] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.134783] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.185063] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:15.322Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[   17.195283] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.214325] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.226123] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.228472] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.252206] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.255266] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.299525] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.313733] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.344456] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.366449] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.391199] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.420436] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.436283] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.472198] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.507627] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.536649] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.542504] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.570302] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.590449] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.624419] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.648562] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.726163] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.732559] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.787437] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.803143] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.837878] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.840738] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.922554] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.936995] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.104764] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.152345] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.177954] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.220623] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.261520] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.313547] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.372306] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.376652] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.419634] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.437118] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.478175] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.497546] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.535382] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.538166] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.569666] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.572524] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.633600] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   18.722787] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   18.761779] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   18.792849] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   18.806719] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   18.824488] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   18.841321] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   18.903994] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   18.931419] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:15.323Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[   18.963614] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   18.986803] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   19.015731] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   19.030156] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   19.044644] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   19.095286] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   19.115290] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   19.127166] systemd[1]: Listening on Process Core Dump Socket. <NL> (process:676): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 2e854001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 5928749820 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000021] tsc: Detected 2095.076 MHz processor <NL> [    0.002379] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.002473] x86/PAT: PAT not supported by the CPU. <NL> [    0.002484] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.014787] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.023946] check: Scanning 1 areas for low memory corruption <NL> [    0.024311] ACPI: Early table checksum verification disabled <NL> [    0.024358] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.024374] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.024391] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.024402] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.024410] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.024417] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.024425] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.024433] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.024440] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.024443] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.024446] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.024448] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.024451] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.024453] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.024543] Zone ranges: <NL> [    0.024552]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.024556]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.024559]   Normal   empty <NL> [    0.024562] Movable zone start for each node <NL> [    0.024564] Early memory node ranges <NL> [    0.024566]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.024569]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.024572] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.076705] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.076742] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.405269] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.405923] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.405950] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.406009] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.406016] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.406020] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.406023] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.406033] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.406036] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.406054] Using ACPI (MADT) for SMP configuration information <NL> [    0.406058] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.406074] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.406125] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.406128] Booting paravirtualized kernel on KVM"}
{"timestamp_utc": "2024-07-31T08:13:15.324Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[    0.406139] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.406156] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.463204] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.463271] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.463283] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.463288] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.463836] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.464008] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.464133] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.468015] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.468122] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.468154] Kernel/User page tables isolation: enabled <NL> [    0.468271] ftrace: allocating 47967 entries in 188 pages <NL> [    0.570675] ftrace: allocated 188 pages with 5 groups <NL> [    0.571209] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.571212] rcu: \tRCU event tracing is enabled. <NL> [    0.571214] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.571217] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.571219] \tRude variant of Tasks RCU enabled. <NL> [    0.571220] \tTracing variant of Tasks RCU enabled. <NL> [    0.571223] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.571226] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.579520] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.589563] Console: colour VGA+ 80x25 <NL> [    0.879291] printk: console [ttyS0] enabled <NL> [    0.880101] ACPI: Core revision 20200925 <NL> [    0.881416] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.883055] APIC: Switch to symmetric I/O mode setup <NL> [    0.884077] x2apic enabled <NL> [    0.885022] Switched APIC routing to physical x2apic. <NL> [    0.887239] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.888417] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.890036] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.891276] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.892007] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.893048] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.894024] Spectre V2 : Mitigation: Retpolines <NL> [    0.894626] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.895006] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.896024] Speculative Store Bypass: Vulnerable <NL> [    0.896678] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.897006] MMIO Stale Data: Unknown: No mitigations <NL> [    0.898041] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.924215] Freeing SMP alternatives memory: 48K <NL> [    0.925074] pid_max: default: 32768 minimum: 301 <NL> [    0.927029] LSM: Security Framework initializing <NL> [    0.930055] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.931055] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.969003] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.969670] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.971170] rcu: Hierarchical SRCU implementation. <NL> [    0.972648] smp: Bringing up secondary CPUs ... <NL> [    0.974071] x86: Booting SMP configuration: <NL> [    0.974669] .... node  #0, CPUs:      #1 <NL> [    0.309075] kvm-clock: cpu 1, msr 2e854041, secondary cpu clock <NL> [    0.309075] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.985074] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.991191]  #2 <NL> [    0.309075] kvm-clock: cpu 2, msr 2e854081, secondary cpu clock <NL> [    0.309075] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.997071] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    1.001070]  #3 <NL> [    0.309075] kvm-clock: cpu 3, msr 2e8540c1, secondary cpu clock <NL> [    0.309075] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    1.009035] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    1.016041] smp: Brought up 1 node, 4 CPUs <NL> [    1.017033] smpboot: Max logical packages: 4 <NL> [    1.018022] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    1.027156] devtmpfs: initialized <NL> [    1.029244] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.030016] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    1.031256] pinctrl core: initialized pinctrl subsystem <NL> [    1.035270] NET: Registered protocol family 16 <NL> [    1.036312] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.036314] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.038042] cpuidle: using governor menu <NL> [    1.041155] ACPI: bus type PCI registered <NL> [    1.042230] PCI: Using configuration type 1 for base access <NL> [    1.047151] Kprobes globally optimized <NL> [    1.251010] raid6: sse2x4   gen()  5258 MB/s <NL> [    1.269008] raid6: sse2x4   xor()  3110 MB/s <NL> [    1.287012] raid6: sse2x2   gen()  4826 MB/s <NL> [    1.305013] raid6: sse2x2   xor()  3102 MB/s <NL> [    1.323013] raid6: sse2x1   gen()  4139 MB/s <NL> [    1.340011] raid6: sse2x1   xor()  2595 MB/s <NL> [    1.341014] raid6: using algorithm sse2x4 gen() 5258 MB/s <NL> [    1.342038] raid6: .... xor() 3110 MB/s, rmw enabled <NL> [    1.343010] raid6: using intx1 recovery algorithm <NL> [    1.344140] ACPI: Added _OSI(Module Device) <NL> [    1.344711] ACPI: Added _OSI(Processor Device) <NL> [    1.345007] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.345635] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.346017] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.347007] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.348007] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.350508] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.355074] ACPI: Interpreter enabled <NL> [    1.355639] ACPI: (supports S0 S3 S5) <NL> [    1.356009] ACPI: Using IOAPIC for interrupt routing <NL> [    1.356763] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.357286] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.364118] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.365016] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.366017] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.367132] PCI host bridge to bus 0000:00 <NL> [    1.368026] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.369008] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.370009] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.371010] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.372015] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.373009] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.374008] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.375008] pci_bus 0000:00: root bus resource [bus 00-ff]"}
{"timestamp_utc": "2024-07-31T08:13:15.325Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[    1.376085] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.377647] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.379210] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.385453] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.387848] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.388019] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.389020] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.390017] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.391316] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.392563] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.393038] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.395055] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.399123] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.403044] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.414111] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.416608] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.419011] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.421021] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.430837] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.431397] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.434021] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.437017] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.446019] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.447374] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.450014] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.453014] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.462015] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.463365] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.467016] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.469839] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.479019] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.481239] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.484841] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.487016] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.497390] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.498188] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.499190] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.501131] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.502113] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.506064] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.506856] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.507010] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.508007] vgaarb: loaded <NL> [    1.508701] SCSI subsystem initialized <NL> [    1.510134] ACPI: bus type USB registered <NL> [    1.511112] usbcore: registered new interface driver usbfs <NL> [    1.512067] usbcore: registered new interface driver hub <NL> [    1.512763] usbcore: registered new device driver usb <NL> [    1.513067] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.514006] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.515045] PTP clock support registered <NL> [    1.518321] Bluetooth: Core ver 2.22 <NL> [    1.518842] NET: Registered protocol family 31 <NL> [    1.519006] Bluetooth: HCI device and connection manager initialized <NL> [    1.520021] Bluetooth: HCI socket layer initialized <NL> [    1.520662] Bluetooth: L2CAP socket layer initialized <NL> [    1.521033] Bluetooth: SCO socket layer initialized <NL> [    1.524075] PCI: Using ACPI for IRQ routing <NL> [    1.525402] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.526065] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.527009] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.542447] clocksource: Switched to clocksource kvm-clock <NL> [    2.385117] pnp: PnP ACPI init <NL> [    2.394094] pnp: PnP ACPI: found 7 devices <NL> [    2.422310] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.436313] NET: Registered protocol family 2 <NL> [    2.444969] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    2.461042] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    2.477116] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.485792] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    2.486910] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    2.488212] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.489696] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.494193] NET: Registered protocol family 1 <NL> [    2.530564] RPC: Registered named UNIX socket transport module. <NL> [    2.533736] RPC: Registered udp transport module. <NL> [    2.540010] RPC: Registered tcp transport module. <NL> [    2.542555] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.545377] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.552990] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.553800] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.554630] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.555416] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.556208] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.557060] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    2.558053] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.558845] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.578119] pci 0000:00:00.0: quirk_natoma+0x0/0x20 took 18816 usecs <NL> [    2.581417] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.589541] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.593177] PCI: CLS 0 bytes, default 64 <NL> [    2.599121] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.630494] check: Scanning for low memory corruption every 60 seconds <NL> [    2.634542] Initialise system trusted keyrings <NL> [    2.642416] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.671570] NFS: Registering the id_resolver key type <NL> [    2.676701] Key type id_resolver registered <NL> [    2.679328] Key type id_legacy registered <NL> [    2.695551] Key type cifs.idmap registered <NL> [    2.697168] 9p: Installing v9fs 9p2000 file system support <NL> [    2.700584] xor: measuring software checksum speed <NL> [    2.703000]    prefetch64-sse  : 10652 MB/sec <NL> [    2.707014]    generic_sse     :  9048 MB/sec <NL> [    2.710307] xor: using function: prefetch64-sse (10652 MB/sec) <NL> [    2.713101] Key type asymmetric registered <NL> [    2.715225] Asymmetric key parser 'x509' registered <NL> [    2.717390] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.730402] io scheduler mq-deadline registered <NL> [    2.732618] io scheduler kyber registered <NL> [    2.736057] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.761202] ACPI: Power Button [PWRF] <NL> [    2.784625] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.788642] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.793333] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.797401] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.798713] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.800666] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.802286] Linux agpgart interface v0.103"}
{"timestamp_utc": "2024-07-31T08:13:15.326Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[    2.805373] ACPI: bus type drm_connector registered <NL> [    2.819609] brd: module loaded <NL> [    2.822943] loop: module loaded <NL> [    2.824225] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.825406] vda: detected capacity change from 0 to 2576215040 <NL> [    2.830298] Uniform Multi-Platform E-IDE driver <NL> [    2.831839] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.833673] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.839290] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.839290] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.841651]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.842303]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    4.103544] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.738565] hdc: MWDMA2 mode selected <NL> [    4.739286] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.739922] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.740696] ide-gd driver 1.18 <NL> [    4.749018] e100: Intel(R) PRO/100 Network Driver <NL> [    4.750125] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.750865] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.751504] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.642892] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.645158] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.648272] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    6.328711] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:1f <NL> [    6.335481] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.342776] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    7.017546] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:20 <NL> [    7.020040] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    7.022966] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    7.638074] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:21 <NL> [    7.642831] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    7.647501] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    7.649125] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    7.651214] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    7.653224] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    7.654711] PPP generic driver version 2.4.2 <NL> [    7.656496] PPP BSD Compression module registered <NL> [    7.659356] PPP Deflate Compression module registered <NL> [    7.663664] NET: Registered protocol family 24 <NL> [    7.666694] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    7.670832] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    7.673147] SLIP linefill/keepalive option. <NL> [    7.674290] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    7.676435] ehci-pci: EHCI PCI platform driver <NL> [    7.677911] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    7.682571] ohci-pci: OHCI PCI platform driver <NL> [    7.683657] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    7.689853] usbcore: registered new interface driver usb-storage <NL> [    7.690659] usbcore: registered new interface driver usbserial_generic <NL> [    7.691502] usbserial: USB Serial support registered for generic <NL> [    7.692268] usbcore: registered new interface driver ftdi_sio <NL> [    7.693010] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    7.702298] usbcore: registered new interface driver pl2303 <NL> [    7.704029] usbserial: USB Serial support registered for pl2303 <NL> [    7.706281] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    7.715801] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    7.718896] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    7.719807] mousedev: PS/2 mouse device common for all mice <NL> [    7.720862] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    7.746568] rtc_cmos 00:00: RTC can wake from S4 <NL> [    7.783974] rtc_cmos 00:00: registered as rtc0 <NL> [    7.785371] hpet: Lost 1 RTC interrupts <NL> [    7.788896] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:03 UTC (1722413583) <NL> [    7.790833] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    7.796619] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    7.799553] intel_pstate: CPU model not supported <NL> [    7.809801] sdhci: Secure Digital Host Controller Interface driver <NL> [    7.811768] sdhci: Copyright(c) Pierre Ossman <NL> [    7.813165] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    7.815144] usbcore: registered new interface driver usbhid <NL> [    7.817012] usbhid: USB HID core driver <NL> [    7.823741] u32 classifier <NL> [    7.824112]     input device check on <NL> [    7.824585]     Actions configured <NL> [    7.825447] xt_time: kernel timezone is -0000 <NL> [    7.826092] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.826950] gre: GRE over IPv4 demultiplexor driver <NL> [    7.827583] ip_gre: GRE over IPv4 tunneling driver <NL> [    7.836677] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    7.837726] NET: Registered protocol family 10 <NL> [    7.863935] Segment Routing with IPv6 <NL> [    7.865423] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.875716] ip6_gre: GRE over IPv6 tunneling driver <NL> [    7.877338] NET: Registered protocol family 17 <NL> [    7.878731] Bridge firewalling registered <NL> [    7.880073] 8021q: 802.1Q VLAN Support v1.8 <NL> [    7.890816] 9pnet: Installing 9P2000 support <NL> [    7.892011] Key type dns_resolver registered <NL> [    7.893591] NET: Registered protocol family 40 <NL> [    7.913497] IPI shorthand broadcast: enabled <NL> [    7.914111] sched_clock: Marking stable (7606006188, 308075881)->(9389620582, -1475538513) <NL> [    7.988122] registered taskstats version 1 <NL> [    8.001724] Loading compiled-in X.509 certificates <NL> [    8.070513] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    8.089618] Key type .fscrypt registered <NL> [    8.090169] Key type fscrypt-provisioning registered <NL> [    8.092452] Btrfs loaded, crc32c=crc32c-generic <NL> [    8.094571] Key type encrypted registered <NL> [    8.095677] printk: console [netcon0] enabled <NL> [    8.096322] netconsole: network logging started <NL> [    8.491825] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    8.497450] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    8.513375] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    8.535581] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    8.546357] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    8.561679] IP-Config: Failed to open gretap0 <NL> [    8.566184] IP-Config: Failed to open erspan0 <NL> [    8.582162] Sending DHCP requests . <NL> [   10.522999] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX"}
{"timestamp_utc": "2024-07-31T08:13:15.327Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   10.525180] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.526677] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   10.527482] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   10.584914] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.586599] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.595256] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   10.597807] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   11.402447] ., OK <NL> [   11.419136] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   11.420062] IP-Config: Complete: <NL> [   11.420502]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   11.422731]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   11.423604]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   11.423605]      nameserver0=10.0.2.3 <NL> [   11.646874] md: Waiting for all devices to be available before autodetect <NL> [   11.650851] md: If you don't use raid, use raid=noautodetect <NL> [   11.665159] md: Autodetecting RAID arrays. <NL> [   11.673257] md: autorun ... <NL> [   11.678685] md: ... autorun DONE. <NL> [   11.682961] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   11.722677] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   11.731798] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   11.746743] devtmpfs: mounted <NL> [   11.763937] Freeing unused kernel image (initmem) memory: 1964K <NL> [   11.768314] Write protecting the kernel read-only data: 22528k <NL> [   11.776909] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   11.784018] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   11.785112] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   12.173837] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   12.198394] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   12.424608] #####FSS INIT: Running on host <NL> [   12.689792] #####FSS INIT: FSS system init pre startup script <NL> [   12.742952] random: python3: uninitialized urandom read (24 bytes read) <NL> [   15.476451] random: crng init done <NL> [   17.660688] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> (process:677): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 94a54001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 4325995920 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000019] tsc: Detected 2095.076 MHz processor <NL> [    0.001624] last_pfn = 0x140000 max_arch_pfn = 0x400000000"}
{"timestamp_utc": "2024-07-31T08:13:15.328Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[    0.001713] x86/PAT: PAT not supported by the CPU. <NL> [    0.001725] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.001739] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.014631] found SMP MP-table at [mem 0x000f6340-0x000f634f] <NL> [    0.014737] check: Scanning 1 areas for low memory corruption <NL> [    0.015298] ACPI: Early table checksum verification disabled <NL> [    0.015323] ACPI: RSDP 0x00000000000F6110 000014 (v00 BOCHS ) <NL> [    0.015336] ACPI: RSDT 0x00000000BFFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.015351] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.015362] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.015369] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.015376] ACPI: SSDT 0x00000000BFFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.015383] ACPI: APIC 0x00000000BFFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.015390] ACPI: HPET 0x00000000BFFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.015397] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.015400] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.015402] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.015404] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffc33] <NL> [    0.015406] ACPI: Reserving APIC table memory at [mem 0xbffffc34-0xbffffcc3] <NL> [    0.015408] ACPI: Reserving HPET table memory at [mem 0xbffffcc4-0xbffffcfb] <NL> [    0.015522] Zone ranges: <NL> [    0.015524]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.015528]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.015531]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.015533] Movable zone start for each node <NL> [    0.015535] Early memory node ranges <NL> [    0.015537]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.015540]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.015542]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.015545] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.015600] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.015905] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.745527] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.748296] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.748321] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.748363] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.748369] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.748372] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.748374] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.748382] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.748384] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.748396] Using ACPI (MADT) for SMP configuration information <NL> [    0.748400] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.748408] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.748446] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.748449] Booting paravirtualized kernel on KVM <NL> [    0.748455] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.748466] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.758757] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.758829] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.758839] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.758844] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.779122] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.783682] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.783804] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    1.445198] Memory: 4026256K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 167380K reserved, 0K cma-reserved) <NL> [    1.445324] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    1.445349] Kernel/User page tables isolation: enabled <NL> [    1.445449] ftrace: allocating 47967 entries in 188 pages <NL> [    1.709887] ftrace: allocated 188 pages with 5 groups <NL> [    1.710376] rcu: Preemptible hierarchical RCU implementation. <NL> [    1.710379] rcu: \tRCU event tracing is enabled. <NL> [    1.710382] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    1.710385] \tTrampoline variant of Tasks RCU enabled. <NL> [    1.710386] \tRude variant of Tasks RCU enabled. <NL> [    1.710388] \tTracing variant of Tasks RCU enabled. <NL> [    1.710390] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    1.710392] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    1.762972] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    1.845072] Console: colour VGA+ 80x25 <NL> [    2.622884] printk: console [ttyS0] enabled <NL> [    2.623437] ACPI: Core revision 20200925 <NL> [    2.651993] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    2.653063] APIC: Switch to symmetric I/O mode setup <NL> [    2.653836] x2apic enabled <NL> [    2.654472] Switched APIC routing to physical x2apic. <NL> [    2.677402] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    2.686909] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.695859] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    2.696855] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    2.696855] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    2.696855] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    2.696855] Spectre V2 : Mitigation: Retpolines <NL> [    2.696855] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    2.696855] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    2.696855] Speculative Store Bypass: Vulnerable <NL> [    2.696855] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    2.696863] MMIO Stale Data: Unknown: No mitigations <NL> [    2.697498] x86/fpu: x87 FPU will use FXSAVE <NL> [    2.719736] Freeing SMP alternatives memory: 48K <NL> [    2.719871] pid_max: default: 32768 minimum: 301 <NL> [    2.720891] LSM: Security Framework initializing <NL> [    2.722937] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.723942] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.801855] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    2.802393] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    2.803029] rcu: Hierarchical SRCU implementation. <NL> [    2.805293] smp: Bringing up secondary CPUs ... <NL> [    2.806268] x86: Booting SMP configuration: <NL> [    2.806862] .... node  #0, CPUs:      #1 <NL> [    0.930478] kvm-clock: cpu 1, msr 94a54041, secondary cpu clock <NL> [    0.930478] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    2.812939] kvm-guest: stealtime: cpu 1, msr 13bc9b600 <NL> [    2.820288]  #2 <NL> [    0.930478] kvm-clock: cpu 2, msr 94a54081, secondary cpu clock <NL> [    0.930478] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    2.826893] kvm-guest: stealtime: cpu 2, msr 13bd1b600 <NL> [    2.833310]  #3 <NL> [    0.930478] kvm-clock: cpu 3, msr 94a540c1, secondary cpu clock <NL> [    0.930478] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    2.838933] kvm-guest: stealtime: cpu 3, msr 13bd9b600"}
{"timestamp_utc": "2024-07-31T08:13:15.329Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[    2.839875] smp: Brought up 1 node, 4 CPUs <NL> [    2.840864] smpboot: Max logical packages: 4 <NL> [    2.841880] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    2.849201] devtmpfs: initialized <NL> [    2.851006] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    2.851871] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    2.853011] pinctrl core: initialized pinctrl subsystem <NL> [    2.856100] NET: Registered protocol family 16 <NL> [    2.857271] thermal_sys: Registered thermal governor 'step_wise' <NL> [    2.857273] thermal_sys: Registered thermal governor 'user_space' <NL> [    2.859892] cpuidle: using governor menu <NL> [    2.861952] ACPI: bus type PCI registered <NL> [    2.863024] PCI: Using configuration type 1 for base access <NL> [    2.869064] Kprobes globally optimized <NL> [    3.052861] raid6: sse2x4   gen()  4404 MB/s <NL> [    3.070875] raid6: sse2x4   xor()  3201 MB/s <NL> [    3.088865] raid6: sse2x2   gen()  5340 MB/s <NL> [    3.106863] raid6: sse2x2   xor()  3067 MB/s <NL> [    3.124865] raid6: sse2x1   gen()  3940 MB/s <NL> [    3.142871] raid6: sse2x1   xor()  2382 MB/s <NL> [    3.144866] raid6: using algorithm sse2x2 gen() 5340 MB/s <NL> [    3.146862] raid6: .... xor() 3067 MB/s, rmw enabled <NL> [    3.147875] raid6: using intx1 recovery algorithm <NL> [    3.150147] ACPI: Added _OSI(Module Device) <NL> [    3.150868] ACPI: Added _OSI(Processor Device) <NL> [    3.151866] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    3.152864] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    3.153894] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    3.154859] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    3.155867] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    3.160000] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    3.163627] ACPI: Interpreter enabled <NL> [    3.163891] ACPI: (supports S0 S3 S5) <NL> [    3.164860] ACPI: Using IOAPIC for interrupt routing <NL> [    3.165924] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    3.167173] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    3.174050] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    3.174892] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    3.175898] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    3.177061] PCI host bridge to bus 0000:00 <NL> [    3.177865] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    3.178866] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    3.179867] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    3.180864] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    3.181863] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    3.182863] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    3.183863] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    3.184863] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    3.185934] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    3.187439] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    3.189245] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    3.195866] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    3.198891] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    3.199867] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    3.200865] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    3.201865] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    3.203159] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    3.205055] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    3.205878] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    3.208052] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    3.210914] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    3.213915] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    3.224907] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    3.226616] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    3.228865] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    3.231863] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    3.241864] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    3.244184] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    3.246864] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    3.249863] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    3.259866] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    3.261398] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    3.263865] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    3.266864] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    3.276688] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    3.277173] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    3.279865] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    3.282864] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    3.292865] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    3.295004] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    3.297758] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    3.299863] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    3.309866] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    3.312211] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    3.314865] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    3.317866] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    3.327871] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    3.329898] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    3.332864] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    3.335864] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    3.345864] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    3.347908] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    3.350863] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    3.352864] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    3.363375] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    3.365022] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    3.366014] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    3.367001] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    3.367939] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    3.370542] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    3.370855] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    3.370867] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    3.371861] vgaarb: loaded <NL> [    3.373089] SCSI subsystem initialized <NL> [    3.379929] ACPI: bus type USB registered <NL> [    3.381898] usbcore: registered new interface driver usbfs <NL> [    3.382893] usbcore: registered new interface driver hub <NL> [    3.383884] usbcore: registered new device driver usb <NL> [    3.384902] pps_core: LinuxPPS API ver. 1 registered <NL> [    3.385860] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    3.386901] PTP clock support registered <NL> [    3.393161] Bluetooth: Core ver 2.22 <NL> [    3.393892] NET: Registered protocol family 31 <NL> [    3.394860] Bluetooth: HCI device and connection manager initialized"}
{"timestamp_utc": "2024-07-31T08:13:15.330Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[    3.395879] Bluetooth: HCI socket layer initialized <NL> [    3.396862] Bluetooth: L2CAP socket layer initialized <NL> [    3.397886] Bluetooth: SCO socket layer initialized <NL> [    3.399909] PCI: Using ACPI for IRQ routing <NL> [    3.401945] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    3.403855] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    3.404859] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    3.419857] clocksource: Switched to clocksource kvm-clock <NL> [    4.004788] pnp: PnP ACPI init <NL> [    4.014249] pnp: PnP ACPI: found 7 devices <NL> [    4.040383] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    4.052891] NET: Registered protocol family 2 <NL> [    4.069292] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    4.082323] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    4.097520] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    4.124322] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    4.141571] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    4.154673] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    4.165143] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    4.166357] NET: Registered protocol family 1 <NL> [    4.186030] RPC: Registered named UNIX socket transport module. <NL> [    4.187889] RPC: Registered udp transport module. <NL> [    4.188903] RPC: Registered tcp transport module. <NL> [    4.190578] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    4.192392] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    4.194406] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    4.199104] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    4.200775] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    4.202506] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    4.203775] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    4.213271] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    4.214205] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    4.214932] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    4.215684] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    4.220648] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    4.222504] PCI: CLS 0 bytes, default 64 <NL> [    4.223708] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    4.248877] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    4.253044] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    4.281151] check: Scanning for low memory corruption every 60 seconds <NL> [    4.287769] Initialise system trusted keyrings <NL> [    4.301030] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    4.311769] NFS: Registering the id_resolver key type <NL> [    4.317211] Key type id_resolver registered <NL> [    4.318856] Key type id_legacy registered <NL> [    4.341890] Key type cifs.idmap registered <NL> [    4.344302] 9p: Installing v9fs 9p2000 file system support <NL> [    4.347060] xor: measuring software checksum speed <NL> [    4.351061]    prefetch64-sse  :  9935 MB/sec <NL> [    4.357326]    generic_sse     :  7767 MB/sec <NL> [    4.361285] xor: using function: prefetch64-sse (9935 MB/sec) <NL> [    4.362519] Key type asymmetric registered <NL> [    4.363052] Asymmetric key parser 'x509' registered <NL> [    4.363693] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    4.377739] io scheduler mq-deadline registered <NL> [    4.378900] io scheduler kyber registered <NL> [    4.382393] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    4.399271] ACPI: Power Button [PWRF] <NL> [    4.418766] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    4.428711] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    4.442322] N_HDLC line discipline registered with maxframe=4096 <NL> [    4.451884] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    4.465142] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    4.489189] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    4.492161] Linux agpgart interface v0.103 <NL> [    4.493211] ACPI: bus type drm_connector registered <NL> [    4.524847] brd: module loaded <NL> [    4.538652] loop: module loaded <NL> [    4.546778] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    4.552603] vda: detected capacity change from 0 to 2576215040 <NL> [    4.607726] Uniform Multi-Platform E-IDE driver <NL> [    4.616594] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    4.635934] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    4.657571] legacy IDE will be removed in 2021, please switch to libata <NL> [    4.657571] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    4.661438]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    4.698559]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    5.960018] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    6.612068] hdc: MWDMA2 mode selected <NL> [    6.612854] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    6.613546] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    6.614408] ide-gd driver 1.18 <NL> [    6.631559] e100: Intel(R) PRO/100 Network Driver <NL> [    6.632217] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    6.632959] e1000: Intel(R) PRO/1000 Network Driver <NL> [    6.643372] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    6.644653] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    7.215082] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    7.227367] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    7.231614] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    7.861294] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:06 <NL> [    7.873680] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    7.889431] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    8.629276] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:05 <NL> [    8.637930] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    9.281885] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:03 <NL> [    9.296842] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    9.933677] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:04 <NL> [    9.949734] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [   10.772657] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:02 <NL> [   10.787419] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [   11.783437] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:07 <NL> [   11.802631] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [   11.817073] e1000e: Intel(R) PRO/1000 Network Driver <NL> [   11.826212] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [   11.827090] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [   11.827830] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [   11.832526] PPP generic driver version 2.4.2 <NL> [   11.833523] PPP BSD Compression module registered <NL> [   11.834346] PPP Deflate Compression module registered <NL> [   11.835155] NET: Registered protocol family 24"}
{"timestamp_utc": "2024-07-31T08:13:15.331Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   11.835780] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [   11.844106] CSLIP: code copyright 1989 Regents of the University of California. <NL> [   11.845026] SLIP linefill/keepalive option. <NL> [   11.845631] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [   11.846504] ehci-pci: EHCI PCI platform driver <NL> [   11.853235] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [   11.854176] ohci-pci: OHCI PCI platform driver <NL> [   11.854781] uhci_hcd: USB Universal Host Controller Interface driver <NL> [   11.855714] usbcore: registered new interface driver usb-storage <NL> [   11.856642] usbcore: registered new interface driver usbserial_generic <NL> [   11.864619] usbserial: USB Serial support registered for generic <NL> [   11.865399] usbcore: registered new interface driver ftdi_sio <NL> [   11.866149] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [   11.867124] usbcore: registered new interface driver pl2303 <NL> [   11.873259] usbserial: USB Serial support registered for pl2303 <NL> [   11.874189] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [   11.881253] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [   11.882081] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [   11.882990] mousedev: PS/2 mouse device common for all mice <NL> [   11.919151] rtc_cmos 00:00: RTC can wake from S4 <NL> [   11.938103] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [   11.938105] rtc_cmos 00:00: registered as rtc0 <NL> [   11.941640] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:06 UTC (1722413586) <NL> [   11.946080] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [   11.964191] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [   11.968614] intel_pstate: CPU model not supported <NL> [   11.972980] sdhci: Secure Digital Host Controller Interface driver <NL> [   11.985457] sdhci: Copyright(c) Pierre Ossman <NL> [   11.986857] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [   11.988933] usbcore: registered new interface driver usbhid <NL> [   11.990101] usbhid: USB HID core driver <NL> [   11.993373] u32 classifier <NL> [   11.995511]     input device check on <NL> [   11.999470]     Actions configured <NL> [   12.000796] xt_time: kernel timezone is -0000 <NL> [   12.001427] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [   12.002401] gre: GRE over IPv4 demultiplexor driver <NL> [   12.003035] ip_gre: GRE over IPv4 tunneling driver <NL> [   12.004299] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [   12.005606] NET: Registered protocol family 10 <NL> [   12.052304] Segment Routing with IPv6 <NL> [   12.053578] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [   12.055096] ip6_gre: GRE over IPv6 tunneling driver <NL> [   12.056203] NET: Registered protocol family 17 <NL> [   12.061994] Bridge firewalling registered <NL> [   12.062619] 8021q: 802.1Q VLAN Support v1.8 <NL> [   12.063246] 9pnet: Installing 9P2000 support <NL> [   12.063884] Key type dns_resolver registered <NL> [   12.064604] NET: Registered protocol family 40 <NL> [   12.070426] IPI shorthand broadcast: enabled <NL> [   12.071561] sched_clock: Marking stable (11142007556, 929478262)->(13308486492, -1237000674) <NL> [   12.103073] registered taskstats version 1 <NL> [   12.105322] Loading compiled-in X.509 certificates <NL> [   12.134368] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [   12.140166] Key type .fscrypt registered <NL> [   12.140779] Key type fscrypt-provisioning registered <NL> [   12.144764] Btrfs loaded, crc32c=crc32c-generic <NL> [   12.151708] Key type encrypted registered <NL> [   12.154105] printk: console [netcon0] enabled <NL> [   12.156385] netconsole: network logging started <NL> [   12.626244] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   12.658893] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   12.679581] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   12.691633] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   12.780318] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   12.791201] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   12.828982] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   12.869069] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   12.869800] IP-Config: Failed to open gretap0 <NL> [   12.870269] IP-Config: Failed to open erspan0 <NL> [   12.880878] Sending DHCP requests . <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37286; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37286 <NL> (process:675): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map:"}
{"timestamp_utc": "2024-07-31T08:13:15.332Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 2f254001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 4569249732 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000021] tsc: Detected 2095.076 MHz processor <NL> [    0.014789] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.014876] x86/PAT: PAT not supported by the CPU. <NL> [    0.014886] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.041844] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.041952] check: Scanning 1 areas for low memory corruption <NL> [    0.042139] ACPI: Early table checksum verification disabled <NL> [    0.042164] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.042177] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.042193] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.042203] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.042211] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.042217] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.042225] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.042232] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.042239] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.042241] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.042244] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.042246] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.042248] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.042250] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.060362] Zone ranges: <NL> [    0.060367]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.060372]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.060375]   Normal   empty <NL> [    0.060378] Movable zone start for each node <NL> [    0.060380] Early memory node ranges <NL> [    0.060382]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.060385]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.060388] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.060918] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.060952] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.083197] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.083899] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.083920] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.083967] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.083974] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.083977] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.083979] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.083987] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.083989] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.084001] Using ACPI (MADT) for SMP configuration information <NL> [    0.084004] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.084014] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.084051] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.084054] Booting paravirtualized kernel on KVM <NL> [    0.084060] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.084073] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.084833] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.084877] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.084886] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.084889] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.085355] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.085450] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.085563] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.102940] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.103016] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.103030] Kernel/User page tables isolation: enabled <NL> [    0.103074] ftrace: allocating 47967 entries in 188 pages <NL> [    0.280168] ftrace: allocated 188 pages with 5 groups <NL> [    0.280817] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.280821] rcu: \tRCU event tracing is enabled. <NL> [    0.280823] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.280825] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.280827] \tRude variant of Tasks RCU enabled. <NL> [    0.280828] \tTracing variant of Tasks RCU enabled. <NL> [    0.280831] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.280833] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.303049] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.338425] Console: colour VGA+ 80x25 <NL> [    0.671642] printk: console [ttyS0] enabled <NL> [    0.691631] ACPI: Core revision 20200925 <NL> [    0.692350] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.693673] APIC: Switch to symmetric I/O mode setup <NL> [    0.694556] x2apic enabled <NL> [    0.707139] Switched APIC routing to physical x2apic. <NL> [    0.709144] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.709968] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.711239] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.712380] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.712991] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.713247] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.714249] Spectre V2 : Mitigation: Retpolines <NL> [    0.715245] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.716245] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.717244] Speculative Store Bypass: Vulnerable <NL> [    0.718245] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.718969] MMIO Stale Data: Unknown: No mitigations <NL> [    0.719247] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.752698] Freeing SMP alternatives memory: 48K <NL> [    0.753277] pid_max: default: 32768 minimum: 301 <NL> [    0.754351] LSM: Security Framework initializing <NL> [    0.756258] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear)"}
{"timestamp_utc": "2024-07-31T08:13:15.333Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[    0.757254] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.836285] APIC calibration not consistent with PM-Timer: 102ms instead of 100ms <NL> [    0.837237] APIC delta adjusted to PM-Timer: 6250115 (6433225) <NL> [    0.837293] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.838551] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.841366] rcu: Hierarchical SRCU implementation. <NL> [    0.844330] smp: Bringing up secondary CPUs ... <NL> [    0.845459] x86: Booting SMP configuration: <NL> [    0.846245] .... node  #0, CPUs:      #1 <NL> [    0.397043] kvm-clock: cpu 1, msr 2f254041, secondary cpu clock <NL> [    0.397043] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.852316] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.859457]  #2 <NL> [    0.397043] kvm-clock: cpu 2, msr 2f254081, secondary cpu clock <NL> [    0.397043] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.863316] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    0.870619]  #3 <NL> [    0.397043] kvm-clock: cpu 3, msr 2f2540c1, secondary cpu clock <NL> [    0.397043] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.876293] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    0.882250] smp: Brought up 1 node, 4 CPUs"}
{"timestamp_utc": "2024-07-31T08:13:15.595Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[    0.883267] smpboot: Max logical packages: 4 <NL> [    0.884249] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    0.894461] devtmpfs: initialized <NL> [    0.896325] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.897259] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.898338] pinctrl core: initialized pinctrl subsystem <NL> [    0.903395] NET: Registered protocol family 16 <NL> [    0.904825] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.904828] thermal_sys: Registered thermal governor 'user_space'"}
{"timestamp_utc": "2024-07-31T08:13:15.596Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[    0.907264] cpuidle: using governor menu <NL> [    0.910330] ACPI: bus type PCI registered <NL> [    0.911440] PCI: Using configuration type 1 for base access <NL> [    0.916889] Kprobes globally optimized <NL> [    1.098246] raid6: sse2x4   gen()  4224 MB/s <NL> [    1.116245] raid6: sse2x4   xor()  2951 MB/s <NL> [    1.134246] raid6: sse2x2   gen()  4794 MB/s <NL> [    1.152246] raid6: sse2x2   xor()  3027 MB/s <NL> [    1.170244] raid6: sse2x1   gen()  3266 MB/s <NL> [    1.188243] raid6: sse2x1   xor()  2422 MB/s <NL> [    1.189245] raid6: using algorithm sse2x2 gen() 4794 MB/s <NL> [    1.190244] raid6: .... xor() 3027 MB/s, rmw enabled <NL> [    1.191256] raid6: using intx1 recovery algorithm <NL> [    1.193335] ACPI: Added _OSI(Module Device) <NL> [    1.194247] ACPI: Added _OSI(Processor Device) <NL> [    1.195250] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.196247] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.197249] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.198245] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.198914] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.203370] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.206241] ACPI: Interpreter enabled <NL> [    1.207269] ACPI: (supports S0 S3 S5) <NL> [    1.208244] ACPI: Using IOAPIC for interrupt routing <NL> [    1.209279] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.211237] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.216604] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.217271] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.219285] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.220461] PCI host bridge to bus 0000:00 <NL> [    1.221247] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.222244] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.223248] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.224244] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.225250] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.226248] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.227251] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.228544] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.231297] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.233517] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.236244] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.243711] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.247273] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.248251] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.249250] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.250251] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.251541] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.253312] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.254260] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.255627] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.258291] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.261303] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.273295] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.275341] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.278250] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.281245] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.292248] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.294452] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.297247] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.299247] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.309248] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.311433] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.314248] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.317247] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.327250] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.329484] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.332250] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.335250] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.344250] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.345636] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.348248] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.351248] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.362678] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.363412] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.364422] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.367435] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.368347] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.370984] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.371237] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.371250] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.372241] vgaarb: loaded <NL> [    1.374272] SCSI subsystem initialized <NL> [    1.379299] ACPI: bus type USB registered <NL> [    1.379950] usbcore: registered new interface driver usbfs <NL> [    1.380287] usbcore: registered new interface driver hub <NL> [    1.381270] usbcore: registered new device driver usb <NL> [    1.382286] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.383241] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.384267] PTP clock support registered <NL> [    1.386716] Bluetooth: Core ver 2.22 <NL> [    1.387269] NET: Registered protocol family 31 <NL> [    1.388244] Bluetooth: HCI device and connection manager initialized <NL> [    1.389259] Bluetooth: HCI socket layer initialized <NL> [    1.390246] Bluetooth: L2CAP socket layer initialized <NL> [    1.391266] Bluetooth: SCO socket layer initialized <NL> [    1.393289] PCI: Using ACPI for IRQ routing <NL> [    1.394537] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.395290] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.396244] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.412966] clocksource: Switched to clocksource kvm-clock <NL> [    2.182458] pnp: PnP ACPI init <NL> [    2.193759] pnp: PnP ACPI: found 7 devices <NL> [    2.230513] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.253453] NET: Registered protocol family 2 <NL> [    2.262258] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    2.286544] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    2.297393] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.298661] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    2.299896] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    2.301158] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.312958] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.318655] NET: Registered protocol family 1 <NL> [    2.337524] RPC: Registered named UNIX socket transport module. <NL> [    2.338380] RPC: Registered udp transport module. <NL> [    2.338979] RPC: Registered tcp transport module. <NL> [    2.341605] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.345720] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.346545] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window]"}
{"timestamp_utc": "2024-07-31T08:13:15.597Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[    2.347365] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.352141] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.352889] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.353764] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.354713] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    2.363471] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.364252] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.365010] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.365880] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.367025] PCI: CLS 0 bytes, default 64 <NL> [    2.367824] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.411095] check: Scanning for low memory corruption every 60 seconds <NL> [    2.412416] Initialise system trusted keyrings <NL> [    2.421092] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.449196] NFS: Registering the id_resolver key type <NL> [    2.459506] Key type id_resolver registered <NL> [    2.461713] Key type id_legacy registered <NL> [    2.501344] Key type cifs.idmap registered <NL> [    2.504032] 9p: Installing v9fs 9p2000 file system support <NL> [    2.507301] xor: measuring software checksum speed <NL> [    2.513219]    prefetch64-sse  : 10052 MB/sec <NL> [    2.524306]    generic_sse     :  6892 MB/sec <NL> [    2.532348] xor: using function: prefetch64-sse (10052 MB/sec) <NL> [    2.540326] Key type asymmetric registered <NL> [    2.542178] Asymmetric key parser 'x509' registered <NL> [    2.552468] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.559389] io scheduler mq-deadline registered <NL> [    2.561583] io scheduler kyber registered <NL> [    2.564763] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.583115] ACPI: Power Button [PWRF] <NL> [    2.594567] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.598775] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.603695] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.607621] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.610985] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.615246] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.620120] Linux agpgart interface v0.103 <NL> [    2.623072] ACPI: bus type drm_connector registered <NL> [    2.648885] brd: module loaded <NL> [    2.654480] loop: module loaded <NL> [    2.658672] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.667742] vda: detected capacity change from 0 to 2576215040 <NL> [    2.729122] Uniform Multi-Platform E-IDE driver <NL> [    2.734314] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.753037] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.757854] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.757854] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.764680]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.767428]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    4.022129] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.663148] hdc: MWDMA2 mode selected <NL> [    4.663845] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.664494] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.665245] ide-gd driver 1.18 <NL> [    4.707261] e100: Intel(R) PRO/100 Network Driver <NL> [    4.707889] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.708634] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.709667] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.306810] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.313497] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.317708] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    5.924614] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:09 <NL> [    5.935549] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.946827] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.601828] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:0a <NL> [    6.621142] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.632483] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    7.157470] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:0b <NL> [    7.164898] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    7.172132] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    7.177225] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    7.183468] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    7.188696] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    7.191588] PPP generic driver version 2.4.2 <NL> [    7.194182] PPP BSD Compression module registered <NL> [    7.195559] PPP Deflate Compression module registered <NL> [    7.198973] NET: Registered protocol family 24 <NL> [    7.201122] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled)."}
{"timestamp_utc": "2024-07-31T08:13:15.598Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[    7.205980] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    7.208876] SLIP linefill/keepalive option. <NL> [    7.209451] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    7.210288] ehci-pci: EHCI PCI platform driver <NL> [    7.210891] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    7.211699] ohci-pci: OHCI PCI platform driver <NL> [    7.212302] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    7.220125] usbcore: registered new interface driver usb-storage <NL> [    7.220928] usbcore: registered new interface driver usbserial_generic <NL> [    7.225144] usbserial: USB Serial support registered for generic <NL> [    7.227012] usbcore: registered new interface driver ftdi_sio <NL> [    7.227761] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    7.228710] usbcore: registered new interface driver pl2303 <NL> [    7.229436] usbserial: USB Serial support registered for pl2303 <NL> [    7.236619] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    7.258218] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    7.260829] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    7.263552] mousedev: PS/2 mouse device common for all mice <NL> [    7.266301] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    7.269371] rtc_cmos 00:00: RTC can wake from S4 <NL> [    7.270774] rtc_cmos 00:00: registered as rtc0 <NL> [    7.271737] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:01 UTC (1722413581) <NL> [    7.272849] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    7.285348] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    7.291003] intel_pstate: CPU model not supported <NL> [    7.292543] sdhci: Secure Digital Host Controller Interface driver <NL> [    7.294724] sdhci: Copyright(c) Pierre Ossman <NL> [    7.296314] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    7.299032] usbcore: registered new interface driver usbhid <NL> [    7.311471] usbhid: USB HID core driver <NL> [    7.313630] u32 classifier <NL> [    7.315185]     input device check on <NL> [    7.317931]     Actions configured <NL> [    7.319384] xt_time: kernel timezone is -0000 <NL> [    7.329338] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.331129] gre: GRE over IPv4 demultiplexor driver <NL> [    7.333878] ip_gre: GRE over IPv4 tunneling driver <NL> [    7.348166] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    7.350447] NET: Registered protocol family 10 <NL> [    7.364928] Segment Routing with IPv6 <NL> [    7.366268] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.368571] ip6_gre: GRE over IPv6 tunneling driver <NL> [    7.370557] NET: Registered protocol family 17 <NL> [    7.372344] Bridge firewalling registered <NL> [    7.374160] 8021q: 802.1Q VLAN Support v1.8 <NL> [    7.375365] 9pnet: Installing 9P2000 support <NL> [    7.376429] Key type dns_resolver registered <NL> [    7.378598] NET: Registered protocol family 40 <NL> [    7.381344] IPI shorthand broadcast: enabled <NL> [    7.382455] sched_clock: Marking stable (6986334341, 396043681)->(9323737436, -1941359414) <NL> [    7.390305] registered taskstats version 1 <NL> [    7.393035] Loading compiled-in X.509 certificates <NL> [    7.411663] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    7.418950] Key type .fscrypt registered <NL> [    7.421423] Key type fscrypt-provisioning registered <NL> [    7.425789] Btrfs loaded, crc32c=crc32c-generic <NL> [    7.435332] Key type encrypted registered <NL> [    7.436954] printk: console [netcon0] enabled <NL> [    7.438139] netconsole: network logging started <NL> [    8.007373] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    8.013310] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    8.021656] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    8.035538] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    8.047471] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    8.057427] IP-Config: Failed to open gretap0 <NL> [    8.061631] IP-Config: Failed to open erspan0 <NL> [    8.077417] Sending DHCP requests . <NL> [   10.025563] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.038490] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   10.087547] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.100173] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.117144] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.122183] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   10.134564] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   10.135717] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   10.379973] ., OK <NL> [   10.384588] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   10.385562] IP-Config: Complete: <NL> [   10.386004]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   10.392461]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   10.393242]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   10.393243]      nameserver0=10.0.2.3 <NL> [   10.728546] md: Waiting for all devices to be available before autodetect <NL> [   10.730476] md: If you don't use raid, use raid=noautodetect <NL> [   10.732241] md: Autodetecting RAID arrays. <NL> [   10.737401] md: autorun ... <NL> [   10.737764] md: ... autorun DONE. <NL> [   10.744035] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   10.938716] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   10.939818] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   10.947369] devtmpfs: mounted <NL> [   10.954518] Freeing unused kernel image (initmem) memory: 1964K"}
{"timestamp_utc": "2024-07-31T08:13:15.599Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   10.955431] Write protecting the kernel read-only data: 22528k <NL> [   10.958911] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   10.960305] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   10.964855] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   11.624654] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   11.629455] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   11.760616] #####FSS INIT: Running on host <NL> [   11.935222] #####FSS INIT: FSS system init pre startup script <NL> [   11.973252] random: python3: uninitialized urandom read (24 bytes read) <NL> [   14.826583] random: crng init done <NL> [   16.317413] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   16.329677] #####FSS INIT: FSS no slotRole found <NL> [   16.334497] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   16.341351] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   16.368726] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   16.386296] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   16.408313] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   16.411172] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   16.434517] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   16.512978] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   16.530996] systemd[1]: Detected virtualization kvm. <NL> [   16.535648] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   16.591070] systemd[1]: Hostname set to <fujitsu>. <NL> [   16.594817] systemd[1]: Initializing machine ID from random generator. <NL> [   16.696628] systemd-sysv-generator[342]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   16.735943] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   17.423012] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.428264] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.438993] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.466256] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.480388] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.498217] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.507536] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.525180] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.539442] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.584807] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.590437] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.623028] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.652621] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.660661] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.676378] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.681618] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.731164] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.750846] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.770991] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.778913] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.805760] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:15.600Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   17.828656] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.844407] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.874496] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.886799] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.901510] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.926914] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.952620] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.955551] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.000963] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.019337] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.052134] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.069479] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.130220] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.133305] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.168865] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.177320] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.217599] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.223390] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.382585] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.427955] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.446557] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.497889] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.515479] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.545406] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.578576] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.606874] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.748136] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.779963] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.790772] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.807555] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.848997] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.852587] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:15.601Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   18.883665] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.890357] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.934630] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   18.991433] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   19.006575] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   19.041161] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   19.052969] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   19.084388] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   19.089946] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   19.108915] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   19.110995] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   19.135431] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   19.158600] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   19.160065] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   19.161546] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   19.232078] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   19.315794] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   19.331526] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   19.361693] systemd[1]: Listening on Process Core Dump Socket. <NL> (process:674): GLib-WARNING **: 03:12:48.510: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80 <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved"}
{"timestamp_utc": "2024-07-31T08:13:15.602Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr a8454001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 7998518616 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000024] tsc: Detected 2095.076 MHz processor <NL> [    0.001632] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.001729] x86/PAT: PAT not supported by the CPU. <NL> [    0.001741] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.001754] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.017143] found SMP MP-table at [mem 0x000f6380-0x000f638f] <NL> [    0.017292] check: Scanning 1 areas for low memory corruption <NL> [    0.026543] ACPI: Early table checksum verification disabled <NL> [    0.026587] ACPI: RSDP 0x00000000000F61D0 000014 (v00 BOCHS ) <NL> [    0.026613] ACPI: RSDT 0x00000000BFFFFBC1 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.026632] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.026647] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.026655] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.026662] ACPI: SSDT 0x00000000BFFFF234 0008DD (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.026669] ACPI: APIC 0x00000000BFFFFB11 000078 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.026676] ACPI: HPET 0x00000000BFFFFB89 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.026683] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.026685] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.026687] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.026689] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffb10] <NL> [    0.026691] ACPI: Reserving APIC table memory at [mem 0xbffffb11-0xbffffb88] <NL> [    0.026693] ACPI: Reserving HPET table memory at [mem 0xbffffb89-0xbffffbc0] <NL> [    0.026802] Zone ranges: <NL> [    0.026817]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.026822]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.026825]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.026828] Movable zone start for each node <NL> [    0.026830] Early memory node ranges <NL> [    0.026832]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.026834]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.026837]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.026840] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.034890] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.034938] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.628180] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.628911] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.628932] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.628984] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.628991] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.628996] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.628998] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.629008] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.629011] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.629027] Using ACPI (MADT) for SMP configuration information <NL> [    0.629031] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.629047] smpboot: Allowing 1 CPUs, 0 hotplug CPUs <NL> [    0.629093] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.629097] Booting paravirtualized kernel on KVM <NL> [    0.629104] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.629119] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:1 nr_node_ids:1 <NL> [    0.663598] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u2097152 <NL> [    0.663657] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.663667] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.663672] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.724141] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.737853] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.737915] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    1.465387] Memory: 4026940K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 166696K reserved, 0K cma-reserved) <NL> [    1.465474] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1 <NL> [    1.465498] Kernel/User page tables isolation: enabled <NL> [    1.465585] ftrace: allocating 47967 entries in 188 pages <NL> [    1.570640] ftrace: allocated 188 pages with 5 groups <NL> [    1.587275] rcu: Preemptible hierarchical RCU implementation. <NL> [    1.587280] rcu: \tRCU event tracing is enabled. <NL> [    1.587283] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=1. <NL> [    1.587285] \tTrampoline variant of Tasks RCU enabled. <NL> [    1.587287] \tRude variant of Tasks RCU enabled. <NL> [    1.587288] \tTracing variant of Tasks RCU enabled. <NL> [    1.587291] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    1.587293] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1 <NL> [    1.603976] NR_IRQS: 4352, nr_irqs: 256, preallocated irqs: 16 <NL> [    1.615006] Console: colour VGA+ 80x25 <NL> [    1.965618] printk: console [ttyS0] enabled"}
{"timestamp_utc": "2024-07-31T08:13:15.603Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[    1.967618] ACPI: Core revision 20200925 <NL> [    1.970316] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    1.975616] APIC: Switch to symmetric I/O mode setup <NL> [    1.977884] x2apic enabled <NL> [    1.979647] Switched APIC routing to physical x2apic. <NL> [    1.984796] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    1.989505] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    1.995139] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    1.996390] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    1.997135] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    1.998154] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    1.999141] Spectre V2 : Mitigation: Retpolines <NL> [    1.999716] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    2.000138] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    2.001129] Speculative Store Bypass: Vulnerable <NL> [    2.002148] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    2.003134] MMIO Stale Data: Unknown: No mitigations <NL> [    2.004177] x86/fpu: x87 FPU will use FXSAVE <NL> [    2.070119] Freeing SMP alternatives memory: 48K <NL> [    2.071165] pid_max: default: 32768 minimum: 301 <NL> [    2.072222] LSM: Security Framework initializing <NL> [    2.074140] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.075158] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.104158] APIC calibration not consistent with PM-Timer: 102ms instead of 100ms <NL> [    2.105119] APIC delta adjusted to PM-Timer: 6250164 (6433957) <NL> [    2.105119] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    2.106253] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    2.108275] rcu: Hierarchical SRCU implementation. <NL> [    2.109638] smp: Bringing up secondary CPUs ... <NL> [    2.110130] smp: Brought up 1 node, 1 CPU <NL> [    2.111126] smpboot: Max logical packages: 1 <NL> [    2.112131] smpboot: Total of 1 processors activated (4190.15 BogoMIPS) <NL> [    2.114438] devtmpfs: initialized <NL> [    2.115697] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    2.116130] futex hash table entries: 256 (order: 2, 16384 bytes, linear) <NL> [    2.118158] pinctrl core: initialized pinctrl subsystem <NL> [    2.119310] NET: Registered protocol family 16 <NL> [    2.120226] thermal_sys: Registered thermal governor 'step_wise' <NL> [    2.120227] thermal_sys: Registered thermal governor 'user_space' <NL> [    2.121064] cpuidle: using governor menu <NL> [    2.122214] ACPI: bus type PCI registered <NL> [    2.123207] PCI: Using configuration type 1 for base access <NL> [    2.127663] Kprobes globally optimized <NL> [    2.254149] raid6: sse2x4   gen()  3495 MB/s <NL> [    2.272140] raid6: sse2x4   xor()  3600 MB/s <NL> [    2.290127] raid6: sse2x2   gen()  5436 MB/s <NL> [    2.308128] raid6: sse2x2   xor()  2878 MB/s <NL> [    2.326127] raid6: sse2x1   gen()  4190 MB/s <NL> [    2.344129] raid6: sse2x1   xor()  2925 MB/s <NL> [    2.345131] raid6: using algorithm sse2x2 gen() 5436 MB/s <NL> [    2.346129] raid6: .... xor() 2878 MB/s, rmw enabled <NL> [    2.347145] raid6: using intx1 recovery algorithm <NL> [    2.349225] ACPI: Added _OSI(Module Device) <NL> [    2.350131] ACPI: Added _OSI(Processor Device) <NL> [    2.351131] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    2.352128] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    2.353142] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    2.354129] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    2.355129] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    2.358312] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    2.360588] ACPI: Interpreter enabled <NL> [    2.361163] ACPI: (supports S0 S3 S5) <NL> [    2.362127] ACPI: Using IOAPIC for interrupt routing <NL> [    2.363161] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    2.364418] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    2.368927] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    2.369146] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    2.370174] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    2.371294] PCI host bridge to bus 0000:00 <NL> [    2.372145] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    2.373133] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    2.374133] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    2.375133] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    2.376132] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    2.377131] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    2.378133] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    2.379129] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    2.379930] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    2.381515] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    2.382898] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    2.388131] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    2.391158] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    2.392149] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    2.393138] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    2.394131] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    2.396212] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    2.397690] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    2.398142] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    2.400324] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    2.405231] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    2.409229] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    2.422229] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    2.424318] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    2.427132] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    2.430140] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    2.439132] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    2.440470] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    2.443132] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    2.446131] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    2.456133] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    2.458187] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    2.460957] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff]"}
{"timestamp_utc": "2024-07-31T08:13:15.604Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[    2.463133] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    2.473148] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    2.475215] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    2.478132] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    2.480132] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    2.490132] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    2.492248] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    2.495132] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    2.498955] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    2.507132] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    2.509238] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    2.512132] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    2.515130] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    2.526132] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    2.527495] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    2.530131] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    2.533132] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    2.543131] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    2.545187] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    2.548131] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    2.551132] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    2.562831] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    2.563318] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    2.564302] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    2.565298] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    2.566250] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    2.568846] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    2.569119] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    2.569137] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    2.570130] vgaarb: loaded <NL> [    2.571501] SCSI subsystem initialized <NL> [    2.572399] ACPI: bus type USB registered <NL> [    2.573227] usbcore: registered new interface driver usbfs <NL> [    2.574150] usbcore: registered new interface driver hub <NL> [    2.574818] usbcore: registered new device driver usb <NL> [    2.575182] pps_core: LinuxPPS API ver. 1 registered <NL> [    2.576134] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    2.577157] PTP clock support registered <NL> [    2.579429] Bluetooth: Core ver 2.22 <NL> [    2.580172] NET: Registered protocol family 31 <NL> [    2.581126] Bluetooth: HCI device and connection manager initialized <NL> [    2.582158] Bluetooth: HCI socket layer initialized <NL> [    2.582794] Bluetooth: L2CAP socket layer initialized <NL> [    2.583145] Bluetooth: SCO socket layer initialized <NL> [    2.584265] PCI: Using ACPI for IRQ routing <NL> [    2.585593] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    2.586165] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    2.587126] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    2.591202] clocksource: Switched to clocksource kvm-clock <NL> [    3.048932] pnp: PnP ACPI init <NL> [    3.050865] pnp: PnP ACPI: found 7 devices <NL> [    3.071012] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    3.072344] NET: Registered protocol family 2 <NL> [    3.073670] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    3.084068] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    3.085326] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    3.107128] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    3.110512] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    3.112948] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    3.115444] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    3.123137] NET: Registered protocol family 1 <NL> [    3.124911] RPC: Registered named UNIX socket transport module. <NL> [    3.126950] RPC: Registered udp transport module. <NL> [    3.128566] RPC: Registered tcp transport module. <NL> [    3.129879] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    3.136063] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    3.138233] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    3.145460] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    3.147643] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    3.149860] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    3.157112] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    3.159345] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    3.167100] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    3.169123] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    3.171203] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    3.173658] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    3.181767] PCI: CLS 0 bytes, default 64 <NL> [    3.183091] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    3.186536] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    3.193946] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    3.202627] check: Scanning for low memory corruption every 60 seconds <NL> [    3.205633] Initialise system trusted keyrings <NL> [    3.207405] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    3.216419] NFS: Registering the id_resolver key type <NL> [    3.222640] Key type id_resolver registered <NL> [    3.225235] Key type id_legacy registered <NL> [    3.228355] Key type cifs.idmap registered <NL> [    3.235650] 9p: Installing v9fs 9p2000 file system support <NL> [    3.238965] xor: measuring software checksum speed <NL> [    3.244190]    prefetch64-sse  : 10568 MB/sec <NL> [    3.255339]    generic_sse     :  7047 MB/sec <NL> [    3.259513] xor: using function: prefetch64-sse (10568 MB/sec) <NL> [    3.268172] Key type asymmetric registered <NL> [    3.270406] Asymmetric key parser 'x509' registered <NL> [    3.273471] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    3.282604] io scheduler mq-deadline registered <NL> [    3.285508] io scheduler kyber registered <NL> [    3.293541] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    3.304434] ACPI: Power Button [PWRF] <NL> [    3.309109] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    3.314639] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    3.328088] N_HDLC line discipline registered with maxframe=4096 <NL> [    3.332267] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    3.336480] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    3.344499] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    3.353842] Linux agpgart interface v0.103 <NL> [    3.357012] ACPI: bus type drm_connector registered <NL> [    3.387279] brd: module loaded <NL> [    3.410187] loop: module loaded <NL> [    3.422751] virtio_blk virtio0: [vda] 5016568 512-byte logical blocks (2.57 GB/2.39 GiB) <NL> [    3.425906] vda: detected capacity change from 0 to 2568482816 <NL> [    3.439508] Uniform Multi-Platform E-IDE driver <NL> [    3.440237] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    3.441229] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    3.442214] legacy IDE will be removed in 2021, please switch to libata <NL> [    3.442214] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    3.448797]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    3.457661]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    4.705205] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    5.346261] hdc: MWDMA2 mode selected <NL> [    5.347015] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    5.347756] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    5.348647] ide-gd driver 1.18 <NL> [    5.349794] e100: Intel(R) PRO/100 Network Driver"}
{"timestamp_utc": "2024-07-31T08:13:15.605Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[    5.364518] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    5.374873] e1000: Intel(R) PRO/1000 Network Driver <NL> [    5.377408] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.388250] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    6.210526] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    6.222715] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    6.235113] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    7.082119] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:1c <NL> [    7.084468] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    7.087520] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    7.611267] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:1b <NL> [    7.613360] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    8.392213] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:19 <NL> [    8.400905] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    9.194175] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:1a <NL> [    9.195758] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [   10.439965] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:18 <NL> [   10.464337] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [   11.728796] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:1d <NL> [   11.729738] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [   11.730692] e1000e: Intel(R) PRO/1000 Network Driver <NL> [   11.731332] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [   11.753249] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [   11.753953] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [   11.754720] PPP generic driver version 2.4.2 <NL> [   11.755441] PPP BSD Compression module registered <NL> [   11.756058] PPP Deflate Compression module registered <NL> [   11.756698] NET: Registered protocol family 24 <NL> [   11.772816] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [   11.774101] CSLIP: code copyright 1989 Regents of the University of California. <NL> [   11.775106] SLIP linefill/keepalive option. <NL> [   11.775695] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [   11.785821] ehci-pci: EHCI PCI platform driver <NL> [   11.786504] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [   11.787390] ohci-pci: OHCI PCI platform driver <NL> [   11.788015] uhci_hcd: USB Universal Host Controller Interface driver <NL> [   11.788976] usbcore: registered new interface driver usb-storage <NL> [   11.809892] usbcore: registered new interface driver usbserial_generic <NL> [   11.810732] usbserial: USB Serial support registered for generic <NL> [   11.811521] usbcore: registered new interface driver ftdi_sio <NL> [   11.812308] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [   11.824367] usbcore: registered new interface driver pl2303 <NL> [   11.825102] usbserial: USB Serial support registered for pl2303 <NL> [   11.826023] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [   11.827897] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [   11.848740] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [   11.849569] mousedev: PS/2 mouse device common for all mice <NL> [   11.850710] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [   11.871261] rtc_cmos 00:00: RTC can wake from S4 <NL> [   11.872690] rtc_cmos 00:00: registered as rtc0 <NL> [   11.873374] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:08 UTC (1722413588) <NL> [   11.901273] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [   11.903779] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [   11.909362] intel_pstate: CPU model not supported <NL> [   11.919930] sdhci: Secure Digital Host Controller Interface driver <NL> [   11.920971] sdhci: Copyright(c) Pierre Ossman <NL> [   11.922043] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [   11.932609] usbcore: registered new interface driver usbhid <NL> [   11.933658] usbhid: USB HID core driver <NL> [   11.947395] u32 classifier <NL> [   11.948341]     input device check on <NL> [   11.949296]     Actions configured <NL> [   11.961395] xt_time: kernel timezone is -0000 <NL> [   11.970286] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [   11.972269] gre: GRE over IPv4 demultiplexor driver <NL> [   11.982230] ip_gre: GRE over IPv4 tunneling driver <NL> [   11.983448] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [   11.984507] NET: Registered protocol family 10 <NL> [   11.985920] Segment Routing with IPv6 <NL> [   11.989670] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [   11.990861] ip6_gre: GRE over IPv6 tunneling driver <NL> [   11.991660] NET: Registered protocol family 17 <NL> [   12.009412] Bridge firewalling registered <NL> [   12.010001] 8021q: 802.1Q VLAN Support v1.8 <NL> [   12.010612] 9pnet: Installing 9P2000 support <NL> [   12.011233] Key type dns_resolver registered <NL> [   12.011880] NET: Registered protocol family 40 <NL> [   12.020865] IPI shorthand broadcast: enabled <NL> [   12.021480] sched_clock: Marking stable (11635011276, 385798007)->(12715143382, -694334099) <NL> [   12.022675] registered taskstats version 1 <NL> [   12.023242] Loading compiled-in X.509 certificates <NL> [   12.038698] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [   12.040054] Key type .fscrypt registered <NL> [   12.040547] Key type fscrypt-provisioning registered <NL> [   12.061001] Btrfs loaded, crc32c=crc32c-generic <NL> [   12.062280] Key type encrypted registered <NL> [   12.063152] printk: console [netcon0] enabled <NL> [   12.063765] netconsole: network logging started <NL> [   12.530156] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   12.606268] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   12.670761] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   12.711750] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   12.725041] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   12.739349] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   12.751008] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   12.762035] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   12.768409] IP-Config: Failed to open gretap0 <NL> [   12.772761] IP-Config: Failed to open erspan0 <NL> [   12.793098] Sending DHCP requests . <NL> [   14.631619] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.633624] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   14.696627] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.698293] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   14.759627] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.772633] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.784541] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   17.307536] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   17.328930] #####FSS INIT: FSS no slotRole found"}
{"timestamp_utc": "2024-07-31T08:13:15.606Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   17.341033] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   17.360416] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   17.441862] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   17.456989] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   17.469785] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   17.472582] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   17.512585] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   17.720123] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   17.832955] systemd[1]: Detected virtualization kvm. <NL> [   17.833584] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   17.849213] systemd[1]: Hostname set to <fujitsu>. <NL> [   17.862874] systemd[1]: Initializing machine ID from random generator. <NL> [   18.010788] systemd-sysv-generator[344]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   18.069277] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   18.692975] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.751161] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.816328] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.871772] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.947241] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.003592] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.025228] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.114299] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.133568] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.195999] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.230311] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.321984] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.335896] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.352018] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.435206] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.445382] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.503865] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.525403] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.635432] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.647634] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.701346] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.728670] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   19.733633] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   19.799111] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.811777] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37215, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:15.863Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p03.s01.NE2-main-debug-ssh", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37281, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37281, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37281\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6."}
{"timestamp_utc": "2024-07-31T08:13:15.864Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p01.s01.NE1-main-debug-ssh", "message_content": "from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37313, with username 'fujitsu', password '1finity', key_filename None <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37193, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37251, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37251, username 'fujitsu', password '1finity', key_filename None <NL> [   17.678578] #####FSS INIT: FSS no slotRole found <NL> [   17.688179] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   17.706579] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   17.735045] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   17.757862] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   17.774866] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   17.779420] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   17.823754] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   18.012443] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   18.055172] systemd[1]: Detected virtualization kvm. <NL> [   18.055864] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   18.070994] systemd[1]: Hostname set to <fujitsu>. <NL> [   18.088244] systemd[1]: Initializing machine ID from random generator. <NL> [   18.325364] systemd-sysv-generator[344]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   18.370376] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   18.600318] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.621859] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.642684] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.739544] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.758631] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.797724] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.836624] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.869374] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.888455] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.966575] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.032527] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.061119] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.086946] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.100560] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.123449] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.129933] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.200631] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.212006] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.237822] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.241079] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.273204] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.284532] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   19.290952] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   19.317159] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.327435] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37193, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37251\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:15.865Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p06.NE3-trib1-debug-ssh", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37219, with username 'fujitsu', password '1finity', key_filename None <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37285, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37219, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37193\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37219\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37285, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37285\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:15 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37247, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:16.121Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',) <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   19.132324] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   19.172272] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit)."}
{"timestamp_utc": "2024-07-31T08:13:16.122Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[   19.175970] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   19.194162] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   19.207774] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   19.214060] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   19.219576] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   19.222154] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   19.243236] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   19.248026] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   19.272291] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   19.293864] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   19.305496] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   19.316836] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   19.332904] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   19.344927] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   19.373843] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   19.438133] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   19.517311] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   19.555294] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   19.578895] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   19.624079] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   19.660963] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   19.672316] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   19.727933] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   19.753361] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   19.775073] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   19.792009] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   19.825658] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   19.840150] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   19.867252] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   19.880482] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   19.896203] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   19.911568] fuse: init (API version 7.32) <NL> [   19.923995] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   19.975440] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   19.989890] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   20.044290] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   20.125036] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   20.170924] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   20.187509] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   20.221407] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> [   20.221459] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   20.238521] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   20.254281] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   20.255918] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   20.349267] dcn_phantom_drv: VIF Support v1.0 <NL> [   20.497192] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   20.511790] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   20.538832] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   20.573259] packet_injector_class: driver registered correctly with major number 246 <NL> [   20.580648] systemd[1]: Mounting /var/ftp... <NL> [   20.593374] Packet_injector 257949696: minor device creation 246:0 <NL> [   20.593464] Packet_injector 257949697: minor device creation 246:1 <NL> [   20.593516] Packet_injector 257949698: minor device creation 246:2 <NL> [   20.593569] Packet_injector 257949699: minor device creation 246:3 <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   20.615184] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   20.626790] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   20.706419] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   20.731537] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   20.748381] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   20.784828] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   20.829173] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> Starting \u001b[0;1;39mApply[   21.093675] systemd-journald[359]: Received client request to flush runtime journal."}
{"timestamp_utc": "2024-07-31T08:13:16.686Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   19.865391] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.868254] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.892891] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.895698] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.905578] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.908833] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.936531] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.940013] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.964083] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.992609] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.023989] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.026811] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.143722] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.163440] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.282776] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.419230] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.463254] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.521036] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.583132] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.706888] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.806332] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.864046] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.951866] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.975910] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.020762] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.028095] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.037284] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.062067] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.108457] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:16.687Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   21.111313] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.167136] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   21.330541] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   21.343726] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   21.356977] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   19.389862] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   19.469260] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   19.494289] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   19.548479] systemd[1]: Starting Journal Socket... <NL> [   19.549561] systemd[348]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   19.605199] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   19.621782] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   19.651833] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   19.691902] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   19.725881] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   19.767213] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   19.797202] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   19.821146] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   19.869434] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   19.886528] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   19.914593] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   19.952278] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   19.971860] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   20.014107] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   20.057750] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   20.072817] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   20.103488] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   20.189695] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   20.263386] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   20.294544] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   20.327826] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   20.353136] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   20.360375] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   20.361793] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   20.384225] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   20.385672] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   20.428628] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   20.445266] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   20.473530] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   20.517448] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   20.530252] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   20.558267] fuse: init (API version 7.32) <NL> [   20.568914] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   20.579909] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   20.589942] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   20.600595] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   20.611995] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   20.634846] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   20.682582] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   20.705730] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   20.718433] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   20.737240] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   20.753281] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   20.764255] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   20.778328] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   20.792094] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   20.808458] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   20.841077] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   20.848228] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   20.860388] dcn_phantom_drv: VIF Support v1.0 <NL> [   20.861449] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   20.912306] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   20.937003] systemd[1]: Mounted /var/log. <NL> [   20.942803] packet_injector_class: driver registered correctly with major number 246"}
{"timestamp_utc": "2024-07-31T08:13:16.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   20.953003] Packet_injector 257949696: minor device creation 246:0 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   20.961743] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   20.967504] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   20.971528] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   20.973198] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   20.975597] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   20.992123] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:17.249Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   19.351990] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.362020] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.428720] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.449768] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.534465] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.553305] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.611984] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.621909] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.634295] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.653231] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.707530] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.713080] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.783758] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.797864] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.956018] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.010037] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.043060] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.088804] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.153118] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.198707] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.244204] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.287764] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:17.250Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   20.306073] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.434661] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.535313] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.568061] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.610647] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.623948] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.661509] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.677333] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.708613] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   20.743612] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   20.776795] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   20.780903] systemd[1]: Created slice Slice /system/modprobe."}
{"timestamp_utc": "2024-07-31T08:13:18.613Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   12.349840] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.352422] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.363706] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.390420] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   12.396465] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   12.402952] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   12.412727] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.468289] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready"}
{"timestamp_utc": "2024-07-31T08:13:18.614Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   12.480790] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.481876] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.511070] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.524392] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   12.526005] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   12.535659] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   12.644427] ., OK <NL> [   12.648620] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   12.649553] IP-Config: Complete: <NL> [   12.651460]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   12.654011]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   12.661255]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   12.661258]      nameserver0=10.0.2.3 <NL> [   13.173035] md: Waiting for all devices to be available before autodetect <NL> [   13.188349] md: If you don't use raid, use raid=noautodetect <NL> [   13.212854] md: Autodetecting RAID arrays. <NL> [   13.227980] md: autorun ... <NL> [   13.230793] md: ... autorun DONE. <NL> [   13.245584] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   13.328918] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   13.330089] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   13.336613] devtmpfs: mounted <NL> [   13.354864] Freeing unused kernel image (initmem) memory: 1964K <NL> [   13.357345] Write protecting the kernel read-only data: 22528k <NL> [   13.376507] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   13.383511] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   13.385156] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   13.986095] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   14.001624] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   14.157393] #####FSS INIT: Running on host <NL> [   14.357678] #####FSS INIT: FSS system init pre startup script <NL> [   14.418964] random: python3: uninitialized urandom read (24 bytes read) <NL> [   17.927259] random: crng init done <NL> [   20.748952] #####FSS INIT: UnitCode:f9fc  ShelfRole:MAIN <NL> [   20.788926] #####FSS INIT: FSS no slotRole found <NL> [   20.790397] #####FSS INIT: FSS system init get inputs from PSI f9fc : MAIN <NL> [   20.791329] #####FSS INIT:PI data: unitCode=f9fc Role=MAIN <NL> [   20.848689] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   20.885554] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   20.915011] #####FSS INIT:FSS MAIN Target File found : /lib/systemd/system/FSS-MAIN.target <NL> [   20.967705] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-MAIN.target <NL> [   21.051808] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   21.103051] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   21.171153] systemd[1]: Detected virtualization kvm. <NL> [   21.175828] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   21.253438] systemd[1]: Hostname set to <fujitsu>. <NL> [   21.272902] systemd[1]: Initializing machine ID from random generator. <NL> [   21.409732] systemd-sysv-generator[341]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   21.486176] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   22.190990] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.298346] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.361070] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.501363] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.580850] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.617101] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.666606] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.736505] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.745446] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.811506] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.821553] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.859748] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.907040] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:19.176Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   21.391856] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   21.415732] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   21.428414] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   21.470038] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   21.492411] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   21.494585] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   21.511244] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   21.522006] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   21.523659] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   21.540007] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   21.603855] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   21.612465] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   21.619439] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   21.660395] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   21.714959] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   21.735025] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   21.759411] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   21.820287] systemd[350]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   21.846455] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   21.870956] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   21.885567] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   21.922957] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   22.034895] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   22.133851] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   22.197284] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   22.218212] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   22.229929] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   22.258790] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   22.304631] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   22.310868] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   22.400437] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   22.487572] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   22.571178] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:19.177Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   22.652358] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   22.705128] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   22.804991] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   22.884513] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   22.928675] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   22.950555] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   23.010519] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   23.020352] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   23.036843] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   23.043130] fuse: init (API version 7.32) <NL> [   23.056508] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   23.071869] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   23.094130] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   23.101306] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   23.103593] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   23.147781] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   23.220000] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   23.251493] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   23.375480] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   23.429215] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   23.441220] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   23.485769] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   23.547764] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   23.605174] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   23.657467] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   23.684076] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   23.713740] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   23.752913] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   23.765846] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:20.104Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   20.787039] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   20.804835] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   20.817867] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   20.825713] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   20.876456] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:20.105Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   20.878564] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   20.885586] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   20.887065] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   20.888602] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   20.914588] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   20.998467] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   21.030419] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   21.054201] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   21.082159] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   21.109613] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   21.129053] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   21.151282] systemd[1]: Starting Journal Socket... <NL> [   21.162153] systemd[350]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   21.249700] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   21.254940] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   21.257899] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   21.294877] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   21.311390] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   21.340442] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   21.362620] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   21.400216] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   21.510640] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   21.544049] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   21.601123] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   21.672265] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   21.807503] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   21.873304] hrtimer: interrupt took 3311196 ns <NL> [   21.947778] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   22.007540] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   22.039462] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   22.132210] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   22.187701] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   22.269431] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   22.299732] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   22.343969] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   22.345313] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   22.357241] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   22.443112] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   22.458694] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   22.475376] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   22.489787] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   22.525638] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   22.553890] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   22.618059] systemd[1]: Mounting Kernel Configuration File System... <NL> [   22.660675] fuse: init (API version 7.32) <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   22.687310] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   22.698768] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   22.735924] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   22.816400] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   22.817919] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   22.867076] systemd[1]: Mounted Kernel Configuration File System. <NL> [   22.867273] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   22.933306] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   22.950025] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   23.192177] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   23.216544] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   23.231176] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   23.274611] dcn_phantom_drv: VIF Support v1.0"}
{"timestamp_utc": "2024-07-31T08:13:20.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37281, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37281\" SSHException('Error reading SSH protocol banner',) <NL> [   22.927235] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.984565] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.014101] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.017152] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.139088] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.154391] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:20.689Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   23.269080] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.280782] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.311578] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.335483] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.351382] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.400133] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.429102] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   23.449059] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   23.516772] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.531271] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.571485] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.594773] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.687880] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.703321] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.731043] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.769095] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.848604] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.871912] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.919263] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.976764] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.054503] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.057712] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.115964] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.136744] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.299710] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.352831] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:20.944Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p01.s01.NE1-main-debug-ssh", "message_content": "# 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37251, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37251\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37193, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37219, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37193\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37285, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37219\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37285\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:21.872Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   14.797401] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.818304] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   14.820343] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   14.831281] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   14.832998] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   14.845518] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.868446] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   15.222066] ., OK <NL> [   15.223512] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   15.225665] IP-Config: Complete: <NL> [   15.230822]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   15.233623]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   15.239423]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   15.239425]      nameserver0=10.0.2.3 <NL> [   15.683794] md: Waiting for all devices to be available before autodetect <NL> [   15.692049] md: If you don't use raid, use raid=noautodetect <NL> [   15.694142] md: Autodetecting RAID arrays. <NL> [   15.701288] md: autorun ... <NL> [   15.702157] md: ... autorun DONE. <NL> [   15.710187] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   15.722346] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   15.723403] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   15.724407] devtmpfs: mounted <NL> [   15.733296] Freeing unused kernel image (initmem) memory: 1964K <NL> [   15.739221] Write protecting the kernel read-only data: 22528k <NL> [   15.742494] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   15.751725] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   15.752568] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   16.278995] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   16.294436] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   16.522641] #####FSS INIT: Running on host <NL> [   16.721217] #####FSS INIT: FSS system init pre startup script <NL> [   16.835232] random: python3: uninitialized urandom read (24 bytes read) <NL> [   20.126883] random: crng init done <NL> [   22.328634] #####FSS INIT: UnitCode:c200  ShelfRole:MAIN <NL> [   22.378855] #####FSS INIT: FSS no slotRole found <NL> [   22.409794] #####FSS INIT: FSS system init get inputs from PSI c200 : MAIN <NL> [   22.459249] #####FSS INIT:PI data: unitCode=c200 Role=MAIN <NL> [   22.494400] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   22.525413] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-C200-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   22.571572] #####FSS INIT:Specific Target File found : /lib/systemd/system/FSS-C200-MAIN.target <NL> [   22.582282] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-C200-MAIN.target <NL> sh: -d: unknown operand <NL> [   22.603326] #####FSS INIT:systemd will take it from here! <NL> [   22.635966] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   22.655914] systemd[1]: Detected virtualization kvm. <NL> [   22.672978] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   22.696766] systemd[1]: Hostname set to <fujitsu>. <NL> [   22.710178] systemd[1]: Initializing machine ID from random generator. <NL> [   22.877785] systemd-sysv-generator[310]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   22.919359] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   23.272842] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.292640] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.345537] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.430850] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.469328] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.515963] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:21.873Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   23.567061] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.597246] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.608113] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.622349] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.642488] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.711378] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.726126] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.745222] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.761168] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:22.434Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   24.425217] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.428986] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.504412] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.506966] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.519730] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.525421] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.554107] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.559144] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.643065] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.646365] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:22.435Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   24.688612] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   24.885459] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   24.927052] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   24.958019] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   25.016960] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   25.029484] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   25.071915] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   25.094239] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   25.126698] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   25.145002] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   25.241019] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   25.261273] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   25.279573] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   25.472731] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   25.480679] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   25.500555] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   25.504914] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   25.542101] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   25.544832] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   25.565270] systemd[347]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   25.567697] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   25.584827] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   25.588339] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   25.596332] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   25.611620] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   25.646388] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   25.710794] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   25.793264] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   25.817006] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   25.843694] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   25.897640] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   25.937174] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   25.976271] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   25.996332] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   26.163558] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   26.337374] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   26.413934] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   26.479122] fuse: init (API version 7.32) <NL> [   26.492645] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   26.522803] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   26.583052] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   26.631101] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   26.689079] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   26.702344] systemd[1]: Mounted Kernel Trace File System."}
{"timestamp_utc": "2024-07-31T08:13:23.799Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   23.774263] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.792776] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.803105] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.853367] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.870370] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.924869] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.966253] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   24.000743] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   24.044558] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.075534] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.115555] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.145744] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.190790] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.223785] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.280449] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.317727] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.381291] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.434552] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.477727] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.512602] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.618701] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.669447] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.818187] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.894497] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.990321] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.998022] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.074347] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.083172] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.150262] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.156740] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.191874] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.200035] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:25.711Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37281, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37281\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:25.967Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p01.s01.NE1-main-debug-ssh", "message_content": "# 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:25.968Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p01.s01.NE1-main-debug-ssh", "message_content": "# 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37251, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37193, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37193\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37219, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37219\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37285, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37285\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',) <NL> [   25.302214] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   25.402257] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   25.415628] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   25.428709] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   25.439615] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   25.455143] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   25.467531] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   25.486764] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   25.500496] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   25.518947] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   25.524476] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   25.532696] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   25.540796] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   25.592920] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   25.629843] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   25.659788] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   25.685056] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   25.707945] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   25.719430] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   25.756491] systemd[1]: Starting Journal Socket... <NL> [   25.775842] systemd[316]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   25.812169] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   25.823529] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   25.859258] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   25.894899] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   25.921475] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   25.932624] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   26.000258] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   26.084599] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   26.142744] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   26.236921] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   26.275236] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   26.318667] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   26.402921] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   26.622297] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   26.661665] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   26.699585] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   26.738110] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   26.789664] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:25.969Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   26.866491] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   26.968223] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   26.969984] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   26.975862] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   26.988107] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   26.989772] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   26.992219] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   27.066939] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   27.088152] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   27.211586] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   27.216975] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   27.356919] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   27.650608] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   27.758355] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   27.778148] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   27.844234] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   27.886264] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   27.944705] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   28.149933] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   28.151393] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   28.200073] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   28.215449] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   28.265592] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   28.308623] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:26.896Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   14.693048] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.695407] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.707277] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready"}
{"timestamp_utc": "2024-07-31T08:13:26.897Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   14.708612] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   14.762091] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.763594] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   14.885052] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.886355] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.891165] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.899186] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   14.906799] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   14.917561] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   14.927094] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   14.930443] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   15.546860] ., OK <NL> [   15.568774] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   15.586749] IP-Config: Complete: <NL> [   15.597317]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   15.616206]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   15.630172]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   15.630175]      nameserver0=10.0.2.3 <NL> [   16.198454] md: Waiting for all devices to be available before autodetect <NL> [   16.199341] md: If you don't use raid, use raid=noautodetect <NL> [   16.200079] md: Autodetecting RAID arrays. <NL> [   16.200601] md: autorun ... <NL> [   16.205944] md: ... autorun DONE. <NL> [   16.215557] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   16.453335] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   16.465458] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   16.492170] devtmpfs: mounted <NL> [   16.507675] Freeing unused kernel image (initmem) memory: 1964K <NL> [   16.518206] Write protecting the kernel read-only data: 22528k <NL> [   16.543027] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   16.555348] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   16.565665] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   17.660525] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   17.670080] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   18.307276] #####FSS INIT: Running on host <NL> [   18.587364] #####FSS INIT: FSS system init pre startup script <NL> [   18.948242] random: python3: uninitialized urandom read (24 bytes read) <NL> [   25.108522] random: crng init done <NL> [   29.416288] #####FSS INIT: UnitCode:f9fc  ShelfRole:MAIN <NL> [   29.418298] #####FSS INIT: FSS no slotRole found <NL> [   29.418852] #####FSS INIT: FSS system init get inputs from PSI f9fc : MAIN <NL> [   29.419614] #####FSS INIT:PI data: unitCode=f9fc Role=MAIN <NL> [   29.513697] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   29.535609] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   29.547501] #####FSS INIT:FSS MAIN Target File found : /lib/systemd/system/FSS-MAIN.target <NL> [   29.548672] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-MAIN.target <NL> sh: -d: unknown operand <NL> [   29.625123] #####FSS INIT:systemd will take it from here! <NL> [   29.907682] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   29.937938] systemd[1]: Detected virtualization kvm. <NL> [   29.938618] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   30.013087] systemd[1]: Hostname set to <fujitsu>. <NL> [   30.043813] systemd[1]: Initializing machine ID from random generator. <NL> [   30.187786] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   30.379057] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   30.931793] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.007297] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.045321] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.111309] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.130521] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.193706] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.196588] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.227319] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.239332] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.362273] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.381793] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.424254] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.449624] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:27.823Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p04.NE2-trib1-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p04.NE2-trib1-debug-ssh", "message_content": "# 03:13:27 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:27 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:13:27 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:27 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:27 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\": process 3332 terminated with exitcode 0 <NL> # 03:13:27 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:13:27 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #3 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:27 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 7 children running (n01.p09.s01.startup (p)) <NL> # 03:13:27 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:28.079Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   31.480712] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.489081] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.512461] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.515623] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.544560] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.555667] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.647308] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.655066] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.678985] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.760029] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.769873] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.838102] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.869527] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   31.888220] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   31.960044] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.962865] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.016646] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.036832] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:28.080Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   32.119078] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.131177] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.178252] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.181193] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.278024] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.280902] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.350982] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.378278] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.458161] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.473187] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.541195] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.560173] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.656454] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.679672] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:28.641Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   26.750201] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   26.805282] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   26.808779] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   26.846357] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   26.847870] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   26.876056] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   26.886536] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   26.901721] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   26.955236] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   26.973828] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   27.073461] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   27.109492] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   27.111529] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   27.136708] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   27.154213] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> [   27.201532] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   27.237009] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   27.420368] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   27.472525] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   27.499439] dcn_phantom_drv: VIF Support v1.0 <NL> [   27.501344] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   27.564353] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   27.599961] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   27.626709] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   27.657060] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   27.681453] systemd[1]: Mounting /var/telemetry... <NL> [   27.681677] packet_injector_class: driver registered correctly with major number 246 <NL> [   27.726496] Packet_injector 257949696: minor device creation 246:0 <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   27.738111] Packet_injector 257949697: minor device creation 246:1 <NL> [   27.746316] Packet_injector 257949698: minor device creation 246:2 <NL> [   27.752353] Packet_injector 257949699: minor device creation 246:3 <NL> [   27.762966] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   27.893149] systemd[1]: Starting Rule-based Manager for Device Events and Files..."}
{"timestamp_utc": "2024-07-31T08:13:28.642Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   27.917578] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   27.957766] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   27.986750] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   27.994470] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   28.019366] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   28.023339] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   28.039266] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   28.237945] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   28.249653] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   28.302522] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   28.306440] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   28.348058] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   28.401051] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   28.422076] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   28.475893] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   28.978739] systemd-journald[357]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (6s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (7s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (7s / no limit) <NL> [   32.618611] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   32.621912] Console: switching to colour dummy device 80x25 <NL> [   32.635809] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   32.664997] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   32.683521] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   32.791134] Floppy drive(s): fd0 is 1.44M <NL> [   32.817443] FDC 0 is a S82078B <NL> [   32.824321] Console: switching to colour frame buffer device 128x48 <NL> [   32.835957] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> \u001b[K[   32.916586] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   32.917921] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:29.205Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "Kernel Variables\u001b[0m... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (5s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (6s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   26.186582] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   26.210198] Floppy drive(s): fd0 is 1.44M <NL> [   26.225818] FDC 0 is a S82078B <NL> [   26.228716] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [   26.420588] Console: switching to colour dummy device 80x25 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   26.490339] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   26.520731] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   26.601166] Console: switching to colour frame buffer device 128x48 <NL> [   26.604519] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   26.604838] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   26.759578] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:29.206Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:48094)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   33.407744] pktHandler[598]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   33.447168] pktHandler[598]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   33.484704] pktHandler[598]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   33.501227] pktHandler[598]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   33.523258] pktHandler[598]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   33.538434] pktHandler[598]: Init PktClient init complete <NL> [   33.539755] pktHandler[598]: EsalConfig::EsalConfig main 0 <NL> [   33.543091] pktHandler[598]: EsalConfig::EsalConfig trib 1 <NL> [   33.548488] pktHandler[598]: EsalConfig::EsalConfig ciRole 0 <NL> [   33.551595] pktHandler[598]: EsalConfig is not running inside container. <NL> [   33.552602] pktHandler[598]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   33.559402] pktHandler[598]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   33.560487] pktHandler[598]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   33.573208] pktHandler[598]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   33.605126] pktHandler[598]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   33.606559] pktHandler[598]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:13:29.768Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   23.810395] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   23.811476] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   23.833282] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   23.845977] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   23.912172] systemd[1]: Mounting /var/volatile... <NL> [   23.981640] dcn_phantom_drv: VIF Support v1.0 <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   24.184861] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> [   24.223905] packet_injector_class: driver registered correctly with major number 246 <NL> [   24.240211] Packet_injector 257949696: minor device creation 246:0 <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   24.253658] systemd[1]: Mounted /var/ftp. <NL> [   24.254396] Packet_injector 257949697: minor device creation 246:1 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   24.264182] systemd[1]: Mounted /var/log. <NL> [   24.264917] Packet_injector 257949698: minor device creation 246:2 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   24.285814] Packet_injector 257949699: minor device creation 246:3 <NL> [   24.297241] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   24.325295] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   24.398020] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   24.433647] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   24.467456] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   24.518576] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   24.614410] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   24.668955] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   24.670647] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   24.679392] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   24.744974] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   24.794597] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   24.827988] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   25.521347] systemd-journald[359]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6Information startup (7s / 5min 3s) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6Information startup (8s / 5min 3s) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6Information startup (8s / 5min 3s) <NL> [   29.963108] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   30.028527] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   30.045263] Floppy drive(s): fd0 is 1.44M <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> \u001b[K[   30.105435] FDC 0 is a S82078B <NL> [   30.105527] Console: switching to colour dummy device 80x25 <NL> [   30.137442] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> [   30.165078] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   30.228299] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   30.228392] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   30.301671] Console: switching to colour frame buffer device 128x48 <NL> [   30.378257] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:29.769Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:30.040Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   32.765511] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.777099] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.811628] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.826346] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.863236] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.881836] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.917398] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.921408] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   32.974098] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   33.016115] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   33.057021] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   33.133034] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   33.161632] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   33.190088] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   33.215634] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   33.245137] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   33.261211] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   33.270852] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   33.277284] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   33.279638] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   33.286636] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   33.292791] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   33.297260] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   33.336958] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   33.374050] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   33.391676] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   33.406728] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   33.413625] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   33.417036] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   33.431341] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   33.433357] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   33.442430] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   33.444227] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   33.454442] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   33.469182] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   33.487235] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   33.503888] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   33.550897] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   33.572191] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   33.631838] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   33.640583] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   33.717790] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   33.751147] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   33.800954] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   33.983403] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   34.100022] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   34.143876] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   34.239444] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   34.285103] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   34.716454] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   34.737412] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   34.775439] systemd[1]: Mounted Kernel Debug File System."}
{"timestamp_utc": "2024-07-31T08:13:30.041Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:30.297Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   21.010492] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   21.012319] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   21.016519] Packet_injector 257949697: minor device creation 246:1 <NL> [   21.068941] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   21.074781] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   21.116161] Packet_injector 257949698: minor device creation 246:2 <NL> [   21.140356] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   21.145849] Packet_injector 257949699: minor device creation 246:3 <NL> [   21.156311] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   21.219116] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   21.243886] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   21.466204] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   21.537883] systemd[1]: Finished Load/Save Random Seed. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   21.636972] systemd[1]: First Boot Complete was skipped because of a failed condition check (ConditionFirstBoot=yes). <NL> [   21.672825] systemd[1]: Commit a transient machine-id on disk was skipped because of a failed condition check (ConditionPathIsMountPoint=/etc/machine-id). <NL> [   22.128890] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   22.222885] systemd[1]: Finished Apply Kernel Variables. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [   22.942747] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   23.086805] systemd-journald[359]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6Information startup (7s / 5min 2s) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6Information startup (7s / 5min 2s) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6Information startup (8s / 5min 2s) <NL> [   27.108404] Installing knfsd (copyright (C) 1996 okir@monad.swb.de)."}
{"timestamp_utc": "2024-07-31T08:13:30.298Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   27.188443] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   27.188836] Floppy drive(s): fd0 is 1.44M <NL> [   27.211966] FDC 0 is a S82078B <NL> [   27.333291] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   27.333393] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   27.679666] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> \u001b[K[   27.728534] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   27.764149] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   27.798409] Console: switching to colour frame buffer device 128x48 <NL> [   27.830649] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [   33.150130] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:30.859Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37281, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37281\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37193, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:31.115Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p06.NE3-trib1-debug-ssh", "message_content": "# 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37219, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37219\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37285, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:32.479Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   23.281659] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   23.514690] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   23.561653] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   23.612541] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   23.656755] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   23.716171] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   23.775931] packet_injector_class: driver registered correctly with major number 246 <NL> [   23.804527] Packet_injector 257949696: minor device creation 246:0 <NL> [   23.833892] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   23.835034] Packet_injector 257949697: minor device creation 246:1 <NL> [   23.857476] Packet_injector 257949698: minor device creation 246:2 <NL> [   23.858822] Packet_injector 257949699: minor device creation 246:3 <NL> [   23.905665] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   23.938937] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   23.963072] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   23.985836] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   24.001868] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   24.028192] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   24.119547] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   24.183373] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   24.245132] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   24.312825] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   24.331632] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   24.409981] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   24.435273] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   24.438181] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   24.476492] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   25.029592] systemd-journald[360]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (7s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (8s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (8s / no limit) <NL> [   29.583711] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   29.610649] Floppy drive(s): fd0 is 1.44M <NL> [   29.621270] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   29.642517] FDC 0 is a S82078B <NL> [   29.679280] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> \u001b[K[   29.739229] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0"}
{"timestamp_utc": "2024-07-31T08:13:32.480Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   29.752449] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   29.798265] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   29.798561] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   29.812781] Console: switching to colour frame buffer device 128x48 <NL> [   29.858104] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> # 03:13:32 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:32 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:13:32.736Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\": process 3330 terminated with exitcode 0 <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #1 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 6 children running (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:32.991Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p08.NE4-trib1-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p08.NE4-trib1-debug-ssh", "message_content": "# 03:13:32 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:32 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\": process 3336 terminated with exitcode 0 <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #7 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 5 children running (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:36.256Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p03.s01.NE2-main-debug-ssh", "message_content": "# 03:13:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37281, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:35 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37219, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:35 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:37.185Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   19.232638] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   19.303750] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   19.464302] dcn_phantom_drv: VIF Support v1.0 <NL> [   19.517319] systemd-journald[324]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m.[   19.730622] packet_injector_class: driver registered correctly with major number 246 <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [   19.920973] Packet_injector 257949696: minor device creation 246:0 <NL> [   20.007016] Packet_injector 257949697: minor device creation 246:1 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> [   20.057999] Packet_injector 257949698: minor device creation 246:2 <NL> [   20.059959] Packet_injector 257949699: minor device creation 246:3 <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [   22.518656] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (8s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (9s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (9s / no limit) <NL> [   26.716229] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (10s / 5min 1s) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (10s / 5min 1s) <NL> [   27.268579] Floppy drive(s): fd0 is 1.44M <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (11s / 5min 1s) <NL> [   27.842677] FDC 0 is a S82078B <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> [   29.364757] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   29.448853] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   29.476283] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (12s / 5min 1s)[   31.180126] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (14s / 5min 1s) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   31.962795] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   33.515757] Console: switching to colour frame buffer device 128x48 <NL> [   34.203992] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically restarts sync-log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:37.186Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> [   38.215512] sched: RT throttling activated <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [   38.966414] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:47486)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   40.435467] pktHandler[596]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.443260] pktHandler[596]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg"}
{"timestamp_utc": "2024-07-31T08:13:37.187Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   40.481147] pktHandler[596]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   40.516703] pktHandler[596]: GetRxFilters:83 rawdata= <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   40.560291] pktHandler[596]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.569059] pktHandler[596]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.590747] pktHandler[596]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.591872] pktHandler[596]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   40.593066] pktHandler[596]: GetRxFilters:83 rawdata= <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   40.655516] pktHandler[596]: Init PktClient init complete <NL> [   40.689656] pktHandler[596]: EsalConfig::EsalConfig main 1 <NL> [   40.691259] pktHandler[596]: EsalConfig::EsalConfig trib 0 <NL> [   40.693035] pktHandler[596]: EsalConfig::EsalConfig ciRole 0 <NL> [   40.694888] pktHandler[596]: EsalConfig is not running inside container. <NL> [   40.707059] pktHandler[596]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.729678] pktHandler[596]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.747503] pktHandler[596]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.765174] pktHandler[596]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.790371] pktHandler[596]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   40.790492] pktHandler[596]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   40.790572] pktHandler[596]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   40.790644] pktHandler[596]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   40.790716] pktHandler[596]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   40.790799] pktHandler[596]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   40.790873] pktHandler[596]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   40.790949] pktHandler[596]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   40.791056] pktHandler[596]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   40.791126] pktHandler[596]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   40.791220] pktHandler[596]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   40.791301] pktHandler[596]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   40.791377] pktHandler[596]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   40.791449] pktHandler[596]: pkt-handler: sd_notify ready"}
{"timestamp_utc": "2024-07-31T08:13:37.748Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p03.s01.NE2-main-debug-ssh", "message_content": "# 03:13:37 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:37 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:13:38.004Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:37 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:37 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:37 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\": process 3331 terminated with exitcode 0 <NL> # 03:13:37 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:13:37 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:13:37 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37279', '--delay', '5'] (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:13:37 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p03.s02.NE2-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37279', '--delay', '5'] <NL> # 03:13:37 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:13:37 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"command\" <NL> # 03:13:37 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:38.277Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:38 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37279, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:38 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:38.534Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p06.NE3-trib1-debug-ssh", "message_content": "# 03:13:38 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:38 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> [   34.355698] pktHandler[573]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.389269] pktHandler[573]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.401826] pktHandler[573]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.411289] pktHandler[573]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.433209] pktHandler[573]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   34.451933] pktHandler[573]: Init PktClient init complete <NL> [   34.466351] pktHandler[573]: EsalConfig::EsalConfig main 0 <NL> [   34.483761] pktHandler[573]: EsalConfig::EsalConfig trib 1 <NL> [   34.489110] pktHandler[573]: EsalConfig::EsalConfig ciRole 0 <NL> [   34.511354] pktHandler[573]: EsalConfig is not running inside container. <NL> [   34.527602] pktHandler[573]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   34.533204] pktHandler[573]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   34.555139] pktHandler[573]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   34.571241] pktHandler[573]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   34.581831] pktHandler[573]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   34.624512] pktHandler[573]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   34.645268] pktHandler[573]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   34.649707] pktHandler[573]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   34.666887] pktHandler[573]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   34.672531] pktHandler[573]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   34.682736] pktHandler[573]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   34.711601] pktHandler[573]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   34.717153] pktHandler[573]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   34.732382] pktHandler[573]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   34.761768] pktHandler[573]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   34.779669] pktHandler[573]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   34.788173] pktHandler[573]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   34.789306] pktHandler[573]: pkt-handler: sd_notify ready <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:60816)\u001b[0m. <NL> [   35.203809] commsdriver[584]: DllUtil::symbolInit() <NL> [   35.252215] commsdriver[584]: int DllInit() <NL> [   35.252946] commsdriver[584]: DllUtil::DllInit DllInit() return is null <NL> [   35.253837] commsdriver[584]: Could not resolve symbol name get_late_config_file_path <NL> [   35.254776] commsdriver[584]: Could not resolve symbol name create_l3_interface <NL> [   35.255698] commsdriver[584]: Could not resolve symbol name create_l2_interface <NL> [   35.256900] commsdriver[584]: Could not resolve symbol name delete_interface <NL> [   35.257924] commsdriver[584]: Could not resolve symbol name pre_setup_interfaces <NL> [   35.258849] commsdriver[584]: Could not resolve symbol name setup_interfaces <NL> [   35.259716] commsdriver[584]: Could not resolve symbol name post_setup_interfaces <NL> [   35.260639] commsdriver[584]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   35.261817] commsdriver[584]: Could not resolve symbol name setup_late_interfaces <NL> [   35.264326] commsdriver[584]: Could not resolve symbol name post_setup_late_interfaces <NL> [   35.279096] commsdriver[584]: Could not resolve symbol name pre_init <NL> [   35.284110] commsdriver[584]: Could not resolve symbol name post_init <NL> [   35.299881] commsdriver[584]: Could not resolve symbol name pre_handle_link_state_change <NL> [   35.306194] commsdriver[584]: Could not resolve symbol name handle_link_state_change <NL> [   35.327096] commsdriver[584]: Could not resolve symbol name post_handle_link_state_change <NL> [   35.338987] commsdriver[584]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   35.346589] commsdriver[584]: Could not resolve symbol name handle_link_state_notify <NL> [   35.348174] commsdriver[584]: Could not resolve symbol name post_handle_link_state_notify <NL> [   35.368023] commsdriver[584]: Could not resolve symbol name handle_rate_duplex_change <NL> [   35.372406] commsdriver[584]: Could not resolve symbol name delete_mac_address <NL> [   35.389701] commsdriver[584]: Could not resolve symbol name set_vlan_prio <NL> [   35.395057] commsdriver[584]: Could not resolve symbol name replay_mac <NL> [   35.456680] commsdriver[584]: Could not resolve symbol name set_red_state <NL> [   35.469610] commsdriver[584]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   35.478593] commsdriver[584]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   35.481966] commsdriver[584]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   35.489703] commsdriver[584]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   35.492882] commsdriver[584]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.502521] commsdriver[584]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   35.510165] commsdriver[584]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.537224] commsdriver[584]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.541521] commsdriver[584]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   35.549965] commsdriver[584]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   35.550895] commsdriver[584]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   35.556251] commsdriver[584]: SharedMemory::getShmSegment creating new segment <NL> [   35.564115] commsdriver[584]: SharedMemory::getShmSegment SUCCESS shmid_ = 0"}
{"timestamp_utc": "2024-07-31T08:13:38.535Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "fujitsu login: [   38.281220] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   38.009591] commsdriver[634]: SUCCESS <NL> [   40.310252] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   40.403392] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   40.514939] commsdriver[584]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   40.952820] device eth1 entered promiscuous mode <NL> [   40.593523] commsdriver[584]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   41.262818] commsdriver[584]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   41.346757] commsdriver[684]: Actual changes: <NL> [   41.346945] commsdriver[684]: tx-checksum-ip-generic: off <NL> [   41.367767] commsdriver[684]: tx-tcp-segmentation: off [not requested] <NL> [   41.367970] commsdriver[684]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   41.411405] commsdriver[684]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   41.417952] commsdriver[684]: tx-tcp6-segmentation: off [not requested] <NL> [   41.931592] commsdriver[584]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   42.000855] commsdriver[696]: Actual changes: <NL> [   42.007749] commsdriver[696]: tx-checksum-ip-generic: off <NL> [   42.007866] commsdriver[696]: tx-tcp-segmentation: off [not requested] <NL> [   42.007962] commsdriver[696]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   42.008069] commsdriver[696]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   42.008149] commsdriver[696]: tx-tcp6-segmentation: off [not requested] <NL> [   42.850794] br-odcc1: port 1(eth2) entered blocking state <NL> # 03:13:38 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:38 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:38 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\": process 3334 terminated with exitcode 0 <NL> # 03:13:38 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:13:38 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #5 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:38 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 4 children running (n01.p09.s01.startup (p)) <NL> # 03:13:38 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", exit_code 0 <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [   37.592100] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:53142)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   40.196466] pktHandler[580]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.237267] pktHandler[580]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.263912] pktHandler[580]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.280090] pktHandler[580]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.303579] pktHandler[580]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   40.336628] pktHandler[580]: Init PktClient init complete <NL> [   40.340740] pktHandler[580]: EsalConfig::EsalConfig main 0 <NL> [   40.420887] pktHandler[580]: EsalConfig::EsalConfig trib 1 <NL> [   40.431743] pktHandler[580]: EsalConfig::EsalConfig ciRole 0 <NL> [   40.448866] pktHandler[580]: EsalConfig is not running inside container. <NL> [   40.454079] pktHandler[580]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.461703] pktHandler[580]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.471679] pktHandler[580]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.474048] pktHandler[580]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   40.475221] pktHandler[580]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   40.481258] pktHandler[580]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   40.482335] pktHandler[580]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   40.500314] pktHandler[580]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   40.502034] pktHandler[580]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   40.503207] pktHandler[580]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   40.505156] pktHandler[580]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   40.516227] pktHandler[580]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   40.570089] pktHandler[580]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   40.603149] pktHandler[580]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   40.608492] pktHandler[580]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   40.613366] pktHandler[580]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   40.627625] pktHandler[580]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   40.642033] pktHandler[580]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   40.855661] commsdriver[597]: DllUtil::symbolInit() <NL> [   40.856939] commsdriver[597]: int DllInit() <NL> [   40.858526] commsdriver[597]: DllUtil::DllInit DllInit() return is null <NL> [   40.860636] commsdriver[597]: Could not resolve symbol name get_late_config_file_path <NL> [   40.865189] commsdriver[597]: Could not resolve symbol name create_l3_interface <NL> [   40.893050] commsdriver[597]: Could not resolve symbol name create_l2_interface <NL> [   40.908873] commsdriver[597]: Could not resolve symbol name delete_interface <NL> [   40.916387] commsdriver[597]: Could not resolve symbol name pre_setup_interfaces <NL> [   40.924329] commsdriver[597]: Could not resolve symbol name setup_interfaces <NL> [   40.935999] commsdriver[597]: Could not resolve symbol name post_setup_interfaces <NL> [   40.944714] commsdriver[597]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   40.982361] commsdriver[597]: Could not resolve symbol name setup_late_interfaces <NL> [   40.987565] commsdriver[597]: Could not resolve symbol name post_setup_late_interfaces <NL> [   40.992815] commsdriver[597]: Could not resolve symbol name pre_init <NL> [   40.999331] commsdriver[597]: Could not resolve symbol name post_init <NL> [   41.004494] commsdriver[597]: Could not resolve symbol name pre_handle_link_state_change <NL> [   41.031357] commsdriver[597]: Could not resolve symbol name handle_link_state_change <NL> [   41.032657] commsdriver[597]: Could not resolve symbol name post_handle_link_state_change <NL> [   41.033692] commsdriver[597]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   41.042379] commsdriver[597]: Could not resolve symbol name handle_link_state_notify <NL> [   41.057254] commsdriver[597]: Could not resolve symbol name post_handle_link_state_notify"}
{"timestamp_utc": "2024-07-31T08:13:38.536Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   41.064341] commsdriver[597]: Could not resolve symbol name handle_rate_duplex_change <NL> [   41.075682] commsdriver[597]: Could not resolve symbol name delete_mac_address <NL> [   41.079529] commsdriver[597]: Could not resolve symbol name set_vlan_prio <NL> [   41.111686] commsdriver[597]: Could not resolve symbol name replay_mac <NL> [   41.160830] commsdriver[597]: Could not resolve symbol name set_red_state <NL> [   41.163481] commsdriver[597]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   41.169725] commsdriver[597]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   41.176866] commsdriver[597]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   41.184814] commsdriver[597]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   41.199724] commsdriver[597]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   41.216574] commsdriver[597]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   41.229874] commsdriver[597]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   41.243785] commsdriver[597]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   41.260605] commsdriver[597]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   41.294168] commsdriver[597]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   41.338322] commsdriver[597]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg"}
{"timestamp_utc": "2024-07-31T08:13:38.792Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[   33.623660] pktHandler[598]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   33.660431] pktHandler[598]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   33.683433] pktHandler[598]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   33.690884] pktHandler[598]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   33.691953] pktHandler[598]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   33.692823] pktHandler[598]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   33.698553] pktHandler[598]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   33.699644] pktHandler[598]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   33.700706] pktHandler[598]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   33.774412] pktHandler[598]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   33.832263] pktHandler[598]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   33.833443] pktHandler[598]: pkt-handler: sd_notify ready <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   34.108285] commsdriver[609]: DllUtil::symbolInit() <NL> [   34.136972] commsdriver[609]: int DllInit() <NL> [   34.168957] commsdriver[609]: DllUtil::DllInit DllInit() return is null <NL> [   34.186148] commsdriver[609]: Could not resolve symbol name get_late_config_file_path <NL> [   34.202475] commsdriver[609]: Could not resolve symbol name create_l3_interface <NL> [   34.247980] commsdriver[609]: Could not resolve symbol name create_l2_interface <NL> [   34.277099] commsdriver[609]: Could not resolve symbol name delete_interface <NL> [   34.283264] commsdriver[609]: Could not resolve symbol name pre_setup_interfaces <NL> [   34.298604] commsdriver[609]: Could not resolve symbol name setup_interfaces <NL> [   34.327482] commsdriver[609]: Could not resolve symbol name post_setup_interfaces <NL> [   34.329282] commsdriver[609]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   34.360872] commsdriver[609]: Could not resolve symbol name setup_late_interfaces <NL> [   34.374385] commsdriver[609]: Could not resolve symbol name post_setup_late_interfaces <NL> [   34.386283] commsdriver[609]: Could not resolve symbol name pre_init <NL> [   34.392293] commsdriver[609]: Could not resolve symbol name post_init <NL> [   34.401576] commsdriver[609]: Could not resolve symbol name pre_handle_link_state_change <NL> [   34.421743] commsdriver[609]: Could not resolve symbol name handle_link_state_change <NL> [   34.440819] commsdriver[609]: Could not resolve symbol name post_handle_link_state_change <NL> [   34.446213] commsdriver[609]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   34.448854] commsdriver[609]: Could not resolve symbol name handle_link_state_notify <NL> [   34.464945] commsdriver[609]: Could not resolve symbol name post_handle_link_state_notify <NL> [   34.520252] commsdriver[609]: Could not resolve symbol name handle_rate_duplex_change <NL> [   34.558375] commsdriver[609]: Could not resolve symbol name delete_mac_address <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Database Manager\u001b[0m. <NL> [   34.559883] commsdriver[609]: Could not resolve symbol name set_vlan_prio <NL> [   34.595842] commsdriver[609]: Could not resolve symbol name replay_mac <NL> [   34.603647] commsdriver[609]: Could not resolve symbol name set_red_state <NL> [   34.615832] commsdriver[609]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   34.627693] commsdriver[609]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   34.673854] commsdriver[609]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   34.683115] commsdriver[609]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   34.697881] commsdriver[609]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   34.718416] commsdriver[609]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   34.728875] commsdriver[609]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   34.733576] commsdriver[609]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   34.734738] commsdriver[609]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   34.762744] commsdriver[609]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   34.765972] commsdriver[609]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   34.851886] commsdriver[609]: SharedMemory::getShmSegment creating new segment <NL> [   34.864445] commsdriver[609]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser Slice of UID 3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Manager for UID 3000\u001b[0m... <NL> fujitsu login: [   38.378532] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   38.035806] commsdriver[652]: SUCCESS"}
{"timestamp_utc": "2024-07-31T08:13:38.793Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[   40.401312] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   40.402827] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   41.320176] device eth1 entered promiscuous mode <NL> [   40.935660] commsdriver[609]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   40.954465] commsdriver[609]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   41.441705] commsdriver[609]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   41.485434] commsdriver[693]: Actual changes: <NL> [   41.544130] commsdriver[693]: tx-checksum-ip-generic: off <NL> [   41.544234] commsdriver[693]: tx-tcp-segmentation: off [not requested] <NL> [   41.544310] commsdriver[693]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   41.544381] commsdriver[693]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   41.576233] commsdriver[693]: tx-tcp6-segmentation: off [not requested] <NL> [   42.059174] e1000 0000:00:04.0 eth1: Reset adapter <NL> [   42.177617] e1000 0000:00:04.0 eth1: Reset adapter <NL> [   42.072786] commsdriver[609]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   42.168272] commsdriver[705]: Actual changes: <NL> [   42.182181] commsdriver[705]: tx-checksum-ip-generic: off <NL> [   42.187588] commsdriver[705]: tx-tcp-segmentation: off [not requested] <NL> [   42.199808] commsdriver[705]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   42.199908] commsdriver[705]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   42.199987] commsdriver[705]: tx-tcp6-segmentation: off [not requested] <NL> [   42.870010] br-odcc1: port 1(eth2) entered blocking state <NL> [   42.870728] br-odcc1: port 1(eth2) entered disabled state <NL> [   42.871875] device eth2 entered promiscuous mode <NL> [   42.904420] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   42.934541] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   42.953817] device odcc1-peer entered promiscuous mode <NL> [   43.055408] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   43.110846] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   43.113512] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   43.131826] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   42.772186] commsdriver[609]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   42.804923] commsdriver[609]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   43.547092] br-odcc2: port 1(eth3) entered blocking state <NL> [   43.576999] br-odcc2: port 1(eth3) entered disabled state <NL> [   43.599363] device eth3 entered promiscuous mode <NL> [   43.618683] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   43.631750] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   43.656117] device odcc2-peer entered promiscuous mode <NL> [   43.696151] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   43.725849] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   43.742677] br-odcc2: port 2(odcc2-peer) entered forwarding state"}
{"timestamp_utc": "2024-07-31T08:13:40.681Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   28.353692] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   28.391890] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   28.393388] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   28.457430] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   28.502520] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   28.593773] fuse: init (API version 7.32) <NL> [   28.638152] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   28.688948] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   28.759709] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   28.795911] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   28.803931] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv)."}
{"timestamp_utc": "2024-07-31T08:13:40.682Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   28.821989] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   28.898258] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   29.029966] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   29.069496] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   29.117843] systemd[1]: Finished Load/Save Random Seed. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   29.168758] systemd[1]: First Boot Complete was skipped because of a failed condition check (ConditionFirstBoot=yes). <NL> [   29.194193] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   29.265924] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   29.353189] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   29.443729] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   29.537355] systemd[1]: Commit a transient machine-id on disk was skipped because of a failed condition check (ConditionPathIsMountPoint=/etc/machine-id). <NL> [   29.638462] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   29.882188] systemd[1]: Started Rule-based Manager for Device Events and Files. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   30.043524] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   30.100786] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [   30.187221] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   30.464694] systemd-journald[325]: Received client request to flush runtime journal. <NL> [   30.525346] dcn_phantom_drv: VIF Support v1.0 <NL> [   30.729917] packet_injector_class: driver registered correctly with major number 246 <NL> [   30.730973] Packet_injector 257949696: minor device creation 246:0 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m.[   30.867163] Packet_injector 257949697: minor device creation 246:1 <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [   31.216403] Packet_injector 257949698: minor device creation 246:2 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m.[   31.659848] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [   33.978297] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (11s / 5min 4s) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (11s / 5min 4s) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (11s / 5min 4s) <NL> [   37.729892] parport_pc 00:04: reported by Plug and Play ACPI <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> [   38.370536] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (13s / 5min 4s) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   39.301701] Floppy drive(s): fd0 is 1.44M <NL> [   39.840370] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   40.022946] Console: switching to colour dummy device 80x25 <NL> [   40.151612] FDC 0 is a S82078B <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m.[   41.412175] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   41.636090] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   41.738701] Console: switching to colour frame buffer device 128x48 <NL> [   41.889844] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically restarts sync-log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:40.939Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p01.s01.NE1-main-debug-ssh", "message_content": "# 03:13:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:40 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:41.196Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:13:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:57142)\u001b[0m. <NL> [   36.024078] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m... <NL> [   39.753793] pktHandler[590]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.755157] pktHandler[590]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.762497] pktHandler[590]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.775575] pktHandler[590]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.775678] pktHandler[590]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   39.828570] pktHandler[590]: Init PktClient init complete <NL> [   39.828784] pktHandler[590]: EsalConfig::EsalConfig main 0 <NL> [   39.828858] pktHandler[590]: EsalConfig::EsalConfig trib 1 <NL> [   39.828927] pktHandler[590]: EsalConfig::EsalConfig ciRole 0 <NL> [   39.867278] pktHandler[590]: EsalConfig is not running inside container. <NL> [   39.868204] pktHandler[590]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.889596] pktHandler[590]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.916477] pktHandler[590]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.931025] pktHandler[590]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   39.943341] pktHandler[590]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   39.947643] pktHandler[590]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   39.963228] pktHandler[590]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   39.965508] pktHandler[590]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   39.970270] pktHandler[590]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   39.971227] pktHandler[590]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   39.991148] pktHandler[590]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   39.996427] pktHandler[590]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   40.015189] pktHandler[590]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   40.016183] pktHandler[590]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   40.020714] pktHandler[590]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   40.029650] pktHandler[590]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   40.043563] pktHandler[590]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   40.049690] pktHandler[590]: pkt-handler: sd_notify ready <NL> [   40.365533] commsdriver[601]: DllUtil::symbolInit() <NL> [   40.366310] commsdriver[601]: int DllInit() <NL> [   40.366864] commsdriver[601]: DllUtil::DllInit DllInit() return is null <NL> [   40.367679] commsdriver[601]: Could not resolve symbol name get_late_config_file_path <NL> [   40.368880] commsdriver[601]: Could not resolve symbol name create_l3_interface <NL> [   40.370985] commsdriver[601]: Could not resolve symbol name create_l2_interface <NL> [   40.371896] commsdriver[601]: Could not resolve symbol name delete_interface <NL> [   40.381303] commsdriver[601]: Could not resolve symbol name pre_setup_interfaces <NL> [   40.381407] commsdriver[601]: Could not resolve symbol name setup_interfaces <NL> [   40.381479] commsdriver[601]: Could not resolve symbol name post_setup_interfaces <NL> [   40.427458] commsdriver[601]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   40.427555] commsdriver[601]: Could not resolve symbol name setup_late_interfaces <NL> [   40.427628] commsdriver[601]: Could not resolve symbol name post_setup_late_interfaces <NL> [   40.427727] commsdriver[601]: Could not resolve symbol name pre_init <NL> [   40.427819] commsdriver[601]: Could not resolve symbol name post_init <NL> [   40.427891] commsdriver[601]: Could not resolve symbol name pre_handle_link_state_change"}
{"timestamp_utc": "2024-07-31T08:13:41.197Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   40.427960] commsdriver[601]: Could not resolve symbol name handle_link_state_change <NL> [   40.445296] commsdriver[601]: Could not resolve symbol name post_handle_link_state_change <NL> fujitsu login: [   40.517839] commsdriver[601]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   40.564395] commsdriver[601]: Could not resolve symbol name handle_link_state_notify <NL> [   40.564524] commsdriver[601]: Could not resolve symbol name post_handle_link_state_notify <NL> [   40.564609] commsdriver[601]: Could not resolve symbol name handle_rate_duplex_change <NL> [   40.564685] commsdriver[601]: Could not resolve symbol name delete_mac_address <NL> [   40.564754] commsdriver[601]: Could not resolve symbol name set_vlan_prio <NL> [   40.564827] commsdriver[601]: Could not resolve symbol name replay_mac <NL> [   40.564896] commsdriver[601]: Could not resolve symbol name set_red_state <NL> [   40.564964] commsdriver[601]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   40.565098] commsdriver[601]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   40.644165] commsdriver[601]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   40.644304] commsdriver[601]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   40.644383] commsdriver[601]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.644455] commsdriver[601]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   40.644527] commsdriver[601]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.644613] commsdriver[601]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.644980] commsdriver[601]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   40.645138] commsdriver[601]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   40.645487] commsdriver[601]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   40.645565] commsdriver[601]: SharedMemory::getShmSegment creating new segment <NL> [   40.645636] commsdriver[601]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   43.633123] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   43.270922] commsdriver[648]: SUCCESS <NL> [   45.053372] commsdriver[601]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   45.522338] device eth1 entered promiscuous mode <NL> [   45.097238] commsdriver[601]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   45.632048] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   45.639476] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   45.417482] commsdriver[601]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   45.484722] commsdriver[685]: Actual changes: <NL> [   45.484905] commsdriver[685]: tx-checksum-ip-generic: off <NL> [   45.485023] commsdriver[685]: tx-tcp-segmentation: off [not requested] <NL> [   45.485121] commsdriver[685]: tx-tcp-ecn-segmentation: off [not requested]"}
{"timestamp_utc": "2024-07-31T08:13:43.712Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:13:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:43 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> [   34.792428] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   34.808332] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   34.840841] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   34.854639] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   34.875290] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   34.878569] fuse: init (API version 7.32) <NL> [   34.887132] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   34.958201] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   34.968445] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   34.992179] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   35.002879] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   35.030067] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   35.082858] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   35.122230] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   35.129301] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   35.139873] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   35.147627] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   35.173345] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   35.177255] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   35.197500] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   35.221912] dcn_phantom_drv: VIF Support v1.0 <NL> [   35.233693] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   35.299644] packet_injector_class: driver registered correctly with major number 246 <NL> [   35.301302] Packet_injector 257949696: minor device creation 246:0 <NL> [   35.321673] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [   35.345099] Packet_injector 257949697: minor device creation 246:1 <NL> [   35.345135] Packet_injector 257949698: minor device creation 246:2 <NL> [   35.345163] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   35.365175] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   35.405784] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   35.420199] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   35.459276] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   35.470660] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   35.491364] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   35.523361] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   35.907015] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   35.913512] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   36.355529] systemd-journald[358]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [   38.656654] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   39.209762] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   39.212136] Console: switching to colour dummy device 80x25 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   39.298715] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   39.748338] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   39.933614] Console: switching to colour frame buffer device 128x48 <NL> [   39.989739] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device"}
{"timestamp_utc": "2024-07-31T08:13:43.713Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   40.024368] Floppy drive(s): fd0 is 1.44M <NL> [   40.073994] FDC 0 is a S82078B <NL> [   40.121073] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   40.142161] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (14s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (14s / no limit)"}
{"timestamp_utc": "2024-07-31T08:13:46.245Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:13:45 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:45 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:47.609Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [   43.982844] pktHandler[524]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   44.572509] pktHandler[524]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   45.016801] pktHandler[524]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   45.518283] pktHandler[524]: GetRxFilters:83 rawdata= <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   45.690222] pktHandler[524]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   46.008840] pktHandler[524]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   46.224230] pktHandler[524]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [   46.711761] pktHandler[524]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   47.029650] pktHandler[524]: GetRxFilters:83 rawdata= <NL> [   47.034590] pktHandler[524]: Init PktClient init complete <NL> [   47.395184] pktHandler[524]: EsalConfig::EsalConfig main 1 <NL> [   47.417998] pktHandler[524]: EsalConfig::EsalConfig trib 0 <NL> [   47.418830] pktHandler[524]: EsalConfig::EsalConfig ciRole 0 <NL> [   47.420292] pktHandler[524]: EsalConfig is not running inside container. <NL> [   47.442227] pktHandler[524]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.444287] pktHandler[524]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.446254] pktHandler[524]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.450465] pktHandler[524]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.463181] pktHandler[524]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   47.733887] pktHandler[524]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:13:47.610Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[   48.098981] pktHandler[524]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   48.328314] pktHandler[524]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   48.569916] pktHandler[524]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   48.668930] pktHandler[524]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   48.905332] pktHandler[524]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   48.967283] pktHandler[524]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   49.019276] pktHandler[524]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   49.060392] pktHandler[524]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   49.193667] pktHandler[524]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> fujitsu[   49.368159] pktHandler[524]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   49.445203] pktHandler[524]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> login: [   49.467267] pktHandler[524]: pkt-handler: sd_notify ready <NL> [   49.500078] commsdriver[541]: DllUtil::symbolInit() <NL> [   49.535604] commsdriver[541]: int DllInit() <NL> [   49.577637] commsdriver[541]: DllUtil::DllInit DllInit() return is null <NL> [   49.629655] commsdriver[541]: Could not resolve symbol name get_late_config_file_path <NL> [   49.694694] commsdriver[541]: Could not resolve symbol name create_l3_interface <NL> [   49.753493] commsdriver[541]: Could not resolve symbol name create_l2_interface <NL> [   49.819848] commsdriver[541]: Could not resolve symbol name delete_interface <NL> [   49.877411] commsdriver[541]: Could not resolve symbol name pre_setup_interfaces <NL> [   49.878461] commsdriver[541]: Could not resolve symbol name setup_interfaces <NL> [   49.879405] commsdriver[541]: Could not resolve symbol name post_setup_interfaces <NL> [   49.887572] commsdriver[541]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   49.908344] commsdriver[541]: Could not resolve symbol name setup_late_interfaces <NL> [   49.960728] commsdriver[541]: Could not resolve symbol name post_setup_late_interfaces <NL> [   49.998689] commsdriver[541]: Could not resolve symbol name pre_init <NL> [   50.031471] commsdriver[541]: Could not resolve symbol name post_init <NL> [   50.048818] commsdriver[541]: Could not resolve symbol name pre_handle_link_state_change <NL> [   50.079481] commsdriver[541]: Could not resolve symbol name handle_link_state_change <NL> [   50.147663] commsdriver[541]: Could not resolve symbol name post_handle_link_state_change <NL> [   50.182188] commsdriver[541]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   50.243409] commsdriver[541]: Could not resolve symbol name handle_link_state_notify <NL> [   50.244317] commsdriver[541]: Could not resolve symbol name post_handle_link_state_notify <NL> [   50.245237] commsdriver[541]: Could not resolve symbol name handle_rate_duplex_change <NL> [   50.257047] commsdriver[541]: Could not resolve symbol name delete_mac_address <NL> [   50.315098] commsdriver[541]: Could not resolve symbol name set_vlan_prio <NL> [   50.347106] commsdriver[541]: Could not resolve symbol name replay_mac <NL> [   50.354197] commsdriver[541]: Could not resolve symbol name set_red_state <NL> [   50.371491] commsdriver[541]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   50.408151] commsdriver[541]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   50.431629] commsdriver[541]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   50.448205] commsdriver[541]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   50.467919] commsdriver[541]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   50.476265] commsdriver[541]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   50.539740] commsdriver[541]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   50.559663] commsdriver[541]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   50.595562] commsdriver[541]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   50.603682] commsdriver[541]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   50.604466] commsdriver[541]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   50.605661] commsdriver[541]: SharedMemory::getShmSegment creating new segment <NL> [   50.680987] commsdriver[541]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   51.329855] br-lcn00: port 1(eth3) entered blocking state <NL> [   51.358395] br-lcn00: port 1(eth3) entered disabled state <NL> [   51.410384] device eth3 entered promiscuous mode <NL> [   51.460798] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   51.506357] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   51.523072] device lcn00-peer entered promiscuous mode <NL> [   51.652022] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   51.608453] commsdriver[541]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   52.904581] br-lcn01: port 1(eth4) entered blocking state <NL> [   52.956906] br-lcn01: port 1(eth4) entered disabled state <NL> [   52.999609] device eth4 entered promiscuous mode <NL> [   53.123560] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   53.156257] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   53.213278] device lcn01-peer entered promiscuous mode <NL> [   53.652352] 8021q: adding VLAN 0 to HW filter on device eth4"}
{"timestamp_utc": "2024-07-31T08:13:48.537Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:13:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:48 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:48.793Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   40.960380] commsdriver[608]: DllUtil::symbolInit() <NL> [   40.963973] commsdriver[608]: int DllInit() <NL> [   40.971357] commsdriver[608]: DllUtil::DllInit DllInit() return is null <NL> [   40.979221] commsdriver[608]: Could not resolve symbol name get_late_config_file_path <NL> [   40.988340] commsdriver[608]: Could not resolve symbol name create_l3_interface <NL> [   40.997829] commsdriver[608]: Could not resolve symbol name create_l2_interface <NL> [   41.009419] commsdriver[608]: Could not resolve symbol name delete_interface <NL> [   41.033394] commsdriver[608]: Could not resolve symbol name pre_setup_interfaces <NL> [   41.067240] commsdriver[608]: Could not resolve symbol name setup_interfaces <NL> [   41.079627] commsdriver[608]: Could not resolve symbol name post_setup_interfaces <NL> [   41.094835] commsdriver[608]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   41.121907] commsdriver[608]: Could not resolve symbol name setup_late_interfaces <NL> [   41.133646] commsdriver[608]: Could not resolve symbol name post_setup_late_interfaces <NL> [   41.164188] commsdriver[608]: Could not resolve symbol name pre_init <NL> [   41.171343] commsdriver[608]: Could not resolve symbol name post_init <NL> [   41.172298] commsdriver[608]: Could not resolve symbol name pre_handle_link_state_change <NL> [   41.173301] commsdriver[608]: Could not resolve symbol name handle_link_state_change <NL> [   41.187376] commsdriver[608]: Could not resolve symbol name post_handle_link_state_change <NL> [   41.196527] commsdriver[608]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   41.197645] commsdriver[608]: Could not resolve symbol name handle_link_state_notify <NL> [   41.206055] commsdriver[608]: Could not resolve symbol name post_handle_link_state_notify <NL> [   41.207808] commsdriver[608]: Could not resolve symbol name handle_rate_duplex_change <NL> [   41.218614] commsdriver[608]: Could not resolve symbol name delete_mac_address <NL> [   41.224675] commsdriver[608]: Could not resolve symbol name set_vlan_prio <NL> [   41.225595] commsdriver[608]: Could not resolve symbol name replay_mac <NL> [   41.226469] commsdriver[608]: Could not resolve symbol name set_red_state <NL> [   41.234475] commsdriver[608]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   41.243175] commsdriver[608]: config file=int get_config_file_path(char*, uint16_t) in commsQemu"}
{"timestamp_utc": "2024-07-31T08:13:48.794Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   41.256061] commsdriver[608]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   41.268841] commsdriver[608]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   41.274819] commsdriver[608]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   41.277127] commsdriver[608]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   41.281941] commsdriver[608]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   41.289378] commsdriver[608]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   41.301497] commsdriver[608]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   41.303828] commsdriver[608]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   41.320407] commsdriver[608]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   41.343868] commsdriver[608]: SharedMemory::getShmSegment creating new segment <NL> [   41.361610] commsdriver[608]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   44.582993] br-lcn00: port 1(eth3) entered blocking state <NL> [   44.589232] br-lcn00: port 1(eth3) entered disabled state <NL> [   44.590672] device eth3 entered promiscuous mode <NL> [   44.609525] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   44.611672] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   44.618325] device lcn00-peer entered promiscuous mode <NL> [   44.757438] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   44.280785] commsdriver[608]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   45.268358] br-lcn01: port 1(eth4) entered blocking state <NL> [   45.289576] br-lcn01: port 1(eth4) entered disabled state <NL> [   45.335704] device eth4 entered promiscuous mode <NL> [   45.389523] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   45.420821] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   45.442464] device lcn01-peer entered promiscuous mode <NL> [   45.623757] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   45.317922] commsdriver[608]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   46.571154] br-lmp00: port 1(eth2) entered blocking state <NL> [   46.571895] br-lmp00: port 1(eth2) entered disabled state <NL> [   46.591492] device eth2 entered promiscuous mode <NL> [   46.614470] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   46.625435] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   46.634800] device lmp00-peer entered promiscuous mode <NL> [   46.673972] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   46.169881] commsdriver[608]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   46.199233] commsdriver[608]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   46.789429] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   46.800365] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   46.805253] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   47.037863] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   47.046469] br-lcn00: port 1(eth3) entered blocking state <NL> [   47.054515] br-lcn00: port 1(eth3) entered forwarding state <NL> [   48.096460] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   47.602226] commsdriver[748]: SUCCESS <NL> [   48.253459] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   48.263822] br-lcn01: port 1(eth4) entered blocking state <NL> [   48.270685] br-lcn01: port 1(eth4) entered forwarding state <NL> [   48.700821] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   48.702302] br-lmp00: port 1(eth2) entered blocking state <NL> [   48.703858] br-lmp00: port 1(eth2) entered forwarding state <NL> [   50.112770] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   50.114470] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   49.677363] commsdriver[608]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   50.278355] device eth5 entered promiscuous mode <NL> [   49.744232] commsdriver[608]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   50.118886] commsdriver[608]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   50.709868] device erstp-peer entered promiscuous mode <NL> [   51.085008] br-odcc1: port 1(eth1) entered blocking state <NL> [   51.085833] br-odcc1: port 1(eth1) entered disabled state <NL> [   51.093286] device eth1 entered promiscuous mode <NL> [   51.115542] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   51.116450] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   51.117461] device odcc1-peer entered promiscuous mode <NL> [   51.209475] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   50.744424] commsdriver[608]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   50.775830] commsdriver[608]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   51.722141] br-odcc2: port 1(eth6) entered blocking state <NL> [   51.773076] br-odcc2: port 1(eth6) entered disabled state <NL> [   51.797162] device eth6 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:13:48.795Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   51.865747] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   51.884034] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   51.904484] device odcc2-peer entered promiscuous mode <NL> [   51.996239] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   52.042591] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   52.069556] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   52.114811] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   51.568617] commsdriver[608]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   51.604202] commsdriver[608]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   53.067153] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   53.113255] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   53.154514] device eth1.3800 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:13:49.051Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> [   44.838097] sched: RT throttling activated <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   47.278206] pktHandler[529]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.434169] pktHandler[529]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.777648] pktHandler[529]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   47.810405] pktHandler[529]: GetRxFilters:83 rawdata= <NL> [   47.955674] pktHandler[529]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.956888] pktHandler[529]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.958156] pktHandler[529]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.977070] pktHandler[529]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   47.978353] pktHandler[529]: GetRxFilters:83 rawdata= <NL> [   47.979081] pktHandler[529]: Init PktClient init complete <NL> [   48.139277] pktHandler[529]: EsalConfig::EsalConfig main 1 <NL> [   48.140030] pktHandler[529]: EsalConfig::EsalConfig trib 0 <NL> [   48.156176] pktHandler[529]: EsalConfig::EsalConfig ciRole 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   48.244728] pktHandler[529]: EsalConfig is not running inside container. <NL> [   48.404259] pktHandler[529]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   48.536182] pktHandler[529]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   48.634245] pktHandler[529]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [   48.760478] pktHandler[529]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   48.846177] pktHandler[529]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   48.869247] pktHandler[529]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   48.913209] pktHandler[529]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   48.949181] pktHandler[529]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   48.988214] pktHandler[529]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   49.028180] pktHandler[529]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   49.171753] pktHandler[529]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   49.275157] pktHandler[529]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   49.873384] pktHandler[529]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [   49.939488] pktHandler[529]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [   50.179701] pktHandler[529]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   50.210542] pktHandler[529]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   50.313917] pktHandler[529]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   50.421894] pktHandler[529]: pkt-handler: sd_notify ready <NL> [   50.586750] commsdriver[552]: DllUtil::symbolInit() <NL> [   50.615789] commsdriver[552]: int DllInit() <NL> [   50.618778] commsdriver[552]: DllUtil::DllInit DllInit() return is null <NL> [   50.639263] commsdriver[552]: Could not resolve symbol name get_late_config_file_path <NL> [   50.651826] commsdriver[552]: Could not resolve symbol name create_l3_interface <NL> [   50.654549] commsdriver[552]: Could not resolve symbol name create_l2_interface <NL> [   50.681319] commsdriver[552]: Could not resolve symbol name delete_interface <NL> [   50.690334] commsdriver[552]: Could not resolve symbol name pre_setup_interfaces <NL> [   50.697600] commsdriver[552]: Could not resolve symbol name setup_interfaces <NL> [   50.698350] commsdriver[552]: Could not resolve symbol name post_setup_interfaces <NL> [   50.699088] commsdriver[552]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   50.712370] commsdriver[552]: Could not resolve symbol name setup_late_interfaces <NL> [   50.721330] commsdriver[552]: Could not resolve symbol name post_setup_late_interfaces <NL> [   50.723289] commsdriver[552]: Could not resolve symbol name pre_init <NL> [   50.738784] commsdriver[552]: Could not resolve symbol name post_init <NL> [   50.739733] commsdriver[552]: Could not resolve symbol name pre_handle_link_state_change <NL> [   50.740707] commsdriver[552]: Could not resolve symbol name handle_link_state_change"}
{"timestamp_utc": "2024-07-31T08:13:49.052Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   50.741770] commsdriver[552]: Could not resolve symbol name post_handle_link_state_change <NL> [   50.768706] commsdriver[552]: Could not resolve symbol name pre_handle_link_state_notify"}
{"timestamp_utc": "2024-07-31T08:13:50.955Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:13:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:50 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37313\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:53.468Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:13:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:53 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:55.988Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p01.s01.NE1-main-debug-ssh", "message_content": "# 03:13:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37313, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:55 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:57.351Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "\u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (16s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (16s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (17s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (17s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (18s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (18s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (19s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (19s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (20s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (20s / no limit) <NL> [   53.626056] hrtimer: interrupt took 3970655 ns <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (21s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (21s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (22s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (22s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (23s / no limit)"}
{"timestamp_utc": "2024-07-31T08:13:57.352Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "\u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [   59.460937] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:36726)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   60.440824] pktHandler[605]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   60.483742] pktHandler[605]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   60.534351] pktHandler[605]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   60.607627] pktHandler[605]: GetRxFilters:83 rawdata= <NL> [   60.619693] pktHandler[605]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   60.626116] pktHandler[605]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   60.712878] pktHandler[605]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   60.716154] pktHandler[605]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   60.719686] pktHandler[605]: GetRxFilters:83 rawdata= <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   60.798986] pktHandler[605]: Init PktClient init complete <NL> [   60.800294] pktHandler[605]: EsalConfig::EsalConfig main 1 <NL> [   60.804593] pktHandler[605]: EsalConfig::EsalConfig trib 0"}
{"timestamp_utc": "2024-07-31T08:13:58.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p01.s01.NE1-main-debug-ssh", "message_content": "# 03:13:57 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:57 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:13:58 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:58 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:58 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\": process 3329 terminated with exitcode 0 <NL> # 03:13:58 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:13:58 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:13:58 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37311', '--delay', '5'] (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:13:58 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p01.s02.NE1-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37311', '--delay', '5'] <NL> # 03:13:58 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:13:58 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"command\" <NL> # 03:13:58 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", exit_code 0 <NL> # 03:13:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:58 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:58.569Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:58 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37311, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:58 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:01.085Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:14:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:01.650Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   41.355571] commsdriver[597]: SharedMemory::getShmSegment creating new segment <NL> [   41.376604] commsdriver[597]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   44.034988] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   43.934213] commsdriver[638]: SUCCESS <NL> [   46.045024] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.126001] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   46.897544] commsdriver[597]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   47.251653] device eth1 entered promiscuous mode <NL> [   46.977161] commsdriver[597]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   47.355688] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   47.341958] commsdriver[597]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   47.447531] commsdriver[686]: Actual changes: <NL> [   47.448198] commsdriver[686]: tx-checksum-ip-generic: off <NL> [   47.466557] commsdriver[686]: tx-tcp-segmentation: off [not requested] <NL> [   47.466709] commsdriver[686]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   47.466805] commsdriver[686]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   47.466882] commsdriver[686]: tx-tcp6-segmentation: off [not requested] <NL> [   47.955540] commsdriver[597]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   48.000627] commsdriver[698]: Actual changes: <NL> [   48.010319] commsdriver[698]: tx-checksum-ip-generic: off <NL> [   48.010440] commsdriver[698]: tx-tcp-segmentation: off [not requested] <NL> [   48.010516] commsdriver[698]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   48.010590] commsdriver[698]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   48.010670] commsdriver[698]: tx-tcp6-segmentation: off [not requested] <NL> [   48.754854] br-odcc1: port 1(eth2) entered blocking state <NL> [   48.785483] br-odcc1: port 1(eth2) entered disabled state <NL> [   48.803400] device eth2 entered promiscuous mode <NL> [   48.844778] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   48.863535] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   48.881789] device odcc1-peer entered promiscuous mode <NL> [   49.037315] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   49.165830] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   49.216273] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   49.248578] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   49.083634] commsdriver[597]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   49.083852] commsdriver[597]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   49.819624] br-odcc2: port 1(eth3) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:14:01.651Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[   49.847930] br-odcc2: port 1(eth3) entered disabled state <NL> [   49.867561] device eth3 entered promiscuous mode <NL> [   49.965022] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   49.965868] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   49.967190] device odcc2-peer entered promiscuous mode <NL> [   50.014043] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   50.036170] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   50.199847] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   50.290152] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   50.311536] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   50.349473] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   50.082034] commsdriver[597]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   50.105223] commsdriver[597]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   51.121029] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   51.163143] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   51.229501] device eth2.3800 entered promiscuous mode <NL> [   51.289571] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   51.323997] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   51.352691] device gcc0-peer entered promiscuous mode <NL> [   51.183917] commsdriver[597]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   51.238482] commsdriver[597]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   51.609531] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   51.611006] br-odcc1: port 1(eth2) entered blocking state <NL> [   51.612847] br-odcc1: port 1(eth2) entered forwarding state <NL> [   51.627729] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   51.628452] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   52.384508] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   52.385282] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   52.404453] device eth2.3801 entered promiscuous mode <NL> [   52.455183] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   52.476014] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   52.495043] device gcc1-peer entered promiscuous mode <NL> [   52.598601] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   52.612978] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   52.633637] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   52.644899] br-odcc2: port 1(eth3) entered blocking state <NL> [   52.655124] br-odcc2: port 1(eth3) entered forwarding state <NL> [   52.457957] commsdriver[597]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   52.498501] commsdriver[597]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   53.889010] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   53.891050] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   53.924868] device eth3.3802 entered promiscuous mode <NL> [   54.021701] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   54.042786] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   54.061602] device lwap-peer entered promiscuous mode <NL> [   54.182103] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   54.226668] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   54.285392] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   54.286501] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   54.079238] commsdriver[597]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   54.134608] commsdriver[597]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   54.497445] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   55.468375] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   55.501405] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   55.586149] device eth3.3803 entered promiscuous mode <NL> [   55.652860] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   55.681265] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   55.702183] device illdp-peer entered promiscuous mode <NL> [   55.811831] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   55.834940] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   55.575474] commsdriver[597]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   56.851986] commsready[871]: callback: Entry PID=0x367 signo(15) <NL> [   56.911635] change_esal_priority.sh[877]: Comms check for and selectively change esal priorities <NL> [   58.055728] change_esal_priority.sh[877]: Comms did not change any esal thread priorities <NL> [   58.397809] python[937]: running intRstpEnable file creation SCRIPT <NL> [   58.398063] python[937]: Already set to  TRUE <NL> [   58.398169] python[937]:  , NO CHANGE! <NL> [   58.729598] serialportMon[951]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   59.106834] sh[973]: In startMstpInt <NL> [   59.872138] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   59.883973] NFSD: Using legacy client tracking operations. <NL> [   59.885065] NFSD: starting 90-second grace period (net f0000098) <NL> [   60.717926] sh[973]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   63.697072] br.rstp_int: port 1(istp1) entered blocking state <NL> [   63.700965] br.rstp_int: port 1(istp1) entered disabled state <NL> [   63.702005] device istp1 entered promiscuous mode <NL> 2024-07-31 08:14:00,251 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml"}
{"timestamp_utc": "2024-07-31T08:14:03.572Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:03 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:03 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:04.134Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   50.769808] commsdriver[552]: Could not resolve symbol name handle_link_state_notify <NL> [   50.770754] commsdriver[552]: Could not resolve symbol name post_handle_link_state_notify <NL> [   50.771749] commsdriver[552]: Could not resolve symbol name handle_rate_duplex_change <NL> [   50.788274] commsdriver[552]: Could not resolve symbol name delete_mac_address <NL> [   50.789201] commsdriver[552]: Could not resolve symbol name set_vlan_prio <NL> [   50.817387] commsdriver[552]: Could not resolve symbol name replay_mac <NL> [   50.833448] commsdriver[552]: Could not resolve symbol name set_red_state <NL> [   50.834641] commsdriver[552]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   50.845784] commsdriver[552]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   50.865920] commsdriver[552]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   50.880468] commsdriver[552]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   50.897419] commsdriver[552]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   50.922825] commsdriver[552]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   50.975781] commsdriver[552]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   51.098965] commsdriver[552]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   51.201854] commsdriver[552]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   51.222983] commsdriver[552]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   51.263485] commsdriver[552]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   51.289321] commsdriver[552]: SharedMemory::getShmSegment creating new segment <NL> [   51.376966] commsdriver[552]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   52.502542] br-lcn00: port 1(eth3) entered blocking state <NL> [   52.504677] br-lcn00: port 1(eth3) entered disabled state <NL> [   52.559232] device eth3 entered promiscuous mode <NL> fujitsu login: [   52.777126] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   52.777963] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   52.809600] device lcn00-peer entered promiscuous mode <NL> [   52.950107] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   52.685443] commsdriver[552]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   53.556261] br-lcn01: port 1(eth4) entered blocking state <NL> [   53.579310] br-lcn01: port 1(eth4) entered disabled state <NL> [   53.581994] device eth4 entered promiscuous mode <NL> [   53.659165] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   53.749330] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   53.843738] device lcn01-peer entered promiscuous mode <NL> [   54.081489] 8021q: adding VLAN 0 to HW filter on device eth4"}
{"timestamp_utc": "2024-07-31T08:14:04.135Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   54.167380] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   54.205435] br-lcn01: port 2(lcn01-peer) entered forwarding state <NL> [   54.207345] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   53.926232] commsdriver[552]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   55.103691] br-lmp00: port 1(eth2) entered blocking state <NL> [   55.121865] br-lmp00: port 1(eth2) entered disabled state <NL> [   55.213690] device eth2 entered promiscuous mode <NL> [   55.320121] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   55.344761] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   55.457927] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   55.510694] device lmp00-peer entered promiscuous mode <NL> [   55.543055] br-lcn00: port 1(eth3) entered blocking state <NL> [   55.556592] br-lcn00: port 1(eth3) entered forwarding state <NL> [   55.666702] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   55.313287] commsdriver[552]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   55.412567] commsdriver[552]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   55.875611] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   55.876599] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   55.877411] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   56.553719] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   56.555473] br-lcn01: port 1(eth4) entered blocking state <NL> [   56.563704] br-lcn01: port 1(eth4) entered forwarding state <NL> [   57.720537] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   57.760439] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   57.853882] br-lmp00: port 1(eth2) entered blocking state <NL> [   57.885569] br-lmp00: port 1(eth2) entered forwarding state <NL> [   57.547389] commsdriver[679]: SUCCESS <NL> [   59.753058] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   59.852749] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   60.485625] commsdriver[552]: DEBUG: change_linkstate Marking eth5.2003 down for 44[   60.896351] device eth5 entered promiscuous mode <NL> [   60.521693] commsdriver[552]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   60.972767] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   60.904027] commsdriver[552]: DEBUG: change_linkstate Marking erstp down for 46[   61.396592] device erstp-peer entered promiscuous mode <NL> [   61.900638] br-odcc1: port 1(eth1) entered blocking state <NL> [   62.005649] br-odcc1: port 1(eth1) entered disabled state <NL> [   62.116877] device eth1 entered promiscuous mode <NL> [   62.171276] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   62.176356] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   62.177795] device odcc1-peer entered promiscuous mode <NL> [   62.388597] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   62.032486] commsdriver[552]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   62.067953] commsdriver[552]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   62.759949] br-odcc2: port 1(eth6) entered blocking state <NL> [   62.807030] br-odcc2: port 1(eth6) entered disabled state <NL> [   62.940004] device eth6 entered promiscuous mode <NL> [   63.063297] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   63.070987] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   63.072659] device odcc2-peer entered promiscuous mode <NL> [   63.152243] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   62.958507] commsdriver[552]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   63.069191] commsdriver[552]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   64.397945] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   64.398702] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   64.433839] device eth1.3800 entered promiscuous mode <NL> [   64.563754] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   64.595229] br-odcc1: port 1(eth1) entered blocking state <NL> [   64.605751] br-odcc1: port 1(eth1) entered forwarding state <NL> [   64.648562] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.3800: link becomes ready <NL> [   64.679886] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   64.718310] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   64.773858] device gcc0-peer entered promiscuous mode <NL> [   64.954930] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   64.970908] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   65.006338] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   65.028636] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   64.768157] commsdriver[552]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   64.803058] commsdriver[552]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   65.260218] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   65.767357] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX"}
{"timestamp_utc": "2024-07-31T08:14:04.136Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   65.816043] br-odcc2: port 1(eth6) entered blocking state <NL> [   65.840234] br-odcc2: port 1(eth6) entered forwarding state <NL> [   66.019159] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   66.090932] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   66.143420] device eth1.3801 entered promiscuous mode <NL> [   66.191958] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   66.240868] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   66.262117] device gcc1-peer entered promiscuous mode <NL> [   66.317185] br-gcc1: port 1(eth1.3801) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:14:06.023Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:14:05 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:06.281Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   60.809489] pktHandler[605]: EsalConfig::EsalConfig ciRole 0 <NL> [   60.811611] pktHandler[605]: EsalConfig is not running inside container. <NL> [   60.814231] pktHandler[605]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   60.817047] pktHandler[605]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   60.818165] pktHandler[605]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   60.819492] pktHandler[605]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   60.820903] pktHandler[605]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   60.834592] pktHandler[605]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   60.835804] pktHandler[605]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   60.845577] pktHandler[605]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   60.850745] pktHandler[605]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   60.858436] pktHandler[605]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   60.866262] pktHandler[605]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   60.885473] pktHandler[605]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   60.886597] pktHandler[605]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   60.887550] pktHandler[605]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   60.907640] pktHandler[605]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   60.920630] pktHandler[605]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   60.941677] pktHandler[605]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   60.951676] pktHandler[605]: pkt-handler: sd_notify ready <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   61.297821] commsdriver[617]: DllUtil::symbolInit() <NL> [   61.307573] commsdriver[617]: int DllInit() <NL> [   61.311885] commsdriver[617]: DllUtil::DllInit DllInit() return is null <NL> [   61.313295] commsdriver[617]: Could not resolve symbol name get_late_config_file_path <NL> [   61.335731] commsdriver[617]: Could not resolve symbol name create_l3_interface <NL> [   61.440402] commsdriver[617]: Could not resolve symbol name create_l2_interface <NL> [   61.459840] commsdriver[617]: Could not resolve symbol name delete_interface <NL> [   61.465766] commsdriver[617]: Could not resolve symbol name pre_setup_interfaces <NL> [   61.474767] commsdriver[617]: Could not resolve symbol name setup_interfaces <NL> [   61.484300] commsdriver[617]: Could not resolve symbol name post_setup_interfaces <NL> [   61.502143] commsdriver[617]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   61.516170] commsdriver[617]: Could not resolve symbol name setup_late_interfaces <NL> [   61.518448] commsdriver[617]: Could not resolve symbol name post_setup_late_interfaces <NL> [   61.528313] commsdriver[617]: Could not resolve symbol name pre_init <NL> [   61.529397] commsdriver[617]: Could not resolve symbol name post_init <NL> [   61.530316] commsdriver[617]: Could not resolve symbol name pre_handle_link_state_change <NL> [   61.541724] commsdriver[617]: Could not resolve symbol name handle_link_state_change <NL> [   61.548685] commsdriver[617]: Could not resolve symbol name post_handle_link_state_change <NL> [   61.560184] commsdriver[617]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   61.575351] commsdriver[617]: Could not resolve symbol name handle_link_state_notify <NL> [   61.579634] commsdriver[617]: Could not resolve symbol name post_handle_link_state_notify <NL> [   61.587184] commsdriver[617]: Could not resolve symbol name handle_rate_duplex_change <NL> [   61.602285] commsdriver[617]: Could not resolve symbol name delete_mac_address <NL> [   61.609172] commsdriver[617]: Could not resolve symbol name set_vlan_prio <NL> [   61.620146] commsdriver[617]: Could not resolve symbol name replay_mac <NL> [   61.626632] commsdriver[617]: Could not resolve symbol name set_red_state <NL> [   61.632594] commsdriver[617]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   61.643094] commsdriver[617]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   61.670348] commsdriver[617]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   61.674612] commsdriver[617]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   61.681487] commsdriver[617]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.702078] commsdriver[617]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   61.711909] commsdriver[617]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.720259] commsdriver[617]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.745416] commsdriver[617]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   61.757926] commsdriver[617]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   61.765497] commsdriver[617]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   61.774161] commsdriver[617]: SharedMemory::getShmSegment creating new segment <NL> [   61.782349] commsdriver[617]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   65.261350] br-lcn00: port 1(eth3) entered blocking state <NL> [   65.298029] br-lcn00: port 1(eth3) entered disabled state <NL> [   65.309886] device eth3 entered promiscuous mode <NL> [   65.351650] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   65.373644] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   65.408897] device lcn00-peer entered promiscuous mode <NL> [   65.678982] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   64.933715] commsdriver[617]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   66.500472] br-lcn01: port 1(eth4) entered blocking state <NL> [   66.522743] br-lcn01: port 1(eth4) entered disabled state <NL> [   66.554262] device eth4 entered promiscuous mode <NL> [   66.581808] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   66.598281] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   66.622262] device lcn01-peer entered promiscuous mode <NL> [   66.742517] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   66.793468] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   66.800624] br-lcn01: port 2(lcn01-peer) entered forwarding state"}
{"timestamp_utc": "2024-07-31T08:14:06.282Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   66.818355] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   65.931183] commsdriver[617]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   67.196939] br-lmp00: port 1(eth2) entered blocking state <NL> [   67.222364] br-lmp00: port 1(eth2) entered disabled state <NL> [   67.247880] device eth2 entered promiscuous mode <NL> [   67.273668] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   67.295435] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   67.312960] device lmp00-peer entered promiscuous mode <NL> [   67.398146] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   66.551793] commsdriver[617]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   66.595762] commsdriver[617]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   67.549351] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   67.563991] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   67.564815] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   68.071675] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   68.115551] br-lcn00: port 1(eth3) entered blocking state <NL> [   68.149263] br-lcn00: port 1(eth3) entered forwarding state <NL> [   68.969538] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   68.973656] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   69.017452] br-lcn01: port 1(eth4) entered blocking state <NL> [   69.033245] br-lcn01: port 1(eth4) entered forwarding state <NL> [   68.141344] commsdriver[754]: SUCCESS <NL> [   69.416563] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   69.482274] br-lmp00: port 1(eth2) entered blocking state <NL> [   69.500122] br-lmp00: port 1(eth2) entered forwarding state <NL> [   71.014428] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX"}
{"timestamp_utc": "2024-07-31T08:14:08.796Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:08.797Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:08 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:08 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:09.358Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[   53.485301] commsdriver[541]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   54.211204] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   54.213550] br-lcn00: port 1(eth3) entered blocking state <NL> [   54.214353] br-lcn00: port 1(eth3) entered forwarding state <NL> [   54.855143] br-lmp00: port 1(eth2) entered blocking state <NL> [   54.856716] br-lmp00: port 1(eth2) entered disabled state <NL> [   54.863592] device eth2 entered promiscuous mode <NL> [   54.898386] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   54.924219] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   54.963453] device lmp00-peer entered promiscuous mode <NL> [   55.124443] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   55.165032] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   55.193103] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   55.204140] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   54.938188] commsdriver[541]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   55.078583] commsdriver[541]: DEBUG: set_ip Marking lmp00 down for 2[   55.456138] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   55.512524] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   55.536672] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   56.161589] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   56.164902] br-lcn01: port 1(eth4) entered blocking state <NL> [   56.165967] br-lcn01: port 1(eth4) entered forwarding state <NL> [   57.196863] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   57.261983] br-lmp00: port 1(eth2) entered blocking state <NL> [   57.275553] br-lmp00: port 1(eth2) entered forwarding state <NL> [   57.311053] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   57.098087] commsdriver[681]: SUCCESS <NL> [   59.364419] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   59.414056] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   59.412610] commsdriver[541]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   59.767106] device eth5 entered promiscuous mode <NL> [   59.474879] commsdriver[541]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   59.762591] commsdriver[541]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   60.104324] device erstp-peer entered promiscuous mode <NL> [   60.610366] br-odcc1: port 1(eth1) entered blocking state <NL> [   60.624961] br-odcc1: port 1(eth1) entered disabled state <NL> [   60.655106] device eth1 entered promiscuous mode <NL> [   60.779610] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   60.880526] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   60.913654] device odcc1-peer entered promiscuous mode <NL> [   61.042584] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   60.887635] commsdriver[541]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   60.979049] commsdriver[541]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   61.830754] br-odcc2: port 1(eth6) entered blocking state <NL> [   61.894996] br-odcc2: port 1(eth6) entered disabled state <NL> [   61.955848] device eth6 entered promiscuous mode <NL> [   62.075217] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   62.119030] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   62.154873] device odcc2-peer entered promiscuous mode <NL> [   62.210517] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   62.234313] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   62.244770] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   62.254814] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   61.998857] commsdriver[541]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   62.071191] commsdriver[541]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   63.459265] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   63.500585] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   63.585152] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   63.648160] device eth1.3800 entered promiscuous mode <NL> [   63.729798] br-odcc1: port 1(eth1) entered blocking state <NL> [   63.751965] br-odcc1: port 1(eth1) entered forwarding state <NL> [   63.776287] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   63.794280] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   63.799932] device gcc0-peer entered promiscuous mode <NL> [   63.801405] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.3800: link becomes ready <NL> [   63.950371] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   63.987736] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   63.741610] commsdriver[541]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   63.802182] commsdriver[541]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   64.556095] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   64.679690] br-odcc2: port 1(eth6) entered blocking state <NL> [   64.708239] br-odcc2: port 1(eth6) entered forwarding state <NL> [   64.945033] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   65.046737] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   65.133468] device eth1.3801 entered promiscuous mode <NL> [   65.278056] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   65.301377] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   65.320417] device gcc1-peer entered promiscuous mode <NL> [   65.388990] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   65.407586] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   65.434084] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   65.453477] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   65.199612] commsdriver[541]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   65.235733] commsdriver[541]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   65.834695] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   66.783752] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   66.865799] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   66.924488] device eth6.3802 entered promiscuous mode <NL> [   66.958815] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   66.987252] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   67.007433] device lwap-peer entered promiscuous mode <NL> [   67.123857] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   67.189004] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   66.977375] commsdriver[541]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   66.996750] commsdriver[541]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   67.615374] commsdriver[541]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   67.744767] commsdriver[866]: Actual changes: <NL> [   67.796448] commsdriver[866]: tx-checksum-ip-generic: off <NL> [   67.818172] commsdriver[866]: tx-tcp-segmentation: off [not requested] <NL> [   67.849282] commsdriver[866]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   67.928444] commsdriver[866]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   68.004913] commsdriver[866]: tx-tcp6-segmentation: off [not requested][   68.363020] e1000 0000:00:08.0 eth5: Reset adapter <NL> [   68.657082] commsdriver[541]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   68.761322] commsdriver[878]: Actual changes:"}
{"timestamp_utc": "2024-07-31T08:14:09.359Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[   68.823190] commsdriver[878]: tx-checksum-ip-generic: off <NL> [   68.927109] commsdriver[878]: tx-tcp-segmentation: off [not requested] <NL> [   68.973153] commsdriver[878]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   69.032367] commsdriver[878]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   69.107383] commsdriver[878]: tx-tcp6-segmentation: off [not requested] <NL> [   69.177779] commsready[881]: callback: Entry PID=0x371 signo(15) <NL> [   69.278812] change_esal_priority.sh[885]: Comms check for and selectively change esal priorities <NL> [   69.558550] change_esal_priority.sh[885]: Comms did not change any esal thread priorities[   70.913522] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   72.153392] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   74.158817] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   74.272412] NFSD: Using legacy client tracking operations. <NL> [   74.274966] NFSD: starting 90-second grace period (net f0000098)"}
{"timestamp_utc": "2024-07-31T08:14:10.721Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:14:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:13.985Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:13 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:13 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:16.505Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:14:16 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:18.393Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:18 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:18.649Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:14:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:18 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:21.163Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:14:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:22.091Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   71.016163] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   70.198158] commsdriver[617]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   71.146037] device eth5 entered promiscuous mode <NL> [   70.238919] commsdriver[617]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   70.605779] commsdriver[617]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   71.576573] device erstp-peer entered promiscuous mode <NL> [   71.952064] br-odcc1: port 1(eth1) entered blocking state <NL> [   71.961780] br-odcc1: port 1(eth1) entered disabled state <NL> [   71.962750] device eth1 entered promiscuous mode <NL> [   72.002448] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   72.041389] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   72.042451] device odcc1-peer entered promiscuous mode <NL> [   72.153757] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   71.399202] commsdriver[617]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   71.405883] commsdriver[617]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   72.709696] br-odcc2: port 1(eth6) entered blocking state <NL> [   72.728024] br-odcc2: port 1(eth6) entered disabled state <NL> [   72.742516] device eth6 entered promiscuous mode <NL> [   72.777668] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   72.794321] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   72.806246] device odcc2-peer entered promiscuous mode <NL> [   72.850590] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   72.876397] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   72.889029] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   72.900472] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   72.006928] commsdriver[617]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   72.029842] commsdriver[617]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   73.630710] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   73.669675] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   73.713192] device eth1.3800 entered promiscuous mode <NL> [   73.738576] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   73.749282] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   73.763090] device gcc0-peer entered promiscuous mode <NL> [   73.839673] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   73.853231] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   73.854501] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   72.956883] commsdriver[617]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   72.962504] commsdriver[617]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   74.452455] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   74.462908] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   74.482296] device eth1.3801 entered promiscuous mode <NL> [   74.512355] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   74.534706] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   74.546296] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   74.557117] device gcc1-peer entered promiscuous mode <NL> [   74.579356] br-odcc1: port 1(eth1) entered blocking state <NL> [   74.586357] br-odcc1: port 1(eth1) entered forwarding state <NL> [   74.595138] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   74.604987] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   74.611791] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.3801: link becomes ready <NL> [   74.747360] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   74.765002] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   74.791021] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   74.834364] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   73.943954] commsdriver[617]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   73.945120] commsdriver[617]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   75.141838] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   75.178477] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   75.179448] br-odcc2: port 1(eth6) entered blocking state <NL> [   75.180154] br-odcc2: port 1(eth6) entered forwarding state <NL> [   75.867600] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   75.891535] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   75.947014] device eth6.3802 entered promiscuous mode <NL> [   75.993645] br-lwap: port 2(lwap-peer) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:14:22.092Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[   76.017816] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   76.042890] device lwap-peer entered promiscuous mode <NL> [   76.259373] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   76.271187] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   75.389523] commsdriver[617]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   75.407650] commsdriver[617]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   75.845525] commsdriver[617]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   75.978862] commsdriver[939]: Actual changes: <NL> [   75.979173] commsdriver[939]: tx-checksum-ip-generic: off <NL> [   75.980891] commsdriver[939]: tx-tcp-segmentation: off [not requested] <NL> [   75.983454] commsdriver[939]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   75.983559] commsdriver[939]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   75.983657] commsdriver[939]: tx-tcp6-segmentation: off [not requested] <NL> [   76.486668] commsdriver[617]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   76.522297] commsdriver[952]: Actual changes: <NL> [   76.522564] commsdriver[952]: tx-checksum-ip-generic: off <NL> [   76.526594] commsdriver[952]: tx-tcp-segmentation: off [not requested] <NL> [   76.526687] commsdriver[952]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   76.526769] commsdriver[952]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   76.526851] commsdriver[952]: tx-tcp6-segmentation: off [not requested] <NL> [   76.641503] commsready[955]: callback: Entry PID=0x3BB signo(15) <NL> [   76.645275] commsready[955]: DipLog_pimpl destructor called <NL> [   76.645434] commsready[955]: DipVerbosity Listener ZMQ error <NL> [   76.645514] commsready[955]:     ret='Context was terminated <NL> [   76.645623] commsready[955]: deleting subscriber_ socket <NL> [   76.645698] commsready[955]: Exiting verb listener <NL> [   76.687199] change_esal_priority.sh[961]: Comms check for and selectively change esal priorities <NL> [   77.381435] change_esal_priority.sh[961]: Comms did not change any esal thread priorities <NL> [   77.688427] python[1006]: running intRstpEnable file creation SCRIPT <NL> [   77.688687] python[1006]: Already set to  TRUE <NL> [   77.688820] python[1006]:  , NO CHANGE! <NL> [   79.097698] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   79.151264] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   78.567303] serialportMon[1022]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   78.922074] sh[1061]: In startMstpInt <NL> [   80.190458] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   80.258207] NFSD: Using legacy client tracking operations. <NL> [   80.258953] NFSD: starting 90-second grace period (net f0000098) <NL> [   81.070460] sh[1061]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   83.160476] br.rstp_int: port 1(istp1) entered blocking state <NL> [   83.172507] br.rstp_int: port 1(istp1) entered disabled state <NL> [   83.173477] device istp1 entered promiscuous mode <NL> 2024-07-31 08:14:19,256 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:21,097 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:21,097 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:21,101 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml"}
{"timestamp_utc": "2024-07-31T08:14:23.457Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:23 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:23.713Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:14:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:23 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:26.227Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:14:25 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:28.773Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:28 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:28 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:31.289Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:14:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:33.804Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:33 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:33 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:36.319Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:14:36 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:38.846Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:38 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:38 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:41.362Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:14:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:43.879Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:43 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:43 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:45.771Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:14:45 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:49.060Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   42.865137] br-odcc1: port 1(eth2) entered disabled state <NL> [   42.870638] device eth2 entered promiscuous mode <NL> [   42.885750] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   42.886589] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   42.896148] device odcc1-peer entered promiscuous mode <NL> [   42.927573] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   42.967525] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   42.969770] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   42.976796] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   42.614561] commsdriver[584]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   42.614738] commsdriver[584]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   43.540909] br-odcc2: port 1(eth3) entered blocking state <NL> [   43.541653] br-odcc2: port 1(eth3) entered disabled state <NL> [   43.542439] device eth3 entered promiscuous mode <NL> [   43.549925] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   43.550622] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   43.586846] device odcc2-peer entered promiscuous mode <NL> [   43.735032] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   43.394991] commsdriver[584]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   43.403191] commsdriver[584]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   43.945539] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   43.950709] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   44.603856] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   44.604642] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   44.651722] device eth2.3800 entered promiscuous mode <NL> [   44.715419] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   44.740246] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   44.761759] device gcc0-peer entered promiscuous mode <NL> [   44.535307] commsdriver[584]: DEBUG: change_linkstate Marking gcc0 down for 13"}
{"timestamp_utc": "2024-07-31T08:14:49.061Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[   44.543760] commsdriver[584]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   45.236516] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   45.283759] br-odcc1: port 1(eth2) entered blocking state <NL> [   45.305150] br-odcc1: port 1(eth2) entered forwarding state <NL> [   45.315475] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   45.319026] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   45.330540] IPv6: ADDRCONF(NETDEV_CHANGE): eth2.3801: link becomes ready <NL> [   45.656428] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   45.696373] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   45.720761] device eth2.3801 entered promiscuous mode <NL> [   45.827561] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   45.851388] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   45.852507] device gcc1-peer entered promiscuous mode <NL> [   45.983733] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   45.994572] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   45.996568] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.070179] br-odcc2: port 1(eth3) entered blocking state <NL> [   46.106686] br-odcc2: port 1(eth3) entered forwarding state <NL> [   45.674817] commsdriver[584]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   45.715997] commsdriver[584]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   46.975910] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   47.021290] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   47.060035] device eth3.3802 entered promiscuous mode <NL> [   47.105911] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   47.117814] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   47.173423] device lwap-peer entered promiscuous mode <NL> [   47.318341] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   47.319208] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   47.336452] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   47.401223] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   47.094282] commsdriver[584]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   47.116626] commsdriver[584]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   47.860539] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   48.176749] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   48.195474] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   48.218804] device eth3.3803 entered promiscuous mode <NL> [   48.245991] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   48.254007] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   48.265419] device illdp-peer entered promiscuous mode <NL> [   48.327177] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   48.337841] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   48.367028] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   48.378344] br-illdp: port 2(illdp-peer) entered forwarding state <NL> [   48.016642] commsdriver[584]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   48.124686] commsready[869]: callback: Entry PID=0x365 signo(15) <NL> [   48.158749] change_esal_priority.sh[873]: Comms check for and selectively change esal priorities <NL> [   48.871228] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   48.890082] change_esal_priority.sh[873]: Comms did not change any esal thread priorities <NL> [   49.203481] python[919]: running intRstpEnable file creation SCRIPT <NL> [   49.203643] python[919]: Already set to  TRUE <NL> [   49.203737] python[919]:  , NO CHANGE! <NL> [   49.656812] serialportMon[949]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   49.657453] sh[969]: In startMstpInt <NL> [   50.681373] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   50.249202] sh[969]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   50.741360] NFSD: Using legacy client tracking operations. <NL> [   50.755162] NFSD: starting 90-second grace period (net f0000098) <NL> [   51.256209] hrtimer: interrupt took 6158402 ns <NL> 2024-07-31 08:13:48,188 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> [   53.976905] br.rstp_int: port 1(istp1) entered blocking state <NL> [   53.989897] br.rstp_int: port 1(istp1) entered disabled state <NL> [   54.014592] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:50,621 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:13:50,736 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:50,738 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   64.672792] vsftpd_listen_address[952]: listen_address=127.1.1.2 <NL> [   65.226891] br.rstp_int: port 2(istp2) entered blocking state <NL> [   65.227687] br.rstp_int: port 2(istp2) entered disabled state <NL> [   65.236233] device istp2 entered promiscuous mode <NL> [  112.228799] ntputils[1714]: int ntputils_main(int, char**)Starting ntputils <NL> [  112.343482] ntputils[1714]: Running as a daemon <NL> [  112.343611] ntputils[1714]: shelf role is: TRIB <NL> [  112.343690] ntputils[1714]: slot number is: 0 <NL> [  112.343761] ntputils[1714]: slot role is: UNKNOWN <NL> [  112.343831] ntputils[1714]: redundancy_mode: UNKNOWN <NL> [  112.376173] ntputils[1714]: Executing on a work blade <NL> [  112.413783] ntputils[1714]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  112.413875] ntputils[1714]: ================================ <NL> [  112.413938] ntputils[1714]: shelf_role is: TRIB <NL> [  112.413998] ntputils[1714]: redundancy_mode: UNKNOWN <NL> [  112.414098] ntputils[1714]: active_status: active <NL> [  112.414158] ntputils[1714]: ntp_role: trib <NL> [  112.414229] ntputils[1714]: ================================ <NL> # 03:14:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:48 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:48 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:50.950Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:14:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:52.838Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[   43.766645] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   43.418342] commsdriver[609]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   43.441614] commsdriver[609]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   44.371563] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   44.390595] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   44.422502] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   44.440727] device eth2.3800 entered promiscuous mode <NL> [   44.478433] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   44.505706] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   44.509410] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   44.521887] device gcc0-peer entered promiscuous mode <NL> [   44.581819] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   44.595363] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   44.618427] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   44.265283] commsdriver[609]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   44.265413] commsdriver[609]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   45.203597] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   45.225063] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   45.271735] device eth2.3801 entered promiscuous mode <NL> [   45.323543] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   45.339376] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   45.353574] device gcc1-peer entered promiscuous mode <NL> [   45.392752] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   45.410287] br-odcc1: port 1(eth2) entered blocking state <NL> [   45.425106] br-odcc1: port 1(eth2) entered forwarding state <NL> [   45.434116] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   45.442012] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   45.447558] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   45.449237] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   45.457501] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   45.468799] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   45.105689] commsdriver[609]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   45.143483] commsdriver[609]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   45.809707] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   45.867908] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   45.881571] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   45.902813] device eth3.3802 entered promiscuous mode <NL> [   45.935934] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   45.947689] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   45.960599] device lwap-peer entered promiscuous mode <NL> [   46.021650] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   46.032806] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   46.052932] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.056620] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   46.076177] br-odcc2: port 1(eth3) entered blocking state <NL> [   46.081418] br-odcc2: port 1(eth3) entered forwarding state <NL> [   46.088001] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   46.096809] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   45.716258] commsdriver[609]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   45.724862] commsdriver[609]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   46.817628] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   46.840048] br-illdp: port 1(eth3.3803) entered disabled state"}
{"timestamp_utc": "2024-07-31T08:14:52.839Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[   46.871818] device eth3.3803 entered promiscuous mode <NL> [   46.929634] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   46.977390] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   47.029878] device illdp-peer entered promiscuous mode <NL> [   47.226551] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   47.258573] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   46.976986] commsdriver[609]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   47.201397] commsready[879]: callback: Entry PID=0x36F signo(15) <NL> [   47.202284] commsready[879]: DipLog_pimpl destructor called <NL> [   47.202393] commsready[879]: DipVerbosity Listener ZMQ error <NL> [   47.202461] commsready[879]:     ret='Context was terminated <NL> [   47.202586] commsready[879]: deleting subscriber_ socket <NL> [   47.202652] commsready[879]: Exiting verb listener <NL> [   47.257414] change_esal_priority.sh[885]: Comms check for and selectively change esal priorities <NL> [   48.621627] change_esal_priority.sh[885]: Comms did not change any esal thread priorities <NL> [   49.383582] python[946]: running intRstpEnable file creation SCRIPT <NL> [   49.385833] python[946]: Already set to  TRUE <NL> [   49.388402] python[946]:  , NO CHANGE! <NL> [   49.686967] serialportMon[959]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   49.788633] sh[978]: In startMstpInt <NL> [   51.190118] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   51.221685] NFSD: Using legacy client tracking operations. <NL> [   51.225265] NFSD: starting 90-second grace period (net f0000098) <NL> [   52.012583] sh[978]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> 2024-07-31 08:13:48,679 remote-file-info: INFO -[   54.807418] br.rstp_int: port 1(istp1) entered blocking state <NL> remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> [   54.865103] br.rstp_int: port 1(istp1) entered disabled state <NL> [   54.905628] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:51,222 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:13:51,241 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:51,250 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   64.468529] vsftpd_listen_address[963]: listen_address=127.1.1.2 <NL> [   66.035605] br.rstp_int: port 2(istp2) entered blocking state <NL> [   66.039265] br.rstp_int: port 2(istp2) entered disabled state <NL> [   66.040466] device istp2 entered promiscuous mode <NL> [  116.775978] ntputils[1729]: int ntputils_main(int, char**)Starting ntputils <NL> [  116.776447] ntputils[1729]: Running as a daemon <NL> [  116.776617] ntputils[1729]: shelf role is: TRIB <NL> [  116.777086] ntputils[1729]: slot number is: 0 <NL> [  116.777186] ntputils[1729]: slot role is: UNKNOWN <NL> [  116.777259] ntputils[1729]: redundancy_mode: UNKNOWN <NL> [  116.777376] ntputils[1729]: Executing on a work blade <NL> [  116.777463] ntputils[1729]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  116.777552] ntputils[1729]: ================================ <NL> [  116.777625] ntputils[1729]: shelf_role is: TRIB <NL> [  116.777696] ntputils[1729]: redundancy_mode: UNKNOWN <NL> [  116.777777] ntputils[1729]: active_status: active <NL> [  116.777849] ntputils[1729]: ntp_role: trib <NL> [  116.777922] ntputils[1729]: ================================ <NL> [  116.796125] ntputils[1729]: NTPUtilsConfig::do_default_config <NL> [  116.796545] ntputils[1729]: shelf_num/is_client: 1 <NL> [  116.939890] ntputils[1729]: server_ip: 0x55bfad359fc0 <NL> [  116.939990] ntputils[1729]: ip_addr(ilan): 0x55bfad359f80 <NL> [  116.940082] ntputils[1729]: ntp_role trib <NL> [  116.940154] ntputils[1729]: shelf_num aka is_client > 0 <NL> [  116.940279] ntputils[1729]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  116.940356] ntputils[1729]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  116.940427] ntputils[1729]: NTPServer::execute_cmd spawning: <NL> [  116.940499] ntputils[1729]: systemctl --no-block stop ntpd <NL> [  116.941422] ntputils[1729]: child pid is 1738 <NL> [  116.941533] ntputils[1729]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:14:53.766Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:53 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:53 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:55.662Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   45.485203] commsdriver[685]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   45.485301] commsdriver[685]: tx-tcp6-segmentation: off [not requested] <NL> [   45.929840] commsdriver[601]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   45.971411] commsdriver[697]: Actual changes: <NL> [   45.971594] commsdriver[697]: tx-checksum-ip-generic: off <NL> [   45.971678] commsdriver[697]: tx-tcp-segmentation: off [not requested] <NL> [   45.971833] commsdriver[697]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   45.971920] commsdriver[697]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   45.971997] commsdriver[697]: tx-tcp6-segmentation: off [not requested] <NL> [   46.817492] br-odcc1: port 1(eth2) entered blocking state <NL> [   46.839185] br-odcc1: port 1(eth2) entered disabled state <NL> [   46.854055] device eth2 entered promiscuous mode <NL> [   46.870390] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   46.888315] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   46.901862] device odcc1-peer entered promiscuous mode <NL> [   46.983731] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   47.028782] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   47.041508] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   47.086790] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   46.662409] commsdriver[601]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   46.694327] commsdriver[601]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   47.737757] br-odcc2: port 1(eth3) entered blocking state <NL> [   47.738555] br-odcc2: port 1(eth3) entered disabled state <NL> [   47.739383] device eth3 entered promiscuous mode <NL> [   47.806366] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   47.826674] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   47.839157] device odcc2-peer entered promiscuous mode <NL> [   47.900455] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   47.661387] commsdriver[601]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   48.137891] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   48.179993] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   47.665763] commsdriver[601]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   49.123985] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   49.125145] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   49.138544] device eth2.3800 entered promiscuous mode <NL> [   49.168328] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   49.179450] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   49.180626] device gcc0-peer entered promiscuous mode <NL> [   49.330471] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   49.346569] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   49.348066] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   49.395876] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   49.408040] br-odcc1: port 1(eth2) entered blocking state <NL> [   49.408748] br-odcc1: port 1(eth2) entered forwarding state <NL> [   49.409643] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   49.410419] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   48.971168] commsdriver[601]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   48.994302] commsdriver[601]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   50.248744] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   50.249522] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   50.267723] device eth2.3801 entered promiscuous mode <NL> [   50.296834] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   50.304295] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   50.325016] device gcc1-peer entered promiscuous mode <NL> [   50.483808] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   50.513427] br-odcc2: port 1(eth3) entered blocking state <NL> [   50.531966] br-odcc2: port 1(eth3) entered forwarding state <NL> [   50.550045] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   50.553435] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   50.574527] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   50.583914] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   50.189867] commsdriver[601]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   50.202962] commsdriver[601]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   50.720165] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   51.541076] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   51.565311] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   51.621993] device eth3.3802 entered promiscuous mode <NL> [   51.650861] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   51.652852] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   51.655008] device lwap-peer entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:55.663Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[   51.827031] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   51.834968] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   51.467858] commsdriver[601]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   51.484742] commsdriver[601]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   52.664813] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   52.691645] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   52.721287] device eth3.3803 entered promiscuous mode <NL> [   52.774233] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   52.810234] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   52.812281] device illdp-peer entered promiscuous mode <NL> [   52.984429] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   52.991451] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   52.605023] commsdriver[601]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   53.699965] commsready[872]: callback: Entry PID=0x368 signo(15) <NL> [   53.736686] change_esal_priority.sh[876]: Comms check for and selectively change esal priorities <NL> [   54.835830] change_esal_priority.sh[876]: Comms did not change any esal thread priorities <NL> [   55.619810] python[937]: running intRstpEnable file creation SCRIPT <NL> [   55.619980] python[937]: Already set to  TRUE <NL> [   55.620104] python[937]:  , NO CHANGE! <NL> [   55.685483] serialportMon[950]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   55.883482] sh[975]: In startMstpInt <NL> [   56.786839] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   56.794956] NFSD: Using legacy client tracking operations. <NL> [   56.796368] NFSD: starting 90-second grace period (net f0000098) <NL> [   57.477333] sh[975]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   59.632665] br.rstp_int: port 1(istp1) entered blocking state <NL> [   59.670236] br.rstp_int: port 1(istp1) entered disabled state <NL> [   59.699406] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:54,399 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:55,897 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:55,984 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:56,036 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   70.550463] vsftpd_listen_address[954]: listen_address=127.1.1.1 <NL> [   72.011156] br.rstp_int: port 2(istp2) entered blocking state <NL> [   72.054591] br.rstp_int: port 2(istp2) entered disabled state <NL> [   72.100117] device istp2 entered promiscuous mode <NL> [  119.357419] ntputils[1699]: int ntputils_main(int, char**)Starting ntputils <NL> [  119.443155] ntputils[1699]: Running as a daemon <NL> [  119.580638] ntputils[1699]: shelf role is: TRIB <NL> [  119.580734] ntputils[1699]: slot number is: 0 <NL> [  119.580806] ntputils[1699]: slot role is: UNKNOWN"}
{"timestamp_utc": "2024-07-31T08:14:55.920Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[  112.414339] ntputils[1714]: NTPUtilsConfig::do_default_config <NL> [  112.414399] ntputils[1714]: shelf_num/is_client: 1 <NL> [  112.414469] ntputils[1714]: server_ip: 0x55d76a14afc0 <NL> [  112.414532] ntputils[1714]: ip_addr(ilan): 0x55d76a14af80 <NL> [  112.414601] ntputils[1714]: ntp_role trib <NL> [  112.414661] ntputils[1714]: shelf_num aka is_client > 0 <NL> [  112.414721] ntputils[1714]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.414783] ntputils[1714]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.414848] ntputils[1714]: NTPServer::execute_cmd spawning: <NL> [  112.450990] ntputils[1714]: systemctl --no-block stop ntpd <NL> [  112.459952] ntputils[1714]: child pid is 1723"}
{"timestamp_utc": "2024-07-31T08:14:55.921Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "2024-07-31 08:14:47,136 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 56 seconds <NL> [  112.601151] ntputils[1714]: exited, status is 0 <NL> [  112.601288] ntputils[1714]: NTPServer::execute_cmd spawning: <NL> [  112.625172] ntputils[1714]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.625254] ntputils[1714]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.625341] ntputils[1714]: child pid is 1734 <NL> 2024-07-31 08:14:47,305 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:47,326 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  112.720671] ntputils[1737]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:47,441 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:47,459 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  112.998226] ntputils[1769]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:47,653 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:47,697 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:47,839 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> [  113.111904] ntputils[1714]: exited, status is 0 <NL> [  113.289910] ntputils[1714]: NTPServer::execute_cmd spawning: <NL> [  113.290056] ntputils[1714]: /bin/systemctl reset-failed ntpd <NL> [  113.290303] ntputils[1714]: child pid is 1783 <NL> [  113.290391] ntputils[1714]: exited, status is 0 <NL> [  113.290462] ntputils[1714]: NTPServer::execute_cmd spawning: <NL> [  113.290534] ntputils[1714]: systemctl --no-block start ntpd <NL> 2024-07-31 08:14:47,906 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:48,154 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:48,154 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> [  113.319435] ntputils[1714]: child pid is 1787 <NL> 2024-07-31 08:14:48,169 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:48,254 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:48,254 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  113.609557] ntputils[1714]: exited, status is 0 <NL> [  113.686837] ntputils[1714]: client role with Python client, systemD starts it <NL> 2024-07-31 08:14:48,315 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  116.550379] fujitsu-check-ssh-host-key.pl[1917]: Checking system account status... <NL> [  116.699797] fujitsu-check-ssh-host-key.pl[1917]: System account found... <NL> [  116.767280] fujitsu-check-ssh-host-key.pl[1917]: 3004 <NL> [  116.816130] fujitsu-check-ssh-host-key.pl[1917]: /bin/bash <NL> [  116.816327] fujitsu-check-ssh-host-key.pl[1917]: /home/system exists <NL> [  116.816414] fujitsu-check-ssh-host-key.pl[1917]: Checking for trib... <NL> [  116.869319] fujitsu-check-ssh-host-key.pl[1917]: Creating factory user for trib.. <NL> 2024-07-31 08:14:52,265 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:14:52,265 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:52,265 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:52,266 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:52,475 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:52,476 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:52,528 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:52,651 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:52,651 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:52,651 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> [  118.954035] fujitsu-check-ssh-host-key.pl[1971]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  118.954284] fujitsu-check-ssh-host-key.pl[1971]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  119.018623] fujitsu-check-ssh-host-key.pl[1972]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  119.018840] fujitsu-check-ssh-host-key.pl[1972]: /dev/root       2.2G  1.8G  311M  86% / <NL> 2024-07-31 08:14:53,654 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:53,655 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:53,656 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:53,656 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:53,726 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:53,743 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:14:53,778 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:14:53,805 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  119.221117] fujitsu-check-ssh-host-key.pl[1973]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  119.232628] fujitsu-check-ssh-host-key.pl[1973]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  119.333654] fujitsu-check-ssh-host-key.pl[1977]: useradd: user 'fujitsu' already exists <NL> [  119.761276] fujitsu-check-ssh-host-key.pl[1934]: DDS Peristency is enabled <NL> [  119.761488] fujitsu-check-ssh-host-key.pl[1934]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  119.761601] fujitsu-check-ssh-host-key.pl[1934]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  119.761675] fujitsu-check-ssh-host-key.pl[1934]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  119.761748] fujitsu-check-ssh-host-key.pl[1934]: (ui-sys-reset) Running /bin/df -h /etc..."}
{"timestamp_utc": "2024-07-31T08:14:56.177Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:14:56 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:58.703Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:14:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:58 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:58 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:01.218Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:15:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:03.732Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[  119.580878] ntputils[1699]: redundancy_mode: UNKNOWN <NL> [  119.580996] ntputils[1699]: Executing on a work blade <NL> [  119.581268] ntputils[1699]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  119.581354] ntputils[1699]: ================================ <NL> [  119.581424] ntputils[1699]: shelf_role is: TRIB <NL> [  119.581492] ntputils[1699]: redundancy_mode: UNKNOWN <NL> [  119.581561] ntputils[1699]: active_status: active <NL> [  119.581630] ntputils[1699]: ntp_role: trib <NL> [  119.581706] ntputils[1699]: ================================ <NL> 2024-07-31 08:14:54,445 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 58 seconds <NL> 2024-07-31 08:14:54,516 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:54,563 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> 2024-07-31 08:14:54,658 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:54,659 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  119.610745] ntputils[1699]: NTPUtilsConfig::do_default_config <NL> [  120.075660] ntputils[1699]: shelf_num/is_client: 1 <NL> [  120.075762] ntputils[1699]: server_ip: 0x55a34c6eefc0 <NL> [  120.075840] ntputils[1699]: ip_addr(ilan): 0x55a34c6eef80 <NL> [  120.075911] ntputils[1699]: ntp_role trib <NL> [  120.075981] ntputils[1699]: shelf_num aka is_client > 0 <NL> [  120.076075] ntputils[1699]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  120.076146] ntputils[1699]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  120.076228] ntputils[1699]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:15:03.733Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[  120.076306] ntputils[1699]: systemctl --no-block stop ntpd <NL> [  120.076382] ntputils[1699]: child pid is 1715 <NL> [  120.294547] ntputils[1699]: exited, status is 0 <NL> [  120.294676] ntputils[1699]: NTPServer::execute_cmd spawning: <NL> [  120.294749] ntputils[1699]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  120.294821] ntputils[1699]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  120.294891] ntputils[1699]: child pid is 1725 <NL> [  120.501690] ntputils[1733]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:55,241 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:55,241 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:55,241 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:55,241 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:55,336 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:55,336 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:55,338 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:55,371 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:55,420 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:55,725 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  121.172837] ntputils[1787]: Changing Stratum and adding restrictions <NL> [  121.439605] ntputils[1699]: exited, status is 0 <NL> [  121.451465] ntputils[1699]: NTPServer::execute_cmd spawning: <NL> [  121.627361] ntputils[1699]: /bin/systemctl reset-failed ntpd <NL> [  121.627480] ntputils[1699]: child pid is 1805 <NL> [  121.627622] ntputils[1699]: exited, status is 0 <NL> [  121.627701] ntputils[1699]: NTPServer::execute_cmd spawning: <NL> [  121.627774] ntputils[1699]: systemctl --no-block start ntpd <NL> [  121.627853] ntputils[1699]: child pid is 1807 <NL> [  121.627958] ntputils[1699]: exited, status is 0 <NL> [  121.628072] ntputils[1699]: client role with Python client, systemD starts it <NL> 2024-07-31 08:15:00,245 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:15:00,314 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:15:00,363 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:15:00,493 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:15:00,494 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:00,566 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:00,616 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:15:00,671 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:00,671 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:00,671 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> [  126.257784] fujitsu-check-ssh-host-key.pl[1903]: Checking system account status... <NL> [  126.282920] fujitsu-check-ssh-host-key.pl[1903]: System account found... <NL> [  126.400711] fujitsu-check-ssh-host-key.pl[1903]: 3004 <NL> [  126.419750] fujitsu-check-ssh-host-key.pl[1903]: /bin/bash <NL> [  126.442319] fujitsu-check-ssh-host-key.pl[1903]: /home/system exists <NL> [  126.442492] fujitsu-check-ssh-host-key.pl[1903]: Checking for trib... <NL> [  126.454474] fujitsu-check-ssh-host-key.pl[1903]: Creating factory user for trib.. <NL> 2024-07-31 08:15:01,682 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:01,683 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:01,684 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:15:01,685 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:15:01,685 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:01,693 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:15:01,694 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:15:01,694 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  127.542409] fujitsu-check-ssh-host-key.pl[1924]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.542609] fujitsu-check-ssh-host-key.pl[1924]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  127.551355] fujitsu-check-ssh-host-key.pl[1925]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.551530] fujitsu-check-ssh-host-key.pl[1925]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  127.553058] fujitsu-check-ssh-host-key.pl[1926]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.580878] fujitsu-check-ssh-host-key.pl[1926]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  116.941608] ntputils[1729]: NTPServer::execute_cmd spawning: <NL> [  116.941680] ntputils[1729]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  117.060641] ntputils[1729]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  117.060801] ntputils[1729]: child pid is 1742 <NL> [  117.286932] ntputils[1747]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:51,590 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 60 seconds <NL> 2024-07-31 08:14:51,754 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  117.466731] ntputils[1770]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:51,820 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  117.883875] ntputils[1729]: exited, status is 0 <NL> [  117.884039] ntputils[1729]: NTPServer::execute_cmd spawning: <NL> [  117.884111] ntputils[1729]: /bin/systemctl reset-failed ntpd <NL> [  117.884181] ntputils[1729]: child pid is 1788 <NL> [  118.019206] ntputils[1729]: exited, status is 0 <NL> [  118.020804] ntputils[1729]: NTPServer::execute_cmd spawning: <NL> [  118.022560] ntputils[1729]: systemctl --no-block start ntpd <NL> [  118.049433] ntputils[1729]: child pid is 1790 <NL> 2024-07-31 08:14:52,462 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:52,463 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  118.336966] ntputils[1729]: exited, status is 0 <NL> [  118.337155] ntputils[1729]: client role with Python client, systemD starts it <NL> 2024-07-31 08:14:53,186 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:53,186 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:53,188 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:53,189 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:53,189 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:53,189 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:53,247 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:53,274 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:53,274 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:53,359 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:14:56,635 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:14:56,637 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:56,654 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml"}
{"timestamp_utc": "2024-07-31T08:15:03.734Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "(priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:56,674 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:56,688 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:56,707 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:56,732 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:56,754 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:56,794 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:56,794 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> [  122.597541] fujitsu-check-ssh-host-key.pl[1921]: Checking system account status... <NL> [  122.629113] fujitsu-check-ssh-host-key.pl[1921]: System account found... <NL> [  122.676327] fujitsu-check-ssh-host-key.pl[1921]: 3004 <NL> [  122.676518] fujitsu-check-ssh-host-key.pl[1921]: /bin/bash <NL> [  122.676594] fujitsu-check-ssh-host-key.pl[1921]: /home/system exists <NL> [  122.676691] fujitsu-check-ssh-host-key.pl[1921]: Checking for trib... <NL> [  122.676813] fujitsu-check-ssh-host-key.pl[1921]: Creating factory user for trib.. <NL> 2024-07-31 08:14:57,835 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:57,835 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:57,836 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:57,837 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:57,837 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:57,838 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:14:57,838 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:14:57,902 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  123.844561] fujitsu-check-ssh-host-key.pl[1964]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  123.844762] fujitsu-check-ssh-host-key.pl[1964]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  123.845143] fujitsu-check-ssh-host-key.pl[1965]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  123.845226] fujitsu-check-ssh-host-key.pl[1965]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  123.896562] fujitsu-check-ssh-host-key.pl[1966]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  123.927391] fujitsu-check-ssh-host-key.pl[1966]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  124.007597] fujitsu-check-ssh-host-key.pl[1972]: useradd: user 'fujitsu' already exists <NL> [  124.729505] fujitsu-check-ssh-host-key.pl[1935]: DDS Peristency is enabled <NL> [  124.729703] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  124.803390] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  124.803540] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  124.803619] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  124.803693] fujitsu-check-ssh-host-key.pl[1935]: Factory user shell set to /bin/bash <NL> [  124.989581] fujitsu-check-ssh-host-key.pl[1921]: Converting fujitsu user to bash shell... <NL> [  125.036440] fujitsu-check-ssh-host-key.pl[2003]: usermod: no changes <NL> [  125.036635] fujitsu-check-ssh-host-key.pl[1921]: Lock Root account in TRIB... <NL> [  125.092928] fujitsu-check-ssh-host-key.pl[2004]: Running lock on root account... <NL> [  125.570121] fujitsu-check-ssh-host-key.pl[2005]: passwd: password changed. <NL> [  125.570298] fujitsu-check-ssh-host-key.pl[1921]: Trib check done. <NL> [  126.619374] startup[2029]: Startup, World! <NL> [  126.619596] startup[2029]: Cmd arg set to loop 1 <NL> [  127.696129] ains_manager[2026]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  127.789234] ntputils_client.py[1730]: INFO:root:command failed. <NL> # 03:15:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:03 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:03 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:06.247Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:15:05 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:07.613Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[   53.192607] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   53.221585] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   53.223964] device gcc0-peer entered promiscuous mode <NL> [   52.893337] commsdriver[608]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   52.932940] commsdriver[608]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   53.568476] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   53.600906] br-odcc1: port 1(eth1) entered blocking state <NL> [   53.605184] br-odcc1: port 1(eth1) entered forwarding state <NL> [   53.622509] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   53.636919] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   54.375662] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   54.376539] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   54.416737] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   54.442502] device eth1.3801 entered promiscuous mode <NL> [   54.466078] br-odcc2: port 1(eth6) entered blocking state <NL> [   54.472601] br-odcc2: port 1(eth6) entered forwarding state <NL> [   54.487732] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   54.503817] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   54.521377] device gcc1-peer entered promiscuous mode <NL> [   54.586990] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   54.599645] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   54.644558] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   54.686293] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   54.169185] commsdriver[608]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   54.195416] commsdriver[608]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   55.228312] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   55.441319] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   55.455442] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   55.480285] device eth6.3802 entered promiscuous mode <NL> [   55.522381] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   55.568157] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   55.590834] device lwap-peer entered promiscuous mode <NL> [   55.699769] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   55.718478] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   55.746446] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   55.756517] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   55.215547] commsdriver[608]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   55.246922] commsdriver[608]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   55.594272] commsdriver[608]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   56.254933] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   55.682591] commsdriver[933]: Actual changes: <NL> [   55.701243] commsdriver[933]: tx-checksum-ip-generic: off <NL> [   55.731566] commsdriver[933]: tx-tcp-segmentation: off [not requested] <NL> [   55.756991] commsdriver[933]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   55.765534] commsdriver[933]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   55.766509] commsdriver[933]: tx-tcp6-segmentation: off [not requested] <NL> [   56.408529] e1000 0000:00:08.0 eth5: Reset adapter <NL> [   56.084299] commsdriver[608]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   56.177979] commsdriver[945]: Actual changes: <NL> [   56.204453] commsdriver[945]: tx-checksum-ip-generic: off <NL> [   56.233339] commsdriver[945]: tx-tcp-segmentation: off [not requested] <NL> [   56.259449] commsdriver[945]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   56.277586] commsdriver[945]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   56.289483] commsdriver[945]: tx-tcp6-segmentation: off [not requested] <NL> [   56.456807] commsready[950]: callback: Entry PID=0x3B6 signo(15) <NL> [   56.517947] change_esal_priority.sh[954]: Comms check for and selectively change esal priorities <NL> [   57.271296] change_esal_priority.sh[954]: Comms did not change any esal thread priorities <NL> [   57.659167] python[1000]: running intRstpEnable file creation SCRIPT <NL> [   57.659433] python[1000]: Already set to  TRUE <NL> [   57.659544] python[1000]:  , NO CHANGE! <NL> [   58.558776] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   58.668599] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   58.475723] sh[1031]: In startMstpInt <NL> [   58.882670] serialportMon[1021]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   59.668016] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   59.844325] NFSD: Using legacy client tracking operations. <NL> [   59.846735] NFSD: starting 90-second grace period (net f0000098) <NL> [   60.479101] sh[1031]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   64.916715] br.rstp_int: port 1(istp1) entered blocking state <NL> [   64.941062] br.rstp_int: port 1(istp1) entered disabled state <NL> [   64.953842] device istp1 entered promiscuous mode <NL> 2024-07-31 08:14:00,203 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority):"}
{"timestamp_utc": "2024-07-31T08:15:07.614Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "(priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:01,995 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:01,995 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:02,022 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> 2024-07-31 08:14:02,088 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:02,179 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:02,194 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> [   73.207813] vsftpd_listen_address[1025]: listen_address=127.1.254.254 <NL> [   77.140123] br.rstp_int: port 2(istp2) entered blocking state <NL> [   77.177594] br.rstp_int: port 2(istp2) entered disabled state <NL> [   77.199244] device istp2 entered promiscuous mode <NL> [  124.542877] dcn_ka[1594]:  WaitForActive <NL> [  125.567248] dcn_dns_controller[1592]:  WaitForActive <NL> 2024-07-31 08:15:05,488 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 63 seconds <NL> [  130.892500] ntputils[1967]: int ntputils_main(int, char**)Starting ntputils <NL> [  130.892844] ntputils[1967]: Running as a daemon <NL> [  130.892979] ntputils[1967]: shelf role is: MAIN <NL> [  130.893092] ntputils[1967]: slot number is: 0 <NL> [  130.893173] ntputils[1967]: slot role is: UNKNOWN <NL> [  130.893253] ntputils[1967]: redundancy_mode: UNKNOWN <NL> [  130.893361] ntputils[1967]: Executing on a work blade <NL> [  130.893430] ntputils[1967]: ================================ <NL> [  130.893507] ntputils[1967]: shelf_role is: MAIN <NL> [  130.993546] ntputils[1967]: redundancy_mode: UNKNOWN <NL> [  130.993631] ntputils[1967]: active_status: active <NL> [  130.993708] ntputils[1967]: ntp_role: act <NL> 2024-07-31 08:15:05,703 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 63 seconds <NL> 2024-07-31 08:15:05,764 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  130.995052] ntputils[1967]: ================================ <NL> 2024-07-31 08:15:05,901 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  131.281317] ntputils[1967]: NTPUtilsConfig::do_default_config <NL> [  131.456360] ntputils[1967]: shelf_num/is_client: 0"}
{"timestamp_utc": "2024-07-31T08:15:08.554Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:08 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:08.810Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:15:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:08 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:11.338Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:15:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:11.339Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  131.456467] ntputils[1967]: server_ip: 0x55bbb286cfc0 <NL> [  131.456569] ntputils[1967]: ip_addr(ilan): 0x55bbb286cf80 <NL> [  131.456647] ntputils[1967]: ntp_role act <NL> [  131.456722] ntputils[1967]: shelf_num aka is_client == 0 <NL> [  131.456797] ntputils[1967]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  131.456874] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  131.456947] ntputils[1967]: systemctl --no-block stop ntpd <NL> [  131.457073] ntputils[1967]: child pid is 1979 <NL> [  131.457157] ntputils[1967]: exited, status is 0 <NL> [  131.457305] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  131.457383] ntputils[1967]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  131.457460] ntputils[1967]: child pid is 1992 <NL> 2024-07-31 08:15:06,206 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:06,272 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  131.716658] ntputils[1995]: Changing Stratum and adding restrictions <NL> [  131.858334] ntputils[1967]: exited, status is 0 <NL> [  131.858487] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  131.858559] ntputils[1967]: /bin/systemctl reset-failed ntpd <NL> [  131.858632] ntputils[1967]: child pid is 2007 <NL> [  131.858707] ntputils[1967]: exited, status is 0 <NL> [  131.858774] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  131.858841] ntputils[1967]: systemctl --no-block start ntpd <NL> [  131.858917] ntputils[1967]: child pid is 2052 <NL> 2024-07-31 08:15:06,631 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:15:06,642 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:06,782 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:06,783 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:06,783 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:06,783 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  132.288664] ntputils[1967]: exited, status is 0 <NL> [  132.403540] ntputils[1967]: server role, server_ip is set to: 127.0.0.1 <NL> [  132.403654] ntputils[1967]: Running in production mode <NL> [  132.403750] ntputils[1967]: InitDaemon redundancy_mode: UNKNOWN <NL> [  132.497313] ntputils[1967]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  132.497582] ntputils[1967]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  132.497669] ntputils[1967]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  132.497767] ntputils[1967]: registration socket.send OK <NL> 2024-07-31 08:15:07,135 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:07,137 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> 2024-07-31 08:15:07,288 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:15:07,292 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:15:07,675 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:07,630 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> 2024-07-31 08:15:07,851 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> [  133.306636] rdm[1973]: RdmConfig: file_exist 0 <NL> [  133.306913] rdm[1973]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  133.307062] rdm[1973]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> 2024-07-31 08:15:07,950 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:07,967 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:07,979 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:07,980 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:08,010 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> [  133.471596] rdm[1973]: start rdm msg hdlr thd <NL> [  133.473894] ntputils[1967]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  133.596624] ntputils[1967]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  133.596800] ntputils[1967]:  topic reg for: <NL> [  133.596879] ntputils[1967]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  133.596955] ntputils[1967]: registration socket.send OK <NL> [  134.025635] ntputils[1967]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  134.026452] ntputils[1967]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  134.026565] ntputils[1967]:  topic reg for: <NL> [  134.026660] ntputils[1967]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  134.039887] ntputils[1967]: registration socket.send OK <NL> [  134.169531] ntputils[1967]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  134.169753] ntputils[1967]: void NTPServer::check_ntp_enabled() <NL> [  134.169833] ntputils[1967]: check_ntp_enabled not empty <NL> [  134.169906] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  134.169976] ntputils[1967]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  134.193783] ntputils[1967]: child pid is 2167 <NL> 2024-07-31 08:15:08,832 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:08,927 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:08,959 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:09,072 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  134.342962] ntputils[1967]: exited, status is 0 <NL> [  134.506980] ntputils[1967]: check_ntp_enabled skip system script_start <NL> 2024-07-31 08:15:09,057 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:09,145 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:09,145 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:09,145 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:15:09,160 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  134.551148] ntputils[1967]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  134.737706] ntputils[1967]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  134.737823] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  134.737911] ntputils[1967]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  134.739204] ntputils[1967]: child pid is 2169 <NL> [  134.739304] ntputils[1967]: exited, status is 0 <NL> [  134.739382] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  134.739453] ntputils[1967]: systemctl --no-block stop ntpd <NL> [  134.739529] ntputils[1967]: child pid is 2175 <NL> 2024-07-31 08:15:09,362 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version:"}
{"timestamp_utc": "2024-07-31T08:15:13.855Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:13 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:13 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:14.113Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "2024-07-31 08:14:00,919 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:00,919 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:00,920 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   73.756508] vsftpd_listen_address[960]: listen_address=127.1.1.1 <NL> [   75.970084] br.rstp_int: port 2(istp2) entered blocking state <NL> [   75.995441] br.rstp_int: port 2(istp2) entered disabled state <NL> [   76.011807] device istp2 entered promiscuous mode <NL> [  128.112715] ntputils[1752]: int ntputils_main(int, char**)Starting ntputils <NL> [  128.145582] ntputils[1752]: Running as a daemon <NL> [  128.209669] ntputils[1752]: shelf role is: TRIB <NL> [  128.316882] ntputils[1752]: slot number is: 0 <NL> [  128.335048] ntputils[1752]: slot role is: UNKNOWN <NL> [  128.364300] ntputils[1752]: redundancy_mode: UNKNOWN <NL> [  128.466244] ntputils[1752]: Executing on a work blade <NL> 2024-07-31 08:15:04,459 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 63 seconds <NL> [  128.477525] ntputils[1752]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  128.509039] ntputils[1752]: ================================ <NL> [  128.510701] ntputils[1752]: shelf_role is: TRIB <NL> [  128.521204] ntputils[1752]: redundancy_mode: UNKNOWN <NL> [  128.565795] ntputils[1752]: active_status: active <NL> [  128.579987] ntputils[1752]: ntp_role: trib <NL> [  128.580726] ntputils[1752]: ================================ <NL> [  128.615227] ntputils[1752]: NTPUtilsConfig::do_default_config <NL> [  128.659119] ntputils[1752]: shelf_num/is_client: 1 <NL> [  128.659773] ntputils[1752]: server_ip: 0x558e7c1a7fc0 <NL> 2024-07-31 08:15:04,677 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:04,788 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  128.738289] ntputils[1752]: ip_addr(ilan): 0x558e7c1a7f80 <NL> [  128.855638] ntputils[1752]: ntp_role trib <NL> [  128.855743] ntputils[1752]: shelf_num aka is_client > 0 <NL> [  128.855819] ntputils[1752]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  128.855892] ntputils[1752]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  128.855964] ntputils[1752]: NTPServer::execute_cmd spawning: <NL> [  128.856067] ntputils[1752]: systemctl --no-block stop ntpd <NL> [  128.856180] ntputils[1752]: child pid is 1778 <NL> [  128.857045] ntputils[1752]: exited, status is 0 <NL> [  128.857133] ntputils[1752]: NTPServer::execute_cmd spawning: <NL> [  128.857220] ntputils[1752]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  128.857307] ntputils[1752]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  128.857402] ntputils[1752]: child pid is 1789 <NL> [  128.858121] ntputils[1794]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:15:05,110 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:15:05,174 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  129.354029] ntputils[1818]: Changing Stratum and adding restrictions <NL> [  129.395780] ntputils[1752]: exited, status is 0 <NL> [  129.499980] ntputils[1752]: NTPServer::execute_cmd spawning: <NL> [  129.560769] ntputils[1752]: /bin/systemctl reset-failed ntpd <NL> [  129.560861] ntputils[1752]: child pid is 1835 <NL> 2024-07-31 08:15:05,673 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:05,673 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:05,673 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:05,674 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:05,674 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:05,674 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:15:05,757 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:05,757 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:05,757 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:05,814 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  129.756303] ntputils[1752]: exited, status is 0 <NL> [  129.859634] ntputils[1752]: NTPServer::execute_cmd spawning: <NL> [  129.989745] ntputils[1752]: systemctl --no-block start ntpd <NL> [  129.990671] ntputils[1752]: child pid is 1838 <NL> [  129.990782] ntputils[1752]: exited, status is 0 <NL> [  129.990878] ntputils[1752]: client role with Python client, systemD starts it <NL> [  134.694561] fujitsu-check-ssh-host-key.pl[1929]: Checking system account status... <NL> [  134.827946] fujitsu-check-ssh-host-key.pl[1929]: System account found... <NL> [  135.099537] fujitsu-check-ssh-host-key.pl[1929]: 3004 <NL> 2024-07-31 08:15:11,309 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:15:11,347 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:15:11,396 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml"}
{"timestamp_utc": "2024-07-31T08:15:14.114Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "2024-07-31 08:15:11,672 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> [  135.341174] fujitsu-check-ssh-host-key.pl[1929]: /bin/bash <NL> [  135.771376] fujitsu-check-ssh-host-key.pl[1929]: /home/system exists <NL> [  135.771519] fujitsu-check-ssh-host-key.pl[1929]: Checking for trib... <NL> [  135.773250] fujitsu-check-ssh-host-key.pl[1929]: Creating factory user for trib.. <NL> 2024-07-31 08:15:11,782 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:11,948 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:12,046 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:15:12,086 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:12,109 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:12,110 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> 2024-07-31 08:15:13,143 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:13,220 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:13,221 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:15:13,223 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:15:13,274 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE"}
{"timestamp_utc": "2024-07-31T08:15:16.630Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:15:16 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:17.995Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "2024-07-31 08:15:09,563 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  134.991551] ntputils[1967]: exited, status is 0 <NL> [  134.992354] ntputils[1967]: call delete_all_external_servers <NL> [  134.992552] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  134.992697] ntputils[1967]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  135.038319] ntputils[1967]: child pid is 2177 <NL> [  135.055322] ntputils[2177]: remove_all_ext_src <NL> [  135.133135] ntputils[2177]: delete: <NL> [  135.238134] ntputils[1967]: exited, status is 0 <NL> [  135.238327] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  135.256829] ntputils[1967]: /bin/systemctl reset-failed ntpd <NL> [  135.257061] ntputils[1967]: child pid is 2183 <NL> 2024-07-31 08:15:09,916 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:15:09,980 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:10,054 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:10,054 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  135.563737] ntputils[1967]: exited, status is 0 <NL> [  135.564173] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  135.564895] ntputils[1967]: systemctl --no-block start ntpd <NL> [  135.613398] ntputils[1967]: child pid is 2188 <NL> [  135.746957] ntputils[1967]: exited, status is 0 <NL> [  135.806201] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  135.806361] ntputils[1967]: /bin/systemctl reset-failed init_state_check.timer <NL> [  135.966887] ntputils[1967]: child pid is 2190 <NL> [  136.187038] ntputils[1967]: exited, status is 0 <NL> [  136.187273] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  136.187353] ntputils[1967]: /bin/systemctl --no-block start init_state_check.timer <NL> [  136.187438] ntputils[1967]: child pid is 2198 <NL> [  136.483199] ntputils[1967]: exited, status is 0 <NL> [  136.483428] ntputils[1967]: server.InitDaemon <NL> [  136.483522] ntputils[1967]: int NTPServer::platformdds_listen() <NL> [  136.483615] ntputils[1967]: void NTPServer::poller() <NL> [  136.483720] ntputils[1967]: void NTPServer::late_joiner() <NL> [  137.483116] ntputils[1967]: bool NTPServer::handle_command(const string&) <NL> [  137.483314] ntputils[1967]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  137.483393] ntputils[1967]: got Platform::RedundancyMode: UNKNOWN <NL> [  137.483511] ntputils[1967]: got Platform::RedundancyStatus: STANDALONE <NL> [  137.483588] ntputils[1967]: my current red mode is: UNKNOWN <NL> [  137.483664] ntputils[1967]: new red mode is: UNKNOWN <NL> [  137.483740] ntputils[1967]: my current red status is: active <NL> [  137.483833] ntputils[1967]: new red status is: STANDALONE <NL> [  137.483909] ntputils[1967]: received unknown! <NL> [  137.483980] ntputils[1967]: new red mode is: UNKNOWN <NL> [  137.484080] ntputils[1967]: new red status is: STANDALONE <NL> [  137.484153] ntputils[1967]: red status change, update active => STANDALONE <NL> [  137.484230] ntputils[1967]: no active/not-active status change: 0 <NL> 2024-07-31 08:15:13,868 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:13,901 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  139.323579] usb_script_handler.py[1981]: usb: INFO - usb_base.disable_if_not_ha_mode[323] Disabling USB SSW: ha_mode != USB. <NL> [  139.472533] usb_script_handler.py[1981]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  139.472683] usb_script_handler.py[1981]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> 2024-07-31 08:15:13,969 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:14,254 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  139.654856] ntputils[1967]: bool NTPServer::handle_command(const string&) <NL> [  139.655070] ntputils[1967]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  139.655142] ntputils[1967]: got Platform::RedundancyMode: UNKNOWN <NL> [  139.655206] ntputils[1967]: got Platform::RedundancyStatus: STANDALONE <NL> [  139.655267] ntputils[1967]: my current red mode is: UNKNOWN <NL> [  139.655327] ntputils[1967]: new red mode is: UNKNOWN <NL> [  139.655410] ntputils[1967]: my current red status is: STANDALONE <NL> [  139.655487] ntputils[1967]: new red status is: STANDALONE <NL> [  139.655554] ntputils[1967]: received unknown! <NL> [  139.655653] ntputils[1967]: new red mode is: UNKNOWN <NL> [  139.655713] ntputils[1967]: new red status is: STANDALONE <NL> [  139.655770] ntputils[1967]: no active/not-active status change: 0 <NL> 2024-07-31 08:15:15,032 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:15:15,033 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:15:15,033 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:15:15,034 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:15:15,035 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:15,050 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662"}
{"timestamp_utc": "2024-07-31T08:15:17.996Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "2024-07-31 08:15:15,059 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:15,119 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:15,120 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:15:15,120 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:15:15,210 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:15,272 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:15,272 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:15,226 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:15,275 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  140.972387] fujitsu-check-ssh-host-key.pl[2264]: Checking system account status... <NL> [  141.013854] fujitsu-check-ssh-host-key.pl[2264]: System account found... <NL> [  141.116127] fujitsu-check-ssh-host-key.pl[2264]: 3004 <NL> [  141.123222] fujitsu-check-ssh-host-key.pl[2264]: /bin/bash <NL> [  141.123402] fujitsu-check-ssh-host-key.pl[2264]: /home/system exists <NL> [  141.123477] fujitsu-check-ssh-host-key.pl[2264]: Checking for trib... <NL> [  141.123587] fujitsu-check-ssh-host-key.pl[2264]: Checking for PIU ... <NL> [  141.140314] fujitsu-check-ssh-host-key.pl[2264]: slot number (0) is not a PIU. <NL> [  141.231434] fujitsu-check-ssh-host-key.pl[2264]: Trib check done. <NL> 2024-07-31 08:15:16,121 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:16,182 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:16,241 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY"}
{"timestamp_utc": "2024-07-31T08:15:18.557Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:18 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:18.813Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:15:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:18 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:20.180Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "2024-07-31 08:15:16,242 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:16,266 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:16,318 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:16,319 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:15:16,282 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  141.802330] ntp_oper_data.py[1968]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  141.803225] ntp_oper_data.py[1968]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  141.891827] ntp_oper_data.py[1968]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> 2024-07-31 08:15:16,498 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:16,499 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> [  141.960957] ntp_oper_data.py[1968]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> 2024-07-31 08:15:16,561 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:15:16,567 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:16,641 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:16,642 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:16,735 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:15:16,736 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> 2024-07-31 08:15:16,969 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:15:16,970 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  142.365786] ntp_oper_data.py[1968]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  142.365966] ntp_oper_data.py[1968]: INFO:root:redundancy status now set to standalone <NL> [  142.479201] ntp_oper_data.py[1968]: INFO:root:Received redundancy topic <NL> [  142.512554] ntp_oper_data.py[1968]: INFO:root:Redundancy status is standalone <NL> [  142.565755] startup[2297]: Startup, World! <NL> [  142.565907] startup[2297]: Cmd arg set to loop 1 <NL> 2024-07-31 08:15:17,153 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:17,235 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:17,335 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:17,337 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:17,337 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:17,338 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:17,338 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:17,339 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:17,345 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:17,440 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:17,539 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:17,603 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:15:17,604 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:15:17,660 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:17,662 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:17,696 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:17,732 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:17,733 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:17,734 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> 2024-07-31 08:15:17,735 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING"}
{"timestamp_utc": "2024-07-31T08:15:20.181Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "2024-07-31 08:15:17,735 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:17,745 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:17,895 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:17,922 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> 2024-07-31 08:15:17,923 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:15:17,961 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:15:17,961 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:15:17,962 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:17,962 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:17,963 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:18,035 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:18,036 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:18,144 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:15:18,145 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:15:18,145 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0,"}
{"timestamp_utc": "2024-07-31T08:15:21.557Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:15:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:24.074Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:23 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:23 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:25.441Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[   75.546525] serialportMon[1139]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   87.956263] vsftpd_listen_address[1184]: listen_address=127.1.254.254 <NL> 2024-07-31 08:14:23,471 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:26,206 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:26,232 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:26,260 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:26,268 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:26,281 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> 2024-07-31 08:14:26,316 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  112.349564] dcn_dns_controller[1372]:  WaitForActive <NL> [  112.806340] dcn_ka[1374]:  WaitForActive <NL> 2024-07-31 08:14:57,744 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 31 seconds <NL> 2024-07-31 08:14:57,553 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 31 seconds <NL> 2024-07-31 08:14:58,432 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:59,061 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:59,584 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  128.644403] ops-redundancy-mgr[1382]: DipLog_pimpl destructor called"}
{"timestamp_utc": "2024-07-31T08:15:25.442Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "2024-07-31 08:15:02,104 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  131.044536] ops-redundancy-mgr[1382]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:04,796 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> [  132.767032] ops-redundancy-mgr[1382]:     ret='Context was terminated <NL> 2024-07-31 08:15:06,072 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:15:06,883 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  134.199683] ops-redundancy-mgr[1382]: deleting subscriber_ socket <NL> 2024-07-31 08:15:09,022 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:09,063 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> [  136.235465] ops-redundancy-mgr[1382]: Exiting verb listener <NL> [  137.582115] standby_filesync[1391]: DipLog_pimpl destructor called <NL> [  138.028126] standby_filesync[1391]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:11,401 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn <NL> [  138.386809] standby_filesync[1391]:     ret='Context was terminated <NL> 2024-07-31 08:15:12,079 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  139.210420] standby_filesync[1391]: deleting subscriber_ socket <NL> 2024-07-31 08:15:12,512 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:12,890 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  139.798880] standby_filesync[1391]: Exiting verb listener <NL> 2024-07-31 08:15:13,493 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn <NL> 2024-07-31 08:15:14,068 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:13,569 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  141.018039] ntputils[1710]: int ntputils_main(int, char**)Starting ntputils <NL> 2024-07-31 08:15:14,764 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:14,274 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> [  142.009596] ntputils[1710]: Running as a daemon <NL> 2024-07-31 08:15:15,515 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:15,123 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> [  143.591825] ntputils[1710]: shelf role is: MAIN <NL> 2024-07-31 08:15:17,226 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:15:16,499 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> [  144.930735] ntputils[1710]: slot number is: 0 <NL> 2024-07-31 08:15:19,025 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:18,302 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  146.601392] ntputils[1710]: slot role is: UNKNOWN <NL> 2024-07-31 08:15:19,880 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:20,001 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  146.854221] ntputils[1710]: redundancy_mode: UNKNOWN <NL> 2024-07-31 08:15:20,252 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:20,650 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  147.753699] ntputils[1710]: Executing on a work blade <NL> 2024-07-31 08:15:21,435 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  148.599869] ntputils[1710]: ================================ <NL> 2024-07-31 08:15:21,990 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:22,267 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  149.337236] ntputils[1710]: shelf_role is: MAIN <NL> 2024-07-31 08:15:23,336 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:23,598 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  150.410420] ntputils[1710]: redundancy_mode: UNKNOWN <NL> 2024-07-31 08:15:24,025 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> [  151.370024] ntputils[1710]: active_status: active <NL> [  151.468761] ntputils[1710]: ntp_role: act"}
{"timestamp_utc": "2024-07-31T08:15:25.699Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[  127.789500] ntputils_client.py[1730]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  127.789635] ntputils_client.py[1730]: b'31 Jul 08:15:02 ntpdate[1840]: no server suitable for synchronization found\\n' <NL> [  127.965646] startup_finished.py[2025]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  128.180912] dhal_sim_startup.sh[2071]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  129.147863] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  129.221388] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  128.865345] sh[2095]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  128.909504] sh[2095]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  128.910383] confd_mgr_action_server[2055]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 2 <NL> [  131.213727] startup_finished.py[2025]: Startup Finished: systemd state is non-Production mode and running <NL> [  131.233268] startup_finished.py[2025]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  132.170519] startup_finished.py[2025]: *****Startup Finished: stopping EOW timer*****"}
{"timestamp_utc": "2024-07-31T08:15:25.700Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[  132.470658] zebra[2094]: 2024/07/31 08:15:06 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  132.905371] startup_finished.py[2025]: systemctl stop startup_finished_limit.timer <NL> 2024-07-31 08:15:08,471 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  139.961864] layer1_control_layer[2076]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  142.163417] ains_manager[2313]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  145.137430] layer1_control_layer[2076]: DIP entity prov dump <NL> [  145.347086] layer1_control_layer[2076]: EsalConfig::EsalConfig main 0 <NL> [  145.351623] layer1_control_layer[2076]: EsalConfig::EsalConfig trib 1 <NL> [  145.351725] layer1_control_layer[2076]: EsalConfig::EsalConfig ciRole 0 <NL> [  145.467298] layer1_control_layer[2076]: EsalConfig is not running inside container. <NL> [  145.467642] layer1_control_layer[2076]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.467734] layer1_control_layer[2076]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.498084] layer1_control_layer[2076]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.498188] layer1_control_layer[2076]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  145.510303] layer1_control_layer[2076]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  145.510558] layer1_control_layer[2076]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  145.510640] layer1_control_layer[2076]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  145.510712] layer1_control_layer[2076]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  145.510809] layer1_control_layer[2076]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  145.510882] layer1_control_layer[2076]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  145.510970] layer1_control_layer[2076]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  145.511071] layer1_control_layer[2076]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  145.511147] layer1_control_layer[2076]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  145.511238] layer1_control_layer[2076]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  145.511357] layer1_control_layer[2076]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  145.511429] layer1_control_layer[2076]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  145.511506] layer1_control_layer[2076]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> 2024-07-31 08:15:23,620 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:15:23,621 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:23,664 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:23,665 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:23,666 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":2} <NL> 2024-07-31 08:15:23,666 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:15:23,748 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:23,820 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:23,745 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:15:23,827 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:23,827 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:23,828 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:15:23,907 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:15:23,907 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":2} <NL> 2024-07-31 08:15:23,908 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:15:23,958 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:15:24,095 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> [  149.852527] python3[2203]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  149.943651] python3[2203]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  149.944444] python3[2203]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  149.945172] python3[2203]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  150.004564] python3[2203]: max_slotNumber=5 <NL> 2024-07-31 08:15:24,270 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:24,298 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:24,298 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:24,299 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:15:24,299 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:15:24,299 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:15:24,327 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:24,327 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:24,329 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:15:24,379 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> REPO_REPL_EVT"}
{"timestamp_utc": "2024-07-31T08:15:25.956Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:15:25 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:29.225Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:28 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:29.226Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:15:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:28 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:31.117Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:15:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:33.010Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "(priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> 2024-07-31 08:14:21,130 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:21,138 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:21,138 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml"}
{"timestamp_utc": "2024-07-31T08:15:33.011Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "(priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> [   93.223372] vsftpd_listen_address[1026]: listen_address=127.1.254.254 <NL> [   95.363649] br.rstp_int: port 2(istp2) entered blocking state <NL> [   95.370967] br.rstp_int: port 2(istp2) entered disabled state <NL> [   95.372108] device istp2 entered promiscuous mode <NL> [  148.967218] dcn_dns_controller[1601]:  WaitForActive <NL> [  149.069497] dcn_ka[1603]:  WaitForActive <NL> [  151.013624] ntputils[1855]: int ntputils_main(int, char**)Starting ntputils <NL> [  151.013923] ntputils[1855]: Running as a daemon <NL> [  151.239273] ntputils[1855]: shelf role is: MAIN <NL> [  151.239401] ntputils[1855]: slot number is: 0 <NL> [  151.239485] ntputils[1855]: slot role is: UNKNOWN <NL> [  151.239565] ntputils[1855]: redundancy_mode: UNKNOWN <NL> [  151.239709] ntputils[1855]: Executing on a work blade <NL> [  151.239786] ntputils[1855]: ================================ <NL> [  151.239860] ntputils[1855]: shelf_role is: MAIN <NL> [  151.239930] ntputils[1855]: redundancy_mode: UNKNOWN <NL> [  151.240021] ntputils[1855]: active_status: active <NL> [  151.240095] ntputils[1855]: ntp_role: act <NL> [  151.240168] ntputils[1855]: ================================ <NL> 2024-07-31 08:15:26,946 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 65 seconds <NL> [  151.797120] ntputils[1855]: NTPUtilsConfig::do_default_config <NL> [  151.925190] ntputils[1855]: shelf_num/is_client: 0 <NL> [  152.253635] ntputils[1855]: server_ip: 0x55b57998bfc0 <NL> 2024-07-31 08:15:27,408 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:28,007 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> 2024-07-31 08:15:27,572 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 66 seconds <NL> [  152.518383] ntputils[1855]: ip_addr(ilan): 0x55b57998bf80 <NL> [  152.654025] ntputils[1855]: ntp_role act <NL> [  152.654140] ntputils[1855]: shelf_num aka is_client == 0 <NL> [  152.654222] ntputils[1855]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:28,258 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:28,276 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  152.831140] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  152.966158] ntputils[1855]: systemctl --no-block stop ntpd <NL> [  153.274698] ntputils[1855]: child pid is 1914 <NL> [  153.274846] ntputils[1855]: exited, status is 0 <NL> [  153.274932] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  153.275032] ntputils[1855]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  153.275117] ntputils[1855]: child pid is 1926 <NL> [  153.374657] ntputils[1943]: Changing Stratum and adding restrictions <NL> [  153.425237] ntputils[1855]: exited, status is 0 <NL> 2024-07-31 08:15:29,079 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:15:29,081 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:29,092 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:29,094 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:29,101 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:29,104 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  153.477034] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  154.120132] ntputils[1855]: /bin/systemctl reset-failed ntpd <NL> [  154.120262] ntputils[1855]: child pid is 1964 <NL> 2024-07-31 08:15:29,406 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:29,545 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> [  154.160498] ntputils[1855]: exited, status is 0 <NL> [  154.382061] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  154.382278] ntputils[1855]: systemctl --no-block start ntpd <NL> 2024-07-31 08:15:29,870 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:15:29,852 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> 2024-07-31 08:15:29,883 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> 2024-07-31 08:15:29,946 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  154.558934] ntputils[1855]: child pid is 1980 <NL> [  155.079982] ntputils[1855]: exited, status is 0 <NL> [  155.080098] ntputils[1855]: server role, server_ip is set to: 127.0.0.1 <NL> [  155.080202] ntputils[1855]: Running in production mode <NL> [  155.080286] ntputils[1855]: InitDaemon redundancy_mode: UNKNOWN <NL> [  155.080397] ntputils[1855]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  155.080523] ntputils[1855]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  155.080614] ntputils[1855]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  155.080693] ntputils[1855]: registration socket.send OK <NL> 2024-07-31 08:15:30,566 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:15:30,725 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:30,726 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:30,726 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:30,726 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:30,727 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> [  155.340677] rdm[1867]: RdmConfig: file_exist 0 <NL> [  155.340912] rdm[1867]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  155.341069] rdm[1867]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  155.341150] rdm[1867]: start rdm msg hdlr thd <NL> [  155.672902] ntputils[1855]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  155.673103] ntputils[1855]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  155.673186] ntputils[1855]:  topic reg for: <NL> [  155.673268] ntputils[1855]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  155.673382] ntputils[1855]: registration socket.send OK <NL> 2024-07-31 08:15:31,670 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:31,670 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:31,671 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> [  156.387034] ntputils[1855]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1"}
{"timestamp_utc": "2024-07-31T08:15:33.940Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:33 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:33 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:34.505Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "\"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> 2024-07-31 08:15:18,146 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:18,146 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:18,146 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:18,214 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: RESET -> READY_STATE -> reset_fn -> WAIT_STATE <NL> 2024-07-31 08:15:18,331 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:18,361 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:18,214 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:18,488 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount  --script  --base /mnt/secondary/var/shared --algorithm longest-match L1-OTSG2.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  144.476850] startup_finished.py[2292]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  144.565332] ains_manager[2293]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:15:19,397 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:19,662 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:19,678 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:15:34.506Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "2024-07-31 08:15:19,706 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:19,708 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:19,718 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:19,721 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:19,722 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:19,752 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:19,755 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:19,806 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:19,838 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:19,855 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:19,874 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:19,899 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:19,891 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:19,965 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:20,273 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:20,342 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> ERROR:root:empty repository <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> 2024-07-31 08:15:24,051 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:24,236 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:24,236 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:24,356 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:24,357 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:24,357 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:15:24,395 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> 2024-07-31 08:15:24,469 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  150.876782] dhal_sim_startup.sh[2400]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  153.314650] confd_mgr_action_server[2393]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  153.315405] ains_manager[2407]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  154.076352] confd_phase_sentry[2427]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  154.121738] confd_phase_sentry[2427]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  154.355126] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  155.364964] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  155.538108] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  155.010348] temp_acct_cleanup_app[2439]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  155.196854] temp_acct_cleanup_app[2439]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  156.704478] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 1"}
{"timestamp_utc": "2024-07-31T08:15:36.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:15:36 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:38.913Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:38 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:38 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:41.431Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  156.553826] ntputils[1855]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  156.553965] ntputils[1855]:  topic reg for: <NL> [  156.554076] ntputils[1855]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  156.554164] ntputils[1855]: registration socket.send OK <NL> [  156.571284] ntputils[1855]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  156.571424] ntputils[1855]: void NTPServer::check_ntp_enabled() <NL> [  156.571505] ntputils[1855]: check_ntp_enabled not empty <NL> [  156.571578] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  156.571665] ntputils[1855]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> 2024-07-31 08:15:31,994 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:32,273 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:32,274 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:15:32,276 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:32,276 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:32,276 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  156.594192] ntputils[1855]: child pid is 2112 <NL> [  156.894215] ntputils[1855]: exited, status is 0 <NL> [  156.894373] ntputils[1855]: check_ntp_enabled skip system script_start <NL> [  156.894464] ntputils[1855]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  156.894553] ntputils[1855]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  156.894641] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  156.894722] ntputils[1855]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  156.894812] ntputils[1855]: child pid is 2126 <NL> 2024-07-31 08:15:32,420 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  157.188915] ntputils[1855]: exited, status is 0 <NL> [  157.189099] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  157.189179] ntputils[1855]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:32,708 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  157.245893] ntputils[1855]: child pid is 2132 <NL> [  157.418917] ntputils[1855]: exited, status is 0 <NL> [  157.419096] ntputils[1855]: call delete_all_external_servers <NL> [  157.419187] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  157.419256] ntputils[1855]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  157.714056] ntputils[1855]: child pid is 2145 <NL> [  157.715194] ntputils[2145]: remove_all_ext_src <NL> [  157.745231] ntputils[2145]: delete: <NL> [  157.822053] ntputils[1855]: exited, status is 0 <NL> 2024-07-31 08:15:33,106 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:33,218 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:33,402 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:33,322 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  157.822217] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  157.977804] ntputils[1855]: /bin/systemctl reset-failed ntpd <NL> [  157.977931] ntputils[1855]: child pid is 2151 <NL> [  157.978259] ntputils[1855]: exited, status is 0 <NL> [  157.978351] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  157.978422] ntputils[1855]: systemctl --no-block start ntpd <NL> [  157.978507] ntputils[1855]: child pid is 2157 <NL> [  158.777930] ntputils[1855]: exited, status is 0 <NL> [  158.778202] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  158.778279] ntputils[1855]: /bin/systemctl reset-failed init_state_check.timer <NL> [  158.960718] ntputils[1855]: child pid is 2174 <NL> [  159.026875] ntputils[1855]: exited, status is 0 <NL> [  159.027056] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  159.027136] ntputils[1855]: /bin/systemctl --no-block start init_state_check.timer <NL> [  159.027215] ntputils[1855]: child pid is 2180 <NL> [  159.370457] ntputils[1855]: exited, status is 0 <NL> [  159.371929] ntputils[1855]: server.InitDaemon <NL> [  159.372527] ntputils[1855]: int NTPServer::platformdds_listen() <NL> [  159.373149] ntputils[1855]: void NTPServer::late_joiner() <NL> [  159.373672] ntputils[1855]: void NTPServer::poller() <NL> [  160.666691] ntputils[1855]: bool NTPServer::handle_command(const string&) <NL> [  160.666896] ntputils[1855]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  160.678713] ntputils[1855]: got Platform::RedundancyMode: UNKNOWN <NL> [  160.678917] ntputils[1855]: got Platform::RedundancyStatus: STANDALONE <NL> [  160.740883] ntputils[1855]: my current red mode is: UNKNOWN <NL> [  160.741093] ntputils[1855]: new red mode is: UNKNOWN <NL> [  160.741199] ntputils[1855]: my current red status is: active <NL> [  160.741301] ntputils[1855]: new red status is: STANDALONE <NL> [  160.741387] ntputils[1855]: received unknown! <NL> [  160.741461] ntputils[1855]: new red mode is: UNKNOWN <NL> 2024-07-31 08:15:36,400 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:36,401 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:36,413 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:36,413 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  160.772519] ntputils[1855]: new red status is: STANDALONE <NL> [  161.083846] ntputils[1855]: red status change, update active => STANDALONE <NL> [  161.262390] ntputils[1855]: no active/not-active status change: 0 <NL> [  161.680096] ntputils[1855]: bool NTPServer::handle_command(const string&) <NL> [  161.680322] ntputils[1855]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  161.680404] ntputils[1855]: got Platform::RedundancyMode: UNKNOWN <NL> [  161.680478] ntputils[1855]: got Platform::RedundancyStatus: STANDALONE <NL> [  161.680552] ntputils[1855]: my current red mode is: UNKNOWN <NL> [  161.680648] ntputils[1855]: new red mode is: UNKNOWN <NL> [  161.680746] ntputils[1855]: my current red status is: STANDALONE <NL> [  161.680858] ntputils[1855]: new red status is: STANDALONE <NL> [  161.680947] ntputils[1855]: received unknown! <NL> [  161.681084] ntputils[1855]: new red mode is: UNKNOWN <NL> [  161.681157] ntputils[1855]: new red status is: STANDALONE <NL> [  161.681234] ntputils[1855]: no active/not-active status change: 0 <NL> [  163.204482] usb_script_handler.py[1877]: usb: INFO - usb_base.disable_if_not_ha_mode[323] Disabling USB SSW: ha_mode != USB. <NL> [  163.204694] usb_script_handler.py[1877]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  163.354920] usb_script_handler.py[1877]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> 2024-07-31 08:15:40,355 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:15:40,360 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:15:40,361 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:15:40,365 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> # 03:15:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:43.947Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:43 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:43 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:44.509Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "2024-07-31 08:15:40,365 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:40,375 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:40,406 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:15:40,505 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:40,505 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:40,506 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:40,558 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:40,599 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:40,600 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:15:40,602 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:40,700 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:41,625 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:41,627 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:41,663 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:41,663 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:41,690 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:41,873 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:41,874 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:15:41,705 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:42,042 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:42,054 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:42,137 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:15:42,138 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:42,139 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank {"}
{"timestamp_utc": "2024-07-31T08:15:44.510Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:42,255 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:42,256 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:15:42,257 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> [  166.963224] fujitsu-check-ssh-host-key.pl[2272]: Checking system account status... <NL> 2024-07-31 08:15:42,457 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:15:42,541 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:42,553 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:42,553 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:42,555 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:42,671 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  167.144423] fujitsu-check-ssh-host-key.pl[2272]: System account found... <NL> 2024-07-31 08:15:42,716 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:15:42,781 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:15:42,781 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:42,782 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:42,783 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:42,783 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:42,726 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:42,800 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:42,914 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> 2024-07-31 08:15:42,915 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> 2024-07-31 08:15:42,915 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:42,894 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:43,030 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:43,030 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:43,031 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:42,979 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:43,037 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:43,038 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:15:43,038 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:15:43,039 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:43,039 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:43,136 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:43,137 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:43,137 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:43,138 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM"}
{"timestamp_utc": "2024-07-31T08:15:45.888Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "2024-07-31 08:15:24,722 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  151.587749] ntputils[1710]: ================================ <NL> 2024-07-31 08:15:25,282 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  152.263128] ntputils[1710]: NTPUtilsConfig::do_default_config <NL> [  152.524971] ntputils[1710]: shelf_num/is_client: 0 <NL> 2024-07-31 08:15:25,747 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  152.670617] ntputils[1710]: server_ip: 0x564d12361fc0 <NL> [  152.905157] ntputils[1710]: ip_addr(ilan): 0x564d12361f80 <NL> [  153.022215] ntputils[1710]: ntp_role act <NL> [  153.093233] ntputils[1710]: shelf_num aka is_client == 0 <NL> [  153.340894] ntputils[1710]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  153.536595] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  153.572266] ntputils[1710]: systemctl --no-block stop ntpd <NL> [  153.699951] ntputils[1710]: child pid is 1798 <NL> [  153.743167] ntputils[1710]: exited, status is 0 <NL> [  153.889269] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  154.178575] ntputils[1710]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  154.332319] ntputils[1710]: child pid is 1806 <NL> [  154.928695] rdm[1719]: RdmConfig: file_exist 0 <NL> [  155.109162] rdm[1719]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  155.110089] rdm[1719]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  155.110809] rdm[1719]: start rdm msg hdlr thd <NL> [  155.188495] ntputils[1807]: Changing Stratum and adding restrictions <NL> [  155.345910] ntputils[1710]: exited, status is 0 <NL> [  155.474467] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  155.483400] ntputils[1710]: /bin/systemctl reset-failed ntpd <NL> [  155.564045] ntputils[1710]: child pid is 1819 <NL> [  155.586060] ntputils[1710]: exited, status is 0 <NL> [  155.588422] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  155.600311] ntputils[1710]: systemctl --no-block start ntpd <NL> [  155.647317] ntputils[1710]: child pid is 1821 <NL> [  155.777388] ntputils[1710]: exited, status is 0 <NL> [  156.000314] ntputils[1710]: server role, server_ip is set to: 127.0.0.1 <NL> [  156.060924] ntputils[1710]: Running in production mode <NL> [  156.137330] ntputils[1710]: InitDaemon redundancy_mode: UNKNOWN <NL> [  156.195162] ntputils[1710]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  156.244127] ntputils[1710]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  156.332326] ntputils[1710]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  156.484486] ntputils[1710]: registration socket.send OK <NL> [  156.649970] ntputils[1710]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  157.426287] ntputils[1710]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  158.084650] ntputils[1710]:  topic reg for: <NL> [  158.085412] ntputils[1710]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  158.086311] ntputils[1710]: registration socket.send OK <NL> [  158.486891] ntputils[1710]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  158.974814] ntputils[1710]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  159.542035] ntputils[1710]:  topic reg for: <NL> [  159.609750] ntputils[1710]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  159.743251] ntputils[1710]: registration socket.send OK <NL> [  159.765058] ntputils[1710]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  159.901746] ntputils[1710]: void NTPServer::check_ntp_enabled() <NL> [  160.057800] ntputils[1710]: check_ntp_enabled not empty <NL> [  160.212212] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  160.293873] ntputils[1710]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> 2024-07-31 08:15:33,717 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> [  160.641700] ntputils[1710]: child pid is 1854 <NL> 2024-07-31 08:15:34,101 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> [  161.121212] ntputils[1710]: exited, status is 0 <NL> 2024-07-31 08:15:34,398 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  161.172646] ntputils[1710]: check_ntp_enabled skip system script_start <NL> 2024-07-31 08:15:37,432 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> [  164.228737] ntputils[1710]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> 2024-07-31 08:15:37,886 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  165.035421] ntputils[1710]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  165.303219] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:38,572 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:38,579 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  165.451030] ntputils[1710]: /bin/systemctl --no-block stop init_state_check.timer <NL> 2024-07-31 08:15:39,096 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:39,588 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> [  166.396431] ntputils[1710]: child pid is 1866 <NL> 2024-07-31 08:15:39,772 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:15:39,951 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  167.207179] ntputils[1710]: exited, status is 0 <NL> 2024-07-31 08:15:40,462 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:40,707 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  167.981761] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:41,469 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:41,793 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  169.558952] ntputils[1710]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:43,140 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:43,379 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  170.293087] ntputils[1710]: child pid is 1872 <NL> 2024-07-31 08:15:43,756 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY"}
{"timestamp_utc": "2024-07-31T08:15:45.889Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  171.076168] ntputils[1710]: exited, status is 0 <NL> [  171.181534] ntputils[1710]: call delete_all_external_servers <NL> 2024-07-31 08:15:44,457 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  171.243228] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:44,561 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  171.340159] ntputils[1710]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> 2024-07-31 08:15:44,768 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:44,941 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  171.689264] ntputils[1710]: child pid is 1882 <NL> # 03:15:45 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:47.776Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[  119.761821] fujitsu-check-ssh-host-key.pl[1934]: Factory user shell set to /bin/bash"}
{"timestamp_utc": "2024-07-31T08:15:47.777Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[  119.870411] fujitsu-check-ssh-host-key.pl[1917]: Converting fujitsu user to bash shell... <NL> [  119.949496] fujitsu-check-ssh-host-key.pl[1985]: usermod: no changes <NL> [  119.949611] fujitsu-check-ssh-host-key.pl[1917]: Lock Root account in TRIB... <NL> [  119.950099] fujitsu-check-ssh-host-key.pl[1986]: Running lock on root account... <NL> [  120.040351] fujitsu-check-ssh-host-key.pl[1987]: passwd: password changed. <NL> [  120.040500] fujitsu-check-ssh-host-key.pl[1917]: Trib check done. <NL> [  120.574769] startup[2010]: Startup, World! <NL> [  120.575477] startup[2010]: Cmd arg set to loop 1 <NL> [  121.973381] startup_finished.py[2004]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  122.111607] ains_manager[2007]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  122.594565] dhal_sim_startup.sh[2059]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  123.000357] confd_mgr_action_server[2048]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 2 <NL> [  123.814802] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  123.942299] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  123.566342] sh[2085]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  123.566530] sh[2085]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  123.677061] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  123.677314] ntputils_client.py[1716]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  123.758841] ntputils_client.py[1716]: b'31 Jul 08:14:58 ntpdate[1845]: no server suitable for synchronization found\\n' <NL> [  125.790184] startup_finished.py[2004]: Startup Finished: systemd state is non-Production mode and running <NL> [  125.790326] startup_finished.py[2004]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  126.078761] zebra[2084]: 2024/07/31 08:15:00 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  126.701647] startup_finished.py[2004]: *****Startup Finished: stopping EOW timer***** <NL> [  127.632150] startup_finished.py[2004]: systemctl stop startup_finished_limit.timer <NL> [  135.711916] layer1_control_layer[2060]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  136.005827] ains_manager[2286]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  141.161799] layer1_control_layer[2060]: DIP entity prov dump <NL> [  141.444312] layer1_control_layer[2060]: EsalConfig::EsalConfig main 0 <NL> [  141.444554] layer1_control_layer[2060]: EsalConfig::EsalConfig trib 1 <NL> [  141.444628] layer1_control_layer[2060]: EsalConfig::EsalConfig ciRole 0 <NL> [  141.466649] layer1_control_layer[2060]: EsalConfig is not running inside container. <NL> [  141.466889] layer1_control_layer[2060]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  141.466972] layer1_control_layer[2060]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  141.467092] layer1_control_layer[2060]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  141.467178] layer1_control_layer[2060]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  141.467252] layer1_control_layer[2060]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  141.467372] layer1_control_layer[2060]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  141.467444] layer1_control_layer[2060]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  141.467529] layer1_control_layer[2060]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  141.497258] layer1_control_layer[2060]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  141.601815] layer1_control_layer[2060]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  141.601952] layer1_control_layer[2060]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  141.602052] layer1_control_layer[2060]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  141.602128] layer1_control_layer[2060]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  141.602201] layer1_control_layer[2060]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  141.602273] layer1_control_layer[2060]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  141.602343] layer1_control_layer[2060]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  141.602431] layer1_control_layer[2060]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  142.237677] python3[2183]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  142.239112] python3[2183]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  142.240889] python3[2183]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  142.241769] python3[2183]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  142.242644] python3[2183]: max_slotNumber=5 <NL> [  153.189107] python3[2404]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  153.189502] python3[2404]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  153.189779] python3[2404]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  153.193781] python3[2404]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  153.193972] python3[2404]: max_slotNumber=5 <NL> [  153.194099] python3[2404]:  prov channel is 127.0.0.1:10000 <NL> [  153.197601] python3[2404]: success: command executed <NL> [  153.404574] layer1_hal[2088]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  153.462062] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2365 <NL> 2024-07-31 08:15:30,434 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=2 <NL> 2024-07-31 08:15:45,596 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:15:45,597 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:45,693 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:45,696 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:45,698 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":2} <NL> 2024-07-31 08:15:45,704 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:45,745 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:15:45,728 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:15:45,761 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:15:45,763 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:45,769 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:45,781 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:45,783 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:15:45,834 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:15:45,864 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":2}"}
{"timestamp_utc": "2024-07-31T08:15:49.142Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:48 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:48 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:51.030Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "2024-07-31 08:15:43,138 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:15:43,115 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  167.521585] fujitsu-check-ssh-host-key.pl[2272]: 3004 <NL> 2024-07-31 08:15:43,134 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> 2024-07-31 08:15:43,329 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:15:43,206 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> 2024-07-31 08:15:43,240 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:43,384 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:43,421 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  167.925760] fujitsu-check-ssh-host-key.pl[2272]: /bin/bash <NL> [  167.982298] fujitsu-check-ssh-host-key.pl[2272]: /home/system exists <NL> [  167.989844] fujitsu-check-ssh-host-key.pl[2272]: Checking for trib... <NL> [  167.991024] fujitsu-check-ssh-host-key.pl[2272]: Checking for PIU ... <NL> 2024-07-31 08:15:43,425 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:43,549 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:43,584 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:43,651 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:43,639 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: RESET -> READY_STATE -> reset_fn -> WAIT_STATE <NL> [  168.187377] fujitsu-check-ssh-host-key.pl[2272]: slot number (0) is not a PIU. <NL> [  168.231810] fujitsu-check-ssh-host-key.pl[2272]: Trib check done. <NL> 2024-07-31 08:15:43,645 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount  --script  --base /mnt/secondary/var/shared --algorithm longest-match L1-OTSG2.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  168.700367] startup[2306]: Startup, World! <NL> [  168.700669] startup[2306]: Cmd arg set to loop 1 <NL> [  168.923997] ntp_oper_data.py[1857]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  168.924294] ntp_oper_data.py[1857]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  168.969180] ntp_oper_data.py[1857]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  168.982849] ntp_oper_data.py[1857]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> 2024-07-31 08:15:44,757 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:44,758 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:44,759 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:44,759 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:44,807 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:44,808 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:44,808 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo:"}
{"timestamp_utc": "2024-07-31T08:15:51.031Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "2024-07-31 08:15:44,845 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:44,846 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:44,847 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:45,172 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:45,250 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:45,326 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:45,387 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:45,403 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  170.012126] ntp_oper_data.py[1857]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  170.033802] ntp_oper_data.py[1857]: INFO:root:redundancy status now set to standalone <NL> 2024-07-31 08:15:45,520 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:45,466 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  170.046897] ntp_oper_data.py[1857]: INFO:root:Received redundancy topic <NL> 2024-07-31 08:15:45,565 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  170.102552] ntp_oper_data.py[1857]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:15:45,596 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  171.087874] ains_manager[2303]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  171.712938] startup_finished.py[2302]: *****Startup Finished Monitor:Starting the event loop***** <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> ERROR:root:empty repository <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> 2024-07-31 08:15:49,993 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:49,995 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:49,996 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:49,996 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:50,025 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:50,026 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> # 03:15:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:51.593Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[   66.319362] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   65.990289] commsdriver[552]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   66.045275] commsdriver[552]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   67.028462] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   67.100897] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   67.161333] device eth6.3802 entered promiscuous mode <NL> [   67.296697] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   67.347654] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   67.386341] device lwap-peer entered promiscuous mode <NL> [   67.506097] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   67.530932] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   67.235382] commsdriver[552]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   67.294043] commsdriver[552]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   67.923137] commsdriver[552]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   68.000522] commsdriver[868]: Actual changes: <NL> [   68.001274] commsdriver[868]: tx-checksum-ip-generic: off <NL> [   68.001962] commsdriver[868]: tx-tcp-segmentation: off [not requested] <NL> [   68.015660] commsdriver[868]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   68.017645] commsdriver[868]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   68.019629] commsdriver[868]: tx-tcp6-segmentation: off [not requested] <NL> [   68.538644] commsdriver[552]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   68.620632] commsdriver[880]: Actual changes: <NL> [   68.664382] commsdriver[880]: tx-checksum-ip-generic: off <NL> [   68.732588] commsdriver[880]: tx-tcp-segmentation: off [not requested] <NL> [   68.927605] commsdriver[880]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   69.227458] commsdriver[880]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   69.318719] commsdriver[880]: tx-tcp6-segmentation: off [not requested] <NL> [   69.336709] commsready[883]: callback: Entry PID=0x373 signo(15) <NL> [   69.404853] commsready[883]: DipLog_pimpl destructor called <NL> [   69.470994] commsready[883]: DipVerbosity Listener ZMQ error <NL> [   69.471765] commsready[883]:     ret='Context was terminated <NL> [   69.472473] commsready[883]: deleting subscriber_ socket <NL> [   69.473121] commsready[883]: Exiting verb listener <NL> [   69.513725] change_esal_priority.sh[889]: Comms check for and selectively change esal priorities <NL> [   70.594280] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   70.620831] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   70.826212] change_esal_priority.sh[889]: Comms did not change any esal thread priorities <NL> [   79.047272] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   79.328040] NFSD: Using legacy client tracking operations. <NL> [   79.625873] NFSD: starting 90-second grace period (net f0000098) <NL> [   79.455918] serialportMon[1191]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   92.364827] vsftpd_listen_address[1194]: listen_address=127.1.254.254 <NL> 2024-07-31 08:14:32,772 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:36,056 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:36,058 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:36,099 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> 2024-07-31 08:14:36,246 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:36,259 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:36,268 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  125.196941] dcn_ka[1376]:  WaitForActive <NL> [  133.981454] dcn_dns_controller[1373]:  WaitForActive <NL> 2024-07-31 08:15:24,524 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 48 seconds <NL> 2024-07-31 08:15:24,772 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 48 seconds <NL> [  149.128868] standby_filesync[1389]: DipLog_pimpl destructor called <NL> 2024-07-31 08:15:27,688 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:28,980 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  152.661432] standby_filesync[1389]: DipVerbosity Listener ZMQ error <NL> [  154.389660] standby_filesync[1389]:     ret='Context was terminated <NL> 2024-07-31 08:15:31,174 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  154.421371] standby_filesync[1389]: deleting subscriber_ socket <NL> 2024-07-31 08:15:31,434 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  156.349494] standby_filesync[1389]: Exiting verb listener <NL> 2024-07-31 08:15:33,645 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> [  159.392685] ops-redundancy-mgr[1384]: DipLog_pimpl destructor called <NL> 2024-07-31 08:15:36,895 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:37,108 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> [  160.417511] ops-redundancy-mgr[1384]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:39,269 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  162.595452] ops-redundancy-mgr[1384]:     ret='Context was terminated <NL> 2024-07-31 08:15:39,999 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:40,822 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> [  164.476277] ops-redundancy-mgr[1384]: deleting subscriber_ socket <NL> 2024-07-31 08:15:42,014 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn <NL> 2024-07-31 08:15:42,411 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn <NL> [  166.401445] ops-redundancy-mgr[1384]: Exiting verb listener <NL> [  168.510536] ntputils[1733]: int ntputils_main(int, char**)Starting ntputils <NL> [  169.462337] ntputils[1733]: Running as a daemon <NL> [  170.050238] ntputils[1733]: shelf role is: MAIN <NL> [  170.457834] ntputils[1733]: slot number is: 0 <NL> [  170.481475] ntputils[1733]: slot role is: UNKNOWN <NL> [  170.736709] ntputils[1733]: redundancy_mode: UNKNOWN <NL> [  171.029959] ntputils[1733]: Executing on a work blade <NL> 2024-07-31 08:15:48,091 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:48,106 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0"}
{"timestamp_utc": "2024-07-31T08:15:53.501Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  158.243055] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 2 <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> [  159.210864] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  159.211090] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:15:35,246 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:15:35,525 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:15:35,851 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:35,851 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:35,851 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:36,054 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:15:36,056 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:15:36,244 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> [  161.709509] sncp_app[2387]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  161.991724] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 3 <NL> 2024-07-31 08:15:36,880 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700"}
{"timestamp_utc": "2024-07-31T08:15:53.502Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "2024-07-31 08:15:36,882 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  162.946249] ypg_app[2388]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:15:37,654 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:37,902 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:37,902 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:38,365 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:38,366 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:38,367 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:38,601 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> [  164.235091] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  164.346860] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  164.347743] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 4 <NL> 2024-07-31 08:15:38,997 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:15:38,998 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:38,998 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:38,998 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:38,998 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:38,999 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:39,143 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:39,229 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:39,229 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> [  167.279190] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 5 <NL> [  169.198829] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  169.199649] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  170.322444] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 6 <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  173.299484] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 7 <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  174.619231] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  174.619495] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  176.169233] common_alarm_handler[2383]: gen_util: DDS_P2MP not available <NL> [  176.375241] txid_tracker[2440]: ::::create_confd_subscription_connection() try number 8 <NL> [  176.624467] common_alarm_handler[2383]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  176.852627] common_alarm_handler[2383]: topic = SystemProv; id = 1 <NL> [  176.852827] common_alarm_handler[2383]: topic = WdmcfgProv; id = 2 <NL> [  176.853232] common_alarm_handler[2383]: topic = LicenseStatusTopic; id = 3 <NL> [  176.853471] common_alarm_handler[2383]: topic = ShelfProv; id = 5 <NL> [  176.853772] common_alarm_handler[2383]: topic = SlotProv; id = 6 <NL> [  177.052875] common_alarm_handler[2383]: topic = PortProv; id = 7 <NL> [  177.052968] common_alarm_handler[2383]: topic = SubportProv; id = 8 <NL> [  177.196097] common_alarm_handler[2383]: topic = FconProv; id = 9 <NL> [  177.196272] common_alarm_handler[2383]: topic = XconProv; id = 10 <NL> [  177.196356] common_alarm_handler[2383]: topic = OchProv; id = 11 <NL> [  177.196435] common_alarm_handler[2383]: topic = OmsProv; id = 12 <NL> [  177.196506] common_alarm_handler[2383]: topic = OtsProv; id = 13 <NL> [  177.196655] common_alarm_handler[2383]: topic = EthernetProv; id = 14 <NL> [  177.196746] common_alarm_handler[2383]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  177.196826] common_alarm_handler[2383]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  177.196907] common_alarm_handler[2383]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  177.197031] common_alarm_handler[2383]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  177.197113] common_alarm_handler[2383]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  177.305697] common_alarm_handler[2383]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  177.305886] common_alarm_handler[2383]: topic = router_bgp_dds_bgp_global_prov; id = 22"}
{"timestamp_utc": "2024-07-31T08:15:53.758Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:53 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:54.014Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:15:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:53 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:55.902Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  177.305974] common_alarm_handler[2383]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  177.306094] common_alarm_handler[2383]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  177.306169] common_alarm_handler[2383]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  177.306241] common_alarm_handler[2383]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  177.306343] common_alarm_handler[2383]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  177.306421] common_alarm_handler[2383]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  177.306500] common_alarm_handler[2383]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  177.306572] common_alarm_handler[2383]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  177.306673] common_alarm_handler[2383]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  177.306750] common_alarm_handler[2383]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> [  177.306819] common_alarm_handler[2383]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  177.306896] common_alarm_handler[2383]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  177.307022] common_alarm_handler[2383]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  177.307099] common_alarm_handler[2383]: topic = AlarmNotification; id = 40 <NL> [  177.307172] common_alarm_handler[2383]: topic = GenericOperInfoReq; id = 41 <NL> [  177.307243] common_alarm_handler[2383]: topic = PmRtrvReq; id = 42 <NL> [  177.307315] common_alarm_handler[2383]: topic = PmRtrvResp; id = 43 <NL> [  177.307393] common_alarm_handler[2383]: topic = PmInitReq; id = 44 <NL> [  177.307523] common_alarm_handler[2383]: topic = PmOperData; id = 45 <NL> [  177.307599] common_alarm_handler[2383]: topic = StateChange; id = 46 <NL> [  177.307689] common_alarm_handler[2383]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  177.307766] common_alarm_handler[2383]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  177.307846] common_alarm_handler[2383]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> [  177.307920] common_alarm_handler[2383]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  177.411558] common_alarm_handler[2383]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  177.934803] common_alarm_handler[2383]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  177.934906] common_alarm_handler[2383]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  177.935027] common_alarm_handler[2383]: topic = EthIfProv; id = 56 <NL> [  177.935103] common_alarm_handler[2383]: topic = DcnNat64Attributes; id = 57 <NL> [  177.935178] common_alarm_handler[2383]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  178.031986] python3[2524]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  178.070381] python3[2524]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  178.228793] python3[2524]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  178.228936] python3[2524]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  178.229036] python3[2524]: max_slotNumber=5 <NL> [  178.229923] common_alarm_handler[2383]: topic = LldpGlobalCfgProv; id = 59 <NL> [  178.230068] common_alarm_handler[2383]: topic = LldpPortCfgProv; id = 60 <NL> [  178.230149] common_alarm_handler[2383]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  178.230224] common_alarm_handler[2383]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  178.230298] common_alarm_handler[2383]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  178.230379] common_alarm_handler[2383]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  178.230471] common_alarm_handler[2383]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  178.230554] common_alarm_handler[2383]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  178.230630] common_alarm_handler[2383]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  178.230706] common_alarm_handler[2383]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  178.230781] common_alarm_handler[2383]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  178.230855] common_alarm_handler[2383]: topic = DcnPppAttributesProv; id = 70 <NL> [  178.230928] common_alarm_handler[2383]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  178.256098] common_alarm_handler[2383]: topic = LldpBladeCfgProv; id = 72 <NL> [  178.326355] common_alarm_handler[2383]: topic = LldpPortInstCfgProv; id = 73 <NL> [  178.326457] common_alarm_handler[2383]: topic = DcnGreTunnelProv; id = 74 <NL> [  178.326535] common_alarm_handler[2383]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  178.326655] common_alarm_handler[2383]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  178.326737] common_alarm_handler[2383]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  178.326826] common_alarm_handler[2383]: topic = SysGnmiCertProv; id = 78 <NL> [  178.421564] common_alarm_handler[2383]: topic = IetfInterfaceProv; id = 79 <NL> [  178.482919] common_alarm_handler[2383]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  178.502757] common_alarm_handler[2383]: topic = SystemAutoLogoffProv; id = 81 <NL> [  178.516335] common_alarm_handler[2383]: topic = SystemSshClientKeepaliveProv; id = 82"}
{"timestamp_utc": "2024-07-31T08:15:55.903Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  178.519847] common_alarm_handler[2383]: topic = SystemPortsProv; id = 83 <NL> [  178.520752] common_alarm_handler[2383]: topic = OspfProvisioningModeProv; id = 84 <NL> [  178.521645] common_alarm_handler[2383]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  178.522629] common_alarm_handler[2383]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  178.605917] common_alarm_handler[2383]: topic = BasicGroupProv; id = 87 <NL> [  178.906701] common_alarm_handler[2383]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  178.917083] common_alarm_handler[2383]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  178.917195] common_alarm_handler[2383]: topic = SystemFipsProv; id = 90 <NL> [  178.917284] common_alarm_handler[2383]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  178.917373] common_alarm_handler[2383]: topic = SecuritySystemwideProv; id = 92 <NL> [  178.942155] common_alarm_handler[2383]: topic = DataEncryptionProv; id = 93 <NL> [  178.942427] common_alarm_handler[2383]: topic = SystemServicesProv; id = 94 <NL> [  178.942525] common_alarm_handler[2383]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  178.942610] common_alarm_handler[2383]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  178.942715] common_alarm_handler[2383]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  178.942788] common_alarm_handler[2383]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  178.942855] common_alarm_handler[2383]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  178.942922] common_alarm_handler[2383]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  178.942997] common_alarm_handler[2383]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  178.943081] common_alarm_handler[2383]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  178.943150] common_alarm_handler[2383]: topic = FscProv; id = 111 <NL> [  178.943219] common_alarm_handler[2383]: topic = XconProv_v2Prov; id = 112 <NL> [  178.943286] common_alarm_handler[2383]: topic = OchIfProv; id = 113 <NL> [  178.943366] common_alarm_handler[2383]: topic = AclProfileProv; id = 114 <NL> [  178.943443] common_alarm_handler[2383]: topic = OtuProv; id = 115 <NL> [  178.943509] common_alarm_handler[2383]: topic = GeProv; id = 116 <NL> [  178.943575] common_alarm_handler[2383]: topic = OduProv; id = 117 <NL> [  178.945614] python3[2413]: [.244] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  178.945769] python3[2413]: [.253] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  178.945875] python3[2413]: [.404] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  178.945955] python3[2413]: [.405] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  178.946079] python3[2413]: [.405] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  178.946167] python3[2413]: [.405] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'}"}
{"timestamp_utc": "2024-07-31T08:15:56.464Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:15:56 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:57.390Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  178.946271] python3[2413]: [.405] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  178.946346] python3[2413]: [.405] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  178.946433] python3[2413]: [.415] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  178.946509] python3[2413]: [.415] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  178.946581] python3[2413]: [.441] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  178.946655] python3[2413]: [.441] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  178.946742] python3[2413]: [.501] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  178.946819] python3[2413]: [.501] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  178.946944] python3[2413]: [.501] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'}"}
{"timestamp_utc": "2024-07-31T08:15:57.391Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  178.947063] python3[2413]: [.523] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  178.947143] python3[2413]: [.523] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  178.947221] python3[2413]: [.523] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  178.947318] python3[2413]: [.523] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  178.947391] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  178.947549] common_alarm_handler[2383]: topic = TcmProv; id = 118 <NL> [  178.947637] common_alarm_handler[2383]: topic = OCnProv; id = 119 <NL> [  179.120444] common_alarm_handler[2383]: topic = OnDemandDM; id = 120 <NL> [  179.120556] common_alarm_handler[2383]: topic = OducnProv; id = 121 <NL> [  179.120643] common_alarm_handler[2383]: topic = OtsiProv; id = 122 <NL> [  179.120718] common_alarm_handler[2383]: topic = OtsigProv; id = 123 <NL> [  179.120791] common_alarm_handler[2383]: topic = OtucnProv; id = 124 <NL> [  179.120886] common_alarm_handler[2383]: topic = YpgProv; id = 125 <NL> [  179.121156] common_alarm_handler[2383]: topic = EpgProv; id = 126 <NL> [  179.121323] common_alarm_handler[2383]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  179.121403] common_alarm_handler[2383]: topic = DataEncryptionOperReq; id = 128 <NL> [  179.121484] common_alarm_handler[2383]: topic = RoutePolicyTableProv; id = 129 <NL> [  179.121562] common_alarm_handler[2383]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  179.121638] common_alarm_handler[2383]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  179.121713] common_alarm_handler[2383]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  179.121874] common_alarm_handler[2383]: topic = ShapingProfileProv; id = 133 <NL> [  179.121965] common_alarm_handler[2383]: topic = TaildropProfileProv; id = 134 <NL> [  179.122068] common_alarm_handler[2383]: topic = PolicingProfileProv; id = 135 <NL> [  179.122151] common_alarm_handler[2383]: topic = CapabilityProfileProv; id = 136 <NL> [  179.122230] common_alarm_handler[2383]: topic = TransportInterfaceRateProv; id = 137 <NL> [  179.122327] common_alarm_handler[2383]: topic = PmRtrvReqSess; id = 138 <NL> [  179.122404] common_alarm_handler[2383]: topic = PmRtrvRespSess; id = 139 <NL> [  179.122482] common_alarm_handler[2383]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  179.122558] common_alarm_handler[2383]: topic = DataEncryptionPskReq; id = 141 <NL> [  179.122651] common_alarm_handler[2383]: topic = SystemWebserverProv; id = 142 <NL> [  179.122725] common_alarm_handler[2383]: NO match: <NL> [  179.122799] common_alarm_handler[2383]: NO match: <NL> [  179.122870] common_alarm_handler[2383]: NO match: <NL> [  179.462423] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  179.759480] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  179.860451] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  179.860594] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  179.860689] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  179.860785] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  179.860867] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  179.860946] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  179.861070] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  179.861155] python3[2413]: [.524] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  179.861256] python3[2413]: [.614] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  179.861333] python3[2413]: [.614] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  179.861409] python3[2413]: [.614] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  179.861489] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  179.861567] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  179.861663] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  179.861760] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  179.861843] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  179.861918] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> Exception: Connect failed <NL> [  179.929240] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  180.523635] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  180.525649] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  180.525831] python3[2413]: [.635] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  180.525913] python3[2413]: [.646] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  180.644245] python3[2413]: [.646] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  180.690671] python3[2413]: [.646] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  180.719265] python3[2413]: [.646] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  180.747019] python3[2413]: [.647] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  180.774654] python3[2413]: [.647] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  180.780336] python3[2413]: [.647] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'}"}
{"timestamp_utc": "2024-07-31T08:15:58.757Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:59.013Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:15:58 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:58 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:00.421Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "2024-07-31 08:15:44,986 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:45,231 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  172.111507] ntputils[1882]: remove_all_ext_src <NL> 2024-07-31 08:15:45,950 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  172.723168] ntputils[1882]: delete: <NL> [  172.748926] ntp_oper_data.py[1714]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> 2024-07-31 08:15:45,989 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  172.909625] ntp_oper_data.py[1714]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  172.910756] ntp_oper_data.py[1714]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  172.912280] ntp_oper_data.py[1714]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  173.101581] ntp_oper_data.py[1714]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  173.142733] ntp_oper_data.py[1714]: INFO:root:redundancy status now set to standalone <NL> [  173.143834] ntp_oper_data.py[1714]: INFO:root:Received redundancy topic <NL> 2024-07-31 08:15:46,420 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:46,435 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> [  173.248644] ntp_oper_data.py[1714]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:15:46,739 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:15:46,900 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:47,036 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:47,269 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:47,340 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\""}
{"timestamp_utc": "2024-07-31T08:16:00.422Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  174.143334] ntputils[1710]: exited, status is 0 <NL> 2024-07-31 08:15:47,573 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:47,723 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  174.576830] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:48,366 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:48,863 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> [  175.979826] ntputils[1710]: /bin/systemctl reset-failed ntpd <NL> 2024-07-31 08:15:49,481 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:49,774 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> [  176.881310] ntputils[1710]: child pid is 1906 <NL> [  177.286710] ntputils[1710]: exited, status is 0 <NL> 2024-07-31 08:15:50,726 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> [  177.620095] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:51,072 swdllite(mgr): INFO - swdl_state_confdmgr.confdmgr_notify_wait_fn[81] mgr_confdmgr_state: confdmgr notification suppressed, OrderedDict([('mode', 'NORMAL'), ('status', 'SUCCESS'), ('rdm-status', 'STANDALONE')]) <NL> [  177.889322] ntputils[1710]: systemctl --no-block start ntpd <NL> 2024-07-31 08:15:51,469 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  178.316547] ntputils[1710]: child pid is 1910 <NL> 2024-07-31 08:15:51,853 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  178.668651] ntputils[1710]: exited, status is 0 <NL> 2024-07-31 08:15:52,122 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> [  178.966338] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:52,642 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> [  179.452987] ntputils[1710]: /bin/systemctl reset-failed init_state_check.timer <NL> 2024-07-31 08:15:52,946 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  179.986667] ntputils[1710]: child pid is 1916 <NL> [  181.343437] ntputils[1710]: exited, status is 0 <NL> 2024-07-31 08:15:54,158 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  181.611780] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:55,183 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  182.186620] ntputils[1710]: /bin/systemctl --no-block start init_state_check.timer <NL> [  182.584058] ntputils[1710]: child pid is 1923 <NL> [  182.584692] ntputils[1710]: exited, status is 0 <NL> [  182.585339] ntputils[1710]: server.InitDaemon <NL> 2024-07-31 08:15:55,890 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  182.979773] ntputils[1710]: int NTPServer::platformdds_listen() <NL> 2024-07-31 08:15:56,936 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:57,032 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> [  183.819427] ntputils[1710]: void NTPServer::poller() <NL> 2024-07-31 08:15:57,272 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> [  184.153544] ntputils[1710]: void NTPServer::late_joiner() <NL> 2024-07-31 08:15:57,837 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  184.857156] ntputils[1710]: bool NTPServer::handle_command(const string&) <NL> [  184.866406] ntputils[1710]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:15:58,101 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  184.914182] ntputils[1710]: got Platform::RedundancyMode: UNKNOWN <NL> 2024-07-31 08:15:58,312 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  185.166320] ntputils[1710]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:15:58,705 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> [  185.606925] ntputils[1710]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:15:58,711 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  185.767921] ntputils[1710]: new red mode is: UNKNOWN <NL> 2024-07-31 08:15:58,947 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> [  186.063221] ntputils[1710]: my current red status is: active <NL> 2024-07-31 08:15:59,143 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  186.330427] ntputils[1710]: new red status is: STANDALONE <NL> 2024-07-31 08:15:59,479 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM"}
{"timestamp_utc": "2024-07-31T08:16:01.350Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:16:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:03.867Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:03 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:04.123Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:16:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:03 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:06.019Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:16:05 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:09.289Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:08 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:08 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:09.546Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "2024-07-31 08:15:50,047 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:15:50,047 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  176.955635] dhal_sim_startup.sh[2409]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  178.018995] confd_mgr_action_server[2403]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  179.388388] confd_phase_sentry[2445]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  179.388644] confd_phase_sentry[2445]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  179.388791] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  179.405520] temp_acct_cleanup_app[2455]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  179.440353] temp_acct_cleanup_app[2455]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  181.292921] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  180.592249] sncp_app[2398]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  181.638224] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  180.947699] ains_manager[2511]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  182.005960] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 1 <NL> 2024-07-31 08:15:59,365 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> [  184.061594] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  184.061763] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:15:59,505 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:15:59,932 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:15:59,933 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:59,938 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:59,942 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:16:00,389 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  185.019756] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 2 <NL> 2024-07-31 08:16:00,464 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:16:00,658 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:16:00,804 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:16:09.547Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "2024-07-31 08:16:00,907 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:16:00,908 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:00,957 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:16:01,333 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> [  185.617652] ypg_app[2399]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:16:01,347 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:16:01,755 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:16:01,816 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> 2024-07-31 08:16:02,502 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:16:02,503 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:16:02,562 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:16:02,563 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:16:02,563 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:16:02,564 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:16:02,565 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:16:02,957 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  188.118933] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 3 <NL> 2024-07-31 08:16:03,673 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> [  188.830611] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  188.831649] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  191.063822] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 4 <NL> [  191.895671] common_alarm_handler[2395]: gen_util: DDS_P2MP not available <NL> [  192.574803] common_alarm_handler[2395]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  192.692278] common_alarm_handler[2395]: topic = SystemProv; id = 1 <NL> [  192.862894] common_alarm_handler[2395]: topic = WdmcfgProv; id = 2 <NL> [  192.863024] common_alarm_handler[2395]: topic = LicenseStatusTopic; id = 3 <NL> [  192.863125] common_alarm_handler[2395]: topic = ShelfProv; id = 5 <NL> [  192.863247] common_alarm_handler[2395]: topic = SlotProv; id = 6 <NL> [  192.863336] common_alarm_handler[2395]: topic = PortProv; id = 7 <NL> [  192.863418] common_alarm_handler[2395]: topic = SubportProv; id = 8 <NL> [  192.863504] common_alarm_handler[2395]: topic = FconProv; id = 9 <NL> [  193.079287] common_alarm_handler[2395]: topic = XconProv; id = 10 <NL> [  193.080157] common_alarm_handler[2395]: topic = OchProv; id = 11 <NL> [  193.080916] common_alarm_handler[2395]: topic = OmsProv; id = 12"}
{"timestamp_utc": "2024-07-31T08:16:10.910Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:16:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:12.274Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  193.163818] common_alarm_handler[2395]: topic = OtsProv; id = 13 <NL> [  193.164756] common_alarm_handler[2395]: topic = EthernetProv; id = 14 <NL> [  193.165579] common_alarm_handler[2395]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  193.208784] common_alarm_handler[2395]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  193.231038] common_alarm_handler[2395]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  193.235924] common_alarm_handler[2395]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  193.252910] common_alarm_handler[2395]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  193.320384] common_alarm_handler[2395]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  193.595370] common_alarm_handler[2395]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  193.621994] common_alarm_handler[2395]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  193.622991] common_alarm_handler[2395]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  193.623970] common_alarm_handler[2395]: topic = router_bgp_dds_bgp_peer_prov; id = 25"}
{"timestamp_utc": "2024-07-31T08:16:12.275Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  193.825768] common_alarm_handler[2395]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  193.966711] common_alarm_handler[2395]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  193.966822] common_alarm_handler[2395]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  193.966899] common_alarm_handler[2395]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  193.966986] common_alarm_handler[2395]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  193.967079] common_alarm_handler[2395]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  193.967154] common_alarm_handler[2395]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> [  193.967227] common_alarm_handler[2395]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  193.967319] common_alarm_handler[2395]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  193.967394] common_alarm_handler[2395]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  193.967466] common_alarm_handler[2395]: topic = AlarmNotification; id = 40 <NL> [  193.967546] common_alarm_handler[2395]: topic = GenericOperInfoReq; id = 41 <NL> [  193.967629] common_alarm_handler[2395]: topic = PmRtrvReq; id = 42 <NL> [  193.967702] common_alarm_handler[2395]: topic = PmRtrvResp; id = 43 <NL> [  193.967777] common_alarm_handler[2395]: topic = PmInitReq; id = 44 <NL> [  193.967907] common_alarm_handler[2395]: topic = PmOperData; id = 45 <NL> [  193.967982] common_alarm_handler[2395]: topic = StateChange; id = 46 <NL> [  193.968096] common_alarm_handler[2395]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  193.968173] common_alarm_handler[2395]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  193.968248] common_alarm_handler[2395]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> [  193.968338] common_alarm_handler[2395]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  193.968423] common_alarm_handler[2395]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  193.968501] common_alarm_handler[2395]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  193.968585] common_alarm_handler[2395]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  193.968679] common_alarm_handler[2395]: topic = EthIfProv; id = 56 <NL> [  193.968768] common_alarm_handler[2395]: topic = DcnNat64Attributes; id = 57 <NL> [  193.968841] common_alarm_handler[2395]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  194.087929] common_alarm_handler[2395]: topic = LldpGlobalCfgProv; id = 59 <NL> [  194.258867] common_alarm_handler[2395]: topic = LldpPortCfgProv; id = 60 <NL> [  194.258991] common_alarm_handler[2395]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  194.259101] common_alarm_handler[2395]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  194.259177] common_alarm_handler[2395]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  194.259269] common_alarm_handler[2395]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  194.259362] common_alarm_handler[2395]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  194.259437] common_alarm_handler[2395]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  194.259528] common_alarm_handler[2395]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  194.259604] common_alarm_handler[2395]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  194.259684] common_alarm_handler[2395]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  194.259759] common_alarm_handler[2395]: topic = DcnPppAttributesProv; id = 70 <NL> [  194.259834] common_alarm_handler[2395]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  194.259927] common_alarm_handler[2395]: topic = LldpBladeCfgProv; id = 72 <NL> [  194.260015] common_alarm_handler[2395]: topic = LldpPortInstCfgProv; id = 73 <NL> [  194.260100] common_alarm_handler[2395]: topic = DcnGreTunnelProv; id = 74 <NL> [  194.260173] common_alarm_handler[2395]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  194.260246] common_alarm_handler[2395]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  194.260330] common_alarm_handler[2395]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  194.260465] common_alarm_handler[2395]: topic = SysGnmiCertProv; id = 78 <NL> [  194.260542] common_alarm_handler[2395]: topic = IetfInterfaceProv; id = 79 <NL> [  194.260659] common_alarm_handler[2395]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  194.260740] common_alarm_handler[2395]: topic = SystemAutoLogoffProv; id = 81 <NL> [  194.260824] common_alarm_handler[2395]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  194.260916] common_alarm_handler[2395]: topic = SystemPortsProv; id = 83 <NL> [  194.328072] common_alarm_handler[2395]: topic = OspfProvisioningModeProv; id = 84 <NL> [  194.695385] common_alarm_handler[2395]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  194.695516] common_alarm_handler[2395]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  194.695615] common_alarm_handler[2395]: topic = BasicGroupProv; id = 87 <NL> [  194.695716] common_alarm_handler[2395]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  194.695805] common_alarm_handler[2395]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  194.695880] common_alarm_handler[2395]: topic = SystemFipsProv; id = 90 <NL> [  194.695968] common_alarm_handler[2395]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  194.696073] common_alarm_handler[2395]: topic = SecuritySystemwideProv; id = 92 <NL> [  194.696153] common_alarm_handler[2395]: topic = DataEncryptionProv; id = 93 <NL> [  194.696233] common_alarm_handler[2395]: topic = SystemServicesProv; id = 94 <NL> [  194.696364] common_alarm_handler[2395]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  194.696452] common_alarm_handler[2395]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  194.696533] common_alarm_handler[2395]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  194.696614] common_alarm_handler[2395]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  194.696688] common_alarm_handler[2395]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  194.696771] common_alarm_handler[2395]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  194.696855] common_alarm_handler[2395]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  194.696934] common_alarm_handler[2395]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  194.697021] common_alarm_handler[2395]: topic = FscProv; id = 111 <NL> [  194.697112] common_alarm_handler[2395]: topic = XconProv_v2Prov; id = 112 <NL> [  194.697192] common_alarm_handler[2395]: topic = OchIfProv; id = 113 <NL> [  194.697278] common_alarm_handler[2395]: topic = AclProfileProv; id = 114 <NL> [  194.717686] common_alarm_handler[2395]: topic = OtuProv; id = 115 <NL> [  195.245249] common_alarm_handler[2395]: topic = GeProv; id = 116 <NL> [  195.359841] common_alarm_handler[2395]: topic = OduProv; id = 117 <NL> [  195.360791] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  195.360950] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  195.509839] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 5 <NL> Exception: Connect failed"}
{"timestamp_utc": "2024-07-31T08:16:13.202Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  171.824745] ntputils[1733]: ================================ <NL> 2024-07-31 08:15:50,438 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:50,492 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  173.773396] ntputils[1733]: shelf_role is: MAIN <NL> 2024-07-31 08:15:51,127 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  175.363510] ntputils[1733]: redundancy_mode: UNKNOWN <NL> [  176.198174] ntputils[1733]: active_status: active <NL> 2024-07-31 08:15:52,759 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:52,760 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> [  176.877589] ntputils[1733]: ntp_role: act <NL> [  177.970125] ntputils[1733]: ================================ <NL> 2024-07-31 08:15:54,282 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:15:55,007 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  178.083313] ntputils[1733]: NTPUtilsConfig::do_default_config <NL> [  178.326969] ntputils[1733]: shelf_num/is_client: 0 <NL> [  178.327705] ntputils[1733]: server_ip: 0x55a6aa1acfc0 <NL> [  178.387267] ntputils[1733]: ip_addr(ilan): 0x55a6aa1acf80 <NL> 2024-07-31 08:15:55,399 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:54,363 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> [  178.434223] ntputils[1733]: ntp_role act <NL> 2024-07-31 08:15:55,942 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  179.099453] ntputils[1733]: shelf_num aka is_client == 0 <NL> [  179.173446] ntputils[1733]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:55,901 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  179.265833] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  180.020599] ntputils[1733]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:56,445 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  180.063427] ntputils[1733]: child pid is 1805 <NL> [  180.065456] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:15:56,113 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> [  180.123677] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:57,283 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:57,094 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  180.603437] ntputils[1733]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:57,988 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:58,253 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  181.477958] ntputils[1733]: child pid is 1825 <NL> 2024-07-31 08:15:59,004 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  182.709928] rdm[1738]: RdmConfig: file_exist 0 <NL> 2024-07-31 08:15:59,781 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  183.009567] rdm[1738]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> 2024-07-31 08:16:00,711 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> [  183.960044] rdm[1738]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  184.021164] rdm[1738]: start rdm msg hdlr thd <NL> 2024-07-31 08:16:00,933 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  184.465353] ntputils[1848]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:16:01,997 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:02,436 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  185.499725] ntputils[1733]: exited, status is 0 <NL> [  186.043130] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  186.306923] ntputils[1733]: /bin/systemctl reset-failed ntpd <NL> [  186.460740] ntputils[1733]: child pid is 1870 <NL> [  186.769964] ntputils[1733]: exited, status is 0 <NL> [  186.804502] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  186.877298] ntputils[1733]: systemctl --no-block start ntpd <NL> [  186.920886] ntputils[1733]: child pid is 1871 <NL> [  186.955126] ntputils[1733]: exited, status is 0 <NL> [  187.059273] ntputils[1733]: server role, server_ip is set to: 127.0.0.1 <NL> [  187.093178] ntputils[1733]: Running in production mode <NL> [  187.093917] ntputils[1733]: InitDaemon redundancy_mode: UNKNOWN <NL> [  187.094722] ntputils[1733]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  187.198374] ntputils[1733]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  187.217953] ntputils[1733]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  187.321978] ntputils[1733]: registration socket.send OK <NL> [  187.520309] ntputils[1733]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  187.759321] ntputils[1733]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  188.681321] ntputils[1733]:  topic reg for: <NL> [  189.017905] ntputils[1733]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  189.249813] ntputils[1733]: registration socket.send OK <NL> [  189.305898] ntputils[1733]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  189.535566] ntputils[1733]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  189.737667] ntputils[1733]:  topic reg for: <NL> [  189.761996] ntputils[1733]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  189.966172] ntputils[1733]: registration socket.send OK <NL> [  190.022261] ntputils[1733]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  190.375418] ntputils[1733]: void NTPServer::check_ntp_enabled() <NL> [  190.557178] ntputils[1733]: check_ntp_enabled not empty <NL> 2024-07-31 08:16:07,760 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> [  190.896419] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:08,111 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> [  191.155562] ntputils[1733]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> 2024-07-31 08:16:08,455 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  191.471217] ntputils[1733]: child pid is 1920 <NL> 2024-07-31 08:16:10,443 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> [  193.770622] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:16:11,003 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  194.104080] ntputils[1733]: check_ntp_enabled skip system script_start <NL> 2024-07-31 08:16:11,596 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:11,628 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662"}
{"timestamp_utc": "2024-07-31T08:16:14.136Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:13 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:14 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:15.502Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  180.781600] python3[2413]: [.647] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  180.782870] python3[2413]: [.647] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  180.983319] python3[2413]: [.647] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  180.983420] python3[2413]: [.671] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  180.983500] python3[2413]: [.671] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  180.983577] python3[2413]: [.671] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  180.983653] python3[2413]: [.671] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  180.983727] python3[2413]: [.671] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  180.983801] python3[2413]: [.671] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  180.983924] python3[2413]: [.692] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  180.984030] python3[2413]: [.692] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> [  181.041362] python3[2413]: [.692] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  181.378052] python3[2413]: [.692] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  181.378168] python3[2413]: [.692] hookhdlr 140116335949632 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  181.378250] python3[2413]: [.692] hookhdlr 140116335949632 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  181.378327] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  181.378404] python3[2413]: [.697] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  182.222378] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 1 <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  184.248068] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  184.248383] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  185.165595] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 2 <NL> [  185.997145] layer1_control_layer[2418]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  188.127457] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 3 <NL> [  189.110808] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  189.112365] python3[2413]: [.715] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  189.255130] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:16:15.503Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  189.255343] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  190.449724] dcn_dns_controller[1592]: dnsClientStartup() <NL> [  190.453894] dcn_dns_controller[1592]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  190.455077] dcn_dns_controller[1592]: fin_dnsmasq_conf is open <NL> 2024-07-31 08:16:05,454 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:05,446 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:05,547 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:16:05,455 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  191.244935] dcn_ka[1594]: KaSessMgr Process Startup <NL> [  191.345943] confd_mgr[2947]: ConfdMgrConf: DB signature is NOT supported <NL> [  191.517471] confd_mgr[2947]: Read reset type failed basic_ios::clear: iostream error <NL> [  191.588471] confd_mgr[2947]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  192.016552] ntputils[1967]: bool NTPServer::handle_command(const string&) <NL> [  192.082238] ntputils[1967]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  192.402055] ntputils[1967]: got Platform::RedundancyMode: WORK <NL> [  192.402180] ntputils[1967]: got Platform::RedundancyStatus: STANDALONE <NL> [  192.402254] ntputils[1967]: my current red mode is: UNKNOWN <NL> [  192.402326] ntputils[1967]: new red mode is: WORK <NL> [  192.402417] ntputils[1967]: my current red status is: STANDALONE <NL> [  192.402494] ntputils[1967]: new red status is: STANDALONE <NL> [  192.865205] ntputils[1967]: red mode change, update: UNKNOWN => WORK <NL> [  192.865410] ntputils[1967]: no active/not-active status change: 0 <NL> [  192.868728] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 4 <NL> [  193.329271] ntp_oper_data.py[1968]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  193.462457] ntp_oper_data.py[1968]: INFO:root:redundancy status now set to standalone <NL> [  193.462580] ntp_oper_data.py[1968]: INFO:root:Received redundancy topic <NL> [  193.463730] ntp_oper_data.py[1968]: INFO:root:Redundancy status is standalone <NL> [  193.834233] startup_finished.py[2292]: Startup Finished: systemd state is non-Production mode and running <NL> [  193.843722] startup_finished.py[2292]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  193.905919] startup_finished.py[2292]: *****Startup Finished: stopping EOW timer***** <NL> [  194.058281] confd_mgr[2947]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  194.058431] confd_mgr[2947]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  194.270441] dcn_dns_controller[1592]: subscribe_data Enter main loop <NL> [  194.291096] confd_mgr[3015]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:16:06 UTC 2024 <NL> [  194.807809] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 5 <NL> [  194.953987] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  194.954351] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  195.035737] startup_finished.py[2292]: systemctl stop startup_finished_limit.timer <NL> [  195.187695] confd_mgr[3090]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  195.684437] confd_mgr[3015]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  195.883344] confd_mgr[3101]: /usr/bin/ui_sys_reset.py NONE <NL> [  197.215743] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 6 <NL> 2024-07-31 08:16:12,056 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0"}
{"timestamp_utc": "2024-07-31T08:16:16.452Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:16:16 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',) <NL> [  127.592772] fujitsu-check-ssh-host-key.pl[1928]: useradd: user 'fujitsu' already exists <NL> [  127.771116] fujitsu-check-ssh-host-key.pl[1919]: DDS Peristency is enabled <NL> [  127.771362] fujitsu-check-ssh-host-key.pl[1919]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  127.771452] fujitsu-check-ssh-host-key.pl[1919]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  127.771523] fujitsu-check-ssh-host-key.pl[1919]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  127.771594] fujitsu-check-ssh-host-key.pl[1919]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  127.771704] fujitsu-check-ssh-host-key.pl[1919]: Factory user shell set to /bin/bash <NL> [  127.805997] fujitsu-check-ssh-host-key.pl[1903]: Converting fujitsu user to bash shell... <NL> [  127.823458] fujitsu-check-ssh-host-key.pl[1935]: usermod: no changes <NL> [  127.823956] fujitsu-check-ssh-host-key.pl[1903]: Lock Root account in TRIB... <NL> [  127.827513] fujitsu-check-ssh-host-key.pl[1936]: Running lock on root account... <NL> [  127.861436] fujitsu-check-ssh-host-key.pl[1937]: passwd: password changed. <NL> [  127.863906] fujitsu-check-ssh-host-key.pl[1903]: Trib check done. <NL> [  128.169482] startup[1950]: Startup, World! <NL> [  128.169768] startup[1950]: Cmd arg set to loop 1 <NL> [  129.307154] ains_manager[1947]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  129.660063] startup_finished.py[1946]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  130.808872] confd_mgr_action_server[2057]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  130.893387] dhal_sim_startup.sh[2065]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  132.011881] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  132.013138] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  131.607996] sh[2095]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  131.608188] sh[2095]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  132.367081] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  132.367256] ntputils_client.py[1701]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  132.367360] ntputils_client.py[1701]: b'31 Jul 08:15:06 ntpdate[1859]: no server suitable for synchronization found\\n' <NL> [  134.204133] startup_finished.py[1946]: Startup Finished: systemd state is non-Production mode and running <NL> [  134.215376] startup_finished.py[1946]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  134.955779] zebra[2087]: 2024/07/31 08:15:09 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  135.145904] startup_finished.py[1946]: *****Startup Finished: stopping EOW timer***** <NL> [  135.662628] startup_finished.py[1946]: systemctl stop startup_finished_limit.timer <NL> [  139.380799] ains_manager[2252]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  142.063978] layer1_control_layer[2077]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  147.533690] layer1_control_layer[2077]: DIP entity prov dump <NL> [  147.791139] layer1_control_layer[2077]: EsalConfig::EsalConfig main 0 <NL> [  147.791402] layer1_control_layer[2077]: EsalConfig::EsalConfig trib 1 <NL> [  147.791547] layer1_control_layer[2077]: EsalConfig::EsalConfig ciRole 0 <NL> [  147.855344] layer1_control_layer[2077]: EsalConfig is not running inside container. <NL> [  147.855960] layer1_control_layer[2077]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.856113] layer1_control_layer[2077]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.856285] layer1_control_layer[2077]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.856416] layer1_control_layer[2077]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  147.856558] layer1_control_layer[2077]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  147.856724] layer1_control_layer[2077]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  147.856877] layer1_control_layer[2077]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  147.857098] layer1_control_layer[2077]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  147.857261] layer1_control_layer[2077]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  147.857454] layer1_control_layer[2077]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  147.857682] layer1_control_layer[2077]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  147.857802] layer1_control_layer[2077]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf"}
{"timestamp_utc": "2024-07-31T08:16:16.453Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[  147.857970] layer1_control_layer[2077]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  147.858109] layer1_control_layer[2077]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  147.858252] layer1_control_layer[2077]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  147.858366] layer1_control_layer[2077]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  147.858484] layer1_control_layer[2077]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> 2024-07-31 08:15:25,521 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=1 <NL> [  151.027865] python3[2190]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  151.091912] python3[2190]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  151.092068] python3[2190]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  151.092145] python3[2190]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  151.092215] python3[2190]: max_slotNumber=5 <NL> [  152.287245] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  152.287478] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  152.287567] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.293465, delay 0.03767\\n31 Jul 08:15:26 ntpdate[2360]: no server suitable for synchronization found\\n' <NL> [  161.452238] python3[2430]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  161.473954] python3[2430]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  161.549395] python3[2430]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  161.549493] python3[2430]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  161.549574] python3[2430]: max_slotNumber=5 <NL> [  161.549668] python3[2430]:  prov channel is 127.0.0.1:10000 <NL> [  161.549754] python3[2430]: success: command executed <NL> [  161.709227] layer1_hal[2110]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  161.752105] layer1_control_layer[2077]:    ChalApi Constructor with tid = 2357 <NL> [  164.482208] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  164.482382] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  164.482510] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.298402, delay 0.03076\\n31 Jul 08:15:39 ntpdate[2454]: no server suitable for synchronization found\\n' <NL> [  176.664752] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  176.666375] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  176.666499] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.291480, delay 0.06607\\n31 Jul 08:15:51 ntpdate[2479]: no server suitable for synchronization found\\n' <NL> [  188.635325] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  188.668762] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  188.668990] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.297671, delay 0.03044\\n31 Jul 08:16:03 ntpdate[2513]: no server suitable for synchronization found\\n' <NL> [  200.031050] hrtimer: interrupt took 26347657 ns <NL> [  200.692383] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  200.692574] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:16:17.823Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  195.660117] common_alarm_handler[2395]: topic = TcmProv; id = 118 <NL> [  195.908898] common_alarm_handler[2395]: topic = OCnProv; id = 119 <NL> [  195.909015] common_alarm_handler[2395]: topic = OnDemandDM; id = 120 <NL> [  195.909112] common_alarm_handler[2395]: topic = OducnProv; id = 121 <NL> [  195.909193] common_alarm_handler[2395]: topic = OtsiProv; id = 122 <NL> [  195.909278] common_alarm_handler[2395]: topic = OtsigProv; id = 123 <NL> Exception: Connect failed <NL> [  195.935208] common_alarm_handler[2395]: topic = OtucnProv; id = 124 <NL> [  196.017886] common_alarm_handler[2395]: topic = YpgProv; id = 125 <NL> [  196.293974] common_alarm_handler[2395]: topic = EpgProv; id = 126 <NL> [  196.529720] common_alarm_handler[2395]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  196.782802] common_alarm_handler[2395]: topic = DataEncryptionOperReq; id = 128 <NL> [  196.793285] common_alarm_handler[2395]: topic = RoutePolicyTableProv; id = 129 <NL> [  196.823719] common_alarm_handler[2395]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  197.097393] common_alarm_handler[2395]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  197.355641] common_alarm_handler[2395]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  197.355792] common_alarm_handler[2395]: topic = ShapingProfileProv; id = 133 <NL> [  197.355877] common_alarm_handler[2395]: topic = TaildropProfileProv; id = 134 <NL> [  197.355968] common_alarm_handler[2395]: topic = PolicingProfileProv; id = 135 <NL> [  197.356077] common_alarm_handler[2395]: topic = CapabilityProfileProv; id = 136 <NL> [  197.356160] common_alarm_handler[2395]: topic = TransportInterfaceRateProv; id = 137 <NL> [  197.356236] common_alarm_handler[2395]: topic = PmRtrvReqSess; id = 138 <NL> [  197.356340] common_alarm_handler[2395]: topic = PmRtrvRespSess; id = 139 <NL> [  197.356420] common_alarm_handler[2395]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  197.356500] common_alarm_handler[2395]: topic = DataEncryptionPskReq; id = 141 <NL> [  197.356589] common_alarm_handler[2395]: topic = SystemWebserverProv; id = 142 <NL> [  197.356674] common_alarm_handler[2395]: NO match: <NL> [  197.356755] common_alarm_handler[2395]: NO match: <NL> [  197.356829] common_alarm_handler[2395]: NO match: <NL> [  197.357803] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 6 <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> /run/rdm_status.sh created successfully <NL> [  198.887989] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  199.440366] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> [  199.623344] python3[2429]: [.623] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  199.801184] python3[2429]: [.623] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  199.856879] python3[2429]: [.681] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  199.909787] python3[2429]: [.681] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  199.924078] python3[2429]: [.681] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  199.933606] python3[2429]: [.682] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'}"}
{"timestamp_utc": "2024-07-31T08:16:17.824Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  199.934968] python3[2429]: [.682] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  199.951335] python3[2429]: [.682] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  199.990125] python3[2429]: [.868] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  200.032018] python3[2429]: [.868] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  200.070813] python3[2429]: [.892] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  200.090614] python3[2429]: [.892] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  200.091948] python3[2429]: [.900] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  200.141015] python3[2429]: [.900] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  200.142696] python3[2429]: [.900] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  200.374214] python3[2429]: [.900] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> /run/rdm_status.sh created successfully <NL> [  200.465457] python3[2429]: [.900] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  200.465697] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  200.465769] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  200.465834] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  200.467596] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 7 <NL> [  200.467793] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  200.467883] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  200.467966] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  200.468061] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  200.468147] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  200.468222] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  200.648494] python3[2429]: [.901] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  201.045837] python3[2429]: [.902] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  201.146683] python3[2429]: [.902] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  201.146799] python3[2429]: [.902] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  201.146881] python3[2429]: [.140] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  201.146968] python3[2429]: [.140] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  201.147080] python3[2429]: [.140] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  201.147164] python3[2429]: [.236] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  201.147242] python3[2429]: [.238] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'}"}
{"timestamp_utc": "2024-07-31T08:16:19.189Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:18 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:19 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:21.705Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:16:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:21.961Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "2024-07-31 08:15:13,344 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:15:13,385 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:15:13,385 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  138.330336] fujitsu-check-ssh-host-key.pl[2001]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  138.330549] fujitsu-check-ssh-host-key.pl[2001]: /dev/root       2.2G  1.8G  311M  86% /"}
{"timestamp_utc": "2024-07-31T08:16:21.962Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[  138.331023] fujitsu-check-ssh-host-key.pl[2002]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  138.331120] fujitsu-check-ssh-host-key.pl[2002]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  138.468749] fujitsu-check-ssh-host-key.pl[2003]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  138.526574] fujitsu-check-ssh-host-key.pl[2003]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  138.564448] fujitsu-check-ssh-host-key.pl[2005]: useradd: user 'fujitsu' already exists <NL> [  139.052453] fujitsu-check-ssh-host-key.pl[1967]: DDS Peristency is enabled <NL> [  139.053566] fujitsu-check-ssh-host-key.pl[1967]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  139.054757] fujitsu-check-ssh-host-key.pl[1967]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  139.086087] fujitsu-check-ssh-host-key.pl[1967]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  139.165140] fujitsu-check-ssh-host-key.pl[1967]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  139.192524] fujitsu-check-ssh-host-key.pl[1967]: Factory user shell set to /bin/bash <NL> [  139.210181] fujitsu-check-ssh-host-key.pl[1929]: Converting fujitsu user to bash shell... <NL> [  139.262023] fujitsu-check-ssh-host-key.pl[2012]: usermod: no changes <NL> [  139.265758] fujitsu-check-ssh-host-key.pl[1929]: Lock Root account in TRIB... <NL> [  139.292384] fujitsu-check-ssh-host-key.pl[2013]: Running lock on root account... <NL> [  139.378784] fujitsu-check-ssh-host-key.pl[2014]: passwd: password changed. <NL> [  139.409124] fujitsu-check-ssh-host-key.pl[1929]: Trib check done. <NL> [  139.943278] startup[2026]: Startup, World! <NL> [  139.943593] startup[2026]: Cmd arg set to loop 1 <NL> [  140.893350] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  140.899226] ntputils_client.py[1753]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  140.899403] ntputils_client.py[1753]: b'31 Jul 08:15:16 ntpdate[1870]: no server suitable for synchronization found\\n' <NL> [  141.349677] startup_finished.py[2022]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  141.716334] ains_manager[2023]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  142.504823] dhal_sim_startup.sh[2078]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  142.909948] confd_mgr_action_server[2072]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  143.612749] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  144.158698] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  143.851483] sh[2100]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  143.973356] sh[2100]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  147.202071] startup_finished.py[2022]: Startup Finished: systemd state is non-Production mode and running <NL> [  147.202369] startup_finished.py[2022]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  147.369347] zebra[2091]: 2024/07/31 08:15:23 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  148.238214] startup_finished.py[2022]: *****Startup Finished: stopping EOW timer***** <NL> [  149.293148] startup_finished.py[2022]: systemctl stop startup_finished_limit.timer <NL> [  156.417417] ains_manager[2304]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  157.578447] layer1_control_layer[2085]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  161.880459] layer1_control_layer[2085]: DIP entity prov dump <NL> [  162.078946] layer1_control_layer[2085]: EsalConfig::EsalConfig main 0 <NL> [  162.079259] layer1_control_layer[2085]: EsalConfig::EsalConfig trib 1 <NL> [  162.153715] layer1_control_layer[2085]: EsalConfig::EsalConfig ciRole 0 <NL> [  162.195425] layer1_control_layer[2085]: EsalConfig is not running inside container. <NL> [  162.227639] layer1_control_layer[2085]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  162.290300] layer1_control_layer[2085]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  162.357861] layer1_control_layer[2085]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  162.422839] layer1_control_layer[2085]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  162.424110] layer1_control_layer[2085]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  162.425383] layer1_control_layer[2085]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  162.483495] layer1_control_layer[2085]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  162.506089] layer1_control_layer[2085]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  162.552917] layer1_control_layer[2085]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  162.553844] layer1_control_layer[2085]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  162.572746] layer1_control_layer[2085]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  162.598405] layer1_control_layer[2085]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  162.604650] layer1_control_layer[2085]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  162.631811] layer1_control_layer[2085]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  162.638262] layer1_control_layer[2085]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  162.662779] layer1_control_layer[2085]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  162.671541] layer1_control_layer[2085]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  166.068334] python3[2217]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  166.068981] python3[2217]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  166.069116] python3[2217]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  166.069197] python3[2217]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  166.069298] python3[2217]: max_slotNumber=5 <NL> [  176.038357] python3[2434]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  176.082825] python3[2434]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  176.090335] python3[2434]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  176.097359] python3[2434]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  176.145554] python3[2434]: max_slotNumber=5 <NL> [  176.164235] python3[2434]:  prov channel is 127.0.0.1:10000 <NL> [  176.165304] python3[2434]: success: command executed <NL> [  176.226214] layer1_hal[2101]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  176.252885] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2368 <NL> 2024-07-31 08:16:02,911 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=3 <NL> [  192.877122] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  192.877596] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  192.877690] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.344732, delay 0.03958\\n31 Jul 08:16:08 ntpdate[2504]: no server suitable for synchronization found\\n' <NL> [  204.903648] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  204.979527] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:16:24.477Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:23 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:24 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:25.038Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  194.690833] ntputils[1733]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> 2024-07-31 08:16:11,794 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:16:12,073 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:12,089 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE"}
{"timestamp_utc": "2024-07-31T08:16:25.039Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  195.540912] ntputils[1733]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> 2024-07-31 08:16:12,576 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:16:12,712 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:16:12,838 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  196.068580] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:13,954 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:16:14,523 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  197.610382] ntputils[1733]: /bin/systemctl --no-block stop init_state_check.timer <NL> 2024-07-31 08:16:14,812 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  198.910582] ntputils[1733]: child pid is 1938 <NL> 2024-07-31 08:16:16,015 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:16:16,210 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  199.292294] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:16:16,712 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:16:17,273 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> [  200.740919] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:18,103 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:18,589 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  201.894724] ntputils[1733]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:16:19,096 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:19,132 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> [  202.263757] ntputils[1733]: child pid is 1939 <NL> 2024-07-31 08:16:19,480 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  202.732288] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:16:19,744 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:16:19,904 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:16:20,012 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  203.208922] ntputils[1733]: call delete_all_external_servers <NL> 2024-07-31 08:16:20,318 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  203.379743] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  203.552508] ntputils[1733]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  203.553655] ntputils[1733]: child pid is 1940 <NL> 2024-07-31 08:16:20,722 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:16:20,796 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> [  203.782993] ntputils[1940]: remove_all_ext_src <NL> 2024-07-31 08:16:21,107 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:16:21,328 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> [  204.464894] ntputils[1940]: delete: <NL> 2024-07-31 08:16:21,634 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  204.807500] ntp_oper_data.py[1734]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> 2024-07-31 08:16:21,820 swdllite(mgr): INFO - swdl_state_confdmgr.confdmgr_notify_wait_fn[81] mgr_confdmgr_state: confdmgr notification suppressed, OrderedDict([('mode', 'NORMAL'), ('status', 'SUCCESS'), ('rdm-status', 'STANDALONE')]) <NL> 2024-07-31 08:16:22,022 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> [  205.405537] ntp_oper_data.py[1734]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> 2024-07-31 08:16:22,685 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:16:22,685 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  205.781647] ntp_oper_data.py[1734]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> 2024-07-31 08:16:22,945 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:23,236 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  206.231502] ntp_oper_data.py[1734]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> 2024-07-31 08:16:23,264 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  206.275770] ntp_oper_data.py[1734]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  206.287952] ntp_oper_data.py[1734]: INFO:root:redundancy status now set to standalone <NL> [  206.288974] ntp_oper_data.py[1734]: INFO:root:Received redundancy topic <NL> [  206.292545] ntp_oper_data.py[1734]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:16:23,303 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:23,526 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> 2024-07-31 08:16:23,563 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:16:23,572 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:16:23,594 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:23,618 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:16:23,642 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  206.637405] ntputils[1733]: exited, status is 0 <NL> [  206.645516] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  206.652375] ntputils[1733]: /bin/systemctl reset-failed ntpd <NL> [  206.658272] ntputils[1733]: child pid is 1942 <NL> [  206.658849] ntputils[1733]: exited, status is 0 <NL> [  206.666299] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:23,671 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\""}
{"timestamp_utc": "2024-07-31T08:16:25.966Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:16:25 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:27.856Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  199.125796] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  199.126152] python3[2413]: [.730] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  199.286273] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  199.287021] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  200.265932] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 7 <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  203.526631] txid_tracker[2806]: ::::create_confd_subscription_connection() try number 8 <NL> [  203.813135] confd_mgr[3178]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  203.813364] confd_mgr[3178]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  203.857309] confd_mgr[3179]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  203.857478] confd_mgr[3179]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  203.952657] confd_mgr[3181]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  203.955777] confd_mgr[3181]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  204.202864] confd_mgr[3105]: DDS Peristency is enabled <NL> [  204.277574] confd_mgr[3105]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  204.282930] confd_mgr[3105]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  204.593769] confd_mgr[3105]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  204.857510] confd_mgr[3105]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  205.046067] layer1_hal[2447]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  205.078937] confd_mgr[3101]: /usr/bin/dbrestore_no.py <NL> [  205.151794] python3[3135]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  205.152000] python3[3135]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  205.152097] python3[3135]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  205.152160] python3[3135]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  205.152222] python3[3135]: max_slotNumber=5 <NL> [  205.152284] python3[3135]:  prov channel is 127.0.0.1:10000 <NL> [  205.152354] python3[3135]: success: command executed <NL> [  205.152996] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  205.153096] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  205.153385] confd_mgr[3192]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  205.153843] confd_mgr[2947]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  205.153931] confd_mgr[2947]: entering: wait_for_alarm_event <NL> [  205.154016] confd_mgr[2947]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  205.154086] confd_mgr[2947]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  205.154149] confd_mgr[2947]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  205.154211] confd_mgr[2947]: ha_sm : wait_for_SWDL_s timer is set <NL> [  205.154278] confd_mgr[2947]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  205.154339] confd_mgr[2947]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  205.154399] confd_mgr[2947]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  205.154472] confd_mgr[2947]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  205.154602] confd_mgr[2947]: entering: at_sm::wait_for_SWDL <NL> [  205.308861] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  205.323892] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  205.324873] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  205.471381] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  205.471490] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  205.471566] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  205.471641] confd_mgr[2947]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  205.471743] confd_mgr[2947]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> 2024-07-31 08:16:20,085 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  208.072758] layer1_control_layer[2418]: DIP entity prov dump <NL> [  208.541073] layer1_control_layer[2418]: EsalConfig::EsalConfig main 1 <NL> [  208.541308] layer1_control_layer[2418]: EsalConfig::EsalConfig trib 0 <NL> [  208.541391] layer1_control_layer[2418]: EsalConfig::EsalConfig ciRole 0 <NL> [  208.645763] layer1_control_layer[2418]: EsalConfig is not running inside container. <NL> [  208.737536] layer1_control_layer[2418]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  208.857420] layer1_control_layer[2418]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  209.135806] layer1_control_layer[2418]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  209.335803] layer1_control_layer[2418]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:16:27.857Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  209.607032] layer1_control_layer[2418]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  209.784030] layer1_control_layer[2418]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  209.785223] layer1_control_layer[2418]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  209.786217] layer1_control_layer[2418]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  209.841034] layer1_control_layer[2418]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  209.864820] layer1_control_layer[2418]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  209.931384] layer1_control_layer[2418]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  209.961831] layer1_control_layer[2418]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  210.012249] layer1_control_layer[2418]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  210.020867] layer1_control_layer[2418]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  210.162886] layer1_control_layer[2418]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  210.179674] layer1_control_layer[2418]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  210.233695] layer1_control_layer[2418]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  210.639688] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  210.748377] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  210.836912] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  210.955662] python3[2413]: [.809] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  211.395221] confd_mgr[3206]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'NONE', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  211.474086] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 1 <NL> [  211.476525] confd_mgr[2947]: ConfdMgrConf::reload: DB signature set to false <NL> [  211.527875] confd_mgr[2947]: is_swdl_alarm_0 <NL> [  211.549911] confd_mgr[2947]: sdb_restore_= 0 <NL> [  211.556922] confd_mgr[2947]: swdl_alarm_ = NONE <NL> [  211.577500] confd_mgr[2947]: swdl_alarm_tag_ = <NL> [  211.593616] confd_mgr[2947]: swdl status = SUCCESS <NL> [  211.609969] confd_mgr[2947]: is_swdl_in_swupgrade = 0 <NL> [  211.642770] confd_mgr[2947]: is_swdl_alarm_0 <NL> [  211.689299] confd_mgr[2947]: sdb_restore_= 0 <NL> [  211.702531] confd_mgr[2947]: swdl_alarm_ = NONE <NL> [  211.728863] confd_mgr[2947]: swdl_alarm_tag_ ="}
{"timestamp_utc": "2024-07-31T08:16:29.225Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:28 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:29 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:30.589Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  201.147345] python3[2429]: [.238] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  201.147424] python3[2429]: [.238] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  201.147502] python3[2429]: [.341] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  201.147579] python3[2429]: [.341] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  201.148752] python3[2429]: [.342] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  201.148913] python3[2429]: [.342] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  201.149030] python3[2429]: [.371] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  201.149124] python3[2429]: [.371] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  201.149203] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  201.149280] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  201.149370] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  201.149445] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  201.149520] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  201.149601] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  201.149680] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  201.149766] python3[2429]: [.372] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  201.149844] python3[2429]: [.401] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  201.149921] python3[2429]: [.401] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  201.150019] python3[2429]: [.401] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'}"}
{"timestamp_utc": "2024-07-31T08:16:30.590Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  201.150102] python3[2429]: [.401] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  201.150196] python3[2429]: [.401] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  201.150295] python3[2429]: [.401] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  201.158394] python3[2429]: [.402] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  201.687896] python3[2429]: [.402] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  201.689212] python3[2602]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  201.827959] python3[2602]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  201.967576] python3[2602]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  201.967706] python3[2602]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  201.967784] python3[2602]: max_slotNumber=5 <NL> [  201.967952] python3[2429]: [.402] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  201.968056] python3[2429]: [.402] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  201.968128] python3[2429]: [.402] hookhdlr 139635753535296 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  201.968197] python3[2429]: [.402] hookhdlr 139635753535296 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  201.968266] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  201.969458] python3[2429]: [.403] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  203.153604] txid_tracker[2459]: ::::create_confd_subscription_connection() try number 8 <NL> [  204.112131] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  204.112322] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  207.298405] layer1_control_layer[2431]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  208.178966] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 1 <NL> [  208.901691] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  208.901937] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  209.952967] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  210.027888] python3[2429]: [.515] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  211.182817] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 2 <NL> 2024-07-31 08:16:27,609 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:27,589 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:27,873 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  212.754712] dcn_ka[1603]: KaSessMgr Process Startup <NL> [  213.075653] dcn_dns_controller[1601]: dnsClientStartup() <NL> 2024-07-31 08:16:28,732 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  213.710614] dcn_dns_controller[1601]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  213.727506] dcn_dns_controller[1601]: fin_dnsmasq_conf is open <NL> [  213.758545] ntp_oper_data.py[1857]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  213.758732] ntp_oper_data.py[1857]: INFO:root:redundancy status now set to standalone <NL> [  213.758802] ntp_oper_data.py[1857]: INFO:root:Received redundancy topic <NL> [  213.758875] ntp_oper_data.py[1857]: INFO:root:Redundancy status is standalone <NL> [  213.759846] confd_mgr[2975]: ConfdMgrConf: DB signature is NOT supported <NL> [  213.760014] confd_mgr[2975]: Read reset type failed basic_ios::clear: iostream error <NL> [  213.760121] confd_mgr[2975]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  213.765757] ntputils[1855]: bool NTPServer::handle_command(const string&) <NL> [  213.855876] ntputils[1855]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  213.856042] ntputils[1855]: got Platform::RedundancyMode: WORK <NL> [  213.856155] ntputils[1855]: got Platform::RedundancyStatus: STANDALONE <NL> [  213.856243] ntputils[1855]: my current red mode is: UNKNOWN <NL> [  213.856355] ntputils[1855]: new red mode is: WORK <NL> [  213.856456] ntputils[1855]: my current red status is: STANDALONE <NL> [  213.856547] ntputils[1855]: new red status is: STANDALONE <NL> [  213.856630] ntputils[1855]: red mode change, update: UNKNOWN => WORK <NL> [  213.860717] ntputils[1855]: no active/not-active status change: 0 <NL> [  214.150370] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:16:31.152Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:16:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:34.417Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:33 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:34 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:36.304Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:16:36 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:39.609Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:39 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:39 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:41.567Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:16:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:44.083Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:44 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:44.339Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:16:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:44 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:46.227Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:16:45 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:48.115Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  214.150571] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  214.579016] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 3 <NL> [  214.799548] startup_finished.py[2302]: Startup Finished: systemd state is non-Production mode and running <NL> [  214.799774] startup_finished.py[2302]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  216.758679] startup_finished.py[2302]: *****Startup Finished: stopping EOW timer***** <NL> [  217.254716] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 4 <NL> [  217.258048] confd_mgr[2975]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  217.258251] confd_mgr[2975]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  218.058221] confd_mgr[3076]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:16:33 UTC 2024 <NL> [  218.140824] startup_finished.py[2302]: systemctl stop startup_finished_limit.timer <NL> [  218.327090] dcn_dns_controller[1601]: subscribe_data Enter main loop <NL> [  218.961048] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  218.961254] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  220.244962] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  220.248497] python3[2429]: [.645] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  220.249202] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 5 <NL> [  220.638287] confd_mgr[3137]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  220.649140] confd_mgr[3076]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  221.025913] confd_mgr[3148]: /usr/bin/ui_sys_reset.py NONE <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  223.375822] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 6 <NL> [  223.702227] python3[3094]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  223.764906] python3[3094]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  223.776358] python3[3094]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  223.800134] python3[3094]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  224.102368] python3[3094]: max_slotNumber=5 <NL> [  224.125304] python3[3094]:  prov channel is 127.0.0.1:10000 <NL> [  224.126787] python3[3094]: success: command executed <NL> [  224.149415] layer1_hal[2469]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  224.387245] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  224.407585] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:16:40,481 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> 2024-07-31 08:16:40,988 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  226.266360] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 7 <NL> [  227.142833] confd_mgr[3194]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  227.316705] confd_mgr[3194]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  227.477088] confd_mgr[3195]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  227.477317] confd_mgr[3195]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  227.565485] confd_mgr[3199]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  227.565715] confd_mgr[3199]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  227.587965] confd_mgr[3151]: DDS Peristency is enabled <NL> [  227.643136] confd_mgr[3151]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  227.643272] confd_mgr[3151]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  227.643372] confd_mgr[3151]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  227.643465] confd_mgr[3151]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  227.792556] confd_mgr[3148]: /usr/bin/dbrestore_no.py <NL> [  227.876680] confd_mgr[3201]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  227.951972] confd_mgr[2975]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  227.967725] confd_mgr[2975]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  227.979689] confd_mgr[2975]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  228.024970] confd_mgr[2975]: entering: wait_for_alarm_event <NL> [  228.095901] confd_mgr[2975]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  228.096138] confd_mgr[2975]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  228.096225] confd_mgr[2975]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  228.096312] confd_mgr[2975]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  228.096388] confd_mgr[2975]: entering: at_sm::wait_for_SWDL"}
{"timestamp_utc": "2024-07-31T08:16:48.116Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  228.104475] confd_mgr[2975]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  228.176302] confd_mgr[2975]: ha_sm : wait_for_SWDL_s timer is set <NL> [  228.258567] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  228.258806] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  228.258901] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  228.258986] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  228.259106] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  228.259194] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  228.259276] confd_mgr[2975]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  228.548518] confd_mgr[2975]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  229.249204] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  229.249445] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  229.288340] txid_tracker[2887]: ::::create_confd_subscription_connection() try number 8 <NL> [  230.198211] layer1_control_layer[2431]: DIP entity prov dump <NL> [  230.249245] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  230.290979] python3[2429]: [.694] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  231.237079] layer1_control_layer[2431]: EsalConfig::EsalConfig main 1 <NL> [  231.237349] layer1_control_layer[2431]: EsalConfig::EsalConfig trib 0 <NL> [  231.237434] layer1_control_layer[2431]: EsalConfig::EsalConfig ciRole 0 <NL> [  231.488773] layer1_control_layer[2431]: EsalConfig is not running inside container. <NL> [  231.489021] layer1_control_layer[2431]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  231.489107] layer1_control_layer[2431]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  231.489184] layer1_control_layer[2431]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  231.490500] layer1_control_layer[2431]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  231.490605] layer1_control_layer[2431]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  231.490707] layer1_control_layer[2431]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:16:49.043Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:49 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:49.300Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:16:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:49 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:49.861Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  186.457906] ntputils[1710]: received unknown! <NL> 2024-07-31 08:15:59,860 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  186.751412] ntputils[1710]: new red mode is: UNKNOWN <NL> [  186.780121] ntputils[1710]: new red status is: STANDALONE <NL> 2024-07-31 08:16:00,136 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  187.199611] ntputils[1710]: red status change, update active => STANDALONE <NL> 2024-07-31 08:16:02,178 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  194.940148] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  191.491423] ntputils[1710]: no active/not-active status change: 0 <NL> [  196.476132] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> 2024-07-31 08:16:08,477 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:08,841 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:16:09,739 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  196.573072] ntputils[1710]: bool NTPServer::handle_command(const string&) <NL> [  196.602657] ntputils[1710]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  196.671323] ntputils[1710]: got Platform::RedundancyMode: UNKNOWN <NL> 2024-07-31 08:16:10,867 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  197.967647] ntputils[1710]: got Platform::RedundancyStatus: STANDALONE <NL> [  199.860582] ntputils[1710]: my current red mode is: UNKNOWN <NL> [  200.030339] ntputils[1710]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:12,473 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  201.782127] ntputils[1710]: my current red status is: STANDALONE <NL> 2024-07-31 08:16:19,438 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0,"}
{"timestamp_utc": "2024-07-31T08:16:49.862Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "\"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  206.693949] ntputils[1710]: new red status is: STANDALONE <NL> [  207.775855] ntputils[1710]: received unknown! <NL> 2024-07-31 08:16:21,162 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:22,590 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  209.519845] ntputils[1710]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:23,945 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  212.367975] ntputils[1710]: new red status is: STANDALONE <NL> [  214.298259] ntputils[1710]: no active/not-active status change: 0 <NL> [  215.132804] ntputils[1710]: bool NTPServer::handle_command(const string&) <NL> [  215.212188] ntputils[1710]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:16:28,497 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  215.343172] ntputils[1710]: got Platform::RedundancyMode: WORK <NL> 2024-07-31 08:16:30,548 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  217.993636] ntputils[1710]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:16:34,007 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:36,472 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  223.209076] ntputils[1710]: my current red mode is: UNKNOWN <NL> [  223.344782] ntputils[1710]: new red mode is: WORK <NL> 2024-07-31 08:16:36,834 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:36,971 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  223.719513] ntputils[1710]: my current red status is: STANDALONE <NL> 2024-07-31 08:16:37,662 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  224.506207] ntputils[1710]: new red status is: STANDALONE <NL> 2024-07-31 08:16:39,040 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  225.954863] ntputils[1710]: red mode change, update: UNKNOWN => WORK <NL> [  227.557136] ntputils[1710]: no active/not-active status change: 0 <NL> [  227.835219] ntp_oper_data.py[1714]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  228.166138] ntp_oper_data.py[1714]: INFO:root:redundancy status now set to standalone <NL> [  228.166937] ntp_oper_data.py[1714]: INFO:root:Received redundancy topic <NL> 2024-07-31 08:16:41,415 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  228.181257] ntp_oper_data.py[1714]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:16:41,445 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> 2024-07-31 08:16:41,589 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:16:41,888 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:42,083 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:42,187 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:16:42,670 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> [  231.339693] fujitsu-check-ssh-host-key.pl[2002]: Checking system account status... <NL> 2024-07-31 08:16:44,190 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:45,823 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  232.758458] fujitsu-check-ssh-host-key.pl[2002]: System account found... <NL> [  234.927932] fujitsu-check-ssh-host-key.pl[2002]: 3004 <NL> [  234.941198] fujitsu-check-ssh-host-key.pl[2002]: /bin/bash <NL> [  234.960858] fujitsu-check-ssh-host-key.pl[2002]: /home/system exists <NL> [  235.014608] fujitsu-check-ssh-host-key.pl[2002]: Checking for trib... <NL> [  235.227734] fujitsu-check-ssh-host-key.pl[2002]: Checking for PIU ... <NL> [  235.308367] fujitsu-check-ssh-host-key.pl[2002]: slot number (0) is not a PIU. <NL> [  235.360471] fujitsu-check-ssh-host-key.pl[2002]: Trib check done. <NL> 2024-07-31 08:16:48,739 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:16:48,937 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:49,043 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:49,091 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE"}
{"timestamp_utc": "2024-07-31T08:16:50.790Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  211.739942] confd_mgr[2947]: swdl status = SUCCESS <NL> [  211.749321] confd_mgr[2947]: is_swdl_in_swupgrade = 0 <NL> [  211.761101] confd_mgr[2947]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  211.783666] confd_mgr[2947]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  211.815702] confd_mgr[3204]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  211.843794] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  211.868965] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  211.869921] confd_mgr[2947]: main::/run/rdm_status.sh found. Invoking it. <NL> [  211.899768] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  211.929713] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  211.942262] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  211.946109] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  211.946982] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  211.947623] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  211.948316] confd_mgr[2947]: ConfdMgrConf::reload: DB signature set to false <NL> [  211.977539] confd_mgr[2947]: confd_db_init::sConfd_db_init_executed_=false <NL> [  211.983880] confd_mgr[2947]: ConfdMgrConf::reload: DB signature set to false <NL> [  212.993737] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 2 <NL> [  214.121210] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3311 <NL> [  214.321682] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  214.321875] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:16:50.791Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  215.393803] systemd-journald[357]: Data hash table of /run/log/journal/5383bddcba4644dfa1b979cbbe931122/system.journal has a fill level at 75.0 (13655 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  215.655615] systemd-journald[357]: /run/log/journal/5383bddcba4644dfa1b979cbbe931122/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  215.961585] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 3 <NL> [  216.470347] confd_mgr[3368]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  216.479125] confd_mgr[3266]: build /etc/confd/confd.conf.bank0 NONE <NL> [  216.862143] confd_mgr[3266]: /etc/confd/default_backup.dbs <NL> [  216.862403] confd_mgr[3266]: Create default DB in bank0 <NL> [  219.353138] systemd-sysv-generator[3438]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  218.998414] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 4 <NL> [  219.281869] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  219.414587] python3[2413]: [.829] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  219.416048] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  219.416254] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  221.998854] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 5 <NL> [  223.990480] confd_mgr[2947]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  223.996205] confd_mgr[2947]: confd_db_init::RESET REASON IS NONE <NL> [  223.996337] confd_mgr[2947]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  223.996443] confd_mgr[2947]: leaving: at_sm::wait_for_SWDL <NL> [  223.996536] confd_mgr[2947]: entering: at_sm::wait_for_start_bank <NL> [  223.996608] confd_mgr[2947]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  224.003619] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  224.021371] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  224.087329] confd_mgr[2947]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  224.215160] confd_mgr[2947]: ha_sm leaving: wait_for_SWDL_s <NL> [  224.232191] confd_mgr[2947]: ha_sm entering: no_ha_s <NL> [  224.232396] confd_mgr[2947]: leaving: at_sm::wait_for_start_bank <NL> [  224.437375] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  224.437526] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  224.438496] confd_mgr[3264]: TRUE <NL> [  224.438711] confd_mgr[2947]: entering: at_sm_dbready::wait_for_db_status <NL> [  224.438809] confd_mgr[2947]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  224.438902] confd_mgr[2947]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  224.438985] confd_mgr[2947]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  224.449177] confd_mgr[3585]: Executing check_db.sh <NL> [  224.449322] confd_mgr[3585]: check_db.sh: found xml files <NL> [  224.449426] confd_mgr[3585]: 0 <NL> [  224.449651] confd_mgr[2947]: Found no error <NL> [  224.449728] confd_mgr[2947]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  224.449798] confd_mgr[2947]: cur_gdbissue 24-1-1 gdbissue 24-1-1 rc = 1 <NL> [  224.449869] confd_mgr[2947]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  224.449939] confd_mgr[2947]: L1-BLADE is in the list: L1-BLADE <NL> [  224.450060] confd_mgr[2947]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  224.450155] confd_mgr[2947]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  224.450267] confd_mgr[2947]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  224.450336] confd_mgr[2947]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  224.450407] confd_mgr[2947]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  224.450481] confd_mgr[2947]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  224.450563] confd_mgr[2947]: guard is_db_okay_g: The HA mode is NONE <NL> [  224.450635] confd_mgr[2947]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  224.450713] confd_mgr[2947]: entering: sm_startconfd::start_confd_p0 <NL> [  224.450797] confd_mgr[2947]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  224.451427] confd_mgr[3591]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:16:38 UTC 2024 <NL> [  224.462240] confd_mgr[2947]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  224.998179] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 6 <NL> [  226.776504] tun: Universal TUN/TAP device driver, 1.6 <NL> [  227.997351] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 7 <NL> [  229.268519] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  229.290037] python3[2413]: [.888] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  229.421956] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  229.422256] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  231.020885] txid_tracker[3229]: ::::create_confd_subscription_connection() try number 8 <NL> [  234.405522] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:16:51.047Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:16:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:54.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:16:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:54 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:54 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:56.826Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:16:56 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:59.364Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:16:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:59 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:59 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:01.882Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:17:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:04.449Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:04 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:04 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:06.338Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:17:05 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:06.594Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  231.490776] layer1_control_layer[2431]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  231.490856] layer1_control_layer[2431]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  231.490951] layer1_control_layer[2431]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  231.491059] layer1_control_layer[2431]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  231.491158] layer1_control_layer[2431]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  231.491247] layer1_control_layer[2431]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  231.491344] layer1_control_layer[2431]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  231.491501] layer1_control_layer[2431]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  231.491593] layer1_control_layer[2431]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  231.491682] layer1_control_layer[2431]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  231.491791] layer1_control_layer[2431]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  233.943464] systemd-journald[358]: Data hash table of /run/log/journal/2248b4323854441fb0634243a4ab8d0b/system.journal has a fill level at 75.0 (13656 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  233.994092] systemd-journald[358]: /run/log/journal/2248b4323854441fb0634243a4ab8d0b/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  234.124182] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 1 <NL> [  234.281357] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  234.281591] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  234.930246] confd_mgr[3217]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'NONE', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  235.817280] confd_mgr[2975]: ConfdMgrConf::reload: DB signature set to false <NL> [  235.817689] confd_mgr[2975]: is_swdl_alarm_0 <NL> [  235.849520] confd_mgr[2975]: sdb_restore_= 0 <NL> [  235.849723] confd_mgr[2975]: swdl_alarm_ = NONE <NL> [  235.849842] confd_mgr[2975]: swdl_alarm_tag_ = <NL> [  235.849945] confd_mgr[2975]: swdl status = SUCCESS <NL> [  235.872120] confd_mgr[2975]: is_swdl_in_swupgrade = 0 <NL> [  235.896333] confd_mgr[2975]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  235.896532] confd_mgr[2975]: is_swdl_alarm_0 <NL> [  235.896747] confd_mgr[2975]: sdb_restore_= 0 <NL> [  235.896833] confd_mgr[2975]: swdl_alarm_ = NONE <NL> [  235.896909] confd_mgr[2975]: swdl_alarm_tag_ = <NL> [  235.896988] confd_mgr[2975]: swdl status = SUCCESS <NL> [  235.897113] confd_mgr[2975]: is_swdl_in_swupgrade = 0 <NL> [  235.898159] confd_mgr[3214]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  235.898304] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  235.898394] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  235.898477] confd_mgr[2975]: main::/run/rdm_status.sh found. Invoking it. <NL> [  236.044073] confd_mgr[2975]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  236.236399] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  236.237356] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  236.237467] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  236.237607] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd"}
{"timestamp_utc": "2024-07-31T08:17:06.595Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  236.237710] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  236.237797] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  236.237915] confd_mgr[2975]: ConfdMgrConf::reload: DB signature set to false <NL> [  236.238024] confd_mgr[2975]: confd_db_init::sConfd_db_init_executed_=false <NL> [  236.245188] confd_mgr[2975]: ConfdMgrConf::reload: DB signature set to false <NL> [  237.087079] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 2 <NL> [  237.293816] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3349 <NL> [  239.252819] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  239.253099] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  241.073880] systemd-sysv-generator[3385]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  240.189821] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 3 <NL> [  240.327426] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  240.404818] python3[2429]: [.801] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  243.133862] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 4 <NL> [  244.238251] confd_mgr[3402]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  244.245625] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  244.254788] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  244.353329] confd_mgr[3333]: build /etc/confd/confd.conf.bank0 NONE <NL> [  244.621611] confd_mgr[3333]: /etc/confd/default_backup.dbs <NL> [  244.621845] confd_mgr[3333]: Create default DB in bank0 <NL> [  246.139131] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 5 <NL> [  247.143307] tun: Universal TUN/TAP device driver, 1.6 <NL> [  249.146793] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 6 <NL> [  249.251643] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  249.251831] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  249.944473] confd_mgr[2975]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  250.027769] confd_mgr[2975]: confd_db_init::RESET REASON IS NONE <NL> [  250.027880] confd_mgr[2975]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  250.027954] confd_mgr[2975]: ha_sm leaving: wait_for_SWDL_s <NL> [  250.028037] confd_mgr[2975]: ha_sm entering: no_ha_s <NL> [  250.028110] confd_mgr[2975]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  250.028182] confd_mgr[2975]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  250.028285] confd_mgr[2975]: leaving: at_sm::wait_for_SWDL <NL> [  250.028368] confd_mgr[2975]: entering: at_sm::wait_for_start_bank <NL> [  250.028444] confd_mgr[2975]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  250.028558] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  250.028642] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  250.028715] confd_mgr[2975]: leaving: at_sm::wait_for_start_bank <NL> [  250.029471] confd_mgr[3327]: TRUE <NL> [  250.029676] confd_mgr[2975]: entering: at_sm_dbready::wait_for_db_status <NL> [  250.029756] confd_mgr[2975]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  250.029878] confd_mgr[2975]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  250.030095] confd_mgr[3628]: Executing check_db.sh <NL> [  250.030172] confd_mgr[3628]: check_db.sh: found xml files <NL> [  250.030246] confd_mgr[3628]: 0 <NL> [  250.030372] confd_mgr[2975]: Found no error"}
{"timestamp_utc": "2024-07-31T08:17:09.865Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:09 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:09 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:11.230Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:17:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:14.551Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:14 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:14 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:16.441Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:17:16 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:19.707Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:19.708Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:19 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:19 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:21.594Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:17:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:24.857Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  206.678216] ntputils[1733]: systemctl --no-block start ntpd <NL> 2024-07-31 08:16:23,740 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  206.812394] ntputils[1733]: child pid is 1943 <NL> 2024-07-31 08:16:23,906 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> [  206.985254] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:16:24,148 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> [  207.236108] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  207.303985] ntputils[1733]: /bin/systemctl reset-failed init_state_check.timer <NL> [  207.305259] ntputils[1733]: child pid is 1948 <NL> [  207.305925] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:16:24,374 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  207.492636] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:24,604 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:16:24,606 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  207.580285] ntputils[1733]: /bin/systemctl --no-block start init_state_check.timer <NL> [  207.683119] ntputils[1733]: child pid is 1951 <NL> 2024-07-31 08:16:24,746 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:16:25,325 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:16:24,751 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  209.774167] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:16:28,782 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:16:29,266 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:30,088 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  213.402840] ntputils[1733]: server.InitDaemon <NL> [  213.623209] ntputils[1733]: int NTPServer::platformdds_listen() <NL> 2024-07-31 08:16:28,854 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:16:31,015 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:16:32,238 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  215.364932] ntputils[1733]: void NTPServer::poller() <NL> [  215.602259] ntputils[1733]: void NTPServer::late_joiner() <NL> [  215.602979] ntputils[1733]: bool NTPServer::handle_command(const string&) <NL> [  215.603825] ntputils[1733]: bool NTPServer::handle_redundancy_topic(const string&)[  216.376250] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> 2024-07-31 08:16:32,901 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')...[  217.375858] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  216.620953] ntputils[1733]: got Platform::RedundancyMode: UNKNOWN <NL> [  220.562938] ntputils[1733]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:16:37,636 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  222.063452] ntputils[1733]: my current red mode is: UNKNOWN <NL> [  223.013416] ntputils[1733]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:40,575 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  225.165333] ntputils[1733]: my current red status is: active <NL> 2024-07-31 08:16:42,406 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124]"}
{"timestamp_utc": "2024-07-31T08:17:24.858Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "2024-07-31 08:16:42,464 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  225.472343] ntputils[1733]: new red status is: STANDALONE <NL> 2024-07-31 08:16:55,093 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  238.229530] ntputils[1733]: received unknown! <NL> 2024-07-31 08:16:56,530 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  240.752407] ntputils[1733]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:58,231 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  242.307442] ntputils[1733]: new red status is: STANDALONE <NL> [  243.316658] ntputils[1733]: red status change, update active => STANDALONE <NL> [  244.047953] ntputils[1733]: no active/not-active status change: 0 <NL> 2024-07-31 08:17:00,843 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  244.413088] ntputils[1733]: bool NTPServer::handle_command(const string&) <NL> [  245.092382] ntputils[1733]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:17:02,080 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  245.860132] ntputils[1733]: got Platform::RedundancyMode: UNKNOWN <NL> 2024-07-31 08:17:04,629 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  247.678076] ntputils[1733]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:17:07,979 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  251.252370] ntputils[1733]: my current red mode is: UNKNOWN <NL> [  254.005024] ntputils[1733]: new red mode is: UNKNOWN <NL> 2024-07-31 08:17:10,800 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  254.851414] ntputils[1733]: my current red status is: STANDALONE <NL> 2024-07-31 08:17:14,433 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  257.699858] ntputils[1733]: new red status is: STANDALONE <NL> [  259.205577] ntputils[1733]: received unknown! <NL> [  259.226569] ntputils[1733]: new red mode is: UNKNOWN <NL> [  259.227304] ntputils[1733]: new red status is: STANDALONE <NL> [  259.227971] ntputils[1733]: no active/not-active status change: 0 <NL> [  259.688185] ntp_oper_data.py[1734]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> 2024-07-31 08:17:16,817 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  260.428450] ntp_oper_data.py[1734]: INFO:root:redundancy status now set to standalone <NL> 2024-07-31 08:17:18,858 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  262.085568] ntp_oper_data.py[1734]: INFO:root:Received redundancy topic <NL> 2024-07-31 08:17:20,688 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:17:21,180 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  264.185161] ntp_oper_data.py[1734]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:17:22,108 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:17:22,527 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> # 03:17:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:24 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:24 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:26.223Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:17:26 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37215\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:28.113Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[  200.692656] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.299103, delay 0.03688\\n31 Jul 08:16:15 ntpdate[2536]: no server suitable for synchronization found\\n' <NL> [  212.471479] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  212.471725] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  212.471840] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.299561, delay 0.04359\\n31 Jul 08:16:27 ntpdate[2557]: no server suitable for synchronization found\\n' <NL> [  224.385730] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  224.385911] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  224.385990] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.287788, delay 0.05014\\n31 Jul 08:16:39 ntpdate[2592]: no server suitable for synchronization found\\n' <NL> [  236.254512] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  236.270365] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  236.298250] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.295915, delay 0.02711\\n31 Jul 08:16:50 ntpdate[2607]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:16:53,114 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:16:53,115 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:16:53,182 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:16:53,183 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:16:53,184 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:16:53,184 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:16:53,199 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:16:53,216 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:16:53,225 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:53,226 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:16:53,264 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:16:53,274 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":1} <NL> 2024-07-31 08:16:53,275 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:16:53,276 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:16:53,308 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:16:53,314 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:16:53,337 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:16:53,337 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:16:53,338 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:16:53,338 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:16:53,338 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:16:53,351 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:16:53,392 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:53,393 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:16:53,373 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:16:53,374 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:16:53,443 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:16:54,049 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:16:54,050 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:16:54,051 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:17:00,095 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:17:00,096 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn"}
{"timestamp_utc": "2024-07-31T08:17:28.114Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[  248.172317] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  248.173307] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  248.181184] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.296205, delay 0.02919\\n31 Jul 08:17:02 ntpdate[2699]: no server suitable for synchronization found\\n' <NL> [  260.039691] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  260.054616] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  260.085041] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.295733, delay 0.03230\\n31 Jul 08:17:14 ntpdate[2718]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  272.274953] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  272.287517] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:17:29.478Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:29 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:29 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:31.397Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:17:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:33.913Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  234.407601] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  235.523027] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 1 <NL> [  238.544018] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 2 <NL> [  239.344198] hrtimer: interrupt took 26833145 ns <NL> [  239.334725] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  239.334879] python3[2413]: [.937] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  239.530714] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  239.593427] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  241.120669] healthcheck_agt.py[3673]: /bin/sh: line 1: podman: command not found <NL> [  241.563856] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 3 <NL> [  244.600791] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  244.603283] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  244.616627] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 4 <NL> [  247.620019] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 5 <NL> [  249.351694] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  249.352315] python3[2413]: [.953] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  249.591523] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  249.611055] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  250.624265] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 6 <NL> [  253.628903] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 7 <NL> [  254.592161] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  254.592326] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  256.625891] txid_tracker[3659]: ::::create_confd_subscription_connection() try number 8 <NL> [  259.389668] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  259.390399] python3[2413]: [.970] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  259.601287] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:17:33.914Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  259.601536] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  260.962862] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 1 <NL> [  263.984665] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 2 <NL> [  264.639300] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  264.639701] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  266.989974] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 3 <NL> [  269.379788] python3[2413]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  269.380034] python3[2413]: [.983] hookhdlr 140116335949632 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  269.663552] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  269.664367] confd_phase_sentry[2427]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f81bb5e25c7; Failed to connect to ConfD: Connection refused <NL> [  270.274356] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 4 <NL> [  273.114437] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 5 <NL> [  273.842453] db_info.py[2395]: Traceback (most recent call last): <NL> [  273.843446] db_info.py[2395]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  273.849400] db_info.py[2395]:     main() <NL> [  273.851330] db_info.py[2395]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  273.853122] db_info.py[2395]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  273.891361] db_info.py[2395]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  273.894094] db_info.py[2395]:     self._init_connection() <NL> [  273.921021] db_info.py[2395]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  273.924278] db_info.py[2395]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  273.999356] db_info.py[2395]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  273.999491] db_info.py[2395]:     _tm.dp.connect( <NL> [  273.999604] db_info.py[2395]: _confd.error.EOF: ConfD closed connection <NL> [  274.657642] confd_phase_sentry[2427]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  274.735072] confd_phase_sentry[2427]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  276.123886] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 6 <NL> [  276.716407] rasis_system_stats.py[2432]: Traceback (most recent call last): <NL> [  276.716734] rasis_system_stats.py[2432]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  276.716851] rasis_system_stats.py[2432]:     main() <NL> [  276.716979] rasis_system_stats.py[2432]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  276.717105] rasis_system_stats.py[2432]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  276.717212] rasis_system_stats.py[2432]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  276.717321] rasis_system_stats.py[2432]:     self._init_connection() <NL> [  276.717398] rasis_system_stats.py[2432]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  276.717479] rasis_system_stats.py[2432]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  276.717555] rasis_system_stats.py[2432]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  276.717636] rasis_system_stats.py[2432]:     _tm.dp.connect( <NL> [  276.717739] rasis_system_stats.py[2432]: _confd.error.EOF: ConfD closed connection <NL> [  277.388310] healthcheck_result_display.py[2410]: Traceback (most recent call last): <NL> [  277.388624] healthcheck_result_display.py[2410]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  277.388775] healthcheck_result_display.py[2410]:     main(hc_utils.setup_logging(__name__)) <NL> [  277.388850] healthcheck_result_display.py[2410]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  277.388921] healthcheck_result_display.py[2410]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  277.389039] healthcheck_result_display.py[2410]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  277.389119] healthcheck_result_display.py[2410]:     self._init_connection() <NL> [  277.389186] healthcheck_result_display.py[2410]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  277.389282] healthcheck_result_display.py[2410]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  277.389363] healthcheck_result_display.py[2410]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock"}
{"timestamp_utc": "2024-07-31T08:17:34.475Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:34 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:34 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:36.988Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:17:36 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37247\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:39.526Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:39 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:39 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:42.040Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:17:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None <NL> [  235.844878] startup_finished.py[2030]: *****Startup Finished Monitor:Starting the event loop***** <NL> 2024-07-31 08:16:49,674 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  237.069206] ains_manager[2031]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  239.133891] usb_script_handler.py[1723]: usb: INFO - usb_base.check_manual_bind_unbind[251] kernel mimic check to manually verify usb presence"}
{"timestamp_utc": "2024-07-31T08:17:42.041Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  239.532289] ains_manager[2199]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  239.727719] startup[2036]: Startup, World! <NL> [  239.769065] startup[2036]: Cmd arg set to loop 1 <NL> [  242.072322] common_alarm_handler[2125]: gen_util: DDS_P2MP not available <NL> [  242.086349] common_alarm_handler[2125]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  242.627548] common_alarm_handler[2125]: topic = SystemProv; id = 1 <NL> [  242.668183] common_alarm_handler[2125]: topic = WdmcfgProv; id = 2 <NL> 2024-07-31 08:16:55,578 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  242.882840] common_alarm_handler[2125]: topic = LicenseStatusTopic; id = 3 <NL> [  245.008522] common_alarm_handler[2125]: topic = ShelfProv; id = 5 <NL> [  245.824874] common_alarm_handler[2125]: topic = SlotProv; id = 6 <NL> 2024-07-31 08:16:59,982 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:17:00,103 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  247.270485] common_alarm_handler[2125]: topic = PortProv; id = 7 <NL> 2024-07-31 08:17:01,613 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:17:02,987 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  250.053268] common_alarm_handler[2125]: topic = SubportProv; id = 8 <NL> 2024-07-31 08:17:04,290 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:17:07,930 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:17:08,020 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  254.792618] common_alarm_handler[2125]: topic = FconProv; id = 9 <NL> [  255.120401] common_alarm_handler[2125]: topic = XconProv; id = 10 <NL> [  255.143529] common_alarm_handler[2125]: topic = OchProv; id = 11 <NL> 2024-07-31 08:17:07,872 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:17:08,122 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> [  255.920958] common_alarm_handler[2125]: topic = OmsProv; id = 12 <NL> [  256.207080] common_alarm_handler[2125]: topic = OtsProv; id = 13 <NL> 2024-07-31 08:17:09,485 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:17:10,017 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> 2024-07-31 08:17:09,828 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  256.776856] common_alarm_handler[2125]: topic = EthernetProv; id = 14 <NL> 2024-07-31 08:17:11,813 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  259.268324] common_alarm_handler[2125]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  259.870490] common_alarm_handler[2125]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  260.154685] common_alarm_handler[2125]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  260.170289] common_alarm_handler[2125]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> 2024-07-31 08:17:13,680 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  260.554893] common_alarm_handler[2125]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  260.566889] common_alarm_handler[2125]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  260.573483] common_alarm_handler[2125]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  260.592325] common_alarm_handler[2125]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  260.923147] common_alarm_handler[2125]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> 2024-07-31 08:17:14,119 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  261.934938] common_alarm_handler[2125]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> 2024-07-31 08:17:17,484 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  264.887711] common_alarm_handler[2125]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  268.670816] common_alarm_handler[2125]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> 2024-07-31 08:17:23,375 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  270.613497] common_alarm_handler[2125]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> [  274.947947] common_alarm_handler[2125]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  275.341801] common_alarm_handler[2125]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  277.090570] common_alarm_handler[2125]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> 2024-07-31 08:17:30,619 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  279.883477] common_alarm_handler[2125]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> 2024-07-31 08:17:33,182 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  280.659740] common_alarm_handler[2125]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> 2024-07-31 08:17:35,242 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  283.213734] common_alarm_handler[2125]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  284.433338] common_alarm_handler[2125]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  284.901685] common_alarm_handler[2125]: topic = AlarmNotification; id = 40 <NL> [  284.929594] common_alarm_handler[2125]: topic = GenericOperInfoReq; id = 41 <NL> 2024-07-31 08:17:37,718 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  285.304019] common_alarm_handler[2125]: topic = PmRtrvReq; id = 42 <NL> [  285.784660] common_alarm_handler[2125]: topic = PmRtrvResp; id = 43 <NL> [  285.785449] common_alarm_handler[2125]: topic = PmInitReq; id = 44 <NL> [  286.207569] common_alarm_handler[2125]: topic = PmOperData; id = 45 <NL> [  286.234223] common_alarm_handler[2125]: topic = StateChange; id = 46 <NL> 2024-07-31 08:17:39,069 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  286.279461] common_alarm_handler[2125]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  286.904905] common_alarm_handler[2125]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  287.299338] common_alarm_handler[2125]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> 2024-07-31 08:17:40,250 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  287.588829] common_alarm_handler[2125]: topic = DcnStaticRouteRoutingInfoTable; id = 52"}
{"timestamp_utc": "2024-07-31T08:17:44.578Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:44 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:44 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:49.837Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:49 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:49 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:51.724Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "2024-07-31 08:15:45,865 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:15:45,868 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:15:45,948 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:45,948 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:45,948 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:45,949 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:15:45,978 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:15:45,986 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:15:45,987 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:45,987 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:45,988 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:15:45,989 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> REPO_REPL_EVT <NL> 2024-07-31 08:15:45,993 swdllite(agt): ERROR - swdl_agent_repo_repl.replicate[400] error(1): error: missing config <NL> 2024-07-31 08:15:45,993 swdllite(agt): ERROR - swdl_agent_staging.repo_repl_fn[400] non-recoverable error encountered <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:15:47,283 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:15:47,284 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:15:47,316 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  175.104835] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  175.105323] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  175.105418] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.588053, delay 0.03943\\n31 Jul 08:15:49 ntpdate[2513]: no server suitable for synchronization found\\n' <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:15:53,505 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:15:53,505 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  187.320933] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  187.321272] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  187.321357] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.589143, delay 0.03383\\n31 Jul 08:16:01 ntpdate[2570]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  199.351355] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  199.351971] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  199.352086] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.586581, delay 0.02809\\n31 Jul 08:16:13 ntpdate[2613]: no server suitable for synchronization found\\n' <NL> [  211.462908] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  211.463419] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  211.463546] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.590165, delay 0.05376\\n31 Jul 08:16:26 ntpdate[2639]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:16:31,372 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  223.769158] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  223.769544] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  223.769655] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.577624, delay 0.06113\\n31 Jul 08:16:38 ntpdate[2681]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:17:51.725Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[  236.019903] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  236.020670] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  236.020768] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.599798, delay 0.06229\\n31 Jul 08:16:50 ntpdate[2710]: no server suitable for synchronization found\\n' <NL> [  247.839952] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  247.842714] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  247.842830] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.582237, delay 0.03600\\n31 Jul 08:17:02 ntpdate[2759]: no server suitable for synchronization found\\n' <NL> [  259.983267] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  259.983669] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  259.983754] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.587577, delay 0.03255\\n31 Jul 08:17:14 ntpdate[2791]: no server suitable for synchronization found\\n' <NL> [  271.895822] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  271.907493] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  271.968023] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.581976, delay 0.04004\\n31 Jul 08:17:26 ntpdate[2818]: no server suitable for synchronization found\\n' <NL> [  283.712948] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  283.718430] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  283.719561] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.579627, delay 0.03908\\n31 Jul 08:17:38 ntpdate[2855]: no server suitable for synchronization found\\n' <NL> [  295.599714] ntputils_client.py[1716]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:17:51.981Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "2024-07-31 08:15:24,412 swdllite(agt): ERROR - swdl_agent_repo_repl.replicate[400] error(1): error: missing config <NL> 2024-07-31 08:15:24,412 swdllite(agt): ERROR - swdl_agent_staging.repo_repl_fn[400] non-recoverable error encountered <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:15:25,772 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:15:25,830 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:15:26,034 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  152.687739] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  152.732600] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  152.732723] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.319501, delay 0.04733\\n31 Jul 08:15:26 ntpdate[2388]: no server suitable for synchronization found\\n' <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:15:32,153 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:15:32,153 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  160.017069] python3[2482]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  160.017320] python3[2482]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  160.017432] python3[2482]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  160.017521] python3[2482]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  160.017599] python3[2482]: max_slotNumber=5 <NL> [  160.017671] python3[2482]:  prov channel is 127.0.0.1:10000 <NL> [  160.017762] python3[2482]: success: command executed <NL> [  160.205398] layer1_hal[2100]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  160.278001] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2359 <NL> [  164.734866] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  164.735381] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  164.735465] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.312513, delay 0.03839\\n31 Jul 08:15:38 ntpdate[2526]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  176.792043] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  176.792389] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  176.792471] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.312505, delay 0.02734\\n31 Jul 08:15:51 ntpdate[2567]: no server suitable for synchronization found\\n' <NL> [  188.668319] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  188.671045] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  188.720175] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.312841, delay 0.03287\\n31 Jul 08:16:02 ntpdate[2612]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:16:09,095 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  200.649177] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  200.677064] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:17:51.982Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[  200.698315] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.313480, delay 0.03001\\n31 Jul 08:16:14 ntpdate[2642]: no server suitable for synchronization found\\n' <NL> [  212.724688] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  212.725418] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  212.725514] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.312899, delay 0.02647\\n31 Jul 08:16:26 ntpdate[2668]: no server suitable for synchronization found\\n' <NL> [  224.869659] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  224.870220] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  224.870334] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.307074, delay 0.04581\\n31 Jul 08:16:39 ntpdate[2710]: no server suitable for synchronization found\\n' <NL> [  236.788777] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  236.789025] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  236.789139] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.312820, delay 0.02737\\n31 Jul 08:16:51 ntpdate[2755]: no server suitable for synchronization found\\n' <NL> [  248.917818] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  248.936643] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  248.968991] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.311104, delay 0.03227\\n31 Jul 08:17:03 ntpdate[2790]: no server suitable for synchronization found\\n' <NL> [  260.669614] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  260.709742] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  260.727806] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.316683, delay 0.03529\\n31 Jul 08:17:14 ntpdate[2817]: no server suitable for synchronization found\\n' <NL> [  272.623574] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  272.657659] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  272.677036] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.314307, delay 0.02908\\n31 Jul 08:17:26 ntpdate[2850]: no server suitable for synchronization found\\n' <NL> [  279.331117] hrtimer: interrupt took 3203252 ns <NL> [  284.475115] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  284.484778] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  284.485811] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.312297, delay 0.02850\\n31 Jul 08:17:38 ntpdate[2887]: no server suitable for synchronization found\\n' <NL> [  296.421123] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  296.421740] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:17:54.494Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:54 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:54.750Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:17:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:54 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:55.676Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  250.030447] confd_mgr[2975]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  250.030519] confd_mgr[2975]: cur_gdbissue 24-1-1 gdbissue 24-1-1 rc = 1 <NL> [  250.030591] confd_mgr[2975]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  250.030663] confd_mgr[2975]: L1-BLADE is in the list: L1-BLADE <NL> [  250.030737] confd_mgr[2975]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  250.030854] confd_mgr[2975]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  250.030933] confd_mgr[2975]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  250.031029] confd_mgr[2975]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  250.031105] confd_mgr[2975]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  250.031179] confd_mgr[2975]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  250.031253] confd_mgr[2975]: guard is_db_okay_g: The HA mode is NONE <NL> [  250.066493] confd_mgr[2975]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  250.107146] confd_mgr[2975]: entering: sm_startconfd::start_confd_p0 <NL> [  250.161997] confd_mgr[2975]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  250.200812] confd_mgr[3634]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:17:05 UTC 2024 <NL> [  250.228043] confd_mgr[2975]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  250.377589] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  250.387342] python3[2429]: [.846] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  252.163856] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 7 <NL> [  254.253474] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  254.254693] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  255.210712] txid_tracker[3284]: ::::create_confd_subscription_connection() try number 8 <NL> [  259.263226] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  259.273026] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  259.648906] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 1 <NL> [  260.375867] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  260.391237] python3[2429]: [.859] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  261.866156] healthcheck_agt.py[3694]: /bin/sh: line 1: podman: command not found <NL> [  262.659299] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 2 <NL> [  264.265637] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  264.265859] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  265.655661] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 3 <NL> [  268.673033] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 4 <NL> [  269.268171] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  269.268501] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  270.405394] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  270.405721] python3[2429]: [.891] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  271.732958] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 5 <NL> [  274.295496] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  274.295989] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  274.671256] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 6 <NL> [  277.674328] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 7 <NL> [  279.333527] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  279.333818] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  280.426172] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  280.496197] python3[2429]: [.913] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  280.701918] txid_tracker[3689]: ::::create_confd_subscription_connection() try number 8"}
{"timestamp_utc": "2024-07-31T08:17:55.677Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  284.328788] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  284.329834] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  284.909855] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 1 <NL> [  287.919920] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 2 <NL> [  289.324741] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  289.325320] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f090e5de5c7; Failed to connect to ConfD: Connection refused <NL> [  290.439471] python3[2429]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  290.439965] python3[2429]: [.926] hookhdlr 139635753535296 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  290.922230] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 3 <NL> [  293.976755] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 4 <NL> [  294.337054] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  294.369769] confd_phase_sentry[2445]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 45): 0x7f090e5de672; EOF on socket to ConfD <NL> [  296.976506] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 5 <NL> [  297.343138] healthcheck_result_display.py[2421]: Traceback (most recent call last): <NL> [  297.343525] healthcheck_result_display.py[2421]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  297.344478] healthcheck_result_display.py[2421]:     main(hc_utils.setup_logging(__name__)) <NL> [  297.344738] healthcheck_result_display.py[2421]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  297.345187] healthcheck_result_display.py[2421]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  297.345383] healthcheck_result_display.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  297.345974] healthcheck_result_display.py[2421]:     self._init_connection() <NL> [  297.346130] healthcheck_result_display.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  297.346646] healthcheck_result_display.py[2421]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  297.346846] healthcheck_result_display.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  297.347345] healthcheck_result_display.py[2421]:     _tm.dp.connect( <NL> [  297.347540] healthcheck_result_display.py[2421]: _confd.error.EOF: ConfD closed connection"}
{"timestamp_utc": "2024-07-31T08:17:57.603Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[  204.979785] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.344532, delay 0.03995\\n31 Jul 08:16:20 ntpdate[2523]: no server suitable for synchronization found\\n' <NL> [  216.933999] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  216.934733] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  216.934822] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.351053, delay 0.02687\\n31 Jul 08:16:32 ntpdate[2543]: no server suitable for synchronization found\\n' <NL> [  228.866331] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  228.875480] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  228.876631] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.351982, delay 0.03426\\n31 Jul 08:16:44 ntpdate[2565]: no server suitable for synchronization found\\n' <NL> [  240.981323] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  241.054886] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  241.066265] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.349333, delay 0.03099\\n31 Jul 08:16:56 ntpdate[2592]: no server suitable for synchronization found\\n' <NL> [  252.818787] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  252.819578] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  252.819729] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.350495, delay 0.02789\\n31 Jul 08:17:08 ntpdate[2623]: no server suitable for synchronization found\\n' <NL> [  264.683290] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  264.684138] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  264.684242] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.351284, delay 0.02795\\n31 Jul 08:17:20 ntpdate[2643]: no server suitable for synchronization found\\n' <NL> [  276.805472] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  276.805779] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  276.805860] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.351056, delay 0.03172\\n31 Jul 08:17:32 ntpdate[2657]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:17:42,146 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:17:42,183 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:17:42,286 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:17:42,293 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:17:42,316 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:17:42,279 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:17:42,376 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:17:42,421 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:17:42,459 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:17:42,419 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:17:42,431 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:17:42,490 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY"}
{"timestamp_utc": "2024-07-31T08:17:57.604Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "2024-07-31 08:17:42,560 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:17:42,599 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:17:42,605 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":1} <NL> 2024-07-31 08:17:42,635 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:17:42,685 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:17:42,768 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:17:42,769 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:17:42,769 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:17:42,790 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:17:42,791 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:17:42,791 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:17:42,792 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:17:42,793 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:17:42,793 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:17:42,825 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> openDdsPorts Output udpPorts-  7661 <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:17:43,826 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:17:43,835 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:17:43,868 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  288.747262] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  288.761862] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  288.817515] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.354767, delay 0.03596\\n31 Jul 08:17:44 ntpdate[2688]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:17:49,940 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:17:49,980 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn"}
{"timestamp_utc": "2024-07-31T08:17:58.532Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  288.135210] common_alarm_handler[2125]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> 2024-07-31 08:17:41,579 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:17:42,106 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  289.365989] cia_control_layer[2127]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:17:42,111 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  290.281557] usb_script_handler.py[1723]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> [  291.227310] usb_script_handler.py[1723]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  291.230298] usb_script_handler.py[1723]: usb: INFO - usb_ssw_main.mount_usb_secondary[106] trying to mount usb as secondary storage <NL> [  291.459277] usb_script_handler.py[1723]: usb: INFO - usb_ssw_main.mount_usb_secondary[108] checking for /dev/mapper/usb-secondary device <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  292.320762] usb_script_handler.py[1723]: usb: INFO - usb_ssw_main.mount_usb_secondary[111] found /dev/mapper/usb-secondary device <NL> [  293.116581] usb_script_handler.py[1723]: usb: INFO - usb_ssw_main.mount_usb_secondary[118] USB ssw mount successful <NL> [  293.172356] usb_script_handler.py[1723]: usb: INFO - usb_base.update_usb_psi_info[550] Publishing Mocked USB PSI Info on Qemu <NL> [  293.203629] usb_script_handler.py[1723]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  293.532405] usb_script_handler.py[1723]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> [  293.721936] common_alarm_handler[2125]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  294.148775] common_alarm_handler[2125]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  294.158862] common_alarm_handler[2125]: topic = EthIfProv; id = 56 <NL> [  294.166833] common_alarm_handler[2125]: topic = DcnNat64Attributes; id = 57 <NL> [  294.178402] common_alarm_handler[2125]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  294.235849] common_alarm_handler[2125]: topic = LldpGlobalCfgProv; id = 59 <NL> [  294.236773] common_alarm_handler[2125]: topic = LldpPortCfgProv; id = 60 <NL> [  294.247781] common_alarm_handler[2125]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  294.321146] common_alarm_handler[2125]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  294.332721] common_alarm_handler[2125]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  294.349889] common_alarm_handler[2125]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  294.361579] common_alarm_handler[2125]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  294.369875] common_alarm_handler[2125]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  294.395450] common_alarm_handler[2125]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  294.407195] common_alarm_handler[2125]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  294.415443] common_alarm_handler[2125]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  294.429834] common_alarm_handler[2125]: topic = DcnPppAttributesProv; id = 70 <NL> [  294.444148] common_alarm_handler[2125]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  294.564122] common_alarm_handler[2125]: topic = LldpBladeCfgProv; id = 72 <NL> [  294.585361] common_alarm_handler[2125]: topic = LldpPortInstCfgProv; id = 73 <NL> [  294.592559] common_alarm_handler[2125]: topic = DcnGreTunnelProv; id = 74 <NL> [  294.597866] common_alarm_handler[2125]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  294.641792] common_alarm_handler[2125]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  294.656879] common_alarm_handler[2125]: topic = DcnDnsClientOptionsProv; id = 77"}
{"timestamp_utc": "2024-07-31T08:17:58.533Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  294.691435] common_alarm_handler[2125]: topic = SysGnmiCertProv; id = 78 <NL> [  294.760891] common_alarm_handler[2125]: topic = IetfInterfaceProv; id = 79 <NL> [  294.777354] common_alarm_handler[2125]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  294.789991] common_alarm_handler[2125]: topic = SystemAutoLogoffProv; id = 81 <NL> [  294.806271] common_alarm_handler[2125]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  294.813472] common_alarm_handler[2125]: topic = SystemPortsProv; id = 83 <NL> [  294.826317] common_alarm_handler[2125]: topic = OspfProvisioningModeProv; id = 84 <NL> [  294.874811] common_alarm_handler[2125]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  294.906308] common_alarm_handler[2125]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  294.928914] common_alarm_handler[2125]: topic = BasicGroupProv; id = 87 <NL> [  294.987814] common_alarm_handler[2125]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  295.159046] common_alarm_handler[2125]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  295.602118] common_alarm_handler[2125]: topic = SystemFipsProv; id = 90 <NL> [  296.220476] common_alarm_handler[2125]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  296.598414] common_alarm_handler[2125]: topic = SecuritySystemwideProv; id = 92 <NL> [  296.631340] common_alarm_handler[2125]: topic = DataEncryptionProv; id = 93 <NL> [  296.888245] common_alarm_handler[2125]: topic = SystemServicesProv; id = 94 <NL> [  297.877561] common_alarm_handler[2125]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> ERROR:root:empty repository <NL> [  298.725180] common_alarm_handler[2125]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  298.921563] common_alarm_handler[2125]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  299.346836] common_alarm_handler[2125]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  300.335457] common_alarm_handler[2125]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  301.420644] common_alarm_handler[2125]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  301.805470] common_alarm_handler[2125]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  302.273663] common_alarm_handler[2125]: topic = SystemwideAcctOrderProv; id = 102 <NL> 2024-07-31 08:17:56,902 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:17:56,905 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:17:56,926 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:17:57,050 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:17:57,067 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  303.815073] usb_script_handler.py[2537]: 2024-Jul-31 08:17:15CommClient::CommClient Connection refused <NL> [  303.903302] usb_script_handler.py[2537]: 2024-Jul-31 08:17:17CommClient::CommClient Connection refused <NL> [  303.923152] usb_script_handler.py[2537]: 2024-Jul-31 08:17:20CommClient::CommClient Connection refused <NL> [  303.984180] usb_script_handler.py[2537]: 2024-Jul-31 08:17:22CommClient::CommClient Connection refused <NL> [  304.006845] usb_script_handler.py[2537]: 2024-Jul-31 08:17:24CommClient::CommClient Connection refused <NL> [  304.056020] usb_script_handler.py[2537]: 2024-Jul-31 08:17:26CommClient::CommClient Connection refused <NL> 2024-07-31 08:17:57,243 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  304.087461] usb_script_handler.py[2537]: 2024-Jul-31 08:17:28CommClient::CommClient Connection refused <NL> 2024-07-31 08:17:57,475 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  304.290612] usb_script_handler.py[2537]: 2024-Jul-31 08:17:31CommClient::CommClient Connection refused <NL> 2024-07-31 08:17:57,544 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0,"}
{"timestamp_utc": "2024-07-31T08:17:59.897Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:17:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:59 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:59 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:05.139Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:04 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:04 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:05.394Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:18:05 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37215\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:18:09.565Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:09 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:09.820Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:18:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:09 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:10.381Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:18:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:15.624Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:14 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:14 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:17.024Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "2024-07-31 08:17:23,092 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  266.418824] ntputils[1733]: bool NTPServer::handle_command(const string&) <NL> 2024-07-31 08:17:24,743 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  269.283628] ntputils[1733]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  269.362938] ntputils[1733]: got Platform::RedundancyMode: WORK <NL> [  269.363837] ntputils[1733]: got Platform::RedundancyStatus: STANDALONE <NL> [  269.364617] ntputils[1733]: my current red mode is: UNKNOWN <NL> [  269.391413] ntputils[1733]: new red mode is: WORK <NL> [  269.411392] ntputils[1733]: my current red status is: STANDALONE <NL> [  269.438765] ntputils[1733]: new red status is: STANDALONE <NL> 2024-07-31 08:17:26,838 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:17:26,857 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> [  270.588527] ntputils[1733]: red mode change, update: UNKNOWN => WORK <NL> [  272.456333] ntputils[1733]: no active/not-active status change: 0 <NL> 2024-07-31 08:17:30,283 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:17:30,305 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> [  276.425878] fujitsu-check-ssh-host-key.pl[2029]: Checking system account status... <NL> 2024-07-31 08:17:33,929 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  277.380612] fujitsu-check-ssh-host-key.pl[2029]: System account found... <NL> 2024-07-31 08:17:36,573 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  281.097884] fujitsu-check-ssh-host-key.pl[2029]: 3004 <NL> [  282.678124] fujitsu-check-ssh-host-key.pl[2029]: /bin/bash <NL> [  282.678935] fujitsu-check-ssh-host-key.pl[2029]: /home/system exists <NL> [  282.679698] fujitsu-check-ssh-host-key.pl[2029]: Checking for trib... <NL> [  282.850377] fujitsu-check-ssh-host-key.pl[2029]: Checking for PIU ... <NL> [  282.949172] fujitsu-check-ssh-host-key.pl[2029]: slot number (0) is not a PIU."}
{"timestamp_utc": "2024-07-31T08:18:17.025Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  283.332508] fujitsu-check-ssh-host-key.pl[2029]: Trib check done. <NL> 2024-07-31 08:17:39,947 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  285.970777] startup_finished.py[2053]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  286.644116] ains_manager[2054]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  286.774575] ains_manager[2477]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> 2024-07-31 08:17:43,884 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  287.836217] usb_script_handler.py[1742]: usb: INFO - usb_base.check_manual_bind_unbind[251] kernel mimic check to manually verify usb presence <NL> 2024-07-31 08:17:45,462 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:17:46,007 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  289.760685] startup[2057]: Startup, World! <NL> 2024-07-31 08:17:48,013 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:17:48,940 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  293.475356] startup[2057]: Cmd arg set to loop 1 <NL> [  295.514512] usb_script_handler.py[1742]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> 2024-07-31 08:17:52,067 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:17:52,398 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  296.441259] common_alarm_handler[2111]: gen_util: DDS_P2MP not available <NL> 2024-07-31 08:17:55,554 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:17:56,729 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> [  300.341611] common_alarm_handler[2111]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> 2024-07-31 08:18:00,408 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  303.962319] common_alarm_handler[2111]: topic = SystemProv; id = 1 <NL> [  305.824500] common_alarm_handler[2111]: topic = WdmcfgProv; id = 2 <NL> [  305.862226] common_alarm_handler[2111]: topic = LicenseStatusTopic; id = 3 <NL> 2024-07-31 08:18:02,837 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> [  305.899579] common_alarm_handler[2111]: topic = ShelfProv; id = 5 <NL> 2024-07-31 08:18:02,800 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:18:03,912 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> [  307.916181] common_alarm_handler[2111]: topic = SlotProv; id = 6 <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> [  309.444757] common_alarm_handler[2111]: topic = PortProv; id = 7 <NL> [  309.447875] common_alarm_handler[2111]: topic = SubportProv; id = 8 <NL> [  309.457529] common_alarm_handler[2111]: topic = FconProv; id = 9 <NL> [  309.547050] common_alarm_handler[2111]: topic = XconProv; id = 10 <NL> 2024-07-31 08:18:06,625 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> [  309.668994] common_alarm_handler[2111]: topic = OchProv; id = 11 <NL> [  310.329660] common_alarm_handler[2111]: topic = OmsProv; id = 12 <NL> 2024-07-31 08:18:06,798 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  310.560436] common_alarm_handler[2111]: topic = OtsProv; id = 13 <NL> 2024-07-31 08:18:09,363 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE[  313.841422] hrtimer: interrupt took 56100 ns <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  313.163958] common_alarm_handler[2111]: topic = EthernetProv; id = 14 <NL> 2024-07-31 08:18:12,669 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  315.922356] common_alarm_handler[2111]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> 2024-07-31 08:18:13,503 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  316.835608] common_alarm_handler[2111]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  318.537331] common_alarm_handler[2111]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  318.539151] common_alarm_handler[2111]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  318.542669] common_alarm_handler[2111]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  318.552264] common_alarm_handler[2111]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  318.561960] common_alarm_handler[2111]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> 2024-07-31 08:18:15,574 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\""}
{"timestamp_utc": "2024-07-31T08:18:20.302Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:19 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:19 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:21.229Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "\"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  304.309166] usb_script_handler.py[2537]: 2024-Jul-31 08:17:33CommClient::CommClient Connection refused <NL> [  304.377197] usb_script_handler.py[2537]: 2024-Jul-31 08:17:35CommClient::CommClient Connection refused <NL> [  304.409993] usb_script_handler.py[2537]: 2024-Jul-31 08:17:38CommClient::CommClient Connection refused <NL> [  304.420726] usb_script_handler.py[2537]: Exception: Connect failed <NL> [  304.440134] cia_control_layer[2127]: EsalConfig::EsalConfig main 1 <NL> [  304.474199] cia_control_layer[2127]: EsalConfig::EsalConfig trib 0 <NL> [  304.479247] cia_control_layer[2127]: EsalConfig::EsalConfig ciRole 0 <NL> [  304.482531] cia_control_layer[2127]: EsalConfig is not running inside container. <NL> [  304.488184] cia_control_layer[2127]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  304.495475] cia_control_layer[2127]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  304.518737] cia_control_layer[2127]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  304.525330] cia_control_layer[2127]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  304.540671] cia_control_layer[2127]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  304.549409] cia_control_layer[2127]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  304.554306] cia_control_layer[2127]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  304.559312] cia_control_layer[2127]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  304.565299] cia_control_layer[2127]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  304.573848] cia_control_layer[2127]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  304.600481] cia_control_layer[2127]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  304.612359] cia_control_layer[2127]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  304.633291] cia_control_layer[2127]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  304.692361] cia_control_layer[2127]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  304.723958] cia_control_layer[2127]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  304.742897] cia_control_layer[2127]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  304.850944] cia_control_layer[2127]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  305.080652] cia_control_layer[2127]: Control Layer started successfully. <NL> [  305.090481] cia_control_layer[2127]: Got the unitName from Platform General topic: BDC2-C200 <NL> [  305.096883] cia_control_layer[2127]: Xml found in the map for unitName: BDC2-C200 <NL> [  305.119929] cia_control_layer[2127]: Going with file C200_shelfData.xml <NL> [  305.136938] common_alarm_handler[2125]: topic = FscProv; id = 111 <NL> [  305.842623] common_alarm_handler[2125]: topic = XconProv_v2Prov; id = 112 <NL> [  307.553848] common_alarm_handler[2125]: topic = OchIfProv; id = 113 <NL> [  307.936250] common_alarm_handler[2125]: topic = AclProfileProv; id = 114 <NL> [  308.238632] common_alarm_handler[2125]: topic = OtuProv; id = 115 <NL> [  308.428586] common_alarm_handler[2125]: topic = GeProv; id = 116 <NL> [  309.177476] common_alarm_handler[2125]: topic = OduProv; id = 117 <NL> [  309.631477] common_alarm_handler[2125]: topic = TcmProv; id = 118 <NL> [  309.656381] common_alarm_handler[2125]: topic = OCnProv; id = 119 <NL> [  309.830324] common_alarm_handler[2125]: topic = OnDemandDM; id = 120 <NL> [  310.502500] common_alarm_handler[2125]: topic = OducnProv; id = 121 <NL> [  311.168149] common_alarm_handler[2125]: topic = OtsiProv; id = 122 <NL> [  311.558750] common_alarm_handler[2125]: topic = OtsigProv; id = 123 <NL> [  311.658083] common_alarm_handler[2125]: topic = OtucnProv; id = 124 <NL> [  311.921218] common_alarm_handler[2125]: topic = YpgProv; id = 125 <NL> [  312.474264] common_alarm_handler[2125]: topic = EpgProv; id = 126 <NL> [  312.805246] common_alarm_handler[2125]: topic = DataEncryptionInterfaceProv; id = 127 <NL> Exception: [  314.524920] common_alarm_handler[2125]: topic = DataEncryptionOperReq; id = 128 <NL> Connect failed[  314.842791] common_alarm_handler[2125]: topic = RoutePolicyTableProv; id = 129 <NL> [  315.280414] common_alarm_handler[2125]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  315.863098] common_alarm_handler[2125]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  315.922513] common_alarm_handler[2125]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  316.409597] common_alarm_handler[2125]: topic = ShapingProfileProv; id = 133 <NL> [  316.836786] common_alarm_handler[2125]: topic = TaildropProfileProv; id = 134 <NL> HA_MODE=1+1, MAIN_TRIB_RED=FALSE <NL> [  317.685459] common_alarm_handler[2125]: topic = PolicingProfileProv; id = 135 <NL> [  317.941671] common_alarm_handler[2125]: topic = CapabilityProfileProv; id = 136 <NL> [  318.181464] common_alarm_handler[2125]: topic = TransportInterfaceRateProv; id = 137 <NL> grep: /var/shared/confd/ResetType[  318.459041] common_alarm_handler[2125]: topic = PmRtrvReqSess; id = 138 <NL> : No such file or directory <NL> [  318.675758] common_alarm_handler[2125]: topic = PmRtrvRespSess; id = 139 <NL> [  318.809259] common_alarm_handler[2125]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  318.816899] common_alarm_handler[2125]: topic = DataEncryptionPskReq; id = 141 <NL> [  318.967638] common_alarm_handler[2125]: topic = SystemWebserverProv; id = 142 <NL> [  319.312404] common_alarm_handler[2125]: NO match: <NL> [  319.354788] common_alarm_handler[2125]: NO match: <NL> [  319.400833] common_alarm_handler[2125]: NO match: <NL> [  319.538068] sncp_app[2129]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  320.021928] cia_control_layer[2127]: Setting Pm xml files as below: <NL> [  320.475131] cia_control_layer[2127]: Shelf: C200_shelfPmData.xml <NL> [  320.477089] cia_control_layer[2127]: Port: C200_pluggablePmData.xml <NL> [  320.758313] cia_control_layer[2127]: Eth: C200_dcnL2EthernetIfData.xml <NL> [  320.825240] usb_script_handler.py[2539]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf noSecondaryStorage' <NL> [  321.257635] usb_script_handler.py[2539]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" noSecondaryStorage' <NL> [  321.740583] usb_script_handler.py[2539]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  323.007253] usb_script_handler.py[2539]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  323.884806] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  324.153885] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  324.313033] ntputils[1710]: child pid is 2758 <NL> [  324.563540] ntputils[1710]: exited, status is 0 <NL> [  325.684251] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift"}
{"timestamp_utc": "2024-07-31T08:18:21.230Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  325.708195] ntputils[1710]: poller time change delta is: 1 <NL> [  325.978907] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  326.222900] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  326.223838] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  326.224737] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  326.225460] ntputils[1710]: push_local_changes OK <NL> [  326.258288] confd_mgr_action_server[2132]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 200 <NL> [  326.360398] usb_script_handler.py[2531]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf invalidUSB'"}
{"timestamp_utc": "2024-07-31T08:18:21.791Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:18:21 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37247\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:18:25.053Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:24 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:24 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:26.940Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:18:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:30.222Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:29 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:29 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:35.462Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:34 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:34 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:40.723Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:39 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:39 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> [  327.043572] usb_script_handler.py[2531]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" invalidUSB' <NL> [  327.478123] usb_script_handler.py[2531]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  327.945284] usb_script_handler.py[2531]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  328.351255] ypg_app[2130]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  328.672797] python3[2142]: [.686] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  328.693059] python3[2142]: [.903] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  330.130304] python3[2142]: [.904] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  330.191257] python3[2142]: [.905] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  330.497734] python3[2142]: [.234] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  330.838748] python3[2142]: [.584] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  330.840049] python3[2142]: [.584] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  330.841257] python3[2142]: [.584] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  330.978829] python3[2142]: [.596] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  330.995354] python3[2142]: [.597] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  331.030572] python3[2142]: [.597] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  331.032114] python3[2142]: [.597] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  331.056215] python3[2142]: [.597] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  331.057684] python3[2142]: [.597] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  331.211446] python3[2142]: [.597] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  331.308810] python3[2142]: [.598] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  331.649918] python3[2142]: [.843] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  331.836569] python3[2142]: [.843] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> 2024-07-31 08:18:25,134 swdllite(mgr): INFO - swdl_base_fsm_fn.cmd_line_processing[110] executing command: ssw-sync <NL> [  332.084321] python3[2142]: [.843] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> 2024-07-31 08:18:26,237 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> /run/rdm_status.sh created successfully <NL> [  333.209609] python3[2142]: [.843] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> 2024-07-31 08:18:26,525 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  333.462959] python3[2142]: [.843] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> 2024-07-31 08:18:26,867 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  333.917455] python3[2142]: [.884] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> 2024-07-31 08:18:27,304 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  334.314751] python3[2142]: [.884] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  334.591548] python3[2142]: [.905] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  334.593386] python3[2142]: [.915] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr"}
{"timestamp_utc": "2024-07-31T08:18:40.724Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "2024-07-31 08:18:27,999 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> [  334.845721] python3[2142]: [.916] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  336.407456] python3[2142]: [.285] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> 2024-07-31 08:18:28,000 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  337.100848] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> 2024-07-31 08:18:30,639 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  337.928329] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> 2024-07-31 08:18:31,277 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  338.765159] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  339.619029] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> 2024-07-31 08:18:33,080 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  339.935869] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  340.405467] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  340.602725] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  341.072869] python3[2142]: [.391] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  341.855216] python3[2142]: [.412] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  342.341755] python3[2142]: [.417] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  342.695683] python3[2142]: [.417] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  344.263106] python3[2142]: [.417] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  344.691816] python3[2142]: [.417] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  345.305282] python3[2142]: [.418] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  345.573318] python3[2142]: [.418] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  345.776353] python3[2142]: [.599] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  346.337966] python3[2142]: [.614] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'}"}
{"timestamp_utc": "2024-07-31T08:18:41.287Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  318.577918] common_alarm_handler[2111]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  318.931647] common_alarm_handler[2111]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  319.116298] common_alarm_handler[2111]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> 2024-07-31 08:18:16,080 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  319.798816] common_alarm_handler[2111]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  320.839225] common_alarm_handler[2111]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> 2024-07-31 08:18:17,216 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  321.678093] common_alarm_handler[2111]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> 2024-07-31 08:18:19,446 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  322.902725] common_alarm_handler[2111]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> STANDALONE <NL> 2024-07-31 08:18:21,696 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  325.412839] common_alarm_handler[2111]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:18:23,327 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  326.717765] common_alarm_handler[2111]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  326.999853] common_alarm_handler[2111]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> 2024-07-31 08:18:23,936 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  327.163293] common_alarm_handler[2111]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  328.460498] common_alarm_handler[2111]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  328.461752] common_alarm_handler[2111]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  328.486804] common_alarm_handler[2111]: topic = AlarmNotification; id = 40 <NL> 2024-07-31 08:18:25,487 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  329.192340] common_alarm_handler[2111]: topic = GenericOperInfoReq; id = 41 <NL> 2024-07-31 08:18:27,153 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:18:27,201 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  330.367145] common_alarm_handler[2111]: topic = PmRtrvReq; id = 42 <NL> [  330.813221] common_alarm_handler[2111]: topic = PmRtrvResp; id = 43 <NL> [  330.814130] common_alarm_handler[2111]: topic = PmInitReq; id = 44 <NL> [  331.189493] common_alarm_handler[2111]: topic = PmOperData; id = 45 <NL> [  331.347303] common_alarm_handler[2111]: topic = StateChange; id = 46 <NL> [  331.355695] common_alarm_handler[2111]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  331.365301] common_alarm_handler[2111]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  331.383347] common_alarm_handler[2111]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> [  331.529028] common_alarm_handler[2111]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  331.605981] common_alarm_handler[2111]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  332.290596] usb_script_handler.py[1742]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> ERROR:root:empty repository <NL> [  332.536849] usb_script_handler.py[1742]: usb: INFO - usb_ssw_main.mount_usb_secondary[106] trying to mount usb as secondary storage <NL> [  332.772555] usb_script_handler.py[1742]: usb: INFO - usb_ssw_main.mount_usb_secondary[108] checking for /dev/mapper/usb-secondary device <NL> [  333.564441] usb_script_handler.py[1742]: usb: INFO - usb_ssw_main.mount_usb_secondary[111] found /dev/mapper/usb-secondary device <NL> [  334.363386] usb_script_handler.py[1742]: usb: INFO - usb_ssw_main.mount_usb_secondary[118] USB ssw mount successful <NL> [  334.738340] usb_script_handler.py[1742]: usb: INFO - usb_base.update_usb_psi_info[550] Publishing Mocked USB PSI Info on Qemu <NL> [  334.958987] usb_script_handler.py[1742]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> 2024-07-31 08:18:32,084 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  335.318852] usb_script_handler.py[1742]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> 2024-07-31 08:18:32,713 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  336.491781] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:18:33,582 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  337.076142] ntputils[1733]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:18:34,333 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  337.489759] ntputils[1733]: child pid is 2649 <NL> 2024-07-31 08:18:34,899 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  338.032362] ntputils[1733]: exited, status is 0 <NL> 2024-07-31 08:18:35,044 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  338.152889] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  338.433842] ntputils[1733]: poller time change delta is: 1 <NL> 2024-07-31 08:18:35,551 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  338.653239] ntputils[1733]: push_local_changes user_changed: 0 delta: 1 <NL> [  338.654131] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  338.656259] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> 2024-07-31 08:18:35,687 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2"}
{"timestamp_utc": "2024-07-31T08:18:41.288Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "} <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  338.702953] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  340.730044] ntputils[1733]: push_local_changes OK <NL> [  340.830605] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  340.981885] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  341.222276] ntputils[1733]: child pid is 2662 <NL> [  341.664161] ntputils[1733]: exited, status is 0 <NL> [  342.084105] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  342.410872] ntputils[1733]: poller time change delta is: 1 <NL> [  342.636364] ntputils[1733]: push_local_changes user_changed: 0 delta: 1 <NL> [  342.794430] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  342.986739] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  343.090596] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  343.092368] ntputils[1733]: push_local_changes OK <NL> [  343.105534] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  343.106914] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  343.107759] ntputils[1733]: child pid is 2690 <NL> [  343.177343] ntputils[1733]: exited, status is 0 <NL> [  343.179328] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift"}
{"timestamp_utc": "2024-07-31T08:18:42.652Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:18:42 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37215\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:18:45.165Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:44 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:44 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:47.678Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:18:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:50.197Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:49 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:49 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:55.476Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:18:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:54 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:54 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:56.038Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  277.404119] healthcheck_result_display.py[2410]:     _tm.dp.connect( <NL> [  277.442334] healthcheck_result_display.py[2410]: _confd.error.EOF: ConfD closed connection <NL> [  279.151850] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 7 <NL> [  279.509638] python3[2413]: [.062] hookhdlr 140116335949632 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  279.509879] python3[2413]: [.071] hookhdlr 140116335949632 callbackhdlr:293 Loading schemas <NL> [  279.511184] python3[2413]: DEBUG item does not exist - shared memory schema not enabled <NL> [  281.126718] python3[2413]: [.729] hookhdlr 140116335949632 callbackhdlr:382 Done load schemas <NL> [  281.130754] python3[2413]: [.730] hookhdlr 140116335949632 callbackhdlr:389 Done register transaction callback <NL> [  282.119938] txid_tracker[3726]: ::::create_confd_subscription_connection() try number 8 <NL> [  282.160068] python3[2413]: [.763] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  282.198508] python3[2413]: [.797] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  282.198687] python3[2413]: [.800] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  282.258093] python3[2413]: [.862] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  282.439838] python3[2413]: [.020] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  282.520379] python3[2413]: [.119] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  282.550081] python3[2413]: [.133] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  282.609424] python3[2413]: [.190] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  282.609608] python3[2413]: [.196] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  282.682113] python3[2413]: [.279] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  282.943689] python3[2413]: [.507] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  283.201120] python3[2413]: [.761] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  286.569440] python3[2413]: [.165] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  286.686975] txid_tracker[3784]: ::::create_confd_subscription_connection() connected <NL> [  289.169834] python3[2413]: [.751] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  292.634031] python3[2413]: [.231] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  295.192655] python3[2413]: [.796] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  298.306812] python3[2413]: [.902] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  298.372957] python3[2413]: [.974] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  298.410447] python3[2413]: [.003] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  298.410651] python3[2413]: [.008] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  298.452528] python3[2413]: [.022] hookhdlr 140116335949632 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  298.457672] python3[2413]: [.023] hookhdlr 140116335949632 callbackhdlr:391 Done register data callbacks <NL> [  355.716037] confd_mgr[2947]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  355.834215] confd_mgr[3922]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:18:50 UTC 2024 <NL> [  355.909132] confd_mgr[3922]: Starting valhdlr.service <NL> [  356.259116] confd_mgr[3922]: Starting validation-handler.service <NL> [  356.399181] confd_mgr[3922]: Starting snmp-fss-fw.service <NL> [  356.783767] confd_mgr[2947]: leaving: sm_startconfd::start_confd_p0 <NL> [  356.876298] confd_mgr[2947]: entering: sm_startconfd::wait_for_p0 <NL> [  356.952318] confd_mgr[2947]: PROCESS1 has not registered yet. <NL> [  356.952440] confd_mgr[2947]: PROCESS_SNMP_CLID has not registered yet. <NL> [  356.952517] confd_mgr[2947]: PROCESS_VALHDLR has not registered yet. <NL> [  357.408896] python3[2413]: DEBUG No crypto keys configured <NL> [  357.444121] python3[2413]: [.041] hookhdlr 140116335949632 callbackhdlr:401 Unable to install crypto keys! <NL> [  357.497162] python3[2413]: [.092] hookhdlr 140116335949632 callbackhdlr:322 Started data handler daemon... <NL> [  357.593319] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  357.690423] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  357.726427] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  357.726561] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  357.726654] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  357.726734] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  357.726812] confd_mgr[2947]: sm_startconfd::p0_ready_dbc <NL> [  357.726890] confd_mgr[2947]: Find message MESSAGE1 <NL> [  357.726977] confd_mgr[2947]: PROCESS_SNMP_CLID has not registered yet. <NL> [  357.727077] confd_mgr[2947]: PROCESS_VALHDLR has not registered yet. <NL> [  357.727311] confd_mgr[2947]: sm_startconfd::p0_not_ready <NL> [  357.727391] confd_mgr[2947]: Find message MESSAGE1 <NL> [  357.727469] confd_mgr[2947]: PROCESS_SNMP_CLID has not registered yet. <NL> [  357.727542] confd_mgr[2947]: PROCESS_VALHDLR has not registered yet. <NL> [  357.727614] confd_mgr[2947]: leaving: sm_startconfd::wait_for_p0 <NL> [  357.727691] confd_mgr[2947]: entering: sm_startconfd::wait_for_p0 <NL> [  357.727783] confd_mgr[2947]: PROCESS_SNMP_CLID has not registered yet. <NL> [  357.727855] confd_mgr[2947]: PROCESS_VALHDLR has not registered yet. <NL> [  357.727939] confd_mgr[2947]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  357.728059] confd_mgr[2947]: Timer /ConfdAT|wait_for_p0 already created <NL> [  357.728140] confd_mgr[2947]: ConfdHA Not supported command CONFIRM <NL> [  357.728340] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  357.728421] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  359.416896] python3[3931]: [.015] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  359.421518] python3[3931]: [.016] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  359.472661] python3[3931]: [.016] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  359.472767] python3[3931]: [.016] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  359.522242] python3[3931]: [.016] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  359.522401] python3[3931]: [.017] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  359.522516] python3[3931]: [.017] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  359.522673] python3[3931]: [.023] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  359.522775] python3[3931]: [.023] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  359.522852] python3[3931]: [.023] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  359.522929] python3[3931]: [.023] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  359.523045] python3[3931]: [.023] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  359.523127] python3[3931]: [.023] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'}"}
{"timestamp_utc": "2024-07-31T08:18:57.404Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  346.410329] python3[2142]: [.746] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  346.966328] python3[2142]: [.823] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  347.335063] python3[2142]: [.979] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  348.273925] python3[2142]: [.002] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  348.790542] python3[2142]: [.131] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  348.857269] python3[2142]: [.131] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  348.893235] python3[2142]: [.131] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  349.176964] python3[2142]: [.132] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  349.701796] python3[2142]: [.351] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  349.734054] python3[2142]: [.352] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  350.391357] python3[2142]: [.352] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  350.777315] python3[2142]: [.367] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  350.972980] python3[2142]: [.368] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  351.494303] usb_script_handler.py[2542]: {\"command\": \"ssw-sync\"} <NL> [  351.839125] usb_script_handler.py[2542]: {'return-value': 0, 'response-message': 'Ok, command accepted'} <NL> [  352.239113] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  352.298320] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  352.473668] ntputils[1710]: child pid is 2839 <NL> [  352.584390] ntputils[1710]: exited, status is 0 <NL> [  352.744771] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  352.952369] ntputils[1710]: poller time change delta is: 1 <NL> [  353.054869] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  353.197052] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  353.341119] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  353.462933] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  353.647349] ntputils[1710]: push_local_changes OK <NL> [  353.664928] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  353.807738] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  353.906276] ntputils[1710]: child pid is 2846 <NL> [  354.209349] ntputils[1710]: exited, status is 0 <NL> ERROR:root:empty repository <NL> [  354.400806] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  354.553604] ntputils[1710]: poller time change delta is: 1 <NL> [  354.602249] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  354.722883] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  354.857744] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  355.048930] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:18:48,395 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  355.267177] ntputils[1710]: push_local_changes OK <NL> 2024-07-31 08:18:48,718 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:18:48,873 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  355.800332] python3[2142]: [.368] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> 2024-07-31 08:18:49,613 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> Exception: [  356.430456] python3[2142]: [.468] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> 2024-07-31 08:18:49,857 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> Connect failed[  356.895534] python3[2142]: [.468] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> 2024-07-31 08:18:50,552 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  357.419794] python3[2142]: [.494] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> 2024-07-31 08:18:51,086 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  357.953850] python3[2142]: [.495] hookhdlr 140548059326272 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:18:51,501 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  358.268495] python3[2142]: [.495] hookhdlr 140548059326272 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> 2024-07-31 08:18:53,360 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  360.699982] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  362.392438] python3[2142]: [.495] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  362.648875] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  363.111307] python3[2142]: [.797] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  363.217919] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  363.283245] python3[2142]: [.955] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  363.364995] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  363.382466] python3[2142]: [.978] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  363.401858] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:18:57.405Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  363.415746] python3[2142]: [.016] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  363.435115] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  363.437274] python3[2142]: [.035] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  363.438713] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  363.439628] python3[2142]: [.075] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  363.500078] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  363.515980] python3[2142]: [.098] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  363.553539] confd_phase_sentry[2146]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set."}
{"timestamp_utc": "2024-07-31T08:18:58.331Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  343.200964] ntputils[1733]: poller time change delta is: 2 <NL> [  343.202144] ntputils[1733]: push_local_changes user_changed: 0 delta: 2 <NL> [  343.219380] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  343.250100] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  343.250920] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  343.263988] ntputils[1733]: push_local_changes OK <NL> [  343.517524] common_alarm_handler[2111]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  343.810926] common_alarm_handler[2111]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  343.811928] common_alarm_handler[2111]: topic = EthIfProv; id = 56 <NL> [  343.812681] common_alarm_handler[2111]: topic = DcnNat64Attributes; id = 57 <NL> [  343.929997] common_alarm_handler[2111]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  344.040612] common_alarm_handler[2111]: topic = LldpGlobalCfgProv; id = 59 <NL> [  344.548852] common_alarm_handler[2111]: topic = LldpPortCfgProv; id = 60 <NL> [  344.627774] common_alarm_handler[2111]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  344.642385] common_alarm_handler[2111]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  344.690463] common_alarm_handler[2111]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  344.691373] common_alarm_handler[2111]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  344.732223] common_alarm_handler[2111]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  344.733278] common_alarm_handler[2111]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  344.870806] common_alarm_handler[2111]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  345.213408] common_alarm_handler[2111]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  345.214485] common_alarm_handler[2111]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  345.385493] common_alarm_handler[2111]: topic = DcnPppAttributesProv; id = 70 <NL> [  345.398123] common_alarm_handler[2111]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  345.415511] common_alarm_handler[2111]: topic = LldpBladeCfgProv; id = 72 <NL> [  345.543180] common_alarm_handler[2111]: topic = LldpPortInstCfgProv; id = 73 <NL> [  345.822738] common_alarm_handler[2111]: topic = DcnGreTunnelProv; id = 74 <NL> [  346.282630] common_alarm_handler[2111]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  346.409297] common_alarm_handler[2111]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  346.467057] common_alarm_handler[2111]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  346.598799] common_alarm_handler[2111]: topic = SysGnmiCertProv; id = 78 <NL> [  346.685514] common_alarm_handler[2111]: topic = IetfInterfaceProv; id = 79 <NL> [  346.765845] common_alarm_handler[2111]: topic = DcnQosDcnQosAttributesProv; id = 80"}
{"timestamp_utc": "2024-07-31T08:18:58.332Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  346.807769] common_alarm_handler[2111]: topic = SystemAutoLogoffProv; id = 81 <NL> [  346.828423] common_alarm_handler[2111]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  347.033855] common_alarm_handler[2111]: topic = SystemPortsProv; id = 83 <NL> [  347.125770] common_alarm_handler[2111]: topic = OspfProvisioningModeProv; id = 84 <NL> Exception: [  347.320590] common_alarm_handler[2111]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> Connect failed <NL> [  347.479916] common_alarm_handler[2111]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  347.881579] common_alarm_handler[2111]: topic = BasicGroupProv; id = 87 <NL> [  347.893847] common_alarm_handler[2111]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  348.198881] common_alarm_handler[2111]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  348.735959] common_alarm_handler[2111]: topic = SystemFipsProv; id = 90 <NL> HA_MODE=1+1, MAIN_TRIB_RED=FALSE <NL> [  349.741236] common_alarm_handler[2111]: topic = SystemFipsCriteriaProv; id = 91 <NL> grep: [  350.013544] common_alarm_handler[2111]: topic = SecuritySystemwideProv; id = 92 <NL> /var/shared/confd/ResetType[  350.138747] common_alarm_handler[2111]: topic = DataEncryptionProv; id = 93 <NL> : No such file or directory[  350.274823] common_alarm_handler[2111]: topic = SystemServicesProv; id = 94 <NL> [  350.329891] common_alarm_handler[2111]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  350.433384] common_alarm_handler[2111]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  350.455752] common_alarm_handler[2111]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  350.587598] common_alarm_handler[2111]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  350.961630] common_alarm_handler[2111]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  351.006382] common_alarm_handler[2111]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  351.008290] common_alarm_handler[2111]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  351.040517] common_alarm_handler[2111]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  351.150514] trb-cdsf-app[2112]: DDD cdsf-app running <NL> 2024-07-31 08:18:48,314 swdllite(mgr): INFO - swdl_base_fsm_fn.cmd_line_processing[110] executing command: ssw-sync <NL> [  351.458546] usb_script_handler.py[2660]: 2024-Jul-31 08:18:05CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:48,548 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  351.687556] usb_script_handler.py[2660]: 2024-Jul-31 08:18:07CommClient::CommClient Connection refused <NL> [  352.104329] usb_script_handler.py[2660]: 2024-Jul-31 08:18:09CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:49,138 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  352.219634] usb_script_handler.py[2660]: 2024-Jul-31 08:18:12CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:49,336 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  352.651690] usb_script_handler.py[2660]: 2024-Jul-31 08:18:14CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:50,142 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  353.229138] usb_script_handler.py[2660]: 2024-Jul-31 08:18:16CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:50,628 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> [  353.802891] usb_script_handler.py[2660]: 2024-Jul-31 08:18:18CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:50,628 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  354.439951] usb_script_handler.py[2660]: 2024-Jul-31 08:18:20CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:51,801 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  355.243163] usb_script_handler.py[2660]: 2024-Jul-31 08:18:22CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:52,852 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  356.007368] usb_script_handler.py[2660]: 2024-Jul-31 08:18:24CommClient::CommClient Connection refused <NL> [  356.482431] usb_script_handler.py[2660]: 2024-Jul-31 08:18:26CommClient::CommClient Connection refused <NL> 2024-07-31 08:18:53,778 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  356.998972] usb_script_handler.py[2660]: Exception: Connect failed <NL> [  358.357629] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  358.548851] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  358.683324] ntputils[1733]: child pid is 2779 <NL> [  358.717227] ntputils[1733]: exited, status is 0 <NL> [  358.892852] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  359.042538] ntputils[1733]: poller time change delta is: 1 <NL> [  359.342917] ntputils[1733]: push_local_changes user_changed: 0 delta: 1 <NL> [  359.590744] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  359.660637] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  359.887280] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  360.098914] ntputils[1733]: push_local_changes OK"}
{"timestamp_utc": "2024-07-31T08:18:59.275Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  363.575919] confd_phase_sentry[2146]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  363.597079] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.608338] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.636990] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.656461] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.666626] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.670701] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.682793] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.702505] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.712414] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.719994] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.721036] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.723360] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.724393] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.757407] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.848172] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.892754] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.897986] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.900244] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.901354] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.903903] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.904915] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.907159] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  363.927725] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  363.982185] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.017498] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.055681] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.081507] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.114219] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:18:59.276Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  364.125533] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.160634] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.237789] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.286195] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.292287] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.313330] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.322497] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.340685] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.361157] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.405669] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.421862] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.446366] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.460322] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.487674] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.496267] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.516616] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.527233] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.551632] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.704755] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  364.774818] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.814263] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:18:59.840Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:18:59 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37247\" AuthenticationException('Authentication timeout.',) <NL> # 03:18:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:59 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:59 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:00.098Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  299.371642] confd_phase_sentry[2445]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  299.431791] confd_phase_sentry[2445]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  299.596225] rasis_system_stats.py[2447]: Traceback (most recent call last): <NL> [  299.667114] rasis_system_stats.py[2447]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  299.733856] rasis_system_stats.py[2447]:     main() <NL> [  299.771700] rasis_system_stats.py[2447]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  299.867129] rasis_system_stats.py[2447]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  299.951572] rasis_system_stats.py[2447]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  299.952902] rasis_system_stats.py[2447]:     self._init_connection() <NL> [  299.994481] rasis_system_stats.py[2447]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  300.051707] rasis_system_stats.py[2447]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  300.095885] rasis_system_stats.py[2447]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  300.154833] rasis_system_stats.py[2447]:     _tm.dp.connect( <NL> [  300.211727] rasis_system_stats.py[2447]: _confd.error.EOF: ConfD closed connection <NL> [  300.241909] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 6 <NL> [  300.597170] python3[2429]: DEBUG EOF on socket to ConfD <NL> [  300.598101] python3[2429]: [.067] hookhdlr 139635753535296 callbackhdlr:457 Exception to create daemon <NL> [  300.616910] python3[2429]: Traceback (most recent call last): <NL> [  300.617868] python3[2429]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  300.619153] python3[2429]:     daemon = self.create_daemon() <NL> [  300.655405] python3[2429]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  300.657207] python3[2429]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  300.658191] python3[2429]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  300.673114] python3[2429]:     self._init_connection() <NL> [  300.673926] python3[2429]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  300.676027] python3[2429]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  300.677237] python3[2429]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  300.678847] python3[2429]:     _tm.dp.connect( <NL> [  300.680999] python3[2429]: _confd.error.EOF: ConfD closed connection <NL> [  300.683043] python3[2429]: [.070] hookhdlr 139635753535296 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  300.922788] db_info.py[2405]: Traceback (most recent call last): <NL> [  300.934118] db_info.py[2405]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  300.993349] db_info.py[2405]:     main() <NL> [  301.034984] db_info.py[2405]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  301.043408] db_info.py[2405]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  301.058575] db_info.py[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  301.061767] db_info.py[2405]:     self._init_connection() <NL> [  301.080312] db_info.py[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  301.113195] db_info.py[2405]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  301.114299] db_info.py[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  301.115597] db_info.py[2405]:     _tm.dp.connect( <NL> [  301.116529] db_info.py[2405]: _confd.error.EOF: ConfD closed connection <NL> [  303.076918] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 7 <NL> [  306.080253] txid_tracker[3739]: ::::create_confd_subscription_connection() try number 8 <NL> [  310.560766] txid_tracker[3793]: ::::create_confd_subscription_connection() connected <NL> [  310.634922] python3[2429]: [.098] hookhdlr 139635753535296 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  310.769215] python3[2429]: [.255] hookhdlr 139635753535296 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  310.769444] python3[2429]: [.256] hookhdlr 139635753535296 callbackhdlr:293 Loading schemas <NL> [  310.830627] python3[2429]: DEBUG item does not exist - shared memory schema not enabled <NL> [  312.881663] python3[2429]: [.365] hookhdlr 139635753535296 callbackhdlr:382 Done load schemas <NL> [  312.882864] python3[2429]: [.365] hookhdlr 139635753535296 callbackhdlr:389 Done register transaction callback <NL> [  313.784925] python3[2429]: [.252] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  313.835779] python3[2429]: [.295] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  313.852865] python3[2429]: [.340] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  314.016638] python3[2429]: [.503] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  314.547716] python3[2429]: [.035] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  314.901390] python3[2429]: [.388] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  314.989881] python3[2429]: [.470] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  315.003339] python3[2429]: [.490] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  315.163629] python3[2429]: [.649] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  315.217735] python3[2429]: [.696] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  315.457620] python3[2429]: [.943] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  315.542239] python3[2429]: [.026] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  318.932890] python3[2429]: [.419] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  320.511629] python3[2429]: [.983] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  322.806170] python3[2429]: [.292] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  325.073241] python3[2429]: [.548] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  327.316805] python3[2429]: [.803] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  327.381162] python3[2429]: [.862] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  327.435875] python3[2429]: [.923] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  327.472956] python3[2429]: [.955] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  327.524981] python3[2429]: [.006] hookhdlr 139635753535296 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  327.525265] python3[2429]: [.006] hookhdlr 139635753535296 callbackhdlr:391 Done register data callbacks <NL> [  362.731178] confd_mgr[2975]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  362.771162] confd_mgr[3921]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:18:58 UTC 2024 <NL> [  362.793157] confd_mgr[3921]: Starting valhdlr.service"}
{"timestamp_utc": "2024-07-31T08:19:00.099Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  363.148763] confd_mgr[3921]: Starting validation-handler.service <NL> [  363.208284] confd_mgr[3921]: Starting snmp-fss-fw.service <NL> [  363.608420] python3[2429]: DEBUG No crypto keys configured <NL> [  363.608710] python3[2429]: [.995] hookhdlr 139635753535296 callbackhdlr:401 Unable to install crypto keys! <NL> [  363.691837] confd_mgr[2975]: leaving: sm_startconfd::start_confd_p0 <NL> [  359.523199] python3[3931]: [.058] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  359.523405] python3[3931]: [.058] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  359.638650] python3[3931]: [.058] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  359.700735] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  359.708509] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  359.708804] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  359.709191] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  359.709476] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  359.709829] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  359.796496] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  359.796621] python3[3931]: [.059] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  359.796819] python3[3931]: [.276] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  359.868325] python3[3931]: [.276] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  359.868430] python3[3931]: [.280] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  359.868530] python3[3931]: [.280] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  359.868607] python3[3931]: [.280] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  359.868681] python3[3931]: [.280] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  359.868754] python3[3931]: [.280] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  359.868833] python3[3931]: [.280] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  359.869030] python3[3931]: [.281] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  359.869110] python3[3931]: [.281] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  359.869192] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  359.869285] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  359.869402] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  359.869478] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  359.869551] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  359.869624] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  359.869736] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  359.869810] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  359.869883] python3[3931]: [.360] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  359.870243] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  359.870385] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  359.870462] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  359.870536] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  359.870610] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  359.870684] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  359.870758] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  359.870848] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  359.892322] python3[3931]: [.361] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  359.993616] python3[3931]: [.375] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  359.993724] python3[3931]: [.376] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  359.993818] python3[3931]: [.376] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  359.993898] python3[3931]: [.376] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  359.993984] python3[3931]: [.376] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  359.994086] python3[3931]: [.376] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  359.994230] python3[3931]: [.376] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  360.013381] python3[3931]: [.618] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  360.065881] python3[3931]: [.618] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  360.066040] python3[3931]: [.619] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  360.066355] python3[3931]: [.619] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  360.066591] python3[3931]: [.619] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  360.066841] python3[3931]: [.619] valhdlr 140234579945280 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  360.098727] python3[3931]: [.619] valhdlr 140234579945280 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  360.177776] python3[3931]: [.761] valhdlr 140234579945280 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  360.177976] python3[3931]: [.762] valhdlr 140234579945280 callbackhdlr:293 Loading schemas <NL> [  360.227935] python3[3931]: DEBUG item does not exist - shared memory schema not enabled <NL> [  361.024060] snmp_clid[3935]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  362.993833] python3[3931]: [.589] valhdlr 140234579945280 callbackhdlr:382 Done load schemas <NL> [  363.039370] python3[3931]: [.624] valhdlr 140234579945280 callbackhdlr:389 Done register transaction callback <NL> [  363.806089] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  363.806587] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  363.806699] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  363.806782] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  363.806855] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  363.806926] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  363.810854] confd_mgr[2947]: ConfdHA Not supported command CONFIRM"}
{"timestamp_utc": "2024-07-31T08:19:02.626Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  363.691973] confd_mgr[2975]: entering: sm_startconfd::wait_for_p0 <NL> [  363.692065] confd_mgr[2975]: PROCESS1 has not registered yet. <NL> [  363.692147] confd_mgr[2975]: PROCESS_SNMP_CLID has not registered yet. <NL> [  363.692224] confd_mgr[2975]: PROCESS_VALHDLR has not registered yet. <NL> [  363.692337] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  363.692416] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  363.692500] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  363.692587] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  363.692676] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  363.692802] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  363.692879] confd_mgr[2975]: ConfdHA Not supported command CONFIRM <NL> [  363.693212] python3[2429]: [.041] hookhdlr 139635753535296 callbackhdlr:322 Started data handler daemon... <NL> [  363.758755] confd_mgr[2975]: sm_startconfd::p0_ready_dbc <NL> [  363.823197] confd_mgr[2975]: Find message MESSAGE1 <NL> [  363.823320] confd_mgr[2975]: PROCESS_SNMP_CLID has not registered yet. <NL> [  363.823400] confd_mgr[2975]: PROCESS_VALHDLR has not registered yet. <NL> [  363.823475] confd_mgr[2975]: sm_startconfd::p0_not_ready <NL> [  363.823573] confd_mgr[2975]: Find message MESSAGE1 <NL> [  363.823649] confd_mgr[2975]: PROCESS_SNMP_CLID has not registered yet. <NL> [  363.823720] confd_mgr[2975]: PROCESS_VALHDLR has not registered yet. <NL> [  363.823790] confd_mgr[2975]: leaving: sm_startconfd::wait_for_p0 <NL> [  363.833880] confd_mgr[2975]: entering: sm_startconfd::wait_for_p0 <NL> [  363.834120] confd_mgr[2975]: PROCESS_SNMP_CLID has not registered yet. <NL> [  363.834223] confd_mgr[2975]: PROCESS_VALHDLR has not registered yet."}
{"timestamp_utc": "2024-07-31T08:19:02.627Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  363.834308] confd_mgr[2975]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  363.834389] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  363.834460] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  363.836333] confd_mgr[2975]: Timer /ConfdAT|wait_for_p0 already created <NL> [  365.503917] python3[3929]: [.980] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.504423] python3[3929]: [.980] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.504552] python3[3929]: [.981] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.504633] python3[3929]: [.981] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.504707] python3[3929]: [.981] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  365.504778] python3[3929]: [.981] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  365.504885] python3[3929]: [.981] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  365.522086] python3[3929]: [.998] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  365.560813] python3[3929]: [.999] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.560924] python3[3929]: [.999] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.560998] python3[3929]: [.999] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.561094] python3[3929]: [.999] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.561170] python3[3929]: [.999] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  365.562214] python3[3929]: [.049] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  365.562704] python3[3929]: [.050] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.562969] python3[3929]: [.050] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.563232] python3[3929]: [.051] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.570525] python3[3929]: [.057] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.570667] python3[3929]: [.057] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  365.570744] python3[3929]: [.057] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  365.570860] python3[3929]: [.058] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  365.570938] python3[3929]: [.058] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  365.571057] python3[3929]: [.058] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  365.571545] python3[3929]: [.059] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  365.602635] python3[3929]: [.090] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  365.827440] python3[3929]: [.121] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.866132] python3[3929]: [.121] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.866305] python3[3929]: [.121] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.866389] python3[3929]: [.121] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.866465] python3[3929]: [.121] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  365.866538] python3[3929]: [.122] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  365.866627] python3[3929]: [.122] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  365.866702] python3[3929]: [.122] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  365.866912] python3[3929]: [.122] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  365.867067] python3[3929]: [.125] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  365.867144] python3[3929]: [.126] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.867218] python3[3929]: [.126] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.867307] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.867382] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.867456] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  365.867572] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  365.867647] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  365.867744] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  365.867822] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  365.868016] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  365.868180] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'}"}
{"timestamp_utc": "2024-07-31T08:19:05.146Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:19:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:04 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:04 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:10.390Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:09 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:09 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> [  364.872947] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  364.895214] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.060174] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.061264] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.094463] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.248456] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.338119] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.366633] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.467238] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.577787] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.579904] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.618359] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.643380] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.774741] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.935434] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.943433] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.973642] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.974640] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  365.993314] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  365.994260] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  366.338564] temp_acct_cleanup_app[2153]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  366.398617] temp_acct_cleanup_app[2153]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  366.473258] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 1 <NL> [  366.539823] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 2 <NL> [  366.596536] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 3 <NL> [  366.597541] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 4 <NL> [  366.618281] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 5 <NL> [  366.626999] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 6 <NL> [  366.668539] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 7 <NL> [  366.678932] txid_tracker[2155]: ::::create_confd_subscription_connection() try number 8 <NL> [  367.060137] cseries_hal[2162]: HAL main() begins. <NL> [  367.133080] cseries_hal[2162]: hal_default::hal_init() called <NL> [  367.166232] cseries_hal[2162]: EsalPmiClient::EsalPmiClient <NL> [  367.285515] trb-cdsf-app[2126]: DDD cdsf-app running <NL> [  368.002550] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  368.132263] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  368.656376] startup_finished.py[2030]: Startup Finished: systemd state is non-Production mode and running <NL> [  368.987201] confd_director.py[2946]: rm: cannot remove '/var/shared/confd/ha_status': No such file or directory"}
{"timestamp_utc": "2024-07-31T08:19:10.391Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  369.519918] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  369.560820] python3[2142]: [.331] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  369.926819] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 1 <NL> [  370.112956] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 2 <NL> [  370.232586] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 3 <NL> [  370.473438] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 4 <NL> [  370.549111] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 5 <NL> [  370.574267] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 6 <NL> [  370.793262] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 7 <NL> [  370.889829] txid_tracker[2317]: ::::create_confd_subscription_connection() try number 8 <NL> [  370.975850] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 1 <NL> [  371.071149] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 2 <NL> [  371.182424] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 3 <NL> [  371.385769] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 4 <NL> [  371.542675] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 5 <NL> [  371.837104] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 6 <NL> [  372.075065] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 7 <NL> [  372.316814] txid_tracker[2502]: ::::create_confd_subscription_connection() try number 8 <NL> [  372.841375] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 1 <NL> [  373.094140] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 2 <NL> [  373.497694] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 3 <NL> [  373.669141] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 4 <NL> [  374.161463] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 5 <NL> [  374.350197] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 6 <NL> [  374.594311] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 7 <NL> [  374.595462] txid_tracker[2632]: ::::create_confd_subscription_connection() try number 8 <NL> [  374.790368] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  374.866357] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  374.884523] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 1 <NL> [  375.271325] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 2 <NL> [  375.401777] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 3 <NL> [  375.696438] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 4"}
{"timestamp_utc": "2024-07-31T08:19:11.319Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  360.112217] common_alarm_handler[2111]: topic = FscProv; id = 111 <NL> [  360.113089] common_alarm_handler[2111]: topic = XconProv_v2Prov; id = 112 <NL> [  360.113877] common_alarm_handler[2111]: topic = OchIfProv; id = 113 <NL> [  360.226869] common_alarm_handler[2111]: topic = AclProfileProv; id = 114 <NL> [  360.249899] common_alarm_handler[2111]: topic = OtuProv; id = 115 <NL> [  360.585710] common_alarm_handler[2111]: topic = GeProv; id = 116 <NL> [  360.623025] common_alarm_handler[2111]: topic = OduProv; id = 117 <NL> [  360.804704] common_alarm_handler[2111]: topic = TcmProv; id = 118 <NL> [  360.971388] common_alarm_handler[2111]: topic = OCnProv; id = 119 <NL> [  361.040317] common_alarm_handler[2111]: topic = OnDemandDM; id = 120 <NL> [  361.275847] common_alarm_handler[2111]: topic = OducnProv; id = 121 <NL> [  361.547296] common_alarm_handler[2111]: topic = OtsiProv; id = 122 <NL> [  362.599224] common_alarm_handler[2111]: topic = OtsigProv; id = 123 <NL> [  362.748813] common_alarm_handler[2111]: topic = OtucnProv; id = 124 <NL> [  362.992452] common_alarm_handler[2111]: topic = YpgProv; id = 125 <NL> [  363.068677] common_alarm_handler[2111]: topic = EpgProv; id = 126 <NL> [  363.368921] common_alarm_handler[2111]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  363.387221] common_alarm_handler[2111]: topic = DataEncryptionOperReq; id = 128 <NL> [  363.465817] common_alarm_handler[2111]: topic = RoutePolicyTableProv; id = 129 <NL> /run/rdm_status.sh created successfully <NL> [  363.743254] common_alarm_handler[2111]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  364.548462] common_alarm_handler[2111]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  365.192221] common_alarm_handler[2111]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  365.253760] common_alarm_handler[2111]: topic = ShapingProfileProv; id = 133 <NL> [  365.756452] common_alarm_handler[2111]: topic = TaildropProfileProv; id = 134 <NL> [  365.883700] common_alarm_handler[2111]: topic = PolicingProfileProv; id = 135 <NL> [  365.947210] common_alarm_handler[2111]: topic = CapabilityProfileProv; id = 136 <NL> [  365.948283] common_alarm_handler[2111]: topic = TransportInterfaceRateProv; id = 137 <NL> [  365.949282] common_alarm_handler[2111]: topic = PmRtrvReqSess; id = 138 <NL> [  365.988764] common_alarm_handler[2111]: topic = PmRtrvRespSess; id = 139 <NL> [  365.989846] common_alarm_handler[2111]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  365.992251] common_alarm_handler[2111]: topic = DataEncryptionPskReq; id = 141 <NL> [  366.019570] common_alarm_handler[2111]: topic = SystemWebserverProv; id = 142 <NL> [  366.093850] common_alarm_handler[2111]: NO match: <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  366.205661] common_alarm_handler[2111]: NO match: <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  366.390805] common_alarm_handler[2111]: NO match: <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  366.833043] cia_control_layer[2113]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  367.241149] cia_control_layer[2113]: EsalConfig::EsalConfig main 1 <NL> [  367.471451] cia_control_layer[2113]: EsalConfig::EsalConfig trib 0 <NL> [  367.658838] cia_control_layer[2113]: EsalConfig::EsalConfig ciRole 0 <NL> [  367.911865] cia_control_layer[2113]: EsalConfig is not running inside container."}
{"timestamp_utc": "2024-07-31T08:19:11.320Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  368.484288] cia_control_layer[2113]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  368.526361] cia_control_layer[2113]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  368.842625] cia_control_layer[2113]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  369.261041] cia_control_layer[2113]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  369.384949] cia_control_layer[2113]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> ERROR:root:empty repository <NL> [  369.680344] cia_control_layer[2113]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  369.936275] cia_control_layer[2113]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  370.376682] cia_control_layer[2113]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  370.489795] cia_control_layer[2113]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  370.823399] cia_control_layer[2113]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  370.912359] cia_control_layer[2113]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> 2024-07-31 08:19:07,986 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  371.033931] cia_control_layer[2113]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> 2024-07-31 08:19:08,115 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  371.211868] cia_control_layer[2113]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  371.503722] cia_control_layer[2113]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  371.543160] cia_control_layer[2113]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  371.544187] cia_control_layer[2113]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> 2024-07-31 08:19:08,580 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  371.590253] cia_control_layer[2113]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> 2024-07-31 08:19:08,625 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  371.638246] cia_control_layer[2113]: Control Layer started successfully. <NL> 2024-07-31 08:19:08,664 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  371.678371] cia_control_layer[2113]: Got the unitName from Platform General topic: BDC2-C200 <NL> 2024-07-31 08:19:08,723 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  371.742174] cia_control_layer[2113]: Xml found in the map for unitName: BDC2-C200 <NL> 2024-07-31 08:19:08,789 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  371.810412] cia_control_layer[2113]: Going with file C200_shelfData.xml <NL> [  371.811468] cia_control_layer[2113]: Setting Pm xml files as below: <NL> [  371.813657] cia_control_layer[2113]: Shelf: C200_shelfPmData.xml <NL> [  371.836146] cia_control_layer[2113]: Port: C200_pluggablePmData.xml <NL> [  371.836985] cia_control_layer[2113]: Eth: C200_dcnL2EthernetIfData.xml <NL> [  371.918563] usb_script_handler.py[2576]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf invalidUSB' <NL> 2024-07-31 08:19:09,050 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  372.257729] usb_script_handler.py[2576]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" invalidUSB' <NL> [  372.942103] usb_script_handler.py[2576]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  373.083287] usb_script_handler.py[2576]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm invalidUSB invalidUSB'"}
{"timestamp_utc": "2024-07-31T08:19:15.484Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:14 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:14 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> [  373.184669] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  373.216811] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  373.290133] ntputils[1733]: child pid is 2851 <NL> [  373.381101] ntputils[1733]: exited, status is 0 <NL> [  373.382181] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  373.391628] ntputils[1733]: poller time change delta is: 1 <NL> [  373.398719] ntputils[1733]: push_local_changes user_changed: 0 delta: 1 <NL> [  373.413439] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  373.444200] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  373.468846] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  373.482610] ntputils[1733]: push_local_changes OK <NL> [  373.513913] usb_script_handler.py[2579]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf noSecondaryStorage' <NL> [  373.632817] usb_script_handler.py[2579]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" noSecondaryStorage' <NL> [  373.746613] usb_script_handler.py[2579]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  373.748288] usb_script_handler.py[2579]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  373.799799] sncp_app[2115]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  373.871417] usb_script_handler.py[2652]: {\"command\": \"ssw-sync\"} <NL> [  373.947318] usb_script_handler.py[2652]: {'return-value': 0, 'response-message': 'Ok, command accepted'} <NL> [  374.027973] ypg_app[2116]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  374.207137] confd_mgr_action_server[2118]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 200 <NL> [  375.296198] python3[2128]: [.414] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  375.469275] python3[2128]: [.415] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  375.819633] python3[2128]: [.431] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'}"}
{"timestamp_utc": "2024-07-31T08:19:15.485Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  376.003364] python3[2128]: [.431] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  376.072149] python3[2128]: [.440] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  376.151877] python3[2128]: [.453] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  376.205159] python3[2128]: [.454] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  376.235549] python3[2128]: [.454] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  376.269141] python3[2128]: [.454] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  376.301730] python3[2128]: [.454] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  376.333369] python3[2128]: [.454] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  376.362710] python3[2128]: [.482] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  376.370970] python3[2128]: [.482] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  376.372348] python3[2128]: [.482] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  376.415240] python3[2128]: [.499] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  376.421194] python3[2128]: [.499] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  376.422551] python3[2128]: [.516] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  376.469952] python3[2128]: [.517] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  376.503078] python3[2128]: [.517] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  376.631902] python3[2128]: [.517] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  376.705310] python3[2128]: [.517] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  376.721381] python3[2128]: [.517] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  376.722792] python3[2128]: [.526] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  376.775331] python3[2128]: [.526] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  376.780428] python3[2128]: [.536] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  376.781684] python3[2128]: [.536] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  376.811529] python3[2128]: [.544] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  376.842893] python3[2128]: [.545] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  376.845765] python3[2128]: [.545] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  376.847336] python3[2128]: [.556] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  376.893449] python3[2128]: [.556] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  376.908092] python3[2128]: [.556] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  376.909598] python3[2128]: [.556] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  376.987299] python3[2128]: [.556] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  377.021977] python3[2128]: [.557] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  377.036176] python3[2128]: [.557] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  377.037570] python3[2128]: [.557] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  377.068764] python3[2128]: [.568] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  377.241862] python3[2128]: [.568] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  377.274192] python3[2128]: [.632] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  377.275718] python3[2128]: [.694] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  377.303989] python3[2128]: [.694] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'}"}
{"timestamp_utc": "2024-07-31T08:19:15.486Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  377.305410] python3[2128]: [.694] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  377.306723] python3[2128]: [.694] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  377.326647] python3[2128]: [.745] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  377.328070] python3[2128]: [.745] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  377.345887] python3[2128]: [.810] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'}"}
{"timestamp_utc": "2024-07-31T08:19:16.854Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  377.363039] python3[2128]: [.811] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  377.388742] python3[2128]: [.811] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  377.390186] python3[2128]: [.811] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  377.399778] python3[2128]: [.811] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  377.410298] python3[2128]: [.815] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  377.411697] python3[2128]: [.862] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  377.433368] python3[2128]: [.862] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  377.434666] python3[2128]: [.862] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  377.436089] python3[2128]: [.862] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  377.451618] python3[2128]: [.862] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  377.499438] python3[2128]: [.862] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  377.527389] python3[2128]: [.862] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  377.528844] python3[2128]: [.863] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  377.530156] python3[2128]: [.898] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  377.540604] python3[2128]: [.928] hookhdlr 139819433846592 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  377.541931] python3[2128]: [.939] hookhdlr 139819433846592 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  377.564884] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.567399] python3[2128]: [.955] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  377.586578] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.596519] python3[2128]: [.968] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  377.597822] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.616235] python3[2128]: [.992] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  377.638869] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.650815] python3[2128]: [.012] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  377.671797] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.694966] python3[2128]: [.050] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  377.696289] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.697339] python3[2128]: [.075] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  377.707354] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.715814] python3[2128]: [.275] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  377.726296] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.733889] python3[2128]: [.426] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  377.743479] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  377.744921] python3[2128]: [.548] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  377.810413] confd_phase_sentry[2132]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  377.829411] confd_phase_sentry[2132]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  377.839839] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  377.896579] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  377.897592] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  377.926349] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  377.928958] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  377.953894] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  377.960324] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  377.962416] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  377.976659] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  377.984887] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  377.994675] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.020764] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.022130] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.024878] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.058325] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.103712] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.106176] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.114568] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.122975] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.126670] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.132529] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.144808] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.145801] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:19:18.744Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:19:18 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37215\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:19:19.673Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  378.164512] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.165488] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.189699] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.198494] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.215092] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.223459] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.241699] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.262234] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.279866] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.288510] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.309953] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.317599] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.319825] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.347371] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.382955] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.409344] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.442992] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.453626] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.473109] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.486699] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.511470] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:19:19.674Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  378.518493] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.540072] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.591913] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.636783] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.654117] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.704647] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.706383] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.729193] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.784549] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.814384] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.843358] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.853515] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.864599] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.883409] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.884390] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.886430] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  378.901454] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  378.952414] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  379.039846] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  379.267053] temp_acct_cleanup_app[2139]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  379.301873] temp_acct_cleanup_app[2139]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  379.372353] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  379.446611] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  379.503489] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 1 <NL> [  379.504538] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 2 <NL> [  379.535369] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 3 <NL> [  379.536337] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 4 <NL> [  379.537296] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 5 <NL> [  379.575579] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 6 <NL> [  379.608131] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 7 <NL> [  379.609130] txid_tracker[2140]: ::::create_confd_subscription_connection() try number 8 <NL> [  380.085434] cseries_hal[2148]: HAL main() begins. <NL> [  380.192463] cseries_hal[2148]: hal_default::hal_init() called <NL> [  380.246683] cseries_hal[2148]: EsalPmiClient::EsalPmiClient <NL> [  381.106681] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 1"}
{"timestamp_utc": "2024-07-31T08:19:19.930Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:19 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:19 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:24.100Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:19:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:25.028Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:24 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:24 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:25.956Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  365.868258] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  366.039716] python3[3929]: [.131] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  366.039841] python3[3929]: [.132] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  366.039966] python3[3929]: [.132] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  366.040063] python3[3929]: [.132] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  366.040137] python3[3929]: [.132] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  366.040212] python3[3929]: [.159] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  366.040296] python3[3929]: [.160] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  366.040371] python3[3929]: [.160] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  366.040451] python3[3929]: [.160] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  366.040525] python3[3929]: [.160] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  366.040610] python3[3929]: [.160] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  366.040684] python3[3929]: [.160] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  366.040759] python3[3929]: [.255] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  366.040839] python3[3929]: [.255] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  366.040935] python3[3929]: [.256] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  366.041023] python3[3929]: [.256] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  366.041097] python3[3929]: [.256] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  366.041171] python3[3929]: [.257] valhdlr 139625452971840 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  366.041295] python3[3929]: [.257] valhdlr 139625452971840 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  366.041379] python3[3929]: [.452] valhdlr 139625452971840 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  366.041452] python3[3929]: [.452] valhdlr 139625452971840 callbackhdlr:293 Loading schemas <NL> [  366.041535] python3[3929]: DEBUG item does not exist - shared memory schema not enabled <NL> [  367.049074] snmp_clid[3933]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  368.016072] python3[3929]: [.502] valhdlr 139625452971840 callbackhdlr:382 Done load schemas <NL> [  368.016283] python3[3929]: [.502] valhdlr 139625452971840 callbackhdlr:389 Done register transaction callback <NL> [  368.342626] python3[3929]: [.825] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  368.512418] python3[3929]: [.998] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  368.515701] python3[3929]: [.002] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  368.847556] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  368.847746] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  368.906562] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  368.912818] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  368.912899] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  368.912960] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  368.913102] confd_mgr[2975]: sm_startconfd::p0_ready_dbc <NL> [  368.913168] confd_mgr[2975]: Find message SNMP_CLID_CONFIRM <NL> [  368.913231] confd_mgr[2975]: PROCESS_VALHDLR has not registered yet. <NL> [  368.913297] confd_mgr[2975]: sm_startconfd::p0_not_ready <NL> [  368.913361] confd_mgr[2975]: Find message SNMP_CLID_CONFIRM <NL> [  368.913449] confd_mgr[2975]: PROCESS_VALHDLR has not registered yet. <NL> [  368.913511] confd_mgr[2975]: leaving: sm_startconfd::wait_for_p0 <NL> [  368.913598] confd_mgr[2975]: entering: sm_startconfd::wait_for_p0 <NL> [  368.913687] confd_mgr[2975]: PROCESS_VALHDLR has not registered yet. <NL> [  368.913755] confd_mgr[2975]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  368.913829] confd_mgr[2975]: ConfdHA Not supported command CONFIRM <NL> [  368.913891] confd_mgr[2975]: Timer /ConfdAT|wait_for_p0 already created"}
{"timestamp_utc": "2024-07-31T08:19:25.957Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  368.913954] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  368.914031] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  368.914478] snmp_clid[3966]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  380.085139] python3[3929]: [.516] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  380.199716] python3[3929]: [.687] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  380.559627] python3[3929]: [.046] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  380.600647] python3[3929]: [.087] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  380.816714] python3[3929]: [.303] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  380.881650] python3[3929]: [.369] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  380.951937] python3[3929]: [.435] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  380.997074] python3[3929]: [.481] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  381.031407] python3[3929]: [.514] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  381.146044] python3[3929]: [.632] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  383.441883] python3[3929]: [.928] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  385.493838] python3[3929]: [.972] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  387.375581] python3[3929]: [.846] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  389.228132] python3[3929]: [.668] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  389.250392] python3[3929]: [.728] valhdlr 139625452971840 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  389.301767] python3[3929]: [.729] valhdlr 139625452971840 callbackhdlr:391 Done register data callbacks <NL> [  389.301885] python3[3929]: DEBUG No crypto keys configured <NL> [  389.302034] python3[3929]: [.734] valhdlr 139625452971840 callbackhdlr:401 Unable to install crypto keys! <NL> [  389.302117] python3[3929]: [.780] valhdlr 139625452971840 callbackhdlr:322 Started data handler daemon... <NL> [  389.302194] python3[3929]: [.780] valhdlr 139625452971840 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  389.469796] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  389.470069] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  389.470168] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  389.470282] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd"}
{"timestamp_utc": "2024-07-31T08:19:30.120Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:29 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:29 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:35.396Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:34 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:34 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> [  381.479278] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 2 <NL> [  381.881778] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 3 <NL> [  381.883136] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 4 <NL> [  381.922602] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 5 <NL> [  382.252886] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 6 <NL> [  382.253985] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 7 <NL> [  382.254964] txid_tracker[2327]: ::::create_confd_subscription_connection() try number 8 <NL> [  382.299878] startup_finished.py[2053]: Startup Finished: systemd state is non-Production mode and running <NL> [  382.494422] confd_director.py[2943]: rm: cannot remove '/var/shared/confd/ha_status': No such file or directory <NL> [  382.736709] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  382.758949] python3[2128]: [.570] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  382.925684] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 1 <NL> [  382.964862] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 2 <NL> [  383.054884] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 3 <NL> [  383.056496] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 4 <NL> [  383.062659] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 5 <NL> [  383.065389] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 6 <NL> [  383.072734] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 7 <NL> [  383.096036] txid_tracker[2480]: ::::create_confd_subscription_connection() try number 8 <NL> [  383.103922] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 1 <NL> [  383.111373] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 2 <NL> [  383.123473] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 3 <NL> [  383.148742] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 4 <NL> [  383.149976] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 5 <NL> [  383.187419] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 6 <NL> [  383.199308] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 7 <NL> [  383.208467] txid_tracker[2580]: ::::create_confd_subscription_connection() try number 8 <NL> [  383.235826] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 1 <NL> [  383.250530] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 2 <NL> [  383.261517] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 3 <NL> [  383.269674] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 4 <NL> [  383.275760] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 5 <NL> [  383.291498] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 6 <NL> [  383.306847] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 7 <NL> [  383.320565] txid_tracker[2756]: ::::create_confd_subscription_connection() try number 8 <NL> [  383.335582] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 1 <NL> [  383.358265] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 2 <NL> [  383.372803] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 3 <NL> [  383.385451] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 4 <NL> [  383.397484] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 5 <NL> [  383.406554] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 6 <NL> [  383.415435] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 7 <NL> [  383.423607] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 8 <NL> [  384.221087] startup_finished.py[2053]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  384.587112] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  384.851206] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  385.707631] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 1 <NL> [  386.216796] cseries_hal[2148]: EsalPmiClient::sharedMemoryInit nPorts/size/nPorts/additionalBuffers 50/6160/50/49 <NL> [  386.649885] cseries_hal[2148]: EsalShm::createShmSegment <NL> [  386.688441] cseries_hal[2148]: EsalShm::createShmSegment attaching to existing shm segment"}
{"timestamp_utc": "2024-07-31T08:19:35.397Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "Exception: [  387.494683] dcn_dns_controller[1373]: dnsClientStartup() <NL> [  387.706476] dcn_dns_controller[1373]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  387.707665] dcn_dns_controller[1373]: fin_dnsmasq_conf is open <NL> Connect failed[  388.231208] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 2 <NL> [  389.641060] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  389.915508] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  391.036268] confd_mgr[2966]: ConfdMgrConf: DB signature is NOT supported <NL> [  391.147066] confd_mgr[2966]: Read reset type failed basic_ios::clear: iostream error <NL> [  391.349640] confd_mgr[2966]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  391.397149] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  391.999725] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  392.175317] ntputils[1733]: child pid is 2974 <NL> [  392.337888] ntputils[1733]: exited, status is 0 <NL> [  392.339271] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  392.361791] ntputils[1733]: poller time change delta is: 1 <NL> [  392.540083] ntputils[1733]: push_local_changes user_changed: 0 delta: 1 <NL> 2024-07-31 08:19:29,608 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  392.813244] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  393.341671] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  393.571205] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  393.572625] ntputils[1733]: push_local_changes OK <NL> [  393.717195] confd_mgr[2966]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  393.920238] confd_mgr[2966]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  394.141345] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 3 <NL> [  394.143114] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  394.177306] python3[2128]: [.582] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1! <NL> [  394.551113] confd_mgr[2988]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:19:28 UTC 2024 <NL> [  394.805287] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 4 <NL> [  394.894488] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  395.087195] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  395.588220] confd_mgr[3006]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  395.862278] startup_finished.py[2053]: *****Startup Finished: stopping EOW timer***** <NL> [  396.032111] confd_mgr[2988]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  396.372880] confd_mgr[3013]: /usr/bin/ui_sys_reset.py NONE <NL> [  396.600723] startup_finished.py[2053]: systemctl stop startup_finished_limit.timer"}
{"timestamp_utc": "2024-07-31T08:19:36.324Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:19:35 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37247\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:19:36.580Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  376.059390] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 5 <NL> [  376.174663] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 6 <NL> [  376.295566] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 7 <NL> [  376.366671] txid_tracker[2751]: ::::create_confd_subscription_connection() try number 8 <NL> [  376.663195] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 1 <NL> [  376.828273] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 2 <NL> [  377.103207] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 3 <NL> [  377.426574] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 4 <NL> [  377.841871] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 5 <NL> [  378.203243] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 6 <NL> [  378.444137] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 7 <NL> [  378.868468] txid_tracker[2829]: ::::create_confd_subscription_connection() try number 8 <NL> [  379.158532] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  379.312136] python3[2142]: [.366] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  379.314038] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  379.475927] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  379.567237] startup_finished.py[2030]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  380.336043] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 1 <NL> [  380.348511] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 2"}
{"timestamp_utc": "2024-07-31T08:19:36.581Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  380.668606] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 3 <NL> [  380.871639] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 4 <NL> [  381.108171] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 5 <NL> [  381.587303] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 6 <NL> [  382.184689] cseries_hal[2162]: EsalPmiClient::sharedMemoryInit nPorts/size/nPorts/additionalBuffers 50/6160/50/49 <NL> [  382.319504] cseries_hal[2162]: EsalShm::createShmSegment <NL> [  382.478874] cseries_hal[2162]: EsalShm::createShmSegment attaching to existing shm segment <NL> [  382.942421] dcn_dns_controller[1372]: dnsClientStartup() <NL> [  383.047426] dcn_dns_controller[1372]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  383.440992] dcn_dns_controller[1372]: fin_dnsmasq_conf is open <NL> [  383.595490] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  383.955443] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  384.149335] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 7 <NL> [  384.286961] startup_finished.py[2030]: *****Startup Finished: stopping EOW timer***** <NL> [  384.771999] dcn_ka[1374]: KaSessMgr Process Startup <NL> [  385.056829] startup_finished.py[2030]: systemctl stop startup_finished_limit.timer <NL> [  385.335606] cseries_hal[2162]: EsalShm::createShmSegment timeout opening syncPath <NL> [  385.439091] cseries_hal[2162]: EsalPmiClient::dumpShm pmShm is null <NL> [  386.022406] cseries_hal[2162]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  386.380790] cia_control_layer[2127]:    ChalApi Constructor with tid = 2745 <NL> [  386.880772] txid_tracker[2934]: ::::create_confd_subscription_connection() try number 8 <NL> [  387.137352] led_controller[2163]:    ChalApi Constructor with tid = 2163 <NL> [  387.151940] confd_mgr[3039]: ConfdMgrConf: DB signature is NOT supported <NL> [  387.442939] confd_mgr[3039]: Read reset type failed basic_ios::clear: iostream error <NL> [  387.444070] confd_mgr[3039]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  387.940894] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  388.028429] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  389.278573] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  389.761390] python3[2142]: [.384] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1! <NL> [  390.921492] confd_mgr[3039]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  391.821578] confd_mgr[3039]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  392.234782] confd_mgr[3062]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:19:24 UTC 2024 <NL> [  392.846048] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  393.299156] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  394.120307] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 1 <NL> [  396.610933] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  396.639347] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  397.733310] ntputils[1710]: child pid is 3093 <NL> [  397.926201] ntputils[1710]: exited, status is 0 <NL> [  398.809712] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  399.246442] ntputils[1710]: poller time change delta is: 1 <NL> [  399.461372] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  399.540961] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  399.593419] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  399.607302] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  399.609872] ntputils[1710]: push_local_changes OK <NL> [  399.677030] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 2 <NL> [  399.999283] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 3 <NL> [  400.260406] confd_mgr[3101]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  400.898445] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  400.899501] python3[2142]: [.532] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1! <NL> [  400.993158] dcn_dns_controller[1372]: subscribe_data Enter main loop <NL> [  401.068799] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  401.176168] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  401.338589] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  401.339991] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  401.341437] ntputils[1710]: child pid is 3113 <NL> [  401.342433] ntputils[1710]: exited, status is 0 <NL> [  401.344100] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  401.618125] ntputils[1710]: poller time change delta is: 1 <NL> [  401.619186] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  401.622352] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  401.693336] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  401.720365] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  401.820424] ntputils[1710]: push_local_changes OK <NL> [  401.821114] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  402.016423] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  402.142656] ntputils[1710]: child pid is 3128 <NL> [  402.585394] ntputils[1710]: exited, status is 0 <NL> [  402.586083] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  402.625364] ntputils[1710]: poller time change delta is: 1"}
{"timestamp_utc": "2024-07-31T08:19:40.745Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:39 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:39 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:41.001Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p05.s01.NE3-main-debug-ssh", "message_content": "# 03:19:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37247, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:45.204Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:44 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:44 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:50.479Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:49 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:50.480Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:19:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:49 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:55.722Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:54 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:55 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> [  397.177074] cseries_hal[2148]: EsalShm::createShmSegment timeout opening syncPath <NL> [  397.566865] cseries_hal[2148]: EsalPmiClient::dumpShm pmShm is null <NL> [  398.159839] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 5 <NL> [  399.678070] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  399.841430] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  400.344899] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 6 <NL> [  400.925320] cia_control_layer[2113]:    ChalApi Constructor with tid = 2752 <NL> [  400.999983] cseries_hal[2148]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  401.729408] led_controller[2149]:    ChalApi Constructor with tid = 2149 <NL> [  402.123105] confd_mgr[3058]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  402.336868] confd_mgr[3058]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  402.340325] confd_mgr[3059]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  402.396026] confd_mgr[3059]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  402.658174] confd_mgr[3060]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  402.783594] confd_mgr[3060]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  403.249802] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  403.256538] python3[2128]: [.706] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1! <NL> [  403.347741] confd_mgr[3014]: DDS Peristency is enabled <NL> [  403.376571] confd_mgr[3014]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  403.561426] confd_mgr[3014]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  403.650425] confd_mgr[3014]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  403.746154] confd_mgr[3014]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  403.813268] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 7 <NL> [  403.896723] confd_mgr[3013]: /usr/bin/dbrestore_no.py <NL> [  404.076480] confd_mgr[3069]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  404.185734] confd_mgr[2966]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  404.276214] confd_mgr[2966]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  404.453106] confd_mgr[2966]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  404.744377] confd_mgr[2966]: entering: wait_for_alarm_event <NL> [  404.891883] confd_mgr[2966]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  404.892936] confd_mgr[2966]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  404.893778] confd_mgr[2966]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  404.894605] confd_mgr[2966]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  405.076212] confd_mgr[2966]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  405.384943] confd_mgr[2966]: ha_sm : wait_for_SWDL_s timer is set <NL> [  405.386261] confd_mgr[2966]: entering: at_sm::wait_for_SWDL <NL> [  405.402724] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  405.549657] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  405.946309] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  406.213452] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  406.394291] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  406.589211] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  406.930237] confd_mgr[2966]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  407.134361] confd_mgr[2966]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  407.494585] txid_tracker[2952]: ::::create_confd_subscription_connection() try number 8 <NL> [  407.835066] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  408.064431] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  408.471609] confd_mgr[3083]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': '1+1', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  408.685907] confd_mgr[2966]: ConfdMgrConf::reload: DB signature set to false <NL> [  409.080126] confd_mgr[2966]: is_swdl_alarm_0 <NL> [  409.210888] confd_mgr[2966]: sdb_restore_= 0 <NL> [  409.352221] confd_mgr[2966]: swdl_alarm_ = NONE <NL> [  409.464832] confd_mgr[2966]: swdl_alarm_tag_ = <NL> [  409.465778] confd_mgr[2966]: swdl status = SUCCESS <NL> [  409.476234] confd_mgr[2966]: is_swdl_in_swupgrade = 0 <NL> [  409.533354] confd_mgr[2966]: is_swdl_alarm_0 <NL> [  409.568128] confd_mgr[2966]: sdb_restore_= 0 <NL> [  409.573255] confd_mgr[2966]: swdl_alarm_ = NONE <NL> [  409.781288] confd_mgr[2966]: swdl_alarm_tag_ = <NL> [  409.985281] confd_mgr[2966]: swdl status = SUCCESS <NL> [  410.142738] confd_mgr[2966]: is_swdl_in_swupgrade = 0 <NL> [  410.362388] confd_mgr[2966]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  410.872407] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  411.573858] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  412.413625] confd_mgr[3081]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  412.624145] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 1 <NL> [  412.768374] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  412.845118] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  413.139337] confd_mgr[2966]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  413.529134] confd_mgr[2966]: main::/run/rdm_status.sh found. Invoking it. <NL> [  413.599151] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  413.897395] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  414.375442] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  414.761941] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  414.782872] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  414.864893] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  415.039527] confd_mgr[2966]: ConfdMgrConf::reload: DB signature set to false <NL> [  415.330883] confd_mgr[2966]: confd_db_init::sConfd_db_init_executed_=false <NL> [  415.570500] confd_mgr[2966]: ConfdMgrConf::reload: DB signature set to false <NL> [  415.809835] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  415.923761] python3[2128]: [.728] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  416.131428] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 2"}
{"timestamp_utc": "2024-07-31T08:19:55.723Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  416.241226] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  416.414086] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  416.611790] confd_mgr[3143]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  416.663646] confd_mgr[3107]: build /etc/confd/confd.conf.bank0 1+1 <NL> [  416.710883] confd_mgr[3107]: 1+1 <NL> [  416.727986] confd_mgr[3107]: add_child <NL> [  416.788566] confd_mgr[3154]: add field enabled true <NL> [  416.865582] confd_mgr[3154]: add field ip 127.1.254.253 <NL> [  416.900374] confd_mgr[3154]: add field port 4569 <NL> [  416.927316] confd_mgr[3154]: add field tickTimeout PT20S <NL> [  416.975471] confd_mgr[3160]: add field enabled false <NL> [  416.988333] confd_mgr[3160]: add field address"}
{"timestamp_utc": "2024-07-31T08:20:00.994Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:00.995Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:19:59 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:00 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:02.360Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:20:02 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37215\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:20:05.624Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:05 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:05 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:07.512Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:20:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:10.776Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:10 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:10 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:20:10 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:20:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:10 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:10 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:20:10 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:20:10 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\": process 3333 terminated with exitcode 0 <NL> # 03:20:10 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:20:10 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:20:10 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37245', '--delay', '5'] (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:20:10 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p05.s02.NE3-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37245', '--delay', '5'] <NL> # 03:20:10 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:20:10 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"command\" <NL> # 03:20:10 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", exit_code 0 <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:20:10 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37245, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:10 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:14.040Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  402.728559] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  402.730250] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  402.826737] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  402.827701] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  402.828423] ntputils[1710]: push_local_changes OK <NL> [  402.988925] confd_mgr[3062]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  403.322106] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  403.824714] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  403.931516] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 4 <NL> [  403.997738] confd_mgr[3124]: /usr/bin/ui_sys_reset.py NONE <NL> [  405.902975] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 5 <NL> [  408.717025] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  408.892584] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  410.416221] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 6 <NL> [  411.003358] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  412.417336] python3[2142]: [.615] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  413.467654] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 7 <NL> [  413.726290] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  414.431784] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  415.639073] txid_tracker[3067]: ::::create_confd_subscription_connection() try number 8 <NL> [  418.578480] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  419.100580] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  421.012635] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:20:14.041Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  421.599191] python3[2142]: [.042] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  424.691705] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 1 <NL> [  425.404727] confd_mgr[3215]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  425.426544] confd_mgr[3215]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  427.374108] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  427.616580] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  427.824987] confd_mgr[3216]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  427.937085] confd_mgr[3216]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  427.938932] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  427.942141] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  427.944258] ntputils[1710]: child pid is 3221 <NL> [  427.947278] ntputils[1710]: exited, status is 0 <NL> [  427.952531] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  427.958880] ntputils[1710]: poller time change delta is: 1 <NL> [  427.973183] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  427.986936] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  428.004318] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  428.022633] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  428.047206] ntputils[1710]: push_local_changes OK <NL> [  428.094866] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 2 <NL> [  428.193180] confd_mgr[3217]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  428.215074] confd_mgr[3217]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  428.255059] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  428.283888] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  428.447638] confd_mgr[3125]: DDS Peristency is enabled <NL> [  428.547240] confd_mgr[3125]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  428.836246] confd_mgr[3125]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  429.133431] confd_mgr[3125]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  429.203139] confd_mgr[3125]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  429.638761] confd_mgr[3124]: /usr/bin/dbrestore_no.py <NL> [  429.835762] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  429.848976] python3[2142]: [.053] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 15 of -1! <NL> [  430.478107] confd_mgr[3231]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  430.836923] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 3 <NL> [  431.325487] confd_mgr[3039]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  431.444256] confd_mgr[3039]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  431.615487] confd_mgr[3039]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  431.777714] confd_mgr[3039]: entering: wait_for_alarm_event <NL> [  431.842887] confd_mgr[3039]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  432.018601] confd_mgr[3039]: ha_sm : wait_for_SWDL_s timer is set <NL> [  432.134360] confd_mgr[3039]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  432.468910] confd_mgr[3039]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  433.074633] confd_mgr[3039]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  433.130704] confd_mgr[3039]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  433.476553] confd_mgr[3039]: entering: at_sm::wait_for_SWDL <NL> [  433.856674] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [  434.035511] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  434.516575] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  435.027298] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  435.451122] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  436.296066] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  436.661123] confd_mgr[3039]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  437.023135] confd_mgr[3039]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE[  437.692407] hrtimer: interrupt took 126627 ns <NL> [  437.599984] healthcheck_agt.py[3264]: /bin/sh: line 1: podman: command not found <NL> [  438.021702] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 4 <NL> [  438.363605] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 5 <NL> [  439.325729] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  439.326800] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  439.542170] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:20:15.405Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:15 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:15 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:15.661Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:20:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:15 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:20.901Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:20 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:20 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:20 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:25.065Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:25 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:25.321Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:20:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:25 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:25.576Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:20:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:25.832Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:20:25 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',) <NL> [  363.810934] confd_mgr[2947]: sm_startconfd::p0_ready_dbc <NL> [  363.811033] confd_mgr[2947]: Find message SNMP_CLID_CONFIRM <NL> [  363.811110] confd_mgr[2947]: PROCESS_VALHDLR has not registered yet. <NL> [  363.811199] confd_mgr[2947]: sm_startconfd::p0_not_ready <NL> [  363.811283] confd_mgr[2947]: Find message SNMP_CLID_CONFIRM <NL> [  363.811349] confd_mgr[2947]: PROCESS_VALHDLR has not registered yet. <NL> [  363.811414] confd_mgr[2947]: leaving: sm_startconfd::wait_for_p0 <NL> [  363.811479] confd_mgr[2947]: entering: sm_startconfd::wait_for_p0 <NL> [  363.811541] confd_mgr[2947]: PROCESS_VALHDLR has not registered yet. <NL> [  363.811607] confd_mgr[2947]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  363.826976] confd_mgr[2947]: Timer /ConfdAT|wait_for_p0 already created <NL> [  363.949746] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  363.949847] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  363.952285] snmp_clid[3974]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  364.529867] python3[3931]: [.132] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  365.002153] python3[3931]: [.606] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  365.018787] python3[3931]: [.623] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  378.480257] python3[3931]: [.080] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  378.569609] python3[3931]: [.172] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  378.813555] python3[3931]: [.412] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  378.832494] python3[3931]: [.437] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  379.104584] python3[3931]: [.705] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  379.147255] python3[3931]: [.750] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  379.222030] python3[3931]: [.824] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  379.231956] python3[3931]: [.836] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  379.296923] python3[3931]: [.899] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  379.338042] python3[3931]: [.942] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  382.092626] python3[3931]: [.695] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  384.293048] python3[3931]: [.897] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  386.911808] python3[3931]: [.515] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  389.615636] python3[3931]: [.218] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  389.630950] python3[3931]: [.236] valhdlr 140234579945280 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  389.646644] python3[3931]: [.245] valhdlr 140234579945280 callbackhdlr:391 Done register data callbacks <NL> [  389.646842] python3[3931]: DEBUG No crypto keys configured <NL> [  389.646941] python3[3931]: [.247] valhdlr 140234579945280 callbackhdlr:401 Unable to install crypto keys! <NL> [  389.659183] python3[3931]: [.263] valhdlr 140234579945280 callbackhdlr:322 Started data handler daemon... <NL> [  389.659363] python3[3931]: [.263] valhdlr 140234579945280 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  389.780224] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  389.787277] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  389.787489] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  389.787569] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  389.787643] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  389.787715] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  389.787784] confd_mgr[2947]: ConfdHA Not supported command CONFIRM <NL> [  389.788213] confd_mgr[2947]: sm_startconfd::p0_ready_dbc <NL> [  389.788305] confd_mgr[2947]: Find message VALHDLR_CONFIRM <NL> [  389.788381] confd_mgr[2947]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  389.788456] confd_mgr[2947]: sm_startconfd::p0_not_ready <NL> [  389.788529] confd_mgr[2947]: Find message VALHDLR_CONFIRM <NL> [  389.788613] confd_mgr[2947]: sm_startconfd::p0_ready_no_dbc <NL> [  389.788686] confd_mgr[2947]: Find message VALHDLR_CONFIRM <NL> [  389.788754] confd_mgr[2947]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  389.788823] confd_mgr[2947]: leaving: sm_startconfd::wait_for_p0 <NL> [  389.790084] confd_mgr[2947]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  389.790224] confd_mgr[2947]: entering: sm_startconfd::start_confd_p1 <NL> [  389.790322] confd_mgr[2947]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  389.833888] confd_mgr[4032]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:19:24 UTC 2024 <NL> [  390.177445] confd_mgr[4042]: /usr/bin/common_confd_start_phase1_cb.sh NONE"}
{"timestamp_utc": "2024-07-31T08:20:25.833Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  390.177668] confd_mgr[2947]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  434.209352] txid_tracker[3784]: ::::create_confd_subscription_connection() connected <NL> [  446.698934] confd_mgr[2947]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  446.775109] confd_mgr[4235]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:20:21 UTC 2024 <NL> [  446.942095] confd_mgr[4235]: Invoking confd_load_upgrade_xml.py <NL> [  448.798823] confd_mgr[4244]: confd_load_upgrade_xml.py: Start <NL> [  448.799185] confd_mgr[4244]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  449.348853] confd_mgr[2947]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  449.418161] confd_mgr[4259]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  449.504849] confd_mgr[2947]: CONFD IN PHASE 1 <NL> [  449.504961] confd_mgr[2947]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  449.505094] confd_mgr[2947]: leaving: sm_startconfd::start_confd_p1 <NL> [  449.505191] confd_mgr[2947]: entering: sm_startconfd::wait_for_p1 <NL> [  449.505270] confd_mgr[2947]: PROCESS3 has not registered yet. <NL> [  449.628297] python3[4030]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  449.628531] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  449.628642] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  449.629591] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  449.665501] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  449.665698] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  449.665807] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  449.665890] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  449.665970] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  449.666082] confd_mgr[2947]: ConfdHA Not supported command CONFIRM <NL> [  449.666152] confd_mgr[2947]: sm_startconfd::p1_not_ready <NL> [  449.666374] confd_mgr[2947]: Find message MESSAGE3 <NL> [  449.666466] confd_mgr[2947]: sm_startconfd::p1_ready <NL> [  449.666549] confd_mgr[2947]: Find message MESSAGE3 <NL> [  449.666626] confd_mgr[2947]: leaving: sm_startconfd::wait_for_p1 <NL> [  449.666702] confd_mgr[2947]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  449.666776] confd_mgr[2947]: entering: sm_startconfd::wait_for_rm"}
{"timestamp_utc": "2024-07-31T08:20:27.738Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  417.010044] confd_mgr[3107]: /etc/confd/default_backup.dbs <NL> [  417.063918] confd_mgr[3107]: Create default DB in bank0 <NL> [  417.091785] dcn_ka[1376]: KaSessMgr Process Startup <NL> [  418.231952] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 3 <NL> [  419.596303] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  419.619491] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  421.383264] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 4 <NL> [  422.877546] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  423.256952] python3[2128]: [.745] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  423.771979] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 5 <NL> [  424.381844] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.561747] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  424.648194] dcn_dns_controller[1373]: subscribe_data Enter main loop <NL> [  425.818281] confd_mgr[2966]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  426.156231] confd_mgr[2966]: confd_db_init::RESET REASON IS NONE <NL> [  426.257200] confd_mgr[2966]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  426.400596] confd_mgr[2966]: leaving: at_sm::wait_for_SWDL <NL> [  426.597934] confd_mgr[2966]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  426.865867] confd_mgr[2966]: ha_sm is_ha_mode_not_none_g cur_mode is 1+1 <NL> [  427.162721] confd_mgr[2966]: ha_sm leaving: wait_for_SWDL_s <NL> [  428.186296] confd_mgr[2966]: ha_sm::start_active_agent_a: The HA mode is 1+1 <NL> [  428.532985] confd_mgr[2966]: ha_sm_active entering: wait_for_active_agent_s <NL> [  428.767345] confd_mgr[2966]: ConfdTribActiveAgent start_rep_server <NL> [  428.818872] confd_mgr[2966]: ConfdTribActiveAgent::server address 127.1.254.254 port 4050 <NL> [  428.884065] confd_mgr[2966]: calling accept_handler <NL> [  428.947610] confd_mgr[2966]: In ConfdTribActiveAgent::check_reset <NL> [  428.949031] confd_mgr[2966]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  428.993943] confd_mgr[2966]: ha_sm_active leaving: wait_for_active_agent_s <NL> [  429.113073] confd_mgr[2966]: process_ha_alarm raise noSecondaryDatabase <NL> [  429.296676] confd_mgr[2966]: ha_sm_active entering: wait_for_standby_s <NL> [  429.397468] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  429.400270] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  429.409969] confd_mgr[2966]: Maskable Alarm <NL> [  429.511217] confd_mgr[2966]: leaving: wait_for_alarm_event <NL> [  429.680938] confd_mgr[2966]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:152:add_to_alarms: OPERATION=raise CONDITION=noSecondaryDatabase #ALARMS=1 <NL> [  429.685327] confd_mgr[2966]: entering: wait_for_alarm_process <NL> [  429.754981] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  429.756306] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  429.843098] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 6 <NL> [  429.849047] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 7 <NL> [  429.850630] confd_mgr[3105]: TRUE <NL> [  429.894884] confd_mgr[2966]: entering: at_sm::wait_for_start_bank <NL> [  429.914454] confd_mgr[2966]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  429.937902] confd_mgr[2966]: leaving: at_sm::wait_for_start_bank <NL> [  429.996437] confd_mgr[2966]: entering: at_sm_dbready::wait_for_db_status <NL> [  430.037951] confd_mgr[2966]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  430.053659] confd_mgr[2966]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  430.163807] confd_mgr[3448]: Executing check_db.sh <NL> [  430.204965] confd_mgr[3448]: check_db.sh: found xml files <NL> [  430.205676] confd_mgr[3448]: 0 <NL> [  430.270330] confd_mgr[2966]: Found no error <NL> [  430.280113] confd_mgr[2966]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  430.338204] confd_mgr[2966]: cur_gdbissue 24.1.1 gdbissue 24.1.1 rc = 1 <NL> [  430.428333] confd_mgr[2966]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  430.439094] confd_mgr[2966]: TSeries-CIS is in the list: TSeries-CIS <NL> [  430.449253] confd_mgr[2966]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  430.498482] confd_mgr[2966]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  430.538040] confd_mgr[2966]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  430.604076] confd_mgr[2966]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  430.750768] confd_mgr[2966]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  430.838303] confd_mgr[2966]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  430.966123] confd_mgr[2966]: guard is_db_okay_g: The HA mode is 1+1 <NL> [  431.122781] confd_mgr[2966]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  431.398129] confd_mgr[2966]: entering: sm_startconfd::start_confd_p0 <NL> [  431.399175] confd_mgr[2966]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  431.535762] confd_mgr[3459]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:20:04 UTC 2024 <NL> [  431.559188] confd_mgr[2966]: leaving: wait_for_alarm_process <NL> [  431.625622] confd_mgr[2966]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:160:write_alarms_to_file: #ALARMS=1 <NL> [  431.684671] confd_mgr[2966]:  write_db_alarm rename was successful <NL> [  431.801132] confd_mgr[2966]: entering: wait_for_alarm_event <NL> [  431.801887] confd_mgr[2966]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  433.065804] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  433.915545] txid_tracker[3127]: ::::create_confd_subscription_connection() try number 8 <NL> [  434.714360] python3[2128]: [.833] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 15 of -1! <NL> [  434.834317] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  434.885733] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  439.522786] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  440.483884] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 1 <NL> [  441.054533] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  443.713845] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 2 <NL> [  444.118221] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.720800] python3[2128]: [.676] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 16 of -1!"}
{"timestamp_utc": "2024-07-31T08:20:27.739Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  445.177777] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  445.303755] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  446.296396] healthcheck_agt.py[3546]: /bin/sh: line 1: podman: command not found <NL> [  446.700781] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 3"}
{"timestamp_utc": "2024-07-31T08:20:30.264Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:30 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:30 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:30.831Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:20:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:30 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:36.072Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:36.073Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:35 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:35 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:35 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:40.235Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:40 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:40 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:40.796Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:20:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:40 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:42.710Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:20:42 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37215\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:20:45.225Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:45 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:45 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:45.786Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:20:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:45 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:47.718Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:20:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:50.232Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:50 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:50 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:50.793Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:20:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:50 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:56.032Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:20:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:55 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:55 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:20:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:55 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:59.312Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  439.821333] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  440.325261] confd_mgr[3246]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': '1+1', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  440.433295] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 6 <NL> [  440.612991] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  440.661132] python3[2142]: [.136] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 16 of -1! <NL> [  440.876394] confd_mgr[3039]: ConfdMgrConf::reload: DB signature set to false <NL> [  440.973306] confd_mgr[3039]: is_swdl_alarm_0 <NL> [  440.973926] confd_mgr[3039]: sdb_restore_= 0 <NL> [  440.975230] confd_mgr[3039]: swdl_alarm_ = NONE <NL> [  441.364845] confd_mgr[3039]: swdl_alarm_tag_ = <NL> [  441.587333] confd_mgr[3039]: swdl status = SUCCESS <NL> [  441.612257] confd_mgr[3039]: is_swdl_in_swupgrade = 0 <NL> [  441.634358] confd_mgr[3039]: is_swdl_alarm_0 <NL> [  441.697220] confd_mgr[3039]: sdb_restore_= 0 <NL> [  441.697807] confd_mgr[3039]: swdl_alarm_ = NONE <NL> [  441.698439] confd_mgr[3039]: swdl_alarm_tag_ = <NL> [  441.699047] confd_mgr[3039]: swdl status = SUCCESS <NL> [  441.977085] confd_mgr[3039]: is_swdl_in_swupgrade = 0 <NL> [  441.980258] confd_mgr[3039]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  442.552166] confd_mgr[3244]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  442.659593] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 7 <NL> [  442.765757] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  442.875395] confd_mgr[3039]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  442.901373] confd_mgr[3039]: main::/run/rdm_status.sh found. Invoking it. <NL> [  443.016332] confd_mgr[3039]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  443.187453] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [  443.244598] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  443.734411] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  443.880397] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  444.282337] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  444.681780] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  444.769956] confd_mgr[3039]: ConfdMgrConf::reload: DB signature set to false <NL> [  444.857574] confd_mgr[3039]: confd_db_init::sConfd_db_init_executed_=false <NL> [  444.971816] confd_mgr[3039]: ConfdMgrConf::reload: DB signature set to false <NL> [  445.219305] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  445.279976] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  445.439626] txid_tracker[3212]: ::::create_confd_subscription_connection() try number 8 <NL> [  448.211555] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  448.913213] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  449.589830] confd_mgr[3338]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  449.912734] confd_mgr[3300]: build /etc/confd/confd.conf.bank0 1+1 <NL> [  450.336186] confd_mgr[3300]: 1+1 <NL> [  450.415914] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  450.423653] python3[2142]: [.151] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 17 of -1! <NL> [  450.453204] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 1 <NL> [  450.464688] confd_mgr[3300]: add_child <NL> [  450.518477] confd_mgr[3350]: add field enabled true <NL> [  450.525757] confd_mgr[3350]: add field ip 127.1.254.253 <NL> [  450.630064] confd_mgr[3350]: add field port 4569 <NL> [  450.890675] confd_mgr[3350]: add field tickTimeout PT20S <NL> [  452.121666] confd_mgr[3358]: add field enabled false <NL> [  452.371293] confd_mgr[3358]: add field address <NL> [  453.056995] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  453.254825] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  453.546533] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 2 <NL> [  456.501486] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 3 <NL> [  457.826381] confd_mgr[3300]: /etc/confd/default_backup.dbs <NL> [  458.402149] confd_mgr[3300]: Create default DB in bank0 <NL> [  458.831151] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  458.863695] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  459.773739] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 4 <NL> [  460.937621] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  461.181590] python3[2142]: [.483] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 18 of -1!"}
{"timestamp_utc": "2024-07-31T08:20:59.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  462.384313] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 5 <NL> [  463.306695] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  464.231996] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  466.075119] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 6 <NL> [  468.680062] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 7 <NL> [  468.701193] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  468.702188] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  470.614242] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  471.445328] python3[2142]: [.718] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 19 of -1! <NL> [  472.008407] txid_tracker[3340]: ::::create_confd_subscription_connection() try number 8 <NL> [  473.247786] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  473.440257] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  478.347685] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  478.891626] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  479.612414] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 1 <NL> [  480.517242] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  480.761206] python3[2142]: [.750] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 20 of -1! <NL> [  481.723222] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 2 <NL> [  483.643130] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:21:00.241Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:00 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:00.498Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:21:00 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:00.754Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:21:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:00 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:05.998Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:05 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:05 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:05 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:11.254Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:10 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:10 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:10 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:15.451Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:15 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:15 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:16.014Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:21:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:15 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:21.261Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:20 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:20 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:20 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:25.427Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:25 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:25 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:25.988Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:21:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:25 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:30.161Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:21:29 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37215\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:21:30.417Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:30 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:30.672Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:21:30 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:30.928Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:21:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:30 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:31.858Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  484.791803] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  486.442282] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 3 <NL> [  488.006870] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 4 <NL> [  488.347403] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  488.434319] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:21:31.859Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  491.029573] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  491.030411] python3[2142]: [.089] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 21 of -1! <NL> [  491.121554] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 5 <NL> [  493.537339] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  493.646124] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  494.601155] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 6 <NL> [  497.777308] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 7 <NL> [  498.526691] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  498.826492] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  500.567875] txid_tracker[3495]: ::::create_confd_subscription_connection() try number 8 <NL> [  501.072595] confd_mgr[3039]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  501.074248] confd_mgr[3039]: confd_db_init::RESET REASON IS NONE <NL> [  501.203612] confd_mgr[3039]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  501.251667] confd_mgr[3039]: ha_sm is_ha_mode_not_none_g cur_mode is 1+1 <NL> [  501.262983] confd_mgr[3039]: ha_sm leaving: wait_for_SWDL_s <NL> [  501.264821] confd_mgr[3039]: ha_sm::start_active_agent_a: The HA mode is 1+1 <NL> [  501.478584] confd_mgr[3039]: ha_sm_active entering: wait_for_active_agent_s <NL> [  501.976453] confd_mgr[3039]: ConfdTribActiveAgent start_rep_server <NL> [  502.033595] confd_mgr[3039]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  502.154854] confd_mgr[3039]: ConfdTribActiveAgent::server address 127.1.254.254 port 4050 <NL> [  503.027949] confd_mgr[3039]: calling accept_handler <NL> [  503.028590] confd_mgr[3039]: leaving: at_sm::wait_for_SWDL <NL> [  503.231559] confd_mgr[3039]: In ConfdTribActiveAgent::check_reset <NL> [  503.559721] confd_mgr[3039]: entering: at_sm::wait_for_start_bank <NL> [  503.698486] confd_mgr[3039]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  504.549602] confd_mgr[3039]: leaving: at_sm::wait_for_start_bank <NL> [  504.664197] confd_mgr[3039]: entering: at_sm_dbready::wait_for_db_status <NL> [  504.713222] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  504.905919] confd_mgr[3039]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  504.908280] confd_mgr[3039]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  505.700434] confd_mgr[3039]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  506.009866] confd_mgr[3039]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  507.458840] confd_mgr[3039]: ha_sm_active leaving: wait_for_active_agent_s <NL> [  507.520413] confd_mgr[3039]: process_ha_alarm raise noSecondaryDatabase <NL> [  507.646409] confd_mgr[3039]: ha_sm_active entering: wait_for_standby_s <NL> [  508.321541] confd_mgr[3039]: Maskable Alarm <NL> [  508.550686] confd_mgr[3039]: leaving: wait_for_alarm_event <NL> [  508.680146] confd_mgr[3039]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:152:add_to_alarms: OPERATION=raise CONDITION=noSecondaryDatabase #ALARMS=1 <NL> [  509.775408] confd_mgr[3039]: entering: wait_for_alarm_process <NL> [  510.071844] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  510.553130] python3[2142]: [.251] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 22 of -1! <NL> [  510.990315] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  511.269297] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  512.095472] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  512.096521] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  512.221940] confd_mgr[3298]: TRUE <NL> [  512.232904] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 1 <NL> [  512.240908] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 2 <NL> [  512.744509] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  513.084685] python3[2142]: [.325] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 23 of -1! <NL> [  513.542737] confd_mgr[3689]: Executing check_db.sh <NL> [  513.546492] confd_mgr[3689]: check_db.sh: found xml files <NL> [  513.723391] confd_mgr[3689]: 0 <NL> [  513.766204] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  513.768285] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  513.847644] confd_mgr[3039]: Found no error <NL> [  513.966568] confd_mgr[3039]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  514.155843] confd_mgr[3039]: cur_gdbissue 24.1.1 gdbissue 24.1.1 rc = 1 <NL> [  514.331468] confd_mgr[3039]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  514.467268] confd_mgr[3039]: TSeries-CIS is in the list: TSeries-CIS <NL> [  514.478770] confd_mgr[3039]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  514.602132] confd_mgr[3039]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  514.722273] confd_mgr[3039]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  514.743366] confd_mgr[3039]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  514.913415] confd_mgr[3039]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  515.387395] confd_mgr[3039]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  515.614352] confd_mgr[3039]: guard is_db_okay_g: The HA mode is 1+1 <NL> [  515.617187] confd_mgr[3039]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  515.819759] confd_mgr[3039]: entering: sm_startconfd::start_confd_p0 <NL> [  516.279717] confd_mgr[3039]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  516.378078] confd_mgr[3039]: leaving: wait_for_alarm_process <NL> [  516.456475] confd_mgr[3039]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:160:write_alarms_to_file: #ALARMS=1 <NL> [  516.587699] confd_mgr[3039]:  write_db_alarm rename was successful <NL> [  516.601268] confd_mgr[3039]: entering: wait_for_alarm_event <NL> [  516.930872] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 3 <NL> [  516.989390] confd_mgr[3697]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:21:17 UTC 2024 <NL> [  516.991347] confd_mgr[3039]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  517.900332] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 4 <NL> [  517.992825] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  518.006235] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  518.009227] ntputils[1710]: child pid is 3794"}
{"timestamp_utc": "2024-07-31T08:21:32.788Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  389.470354] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  389.470469] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  389.472994] confd_mgr[2975]: ConfdHA Not supported command CONFIRM <NL> [  389.473143] confd_mgr[2975]: sm_startconfd::p0_ready_dbc"}
{"timestamp_utc": "2024-07-31T08:21:32.789Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  389.473246] confd_mgr[2975]: Find message VALHDLR_CONFIRM <NL> [  389.473719] confd_mgr[2975]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  389.473948] confd_mgr[2975]: sm_startconfd::p0_not_ready <NL> [  389.474048] confd_mgr[2975]: Find message VALHDLR_CONFIRM <NL> [  389.474127] confd_mgr[2975]: sm_startconfd::p0_ready_no_dbc <NL> [  389.474212] confd_mgr[2975]: Find message VALHDLR_CONFIRM <NL> [  389.474367] confd_mgr[2975]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  389.474443] confd_mgr[2975]: leaving: sm_startconfd::wait_for_p0 <NL> [  389.474516] confd_mgr[2975]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  389.474608] confd_mgr[2975]: entering: sm_startconfd::start_confd_p1 <NL> [  389.474889] confd_mgr[2975]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  389.571525] confd_mgr[4005]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:19:25 UTC 2024 <NL> [  390.024738] confd_mgr[4018]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  390.024967] confd_mgr[2975]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  427.160195] txid_tracker[3793]: ::::create_confd_subscription_connection() connected <NL> [  437.859873] confd_mgr[2975]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  437.882174] confd_mgr[4194]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:20:13 UTC 2024 <NL> [  438.047123] confd_mgr[4194]: Invoking confd_load_upgrade_xml.py <NL> [  440.717510] confd_mgr[4201]: confd_load_upgrade_xml.py: Start <NL> [  440.718156] confd_mgr[4201]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  441.373728] confd_mgr[2975]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  441.467203] confd_mgr[4212]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  441.528108] confd_mgr[2975]: CONFD IN PHASE 1 <NL> [  441.544884] confd_mgr[2975]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  441.545086] confd_mgr[2975]: leaving: sm_startconfd::start_confd_p1 <NL> [  441.545189] confd_mgr[2975]: entering: sm_startconfd::wait_for_p1 <NL> [  441.545291] confd_mgr[2975]: PROCESS3 has not registered yet. <NL> [  441.553625] python3[4003]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  441.598319] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  441.601215] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  441.601633] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  441.601757] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  441.609404] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  441.639971] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  441.640091] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  441.640175] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  441.640252] confd_mgr[2975]: ConfdHA Not supported command CONFIRM <NL> [  441.640325] confd_mgr[2975]: sm_startconfd::p1_not_ready <NL> [  441.640400] confd_mgr[2975]: Find message MESSAGE3 <NL> [  441.640481] confd_mgr[2975]: sm_startconfd::p1_ready <NL> [  441.640635] confd_mgr[2975]: Find message MESSAGE3 <NL> [  441.640713] confd_mgr[2975]: leaving: sm_startconfd::wait_for_p1 <NL> [  441.640788] confd_mgr[2975]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  441.640864] confd_mgr[2975]: entering: sm_startconfd::wait_for_rm <NL> [  441.640948] confd_mgr[2975]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  441.641050] confd_mgr[2975]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  441.725213] confd_mgr[4216]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:20:17 UTC 2024 <NL> [  441.996586] confd_mgr[4230]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  442.017396] confd_mgr[4233]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  442.212393] confd_mgr[2975]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  442.234428] confd_mgr[4243]: /usr/bin/replay_manager NONE <NL> [  442.271652] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  442.271808] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  442.295316] confd_mgr[4241]: redundancy_status is STANDALONE <NL> [  442.295566] confd_mgr[4241]: DDS ports will be opened. <NL> [  442.295665] confd_mgr[4241]: execute replay_manager NONE TRUE <NL> [  442.888611] confd_mgr[4248]: TRACE Connected (cdb) to ConfD <NL> [  442.916764] confd_mgr[4248]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  443.025421] confd_mgr[4248]: TRACE Connected (cdb) to ConfD <NL> [  443.025655] confd_mgr[4248]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  448.231969] confd_mgr[4248]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  448.274778] txid_tracker[3793]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  448.275617] confd_mgr[4248]: TRACE CDB_TRIGGER_SUBS <NL> [  448.276278] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  448.344812] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  448.345054] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  448.345147] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  448.345280] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  448.345368] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  448.433601] txid_tracker[4273]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  448.433838] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  448.434527] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  460.523844] systemd-journald[358]: Data hash table of /run/log/journal/2248b4323854441fb0634243a4ab8d0b/system.journal has a fill level at 75.0 (13654 of 18204 items, 10485760 file size, 767 bytes per hash table item), suggesting rotation. <NL> [  460.613123] systemd-journald[358]: /run/log/journal/2248b4323854441fb0634243a4ab8d0b/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  474.013654] systemd-sysv-generator[4344]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  480.742125] systemd-sysv-generator[4365]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  515.196795] dcn_dns_controller[1601]: fin_file is open <NL> [  515.337276] dcn_dns_controller[1601]: fin_file is open <NL> [  515.705933] userddssub[4455]: useradd: user 'fujitsu' already exists <NL> [  515.717983] userddssub[2461]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  516.264153] ntputils[1855]: bool NTPServer::handle_command(const string&) <NL> [  516.347652] ntputils[1855]: bool NTPServer::handle_configure_cmd(const string&) <NL> [  516.381137] ntputils[1855]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  516.386497] ntputils[1855]: parse_time_persistent_topic ddskind create <NL> [  516.391727] ntputils[1855]: parse_time_persistent_topic name key config <NL> [  516.392660] ntputils[1855]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  516.393802] ntputils[1855]: parse_time_topics command_data enable=yes; <NL> [  516.394709] ntputils[1855]: handle_configure_cmd token is: enable=yes"}
{"timestamp_utc": "2024-07-31T08:21:33.716Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  449.505492] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 4 <NL> [  450.074886] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  450.297935] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  452.524444] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 5 <NL> [  454.802410] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  454.803455] python3[2128]: [.036] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 17 of -1! <NL> [  454.859844] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  455.335724] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  456.683708] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 6 <NL> [  458.538952] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 7 <NL> [  459.816203] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  459.989854] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  461.579938] txid_tracker[3531]: ::::create_confd_subscription_connection() try number 8 <NL> [  464.044797] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  464.171583] python3[2128]: [.081] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 18 of -1! <NL> [  464.837623] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  464.843023] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  467.824773] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 1 <NL> [  469.843915] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  470.361721] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  470.864319] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 2 <NL> [  473.805954] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 3 <NL> [  474.417815] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  474.554670] python3[2128]: [.454] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 19 of -1! <NL> [  474.859274] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  475.162663] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  477.376668] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 4 <NL> [  478.834392] systemd-sysv-generator[3737]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust."}
{"timestamp_utc": "2024-07-31T08:21:33.717Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  479.864958] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  481.526822] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  481.971850] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 5 <NL> [  483.200298] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 6 <NL> [  484.961812] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  485.420346] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused[  486.401689] tun: Universal TUN/TAP device driver, 1.6 <NL> [  487.003166] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  487.459383] python3[2128]: [.775] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 20 of -1! <NL> [  488.479482] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 7 <NL> [  488.908542] txid_tracker[3649]: ::::create_confd_subscription_connection() try number 8 <NL> [  490.126346] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  490.154400] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  494.059814] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 1 <NL> [  494.888213] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  495.421491] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  496.340707] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  496.727484] python3[2128]: [.338] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 21 of -1! <NL> [  497.053186] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 2 <NL> [  499.888459] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  500.124040] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  500.239805] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 3 <NL> [  502.978627] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 4 <NL> [  504.900508] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  505.478652] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  505.876195] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  505.983677] python3[2128]: [.387] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 22 of -1! <NL> [  506.273118] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 5 <NL> [  509.010502] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 6 <NL> [  509.912904] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  510.090663] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  512.008462] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 7 <NL> [  514.930649] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  515.025754] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  515.328755] txid_tracker[3783]: ::::create_confd_subscription_connection() try number 8"}
{"timestamp_utc": "2024-07-31T08:21:35.081Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:21:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:35.644Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:35 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:35 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:35.900Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:21:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:35 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:38.414Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  516.399788] ntputils[1855]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  516.400788] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  516.401515] ntputils[1855]: systemctl --no-block stop ntpd <NL> [  516.402212] ntputils[1855]: child pid is 4522 <NL> [  516.542033] ntputils[1855]: exited, status is 0 <NL> [  516.599016] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  516.649503] ntputils[1855]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  516.652251] ntputils[1855]: child pid is 4532 <NL> [  516.668082] ntputils[1855]: exited, status is 0 <NL> [  516.669767] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  516.671713] ntputils[1855]: /bin/systemctl reset-failed ntpd <NL> [  516.676383] ntputils[1855]: child pid is 4540 <NL> [  516.685243] ntputils[1855]: exited, status is 0 <NL> [  516.685972] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  516.686664] ntputils[1855]: systemctl --no-block start ntpd <NL> [  516.687503] ntputils[1855]: child pid is 4545 <NL> [  516.841865] ntputils[1855]: exited, status is 0 <NL> [  516.842072] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  516.842161] ntputils[1855]: systemctl --no-block start ntpscript <NL> [  516.842264] ntputils[1855]: child pid is 4550 <NL> [  517.233735] ntputils[1855]: exited, status is 0 <NL> [  517.233909] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  517.233986] ntputils[1855]: /bin/systemctl --no-block start init_state_check.timer <NL> [  517.275991] ntputils[1855]: child pid is 4555 <NL> [  517.276114] ntputils[1855]: exited, status is 0 <NL> [  517.278410] ntputils[1855]: Configure command handled successfully, writing to RTC <NL> [  517.278529] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  517.278603] ntputils[1855]: /sbin/hwclock -u --systohc <NL> [  517.279327] ntputils[1855]: child pid is 4559 <NL> [  517.279433] ntputils[1855]: exited, status is 0 <NL> [  517.279504] ntputils[1855]: bool NTPServer::handle_command(const string&)"}
{"timestamp_utc": "2024-07-31T08:21:38.415Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  517.279582] ntputils[1855]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [  517.279734] ntputils[1855]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  517.279820] ntputils[1855]: parse_time_persistent_topic ddskind create <NL> [  517.468785] ntputils[1855]: parse_time_persistent_topic name key setTZ <NL> [  517.468882] ntputils[1855]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  517.468961] ntputils[1855]: parse_time_topics command_data timezone=UTC; <NL> [  517.469085] ntputils[1855]: bool NTPServer::set_timezone(const string&) <NL> [  517.469163] ntputils[1855]: NTPServer::execute_cmd spawning: <NL> [  517.469241] ntputils[1855]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  517.469330] ntputils[1855]: child pid is 4560 <NL> [  517.469415] ntputils[1855]: exited, status is 0 <NL> [  517.469483] ntputils[1855]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  517.492759] ntputils[1855]: push_local_changes user_changed: 1 delta: 0 <NL> [  517.622474] ntputils[1855]: local_push OK u Platform::Time changedByUser 1 <NL> [  517.701483] ntputils[1855]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  517.701621] ntputils[1855]: local_push OK w Platform::Time 0 0 <NL> [  517.701718] ntputils[1855]: push_local_changes OK <NL> [  517.701797] ntputils[1855]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  517.701872] ntputils[1855]: publish_local_changes OK <NL> [  517.867040] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3348 <NL> [  517.885659] layer1_control_layer[2431]: EsalConfig::EsalConfig main 1 <NL> [  517.888754] layer1_control_layer[2431]: EsalConfig::EsalConfig trib 0 <NL> [  517.892103] layer1_control_layer[2431]: EsalConfig::EsalConfig ciRole 0 <NL> [  518.032395] layer1_control_layer[2431]: EsalConfig is not running inside container. <NL> [  518.112129] layer1_control_layer[2431]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  518.112301] layer1_control_layer[2431]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  518.112386] layer1_control_layer[2431]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  518.112504] layer1_control_layer[2431]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  518.112585] layer1_control_layer[2431]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  518.112689] layer1_control_layer[2431]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  518.112768] layer1_control_layer[2431]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  518.112843] layer1_control_layer[2431]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  518.112914] layer1_control_layer[2431]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  518.113069] layer1_control_layer[2431]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  518.113166] layer1_control_layer[2431]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  518.113268] layer1_control_layer[2431]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  518.113365] layer1_control_layer[2431]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  518.113463] layer1_control_layer[2431]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  518.113626] layer1_control_layer[2431]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  518.113722] layer1_control_layer[2431]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  518.113838] layer1_control_layer[2431]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  519.602131] ntp_alarm_event_monitor.py[4552]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  519.602408] ntp_alarm_event_monitor.py[4552]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  520.041797] ntp_alarm_event_monitor.py[4552]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  520.042101] ntp_alarm_event_monitor.py[4552]: INFO:root:redundancy status now set to standalone <NL> [  520.332696] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3347 <NL> [  520.364099] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3347 <NL> [  520.449813] layer1_hal[2469]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  520.450085] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3347 <NL> [  520.450174] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3347 <NL> [  520.450254] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3347 <NL> [  520.483311] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3347 <NL> [  520.524319] layer1_hal[2469]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  520.580617] ntp_alarm_event_monitor.py[4552]: INFO:root:Publish Alarm: Raising alarm <NL> [  520.658184] confd_mgr[4248]:  --> CONFD_OK <NL> [  520.706980] confd_mgr[4634]: openDdsPorts interfaces  eth5.2003 <NL> [  520.707274] confd_mgr[4634]: openDdsPorts Input udpPorts-  7660 <NL> [  520.778120] ntp_alarm_event_monitor.py[4552]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  520.778431] layer1_control_layer[2431]:    ChalApi Constructor with tid = 3350 <NL> [  520.842613] confd_mgr[4634]: openDdsPorts Output udpPorts-  7660 <NL> [  520.881718] confd_mgr[4634]: openDdsPorts Input udpPorts-  7661 <NL> [  520.945574] confd_mgr[4634]: openDdsPorts Output udpPorts-  7661 <NL> [  520.945828] confd_mgr[4634]: openDdsPorts Input udpPorts-  7650 <NL> [  520.991560] confd_mgr[4634]: openDdsPorts Output udpPorts-  7650 <NL> [  521.057940] confd_mgr[4634]: openDdsPorts Input udpPorts-  7651 <NL> [  521.122589] confd_mgr[4634]: openDdsPorts Output udpPorts-  7651 <NL> [  521.168998] confd_mgr[4634]: openDdsPorts Input udpPorts-  7900 <NL> [  521.196690] confd_mgr[4634]: openDdsPorts Output udpPorts-  7900 <NL> [  521.289695] confd_mgr[4634]: openDdsPorts Input udpPorts-  7901 <NL> [  521.367594] confd_mgr[4634]: openDdsPorts Output udpPorts-  7901 <NL> [  521.448405] confd_mgr[4634]: openDdsPorts Input udpPorts-  7910 <NL> [  521.449677] confd_mgr[4634]: openDdsPorts Output udpPorts-  7910 <NL> [  521.449762] confd_mgr[4634]: openDdsPorts Input udpPorts-  7911 <NL> [  521.550486] confd_mgr[4634]: openDdsPorts Output udpPorts-  7911"}
{"timestamp_utc": "2024-07-31T08:21:40.929Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:40 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:40 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:40 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:45.100Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  449.666863] confd_mgr[2947]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  449.666954] confd_mgr[2947]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  449.854676] confd_mgr[4263]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:20:24 UTC 2024 <NL> [  450.202423] confd_mgr[4275]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  450.293243] confd_mgr[4278]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  450.403268] confd_mgr[2947]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  450.468985] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  450.469136] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  450.524567] confd_mgr[4288]: /usr/bin/replay_manager NONE <NL> [  450.609532] confd_mgr[4286]: redundancy_status is STANDALONE <NL> [  450.609734] confd_mgr[4286]: DDS ports will be opened. <NL> [  450.609828] confd_mgr[4286]: execute replay_manager NONE TRUE <NL> [  451.163259] confd_mgr[4293]: TRACE Connected (cdb) to ConfD <NL> [  451.227915] confd_mgr[4293]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  451.245830] confd_mgr[4293]: TRACE Connected (cdb) to ConfD <NL> [  451.355622] confd_mgr[4293]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  456.448823] confd_mgr[4293]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  456.517985] txid_tracker[3784]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  456.538296] confd_mgr[4293]: TRACE CDB_TRIGGER_SUBS <NL> [  456.559804] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  456.564026] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  456.564200] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  456.564280] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  456.564353] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  456.564422] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  456.586683] txid_tracker[4318]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  456.586877] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  456.586977] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  470.855162] systemd-journald[357]: Data hash table of /run/log/journal/5383bddcba4644dfa1b979cbbe931122/system.journal has a fill level at 75.0 (13655 of 18204 items, 10485760 file size, 767 bytes per hash table item), suggesting rotation. <NL> [  470.904950] systemd-journald[357]: /run/log/journal/5383bddcba4644dfa1b979cbbe931122/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  482.640360] systemd-sysv-generator[4397]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  488.130779] systemd-sysv-generator[4420]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  525.404652] dcn_dns_controller[1592]: fin_file is open <NL> [  525.725301] dcn_dns_controller[1592]: fin_file is open <NL> [  526.304123] ntputils[1967]: bool NTPServer::handle_command(const string&) <NL> [  526.304403] ntputils[1967]: bool NTPServer::handle_configure_cmd(const string&) <NL> [  526.304547] ntputils[1967]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  526.304640] ntputils[1967]: parse_time_persistent_topic ddskind create <NL> [  526.304715] ntputils[1967]: parse_time_persistent_topic name key config <NL> [  526.321091] ntputils[1967]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  526.401614] ntputils[1967]: parse_time_topics command_data enable=yes; <NL> [  526.401866] ntputils[1967]: handle_configure_cmd token is: enable=yes <NL> [  526.402039] ntputils[1967]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  526.500030] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  526.500300] ntputils[1967]: systemctl --no-block stop ntpd <NL> [  526.514571] ntputils[1967]: child pid is 4564 <NL> [  526.514760] ntputils[1967]: exited, status is 0 <NL> [  526.525059] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  526.551147] ntputils[1967]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  526.575793] ntputils[1967]: child pid is 4573 <NL> [  526.585196] userddssub[4521]: useradd: user 'fujitsu' already exists <NL> [  526.675273] userddssub[2442]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  526.980432] ntputils[1967]: exited, status is 0 <NL> [  526.980553] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  526.980622] ntputils[1967]: /bin/systemctl reset-failed ntpd <NL> [  526.980703] ntputils[1967]: child pid is 4593 <NL> [  527.136561] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3310 <NL> [  527.198679] layer1_control_layer[2418]: EsalConfig::EsalConfig main 1 <NL> [  527.198815] layer1_control_layer[2418]: EsalConfig::EsalConfig trib 0 <NL> [  527.198891] layer1_control_layer[2418]: EsalConfig::EsalConfig ciRole 0 <NL> [  527.289871] layer1_control_layer[2418]: EsalConfig is not running inside container. <NL> [  527.387326] layer1_control_layer[2418]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  527.387441] layer1_control_layer[2418]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  527.388081] layer1_control_layer[2418]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  527.388184] layer1_control_layer[2418]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  527.388260] layer1_control_layer[2418]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  527.388332] layer1_control_layer[2418]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  527.388409] layer1_control_layer[2418]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  527.388538] layer1_control_layer[2418]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  527.388611] layer1_control_layer[2418]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  527.389301] layer1_control_layer[2418]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  527.389391] layer1_control_layer[2418]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  527.389466] layer1_control_layer[2418]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  527.389541] layer1_control_layer[2418]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  527.389613] layer1_control_layer[2418]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  527.389688] layer1_control_layer[2418]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  527.390332] layer1_control_layer[2418]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  527.390428] layer1_control_layer[2418]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  527.853034] ntputils[1967]: exited, status is 0 <NL> [  527.853212] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  527.853287] ntputils[1967]: systemctl --no-block start ntpd <NL> [  527.853365] ntputils[1967]: child pid is 4619 <NL> [  528.018796] ntputils[1967]: exited, status is 0 <NL> [  528.018941] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  528.019035] ntputils[1967]: systemctl --no-block start ntpscript <NL> [  528.019114] ntputils[1967]: child pid is 4628 <NL> [  528.357657] ntputils[1967]: exited, status is 0 <NL> [  528.357801] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  528.357881] ntputils[1967]: /bin/systemctl --no-block start init_state_check.timer <NL> [  528.429710] ntputils[1967]: child pid is 4634 <NL> [  528.666436] ntputils[1967]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:21:45.101Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  528.666605] ntputils[1967]: Configure command handled successfully, writing to RTC"}
{"timestamp_utc": "2024-07-31T08:21:45.690Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:45 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:45.691Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:21:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:45 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:45.946Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:21:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:45 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:51.190Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:50 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:50 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:50 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:56.433Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:21:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:55 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:55 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> [  528.666709] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  528.666779] ntputils[1967]: /sbin/hwclock -u --systohc <NL> [  528.666853] ntputils[1967]: child pid is 4637 <NL> [  528.687846] ntputils[1967]: exited, status is 0 <NL> [  528.867570] ntputils[1967]: bool NTPServer::handle_command(const string&) <NL> [  528.867709] ntputils[1967]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [  528.867852] ntputils[1967]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  528.885811] ntputils[1967]: parse_time_persistent_topic ddskind create <NL> [  529.036590] ntputils[1967]: parse_time_persistent_topic name key setTZ <NL> [  529.036701] ntputils[1967]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  529.102992] ntputils[1967]: parse_time_topics command_data timezone=UTC; <NL> [  529.254328] ntputils[1967]: bool NTPServer::set_timezone(const string&) <NL> [  529.254449] ntputils[1967]: NTPServer::execute_cmd spawning: <NL> [  529.254548] ntputils[1967]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  529.254624] ntputils[1967]: child pid is 4638 <NL> [  529.254697] ntputils[1967]: exited, status is 0 <NL> [  529.254769] ntputils[1967]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  529.254850] ntputils[1967]: push_local_changes user_changed: 1 delta: 0 <NL> [  529.254935] ntputils[1967]: local_push OK u Platform::Time changedByUser 1 <NL> [  529.315170] ntputils[1967]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  529.343909] ntputils[1967]: local_push OK w Platform::Time 0 0 <NL> [  529.394296] ntputils[1967]: push_local_changes OK <NL> [  529.394399] ntputils[1967]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  529.394532] ntputils[1967]: publish_local_changes OK <NL> [  531.541739] ntp_alarm_event_monitor.py[4630]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  531.542039] ntp_alarm_event_monitor.py[4630]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  532.328168] ntp_alarm_event_monitor.py[4630]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  532.403562] ntp_alarm_event_monitor.py[4630]: INFO:root:redundancy status now set to standalone <NL> [  532.535117] ntp_alarm_event_monitor.py[4630]: INFO:root:Publish Alarm: Raising alarm <NL> [  532.755579] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3309 <NL> [  532.804865] ntp_alarm_event_monitor.py[4630]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  532.956171] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3309 <NL> [  533.109080] layer1_hal[2447]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  533.348346] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3309 <NL> [  533.663866] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3309 <NL> [  533.664886] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3312 <NL> [  533.665020] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3309 <NL> [  533.666994] layer1_control_layer[2418]:    ChalApi Constructor with tid = 3309 <NL> [  533.750145] layer1_hal[2447]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  536.619808] confd_mgr[4293]:  --> CONFD_OK <NL> [  537.268157] confd_mgr[4717]: openDdsPorts interfaces  eth5.2003 <NL> [  537.268376] confd_mgr[4717]: openDdsPorts Input udpPorts-  7660 <NL> [  537.340351] confd_mgr[4717]: openDdsPorts Output udpPorts-  7660 <NL> [  537.366644] confd_mgr[4717]: openDdsPorts Input udpPorts-  7661 <NL> [  537.416241] confd_mgr[4717]: openDdsPorts Output udpPorts-  7661 <NL> [  537.425402] confd_mgr[4717]: openDdsPorts Input udpPorts-  7650 <NL> [  537.447887] confd_mgr[4717]: openDdsPorts Output udpPorts-  7650 <NL> [  537.450544] confd_mgr[4717]: openDdsPorts Input udpPorts-  7651 <NL> [  537.471449] confd_mgr[4717]: openDdsPorts Output udpPorts-  7651 <NL> [  537.471544] confd_mgr[4717]: openDdsPorts Input udpPorts-  7900 <NL> [  537.471627] confd_mgr[4717]: openDdsPorts Output udpPorts-  7900 <NL> [  537.471708] confd_mgr[4717]: openDdsPorts Input udpPorts-  7901 <NL> [  537.471789] confd_mgr[4717]: openDdsPorts Output udpPorts-  7901 <NL> [  537.471907] confd_mgr[4717]: openDdsPorts Input udpPorts-  7910 <NL> [  537.507885] confd_mgr[4717]: openDdsPorts Output udpPorts-  7910"}
{"timestamp_utc": "2024-07-31T08:21:56.434Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  537.584472] confd_mgr[4717]: openDdsPorts Input udpPorts-  7911 <NL> [  537.641271] confd_mgr[4717]: openDdsPorts Output udpPorts-  7911 <NL> [  537.678827] confd_mgr[4717]: openDdsPorts Input udpPorts-  8150 <NL> [  537.679135] confd_mgr[4717]: openDdsPorts Output udpPorts-  8150 <NL> [  537.679220] confd_mgr[4717]: openDdsPorts Input udpPorts-  8151 <NL> [  537.679296] confd_mgr[4717]: openDdsPorts Output udpPorts-  8151 <NL> [  537.679383] confd_mgr[4717]: openDdsPorts Input udpPorts-  8160 <NL> [  537.679468] confd_mgr[4717]: openDdsPorts Output udpPorts-  8160 <NL> [  537.679552] confd_mgr[4717]: openDdsPorts Input udpPorts-  8161 <NL> [  537.679626] confd_mgr[4717]: openDdsPorts Output udpPorts-  8161 <NL> [  537.886694] confd_mgr[4293]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  537.886909] confd_mgr[4293]: replay_manager:  Start-Wed Jul 31 08:20:25 2024 <NL> [  537.887025] confd_mgr[4293]:  ++++++++++++++++++++++ <NL> [  537.887112] confd_mgr[4293]: replay_manager: TXID NOT FOUND ================================== <NL> [  537.887195] confd_mgr[4293]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  537.887298] confd_mgr[4293]: replay_manager: Need to do trigger full replay. <NL> [  537.887380] confd_mgr[4293]: replay_manager: Creating the purge file. <NL> [  537.887460] confd_mgr[4293]: replay_manager: Open DDS Ports <NL> [  537.887541] confd_mgr[4293]: replay_manager: NOW deleting the purge file. <NL> [  537.887622] confd_mgr[4293]: replay_manager:  End-Wed Jul 31 08:21:52 2024 <NL> [  537.887718] confd_mgr[4293]:  ++++++++++++++++++++++ <NL> [  537.887797] confd_mgr[4293]: Not 1+1 Mode <NL> [  537.887876] confd_mgr[4293]: DipLog_pimpl destructor called <NL> [  537.887985] confd_mgr[4293]: DipVerbosity Listener ZMQ error <NL> [  537.888110] confd_mgr[4293]:     ret='Context was terminated <NL> [  537.888191] confd_mgr[4293]: deleting subscriber_ socket <NL> [  537.888272] confd_mgr[4293]: Exiting verb listener <NL> [  538.060278] confd_mgr[2947]: CommAT::asio_subscriber: Connection accepted <NL> [  538.063254] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  538.063377] confd_mgr[2947]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  538.063458] confd_mgr[2947]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  538.063536] confd_mgr[2947]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  538.063634] confd_mgr[2947]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  538.113229] confd_mgr[2947]: sm_startconfd::rm_ready <NL> [  538.144282] confd_mgr[2947]: leaving: sm_startconfd::wait_for_rm <NL> [  538.158850] confd_mgr[2947]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [  538.159033] confd_mgr[2947]: entering: sm_startconfd::start_confd_p2 <NL> [  538.159115] confd_mgr[2947]: ConfdHA Not supported command CONFIRM <NL> [  538.159201] confd_mgr[2947]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [  538.242542] confd_mgr[4760]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:21:52 UTC 2024 <NL> [  538.842547] confd_mgr[4770]: cmnEvtXML has stopped <NL> [  538.933732] confd_mgr[4770]: start event-handler.service <NL> [  539.648503] confd_mgr[4777]: condition_name: systemRestart <NL> [  539.648701] confd_mgr[4777]: entity_type: COM <NL> [  539.648802] confd_mgr[4777]: num_instances: 1 <NL> [  539.661836] confd_mgr[4777]: num_samples: 1 <NL> [  539.775601] confd_mgr[4777]:  EventNotification does not have condition_group. Skipping. <NL> [  539.775699] confd_mgr[4777]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [  539.775862] confd_mgr[4777]: CmnEvtPublisher::main: returning <NL> [  539.776532] ops-service[4786]: rebind_listener \"webui\" <NL> [  539.776625] ops-service[4786]: TRACE Connected (maapi) to ConfD <NL> [  539.776705] ops-service[4786]: TRACE MAAPI_REBIND_LISTENER <NL> [  539.776813] ops-service[4786]:  31-Jul-2024::08:21:54.330 4786/7f2b9d8d8c40/4 SEND op=407 isrel=0 th=-1 16 <NL> [  539.776906] ops-service[4786]:  --> CONFD_OK <NL> # 03:21:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:55 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:00.607Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:00 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:00 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:01.170Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:22:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:00 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:06.412Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:05 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:05 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:05 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:10.577Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:10 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:10 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:11.170Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:22:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:10 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:11 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37215\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:22:11.428Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  515.431854] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  515.710216] python3[2128]: [.400] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 23 of -1! <NL> [  519.874476] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 1 <NL> [  519.950609] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  519.951710] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  523.131823] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 2 <NL> [  524.950936] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  525.221695] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  525.419698] python3[2128]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  525.482663] python3[2128]: [.431] hookhdlr 139819433846592 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 24 of -1! <NL> [  526.061736] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 3 <NL> [  529.072113] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 4 <NL> [  529.964981] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  530.113592] confd_phase_sentry[2132]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f08b440d5c7; Failed to connect to ConfD: Connection refused <NL> [  532.104676] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 5 <NL> [  534.965095] confd_phase_sentry[2132]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  535.131284] confd_phase_sentry[2132]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  535.133268] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 6 <NL> [  536.172810] python3[2128]: DEBUG EOF on socket to ConfD <NL> [  536.175136] python3[2128]: [.932] hookhdlr 139819433846592 callbackhdlr:457 Exception to create daemon <NL> [  536.191801] python3[2128]: Traceback (most recent call last): <NL> [  536.192642] python3[2128]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  536.349299] python3[2128]:     daemon = self.create_daemon() <NL> [  536.394303] python3[2128]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  536.545452] python3[2128]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  536.606514] python3[2128]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  536.697908] python3[2128]:     self._init_connection() <NL> [  536.813770] python3[2128]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  536.885799] python3[2128]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  536.913730] python3[2128]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  537.020456] python3[2128]:     _tm.dp.connect( <NL> [  537.164675] python3[2128]: _confd.error.EOF: ConfD closed connection <NL> [  537.185496] python3[2128]: [.164] hookhdlr 139819433846592 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  538.153566] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 7 <NL> [  541.193073] txid_tracker[3836]: ::::create_confd_subscription_connection() try number 8 <NL> [  543.663615] rasis_system_stats.py[2134]: Traceback (most recent call last): <NL> [  543.665172] rasis_system_stats.py[2134]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  543.691144] rasis_system_stats.py[2134]:     main() <NL> [  543.692182] rasis_system_stats.py[2134]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  543.702315] rasis_system_stats.py[2134]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  543.704660] rasis_system_stats.py[2134]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  543.796240] rasis_system_stats.py[2134]:     self._init_connection() <NL> [  543.797314] rasis_system_stats.py[2134]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  543.908418] rasis_system_stats.py[2134]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  544.174986] rasis_system_stats.py[2134]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  544.431834] rasis_system_stats.py[2134]:     _tm.dp.connect( <NL> [  544.574825] rasis_system_stats.py[2134]: _confd.error.EOF: ConfD closed connection <NL> [  546.171096] python3[2128]: [.182] hookhdlr 139819433846592 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  546.446906] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 1 <NL> [  547.683247] python3[2128]: DEBUG EOF on socket to ConfD <NL> [  548.033238] python3[2128]: [.693] hookhdlr 139819433846592 callbackhdlr:457 Exception to create daemon <NL> [  548.814174] python3[2128]: Traceback (most recent call last): <NL> [  549.041979] python3[2128]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  549.325494] python3[2128]:     daemon = self.create_daemon() <NL> [  549.547224] python3[2128]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  549.811537] python3[2128]:     daemon = self._daemon_cls(name=self._daemon_name,"}
{"timestamp_utc": "2024-07-31T08:22:11.429Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  550.097724] python3[2128]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  550.615565] python3[2128]:     self._init_connection() <NL> [  550.802529] python3[2128]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  550.979692] python3[2128]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  551.056524] python3[2128]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  551.165708] python3[2128]:     _tm.dp.connect( <NL> [  551.239180] python3[2128]: _confd.error.EOF: ConfD closed connection <NL> [  551.304456] python3[2128]: [.732] hookhdlr 139819433846592 callbackhdlr:471 Failed to run daemon main, retry 2 of -1 <NL> [  551.460441] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 2 <NL> [  551.656378] db_info.py[2120]: Traceback (most recent call last): <NL> [  551.817494] db_info.py[2120]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  551.818499] db_info.py[2120]:     main() <NL> [  551.820041] db_info.py[2120]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  551.831907] db_info.py[2120]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  551.942329] db_info.py[2120]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  552.034355] db_info.py[2120]:     self._init_connection() <NL> [  552.142778] db_info.py[2120]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  552.323998] db_info.py[2120]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  552.325199] db_info.py[2120]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  552.326336] db_info.py[2120]:     _tm.dp.connect( <NL> [  552.326928] db_info.py[2120]: _confd.error.EOF: ConfD closed connection <NL> [  552.413169] healthcheck_result_display.py[2126]: Traceback (most recent call last): <NL> [  552.462967] healthcheck_result_display.py[2126]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  552.664038] healthcheck_result_display.py[2126]:     main(hc_utils.setup_logging(__name__)) <NL> [  552.812760] healthcheck_result_display.py[2126]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  553.032692] healthcheck_result_display.py[2126]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT)"}
{"timestamp_utc": "2024-07-31T08:22:15.596Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:15 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:15.597Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:22:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:15 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:16.159Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:22:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:15 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37215, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:21.422Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:20 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:20 retry-ssh-command INFO: attempt 105, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:21 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:23.941Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  518.009839] ntputils[1710]: exited, status is 0 <NL> [  518.015551] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  518.020735] ntputils[1710]: poller time change delta is: 1 <NL> [  518.025055] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  518.027690] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  518.042275] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  518.046895] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  518.050268] ntputils[1710]: push_local_changes OK <NL> [  518.379672] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  518.380594] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  520.874939] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 5 <NL> [  522.348920] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  523.311822] python3[2142]: [.465] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 24 of -1! <NL> [  523.369022] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  523.371354] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  523.847286] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 6 <NL> [  526.863513] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 7 <NL> [  528.378232] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  528.674477] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  529.997099] txid_tracker[3706]: ::::create_confd_subscription_connection() try number 8 <NL> [  532.838316] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  532.840151] python3[2142]: [.094] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 25 of -1! <NL> [  533.552325] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  534.088470] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  536.941951] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 1 <NL> [  538.384158] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  539.281305] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  540.549539] systemd-sysv-generator[3904]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  540.305211] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 2 <NL> [  542.981776] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  544.169555] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 3 <NL> [  545.264636] python3[2142]: [.222] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 26 of -1! <NL> [  546.189667] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  546.339787] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  552.223717] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  553.101158] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused[  554.754710] tun: Universal TUN/TAP device driver, 1.6 <NL> [  554.768081] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  555.582071] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  555.998646] ntputils[1710]: child pid is 3921 <NL> [  556.273418] ntputils[1710]: exited, status is 0 <NL> [  556.575639] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  556.627974] ntputils[1710]: poller time change delta is: 2 <NL> [  557.109599] ntputils[1710]: push_local_changes user_changed: 0 delta: 2 <NL> [  557.406885] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  557.408032] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  557.645811] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  557.954469] ntputils[1710]: push_local_changes OK <NL> [  558.629216] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  559.026223] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  559.476362] ntputils[1710]: child pid is 3939 <NL> [  559.477136] ntputils[1710]: exited, status is 0 <NL> [  559.518227] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  560.318646] ntputils[1710]: poller time change delta is: 2"}
{"timestamp_utc": "2024-07-31T08:22:23.942Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  560.644712] ntputils[1710]: push_local_changes user_changed: 0 delta: 2 <NL> [  560.661373] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  560.662464] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  560.663289] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  560.814341] ntputils[1710]: push_local_changes OK <NL> [  561.110629] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 4 <NL> [  561.772070] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 5 <NL> [  561.958367] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 6 <NL> [  562.387479] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 7 <NL> [  562.725896] txid_tracker[3877]: ::::create_confd_subscription_connection() try number 8 <NL> [  563.929069] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  564.158331] python3[2142]: [.511] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 27 of -1! <NL> [  564.628588] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  564.892178] python3[2142]: [.844] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 28 of -1! <NL> [  565.473551] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [  566.070874] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [  566.197932] ntputils[1710]: child pid is 3957 <NL> [  566.201662] ntputils[1710]: exited, status is 0 <NL> [  566.205707] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [  566.631230] ntputils[1710]: poller time change delta is: 1 <NL> [  566.733795] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [  567.241912] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [  567.470215] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  567.806564] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [  567.828247] ntputils[1710]: push_local_changes OK <NL> [  567.948124] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  568.374911] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  569.603211] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  295.641615] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  295.642759] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.604538, delay 0.12952\\n31 Jul 08:17:50 ntpdate[2881]: no server suitable for synchronization found\\n' <NL> [  307.540965] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  307.543758] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  307.550410] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.581012, delay 0.04163\\n31 Jul 08:18:02 ntpdate[2927]: no server suitable for synchronization found\\n' <NL> [  319.456430] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  319.457472] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  319.490073] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.589080, delay 0.03755\\n31 Jul 08:18:14 ntpdate[2954]: no server suitable for synchronization found\\n' <NL> [  331.374276] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  331.379964] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  331.380852] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.608894, delay 0.07294\\n31 Jul 08:18:25 ntpdate[2981]: no server suitable for synchronization found\\n' <NL> [  343.265547] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  343.266885] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  343.277392] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.608045, delay 0.07314\\n31 Jul 08:18:37 ntpdate[3023]: no server suitable for synchronization found\\n' <NL> [  355.277444] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  355.355975] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  355.356099] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.588524, delay 0.03401\\n31 Jul 08:18:49 ntpdate[3049]: no server suitable for synchronization found\\n' <NL> [  367.227606] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  367.229620] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  367.229731] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.597909, delay 0.05072\\n31 Jul 08:19:01 ntpdate[3109]: no server suitable for synchronization found\\n' <NL> [  378.977443] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  378.978261] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  378.978368] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.590479, delay 0.04655\\n31 Jul 08:19:13 ntpdate[3152]: no server suitable for synchronization found\\n' <NL> [  390.936965] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  390.937471] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  390.937559] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.586297, delay 0.03218\\n31 Jul 08:19:25 ntpdate[3178]: no server suitable for synchronization found\\n' <NL> [  402.792277] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  402.792757] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  402.792876] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.586346, delay 0.04825\\n31 Jul 08:19:37 ntpdate[3214]: no server suitable for synchronization found\\n' <NL> [  414.737417] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  414.738136] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  414.738235] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.581870, delay 0.03413\\n31 Jul 08:19:49 ntpdate[3246]: no server suitable for synchronization found\\n' <NL> [  426.693935] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  426.743594] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  426.743807] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.584926, delay 0.03011\\n31 Jul 08:20:01 ntpdate[3274]: no server suitable for synchronization found\\n' <NL> [  438.590073] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  438.590714] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  438.590954] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.593648, delay 0.04472\\n31 Jul 08:20:13 ntpdate[3320]: no server suitable for synchronization found\\n' <NL> [  450.436232] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  450.452224] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  450.453940] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.585123, delay 0.02946\\n31 Jul 08:20:25 ntpdate[3352]: no server suitable for synchronization found\\n' <NL> [  462.317289] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  462.318354] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  462.318472] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.580882, delay 0.03674\\n31 Jul 08:20:36 ntpdate[3395]: no server suitable for synchronization found\\n' <NL> [  474.258912] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  474.259228] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  474.259330] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.574932, delay 0.05785\\n31 Jul 08:20:48 ntpdate[3421]: no server suitable for synchronization found\\n' <NL> [  527.499481] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  527.500364] ntputils_client.py[1716]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  527.500458] ntputils_client.py[1716]: b'31 Jul 08:21:42 ntpdate[3566]: no server suitable for synchronization found\\n' <NL> [  530.196605] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  530.196810] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  530.196889] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.003696, delay 0.03993\\n31 Jul 08:21:45 ntpdate[3593]: no server suitable for synchronization found\\n' <NL> [  538.194283] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  538.195538] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  538.201858] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.008969, delay 0.06216\\n31 Jul 08:21:53 ntpdate[3612]: no server suitable for synchronization found\\n' <NL> [  550.117748] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  550.137675] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  550.185437] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.000745, delay 0.04845\\n31 Jul 08:22:05 ntpdate[3677]: no server suitable for synchronization found\\n' <NL> [  561.985422] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  562.034141] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:22:23.943Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[  562.034299] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.036220, delay 0.11069\\n31 Jul 08:22:17 ntpdate[3712]: no server suitable for synchronization found\\n' <NL> [  567.592267] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2364 <NL> [  567.635740] layer1_control_layer[2060]: EsalConfig::EsalConfig main 0 <NL> [  567.636046] layer1_control_layer[2060]: EsalConfig::EsalConfig trib 1 <NL> [  567.636172] layer1_control_layer[2060]: EsalConfig::EsalConfig ciRole 0 <NL> [  567.692439] layer1_control_layer[2060]: EsalConfig is not running inside container. <NL> [  567.698362] layer1_control_layer[2060]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  567.698657] layer1_control_layer[2060]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  567.699029] layer1_control_layer[2060]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  567.699166] layer1_control_layer[2060]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:22:25.863Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:25 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp79:37311\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:25 retry-ssh-command INFO: attempt 106, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:26.119Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:22:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:26 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:31.368Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37311, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:30 retry-ssh-command INFO: attempt 107, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:31 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:36.616Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:22:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:35 retry-ssh-command INFO: attempt 108, sleep 5: \"rtxoialp79:37279\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:36 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',) <NL> [  296.421832] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.308230, delay 0.04382\\n31 Jul 08:17:50 ntpdate[2926]: no server suitable for synchronization found\\n' <NL> [  308.315232] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  308.315818] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  308.315923] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.326209, delay 0.06599\\n31 Jul 08:18:02 ntpdate[2954]: no server suitable for synchronization found\\n' <NL> [  320.150482] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  320.152638] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  320.152796] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.310990, delay 0.04375\\n31 Jul 08:18:14 ntpdate[2987]: no server suitable for synchronization found\\n' <NL> [  332.030600] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  332.032271] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  332.032420] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.314780, delay 0.03061\\n31 Jul 08:18:26 ntpdate[3013]: no server suitable for synchronization found\\n' <NL> [  343.976828] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  343.978168] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  343.978309] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.322941, delay 0.04695\\n31 Jul 08:18:38 ntpdate[3056]: no server suitable for synchronization found\\n' <NL> [  355.920890] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  355.921114] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  355.921268] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.313323, delay 0.02847\\n31 Jul 08:18:50 ntpdate[3083]: no server suitable for synchronization found\\n' <NL> [  367.821842] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  367.828921] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  367.830037] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.311924, delay 0.03786\\n31 Jul 08:19:02 ntpdate[3156]: no server suitable for synchronization found\\n' <NL> [  379.640335] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  379.641301] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  379.685200] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.314462, delay 0.03760\\n31 Jul 08:19:13 ntpdate[3186]: no server suitable for synchronization found\\n' <NL> [  391.487244] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  391.488149] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  391.489301] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.330614, delay 0.06296\\n31 Jul 08:19:25 ntpdate[3212]: no server suitable for synchronization found\\n' <NL> [  403.420713] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  403.420949] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  403.421043] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.288970, delay 0.07576\\n31 Jul 08:19:37 ntpdate[3247]: no server suitable for synchronization found\\n' <NL> [  415.239817] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  415.240080] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  415.240147] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.308396, delay 0.03563\\n31 Jul 08:19:49 ntpdate[3274]: no server suitable for synchronization found\\n' <NL> [  427.152509] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  427.153088] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  427.153179] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.308873, delay 0.03821\\n31 Jul 08:20:01 ntpdate[3321]: no server suitable for synchronization found\\n' <NL> [  439.089060] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  439.089249] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  439.089327] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.312967, delay 0.02623\\n31 Jul 08:20:13 ntpdate[3354]: no server suitable for synchronization found\\n' <NL> [  451.024258] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  451.048341] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  451.069802] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.322709, delay 0.06227\\n31 Jul 08:20:25 ntpdate[3384]: no server suitable for synchronization found\\n' <NL> [  539.174163] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  539.174461] ntputils_client.py[1730]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  539.174543] ntputils_client.py[1730]: b'31 Jul 08:21:53 ntpdate[3617]: no server suitable for synchronization found\\n' <NL> [  542.023974] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  542.024180] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  542.024285] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.007721, delay 0.04904\\n31 Jul 08:21:55 ntpdate[3650]: no server suitable for synchronization found\\n' <NL> [  550.750520] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  550.752391] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  550.752512] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.001005, delay 0.02980\\n31 Jul 08:22:04 ntpdate[3705]: no server suitable for synchronization found\\n' <NL> [  562.765643] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  562.766231] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  562.766321] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.003053, delay 0.03206\\n31 Jul 08:22:16 ntpdate[3736]: no server suitable for synchronization found\\n' <NL> [  574.589110] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  574.589506] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  574.589594] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.000362, delay 0.03326\\n31 Jul 08:22:28 ntpdate[3770]: no server suitable for synchronization found\\n' <NL> [  580.775527] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2358 <NL> [  580.843605] layer1_control_layer[2076]: EsalConfig::EsalConfig main 0 <NL> [  580.908365] layer1_control_layer[2076]: EsalConfig::EsalConfig trib 1 <NL> [  580.908485] layer1_control_layer[2076]: EsalConfig::EsalConfig ciRole 0 <NL> [  580.908765] layer1_control_layer[2076]: EsalConfig is not running inside container."}
{"timestamp_utc": "2024-07-31T08:22:36.617Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[  580.908845] layer1_control_layer[2076]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  580.908918] layer1_control_layer[2076]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  580.908989] layer1_control_layer[2076]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  580.909075] layer1_control_layer[2076]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  580.909163] layer1_control_layer[2076]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  580.909288] layer1_control_layer[2076]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  580.909360] layer1_control_layer[2076]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  580.909442] layer1_control_layer[2076]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  580.909513] layer1_control_layer[2076]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  580.909589] layer1_control_layer[2076]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  580.909671] layer1_control_layer[2076]: Libconfig::openAndRead /var/shared/commsStp.conf"}
{"timestamp_utc": "2024-07-31T08:22:37.179Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  521.729309] confd_mgr[4634]: openDdsPorts Input udpPorts-  8150 <NL> [  521.892474] confd_mgr[4634]: openDdsPorts Output udpPorts-  8150 <NL> [  521.917948] confd_mgr[4634]: openDdsPorts Input udpPorts-  8151 <NL> [  522.034723] confd_mgr[4634]: openDdsPorts Output udpPorts-  8151 <NL> [  522.093502] confd_mgr[4634]: openDdsPorts Input udpPorts-  8160 <NL> [  522.093714] confd_mgr[4634]: openDdsPorts Output udpPorts-  8160 <NL> [  522.227571] confd_mgr[4634]: openDdsPorts Input udpPorts-  8161 <NL> [  522.378602] confd_mgr[4634]: openDdsPorts Output udpPorts-  8161 <NL> [  522.807995] confd_mgr[4248]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  522.809931] confd_mgr[4248]: replay_manager:  Start-Wed Jul 31 08:20:18 2024 <NL> [  522.818866] confd_mgr[4248]:  ++++++++++++++++++++++ <NL> [  522.840752] confd_mgr[4248]: replay_manager: TXID NOT FOUND ================================== <NL> [  522.864563] confd_mgr[4248]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  522.883688] confd_mgr[4248]: replay_manager: Need to do trigger full replay. <NL> [  522.952829] confd_mgr[4248]: replay_manager: Creating the purge file. <NL> [  523.037409] confd_mgr[4248]: replay_manager: Open DDS Ports <NL> [  523.037608] confd_mgr[4248]: replay_manager: NOW deleting the purge file. <NL> [  523.037726] confd_mgr[4248]: replay_manager:  End-Wed Jul 31 08:21:37 2024 <NL> [  523.037834] confd_mgr[4248]:  ++++++++++++++++++++++ <NL> [  523.037917] confd_mgr[4248]: Not 1+1 Mode <NL> [  523.037999] confd_mgr[4248]: DipLog_pimpl destructor called <NL> [  523.038123] confd_mgr[4248]: DipVerbosity Listener ZMQ error <NL> [  523.038282] confd_mgr[4248]:     ret='Context was terminated <NL> [  523.051030] confd_mgr[4248]: deleting subscriber_ socket <NL> [  523.249577] confd_mgr[4248]: Exiting verb listener <NL> [  523.251049] confd_mgr[2975]: CommAT::asio_subscriber: Connection accepted <NL> [  523.256303] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  523.269040] confd_mgr[2975]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  523.269171] confd_mgr[2975]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  523.269258] confd_mgr[2975]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  523.269333] confd_mgr[2975]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  523.269450] confd_mgr[2975]: ConfdHA Not supported command CONFIRM <NL> [  523.269526] confd_mgr[2975]: sm_startconfd::rm_ready <NL> [  523.269602] confd_mgr[2975]: leaving: sm_startconfd::wait_for_rm <NL> [  523.269675] confd_mgr[2975]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [  523.269749] confd_mgr[2975]: entering: sm_startconfd::start_confd_p2 <NL> [  523.269823] confd_mgr[2975]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [  523.510194] confd_mgr[4675]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:21:38 UTC 2024 <NL> [  523.916029] confd_mgr[4685]: cmnEvtXML has stopped <NL> [  523.920047] confd_mgr[4685]: start event-handler.service <NL> [  525.292648] confd_mgr[4691]: condition_name: systemRestart <NL> [  525.292925] confd_mgr[4691]: entity_type: COM <NL> [  525.293031] confd_mgr[4691]: num_instances: 1 <NL> [  525.293109] confd_mgr[4691]: num_samples: 1 <NL> [  525.343449] confd_mgr[4691]:  EventNotification does not have condition_group. Skipping. <NL> [  525.344464] confd_mgr[4691]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [  525.344572] confd_mgr[4691]: CmnEvtPublisher::main: returning <NL> [  525.451028] confd_mgr[4685]: /usr/bin/confd_mgr_in_spm.sh <NL> [  525.622641] ops-service[4722]: rebind_listener \"webui\" <NL> [  525.622879] ops-service[4722]: TRACE Connected (maapi) to ConfD <NL> [  525.622973] ops-service[4722]: TRACE MAAPI_REBIND_LISTENER <NL> [  525.648781] ops-service[4722]:  31-Jul-2024::08:21:41.107 4722/7fa95d9a3c40/4 SEND op=407 isrel=0 th=-1 16 <NL> [  525.648941] ops-service[4722]:  --> CONFD_OK <NL> [  525.649046] ops-service[4722]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  525.732175] ops-service[4723]: rebind_listener \"snmp\" <NL> [  525.754597] ops-service[4723]: TRACE Connected (maapi) to ConfD <NL> [  525.754863] ops-service[4723]: TRACE MAAPI_REBIND_LISTENER"}
{"timestamp_utc": "2024-07-31T08:22:37.180Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  525.754955] ops-service[4723]:  31-Jul-2024::08:21:41.241 4723/7fad69276c40/4 SEND op=407 isrel=0 th=-1 4 <NL> [  525.755061] ops-service[4723]:  --> CONFD_OK <NL> [  525.755153] ops-service[4723]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  525.848107] confd_mgr[4685]: /usr/bin/ui_sys_reset.py NONE <NL> [  526.707580] confd_mgr[4747]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  526.707995] confd_mgr[4747]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  526.743750] confd_mgr[4748]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  526.743982] confd_mgr[4748]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  526.825421] confd_mgr[4749]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  526.825729] confd_mgr[4749]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  526.826602] confd_mgr[4727]: DDS Peristency is enabled <NL> [  526.826872] confd_mgr[4727]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  526.847849] confd_mgr[4727]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  526.864957] confd_mgr[4727]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  526.865121] confd_mgr[4727]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  526.866050] confd_mgr[4752]: Execute check_db_status.sh <NL> [  527.046510] confd_mgr[4752]: NE is running a default database! <NL> [  528.635809] systemd-sysv-generator[4769]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  528.005883] confd_mgr[4675]: Starting valhdlr.service if not started already <NL> [  533.563234] confd_mgr[4675]: Starting validation-handler.service if not started already <NL> [  535.538785] systemd-sysv-generator[4788]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  539.836345] confd_mgr[4675]: Starting snmp-fss-fw.service if not started already <NL> [  540.162199] confd_mgr[2975]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [  561.613820] confd_phase_sentry[2445]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [  561.614858] confd_phase_sentry[2445]: ConfdPhaseSentry: starting confd-ready.service <NL> [  562.100979] echo[4900]: Starting confd-ready <NL> [  562.702800] netconfEventSyslog[4906]: EventSyslogDaemon: Trying to connect to Confd <NL> [  562.848253] confd_mgr[2975]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [  565.037451] confd_mgr[4915]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:22:19 UTC 2024 <NL> [  565.137468] automater.sh[4903]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [  565.617078] snmp_trapd[4917]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  566.486082] confd_mgr[4973]: Execute common_confd_nb_ready_cb.sh <NL> [  566.765870] snmp_trapd[4917]: gen_util: DDS_P2MP not available <NL> [  566.906821] confd_mgr[4915]: Invoking confd_nb_enable.py <NL> [  571.033059] confd_mgr[4998]: nb_enable.py: INFO: Start <NL> [  571.046663] confd_mgr[4998]: Running \"systemctl stop netconf_socket_change.path\" <NL> [  571.046811] confd_mgr[4998]: Running \"systemctl stop cli_socket_change.path\" <NL> [  571.046890] confd_mgr[4998]: Running \"iptables -w -F chain-incoming-northbound\" <NL> [  571.046976] confd_mgr[4998]: Running \"iptables -w -D INPUT -p tcp -j chain-incoming-northbound\" <NL> [  571.047068] confd_mgr[4998]: Running \"iptables -w -X chain-incoming-northbound\" <NL> [  571.381461] confd_mgr[4915]: Exiting confd_nb_ready_cb.sh - Wed Jul 31 08:22:26 UTC 2024 <NL> [  573.395394] confd_mgr[2975]: Sending Startup notif <NL> [  578.249151] zero-touch-boot[4929]: NO match: <NL> [  578.251179] zero-touch-boot[4929]: NO match: <NL> [  578.483989] zero-touch-boot[4929]: NO match: <NL> [  580.276547] confd_mgr[5111]:  DB Notif Gen <NL> [  580.670941] confd_mgr[2975]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE"}
{"timestamp_utc": "2024-07-31T08:22:40.448Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "step_id": "s01.p01.s02.NE1-main-cli", "message_content": "# 03:22:39 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:22:39 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:22:39 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"stderr\": DONE <NL> # 03:22:39 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"stdout\": DONE <NL> # 03:22:39 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\": process 3423 terminated with exitcode 0 <NL> # 03:22:39 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:22:39 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:22:39 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p01.main-startup (s)) <NL> # 03:22:39 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #0 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:22:39 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 3 children running (n01.p09.s01.startup (p)) <NL> # 03:22:39 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.s02.NE1-main-cli\", exit_code 0 <NL> # 03:22:39 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.main-startup (s)\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:22:40.705Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:22:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37279, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:41.301Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:22:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:41 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:46.569Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:22:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:46 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:47.496Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "step_id": "s01.p07.s01.NE4-main-debug-ssh", "message_content": "# 03:22:47 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:22:47 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:22:47.752Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:22:47 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:22:47 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:22:47 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\": process 3335 terminated with exitcode 0 <NL> # 03:22:47 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:22:47 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:22:47 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37213', '--delay', '5'] (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:22:47 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p07.s02.NE4-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37213', '--delay', '5'] <NL> # 03:22:47 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:22:47 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"command\" <NL> # 03:22:47 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:22:48.008Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend"}
{"timestamp_utc": "2024-07-31T08:22:48.009Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:22:47 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37213, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:47 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:51.275Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "step_id": "s01.p03.s02.NE2-main-cli", "message_content": "# 03:22:50 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:22:50 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:22:50 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"stderr\": DONE <NL> # 03:22:50 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"stdout\": DONE <NL> # 03:22:50 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\": process 3409 terminated with exitcode 0 <NL> # 03:22:50 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:22:50 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:22:50 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p03.main-startup (s)) <NL> # 03:22:50 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #2 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:22:50 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 2 children running (n01.p09.s01.startup (p)) <NL> # 03:22:50 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.s02.NE2-main-cli\", exit_code 0 <NL> # 03:22:50 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.main-startup (s)\", exit_code 0 <NL> # 03:22:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:51 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:53.166Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:22:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:52 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',) <NL> [  539.776979] ops-service[4786]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  539.800598] ops-service[4791]: rebind_listener \"snmp\" <NL> [  539.885547] ops-service[4791]: TRACE Connected (maapi) to ConfD <NL> [  539.936435] ops-service[4791]: TRACE MAAPI_REBIND_LISTENER <NL> [  539.936529] ops-service[4791]:  31-Jul-2024::08:21:54.389 4791/7fa6658dcc40/4 SEND op=407 isrel=0 th=-1 4 <NL> [  539.936606] ops-service[4791]:  --> CONFD_OK <NL> [  539.936671] ops-service[4791]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  539.937490] confd_mgr[4770]: /usr/bin/confd_mgr_in_spm.sh <NL> [  539.996304] confd_mgr[4770]: /usr/bin/ui_sys_reset.py NONE <NL> [  541.085930] confd_mgr[4834]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  541.161511] confd_mgr[4834]: /dev/root       2.2G  1.8G  295M  87% /[  541.853474] systemd-sysv-generator[4846]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  541.382683] confd_mgr[4835]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  541.454360] confd_mgr[4835]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  541.454681] confd_mgr[4836]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  541.454834] confd_mgr[4836]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  541.455109] confd_mgr[4807]: DDS Peristency is enabled <NL> [  541.455192] confd_mgr[4807]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  541.455269] confd_mgr[4807]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  541.455348] confd_mgr[4807]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  541.455421] confd_mgr[4807]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  541.455936] confd_mgr[4847]: Execute check_db_status.sh <NL> [  541.563477] confd_mgr[4847]: NE is running a default database! <NL> [  542.042689] confd_mgr[4760]: Starting valhdlr.service if not started already <NL> [  547.156942] confd_mgr[4760]: Starting validation-handler.service if not started already <NL> [  548.564029] systemd-sysv-generator[4877]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  552.685974] confd_mgr[4760]: Starting snmp-fss-fw.service if not started already <NL> [  553.372404] confd_mgr[2947]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [  571.788140] confd_phase_sentry[2427]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [  571.794761] confd_phase_sentry[2427]: ConfdPhaseSentry: starting confd-ready.service <NL> [  572.144474] echo[4961]: Starting confd-ready <NL> [  573.349057] netconfEventSyslog[4969]: EventSyslogDaemon: Trying to connect to Confd <NL> [  574.070795] automater.sh[4964]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [  575.369416] confd_mgr[2947]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [  576.326652] confd_mgr[4999]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:22:30 UTC 2024 <NL> [  576.358515] snmp_trapd[4976]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  576.773386] confd_mgr[5048]: Execute common_confd_nb_ready_cb.sh <NL> [  577.335059] confd_mgr[4999]: Invoking confd_nb_enable.py <NL> [  577.410414] snmp_trapd[4976]: gen_util: DDS_P2MP not available <NL> [  580.631998] confd_mgr[5060]: nb_enable.py: INFO: Start <NL> [  580.634018] confd_mgr[5060]: Running \"systemctl stop netconf_socket_change.path\" <NL> [  580.634179] confd_mgr[5060]: Running \"systemctl stop cli_socket_change.path\" <NL> [  580.635073] confd_mgr[5060]: Running \"iptables -w -F chain-incoming-northbound\" <NL> [  580.635759] confd_mgr[5060]: Running \"iptables -w -D INPUT -p tcp -j chain-incoming-northbound\" <NL> [  580.636212] confd_mgr[5060]: Running \"iptables -w -X chain-incoming-northbound\" <NL> [  581.048823] confd_mgr[4999]: Exiting confd_nb_ready_cb.sh - Wed Jul 31 08:22:35 UTC 2024 <NL> [  583.063617] confd_mgr[2947]: Sending Startup notif <NL> [  590.337230] confd_mgr[5158]:  DB Notif Gen <NL> [  591.233302] confd_mgr[2947]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  591.233486] confd_mgr[2947]: leaving: sm_startconfd::start_confd_p2. <NL> [  591.391441] confd_mgr[4758]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  591.680863] confd_mgr[2947]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  591.681180] confd_mgr[2947]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  591.681909] confd_mgr[4286]: DDS Ports are opened <NL> [  592.115180] zero-touch-boot[4984]: NO match: <NL> [  592.115350] zero-touch-boot[4984]: NO match: <NL> [  592.115439] zero-touch-boot[4984]: NO match: <NL> [  594.403628] confd_mgr[5272]: openDdsPorts interfaces  eth5.2003 <NL> [  594.421149] confd_mgr[5272]: openDdsPorts Input udpPorts-  7660 <NL> [  594.526296] confd_mgr[5275]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  594.527045] confd_mgr[5272]: openDdsPorts Output udpPorts-  7660 <NL> [  594.686671] confd_mgr[5279]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  594.696731] confd_mgr[5272]: openDdsPorts Input udpPorts-  7661 <NL> [  594.907169] confd_mgr[5282]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  594.907496] confd_mgr[5272]: openDdsPorts Output udpPorts-  7661 <NL> [  595.069274] confd_mgr[5286]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.102191] confd_mgr[5272]: openDdsPorts Input udpPorts-  7650 <NL> [  595.197584] confd_mgr[5292]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.197777] confd_mgr[5272]: openDdsPorts Output udpPorts-  7650 <NL> [  595.239021] confd_mgr[5294]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.271189] confd_mgr[5272]: openDdsPorts Input udpPorts-  7651"}
{"timestamp_utc": "2024-07-31T08:22:53.167Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "step_id": "NE2-main-console", "message_content": "[  595.685793] confd_mgr[5303]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.686811] confd_mgr[5272]: openDdsPorts Output udpPorts-  7651 <NL> [  595.727745] confd_mgr[5304]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.727932] confd_mgr[5272]: openDdsPorts Input udpPorts-  7900 <NL> [  595.761987] confd_mgr[5306]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.763155] confd_mgr[5272]: openDdsPorts Output udpPorts-  7900 <NL> [  595.764079] confd_mgr[5309]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.769552] confd_mgr[5272]: openDdsPorts Input udpPorts-  7901 <NL> [  595.910746] confd_mgr[5310]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.967453] confd_mgr[5272]: openDdsPorts Output udpPorts-  7901 <NL> [  595.967733] confd_mgr[5313]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.967827] confd_mgr[5272]: openDdsPorts Input udpPorts-  7910 <NL> [  595.968071] confd_mgr[5314]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.968163] confd_mgr[5272]: openDdsPorts Output udpPorts-  7910 <NL> [  595.968420] confd_mgr[5317]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  595.968516] confd_mgr[5272]: openDdsPorts Input udpPorts-  7911 <NL> [  595.968969] confd_mgr[5319]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  596.032293] confd_mgr[5272]: openDdsPorts Output udpPorts-  7911 <NL> [  596.198252] confd_mgr[5321]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  596.216259] confd_mgr[5272]: openDdsPorts Input udpPorts-  8150 <NL> [  596.359587] confd_mgr[5326]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  596.460775] confd_mgr[5272]: openDdsPorts Output udpPorts-  8150 <NL> [  596.527838] confd_mgr[5328]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  596.851753] confd_mgr[5272]: openDdsPorts Input udpPorts-  8151 <NL> [  596.883313] confd_mgr[5333]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  596.883502] confd_mgr[5272]: openDdsPorts Output udpPorts-  8151 <NL> [  596.943830] confd_mgr[5335]: iptables: Bad rule (does a matching rule exist in that chain?)."}
{"timestamp_utc": "2024-07-31T08:22:56.435Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:22:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:56 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:58.358Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:22:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:57 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:01.650Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:01 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:03.019Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:02 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:06.343Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:06 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:08.268Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:07 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:11.613Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:11 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:12.982Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:12 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:17.148Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:23:17.149Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:16 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:18.075Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:17 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:21.344Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:21 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:23.312Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:23 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:26.577Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:26 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:28.465Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:28 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:30.353Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  569.628254] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  569.868412] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  569.939757] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  571.327765] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  571.575357] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  571.980498] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 1 <NL> [  573.702078] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  573.889333] python3[2142]: [.877] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 29 of -1! <NL> [  575.197486] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 2 <NL> [  576.785716] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  577.144162] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  578.039325] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 3 <NL> [  580.750332] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 4 <NL> [  581.356695] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  581.759465] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  583.668908] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  583.761632] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 5 <NL> [  583.959070] python3[2142]: [.048] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 30 of -1! <NL> [  586.368256] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  586.973189] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  587.206659] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 6 <NL> [  589.806502] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 7 <NL> [  591.421784] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  591.426674] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  592.798238] txid_tracker[3986]: ::::create_confd_subscription_connection() try number 8 <NL> [  594.109265] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  594.556431] python3[2142]: [.504] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 31 of -1! <NL> [  596.392382] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  596.393543] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  599.591729] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 1 <NL> [  601.398861] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  602.183297] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  604.704457] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 2 <NL> [  604.818738] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  605.652325] python3[2142]: [.554] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 32 of -1! <NL> [  606.392291] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 3 <NL> [  607.570761] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  608.958200] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  611.882082] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 4 <NL> [  613.546019] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 5 <NL> [  613.636736] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  614.630750] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  616.369519] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  616.640446] python3[2142]: [.065] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 33 of -1! <NL> [  616.809824] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 6 <NL> [  617.338127] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  617.365574] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  617.537206] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 7 <NL> [  621.184354] txid_tracker[4064]: ::::create_confd_subscription_connection() try number 8"}
{"timestamp_utc": "2024-07-31T08:23:30.354Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  621.937970] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  622.764587] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  624.381550] python3[4067]: INFO:root:Started rsync_logfile.py... <NL> [  625.870167] python3[4067]: INFO:root:redundancy status = STANDALONE <NL> [  626.817354] python3[4067]: INFO:root:redundancy mode = UNKNOWN <NL> [  626.995889] python3[4067]: <NL> [  627.136251] python3[4067]: ERROR:root:Error: System is not in redundancy mode <NL> [  627.145198] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  627.492352] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  628.053276] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  628.372424] python3[2142]: [.261] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 34 of -1! <NL> [  629.129115] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 1 <NL> [  630.218460] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 2 <NL> [  631.803337] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  631.905429] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  633.114712] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 3 <NL> [  636.106885] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:23:31.719Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:31 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:33.083Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:33 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:36.347Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:36 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:38.235Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:38 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:41.500Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:41 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:43.388Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:43 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:45.902Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  580.731398] confd_mgr[2975]: leaving: sm_startconfd::start_confd_p2. <NL> [  580.731965] confd_mgr[4671]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  580.732117] confd_mgr[2975]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  580.732204] confd_mgr[2975]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  580.733157] confd_mgr[4241]: DDS Ports are opened <NL> [  581.414708] confd_mgr[5194]: openDdsPorts interfaces  eth5.2003 <NL> [  581.414943] confd_mgr[5194]: openDdsPorts Input udpPorts-  7660 <NL> [  581.637821] confd_mgr[5196]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  581.683652] confd_mgr[5194]: openDdsPorts Output udpPorts-  7660 <NL> [  581.861647] confd_mgr[5202]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  581.861895] confd_mgr[5194]: openDdsPorts Input udpPorts-  7661 <NL> [  582.051656] confd_mgr[5204]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  582.086262] confd_mgr[5194]: openDdsPorts Output udpPorts-  7661 <NL> [  582.192143] confd_mgr[5209]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  582.215644] confd_mgr[5194]: openDdsPorts Input udpPorts-  7650 <NL> [  582.270202] confd_mgr[5220]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  582.270473] confd_mgr[5194]: openDdsPorts Output udpPorts-  7650 <NL> [  582.607914] confd_mgr[5222]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  582.608831] confd_mgr[5194]: openDdsPorts Input udpPorts-  7651 <NL> [  582.665922] confd_mgr[5230]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  582.749836] confd_mgr[5194]: openDdsPorts Output udpPorts-  7651 <NL> [  582.752865] confd_mgr[5234]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  582.917553] confd_mgr[5194]: openDdsPorts Input udpPorts-  7900 <NL> [  583.002793] confd_mgr[5239]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  583.003149] confd_mgr[5194]: openDdsPorts Output udpPorts-  7900 <NL> [  583.103256] confd_mgr[5242]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  583.146704] confd_mgr[5194]: openDdsPorts Input udpPorts-  7901 <NL> [  583.161031] confd_mgr[5244]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  583.166614] confd_mgr[5194]: openDdsPorts Output udpPorts-  7901 <NL> [  583.231796] confd_mgr[5245]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  583.289754] confd_mgr[5194]: openDdsPorts Input udpPorts-  7910 <NL> [  583.417672] confd_mgr[5250]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  583.639202] confd_mgr[5194]: openDdsPorts Output udpPorts-  7910 <NL> [  583.764433] confd_mgr[5256]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  583.764897] confd_mgr[5194]: openDdsPorts Input udpPorts-  7911 <NL> [  583.853510] confd_mgr[5258]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  583.853882] confd_mgr[5194]: openDdsPorts Output udpPorts-  7911 <NL> [  583.873717] confd_mgr[5259]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  584.037043] confd_mgr[5194]: openDdsPorts Input udpPorts-  8150 <NL> [  584.037709] confd_mgr[5261]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  584.123152] confd_mgr[5194]: openDdsPorts Output udpPorts-  8150 <NL> [  584.329996] confd_mgr[5266]: iptables: Bad rule (does a matching rule exist in that chain?)."}
{"timestamp_utc": "2024-07-31T08:23:45.903Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  584.330242] confd_mgr[5194]: openDdsPorts Input udpPorts-  8151 <NL> [  584.389756] confd_mgr[5276]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  584.389967] confd_mgr[5194]: openDdsPorts Output udpPorts-  8151 <NL> [  584.630767] confd_mgr[5278]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  584.856138] confd_mgr[5194]: openDdsPorts Input udpPorts-  8160 <NL> [  584.857609] confd_mgr[5289]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  584.916798] confd_mgr[5194]: openDdsPorts Output udpPorts-  8160 <NL> [  585.254892] confd_mgr[5291]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  585.476855] confd_mgr[5194]: openDdsPorts Input udpPorts-  8161 <NL> [  585.548552] confd_mgr[5295]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  585.549957] confd_mgr[5194]: openDdsPorts Output udpPorts-  8161 <NL> [  585.640921] confd_mgr[5296]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  586.013127] confd_mgr[5328]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  586.399467] netconfEventSyslog[4906]: EventSyslogDaemon Waiting for event notifications... <NL> [  594.863677] confd_mgr[5328]: ==================== saving database ================== <NL> [  594.986042] confd_mgr[5365]: A.cdb <NL> [  595.097071] confd_mgr[5365]: A.cdb.sig <NL> [  595.097417] confd_mgr[5365]: C.cdb <NL> [  597.695333] confd_mgr[5365]: C.cdb.sig <NL> [  597.716315] confd_mgr[5365]: DefTxId <NL> [  597.741367] confd_mgr[5365]: O.cdb <NL> [  597.741657] confd_mgr[5365]: compact.lock <NL> [  597.741823] confd_mgr[5365]: dbmgmtdata.conf <NL> [  597.741943] confd_mgr[5365]: replay.cdb <NL> [  597.749824] confd_mgr[5365]: schema.sig <NL> [  598.705947] systemd-journald[358]: Data hash table of /run/log/journal/2248b4323854441fb0634243a4ab8d0b/system.journal has a fill level at 75.0 (13656 of 18204 items, 10485760 file size, 767 bytes per hash table item), suggesting rotation. <NL> [  598.748994] systemd-journald[358]: /run/log/journal/2248b4323854441fb0634243a4ab8d0b/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  598.009047] confd_mgr[2975]: entering: sm_startconfd::exit_to_ready <NL> [  598.019161] confd_mgr[2975]: leaving: sm_startconfd::exit_to_ready <NL> [  598.019295] confd_mgr[2975]: action at_sm_dbready::do_db_ready_a <NL> [  598.019427] confd_mgr[2975]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME <NL> [  598.019785] confd_mgr[2975]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME not defined. <NL> [  598.019905] confd_mgr[2975]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/recipe-sysroot/usr/include/boost/property_tree/detail/ptree_implementation.hpp(576): Throw in function boost::property_tree::basic_ptree<K, D, C>& boost::property_tree::basic_ptree<Key, Data, KeyCompare>::get_child(const path_type&) [with Key = std::__cxx11::basic_string<char>; Data = std::__cxx11::basic_string<char>; KeyCompare = std::less<std::__cxx11::basic_string<char> >; boost::property_tree::basic_ptree<Key, Data, KeyCompare>::path_type = boost::property_tree::string_path<std::__cxx11::basic_string<char>, boost::property_tree::id_translator<std::__cxx11::basic_string<char> > >] <NL> [  598.020118] confd_mgr[2975]: Dynamic exception type: boost::wrapexcept<boost::property_tree::ptree_bad_path> <NL> [  598.020194] confd_mgr[2975]: std::exception::what: No such node (DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME) <NL> [  598.096926] confd_mgr[2975]: Node is not present in the xml. Ignore the above exception. <NL> [  598.097045] confd_mgr[2975]: The dbmgmt_data_path_ and cdb file path passed to timestamp_operation.py script /var/shared/confd/bank0/dbmgmtdata.conf   /var/shared/confd/bank0/A.cdb <NL> [  599.021764] confd_mgr[2975]: ConfdHA::process_sdb_op SDB_REP_START <NL> [  599.068278] confd_mgr[2975]: ha_sm leaving: no_ha_s <NL> [  599.068394] confd_mgr[2975]: ha_sm entering: no_ha_s <NL> [  623.874191] common_alarm_handler[2395]: DEBUG item has a bad/wrong type - 2 is not a valid value. <NL> [  640.294956] zero-touch-boot[5522]: ls: cannot access './var/lib/dhcp/DHCPCV*.leases.ztp': No such file or directory <NL> [  640.295497] zero-touch-boot[4929]: inotify_add_watch : No such file or directory <NL> [  640.295597] zero-touch-boot[4929]: inotify_add_watch : No such file or directory"}
{"timestamp_utc": "2024-07-31T08:23:46.159Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "[  641.980790] zero-touch-app[5528]: ls: cannot access './var/lib/dhcp/DHCPCV*.leases.ztp': No such file or directory <NL> [  649.624242] python3[3929]: DEBUG Bad path </eqpt/shelf{1}/slot{0}/subslot{0}/port{{'slotID': '1', 'nums:slotNumber': '1'}}> <NL> [  649.624556] python3[3929]: [.105] valhdlr 139625321158208 valshelfmode:122 Error in fetching CP from the keypath /eqpt/shelf{1}/slot{0}/subslot{0}/port{{'slotID': '1', 'nums:slotNumber': '1'}}"}
{"timestamp_utc": "2024-07-31T08:23:46.414Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:46 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:48.402Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:48 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:51.666Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:51 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:53.555Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:23:53.556Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:53 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:56.847Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:23:56.848Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:23:56 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:58.213Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:23:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:58 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:59.580Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  553.161609] healthcheck_result_display.py[2126]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  553.415870] healthcheck_result_display.py[2126]:     self._init_connection() <NL> [  553.624588] healthcheck_result_display.py[2126]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  553.743890] healthcheck_result_display.py[2126]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  554.011812] healthcheck_result_display.py[2126]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  554.877098] healthcheck_result_display.py[2126]:     _tm.dp.connect( <NL> [  555.049736] healthcheck_result_display.py[2126]: _confd.error.EOF: ConfD closed connection <NL> [  555.407343] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 3 <NL> [  555.507049] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 4 <NL> [  557.743425] python3[2128]: [.754] hookhdlr 139819433846592 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  558.180361] python3[2128]: [.089] hookhdlr 139819433846592 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  558.345432] python3[2128]: [.090] hookhdlr 139819433846592 callbackhdlr:293 Loading schemas <NL> [  558.367251] python3[2128]: DEBUG item does not exist - shared memory schema not enabled <NL> [  558.406597] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 5 <NL> [  561.411884] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 6 <NL> [  564.449425] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 7 <NL> [  567.427775] txid_tracker[3926]: ::::create_confd_subscription_connection() try number 8 <NL> [  576.698426] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 1 <NL> [  579.538462] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 2 <NL> [  582.584403] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 3 <NL> [  584.231328] python3[2128]: [.242] hookhdlr 139819433846592 callbackhdlr:382 Done load schemas <NL> [  584.331409] python3[2128]: [.262] hookhdlr 139819433846592 callbackhdlr:389 Done register transaction callback <NL> [  585.667649] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 4 <NL> [  587.417793] python3[2128]: [.289] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  587.609351] python3[2128]: [.328] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  587.965997] python3[2128]: [.719] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  588.005638] python3[2128]: [.729] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  588.088710] python3[2128]: [.741] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  588.600358] python3[2128]: [.824] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  588.997582] python3[2128]: [.854] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  589.488443] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 5 <NL> [  590.353345] python3[2128]: [.063] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  590.568718] python3[2128]: [.196] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb tcmListHook"}
{"timestamp_utc": "2024-07-31T08:23:59.581Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  590.691478] python3[2128]: [.420] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  590.790305] python3[2128]: [.689] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  590.994758] python3[2128]: [.213] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  591.135300] python3[2128]: [.291] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  591.719910] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 6 <NL> [  594.705654] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 7 <NL> [  597.999345] txid_tracker[3993]: ::::create_confd_subscription_connection() try number 8 <NL> [  599.205663] python3[2128]: [.216] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  604.644503] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 1 <NL> [  605.160293] python3[4052]: INFO:root:Started rsync_logfile.py... <NL> [  605.161859] python3[4052]: INFO:root:redundancy status = STANDALONE <NL> [  605.258685] python3[4052]: INFO:root:redundancy mode = UNKNOWN <NL> [  605.270386] python3[4052]: <NL> [  605.278410] python3[4052]: ERROR:root:Error: System is not in redundancy mode <NL> [  607.809602] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 2 <NL> [  608.201095] python3[2128]: [.212] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  610.669967] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 3 <NL> [  611.299229] python3[2128]: [.272] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  613.691135] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 4 <NL> [  616.678270] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 5 <NL> [  617.008492] python3[2128]: [.019] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  619.689727] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 6 <NL> [  620.065819] python3[2128]: [.067] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  620.208430] python3[2128]: [.160] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  620.236834] python3[2128]: [.163] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  620.269242] python3[2128]: [.166] hookhdlr 139819433846592 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  620.300227] python3[2128]: [.169] hookhdlr 139819433846592 callbackhdlr:391 Done register data callbacks <NL> [  622.693108] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 7 <NL> [  625.695949] txid_tracker[4058]: ::::create_confd_subscription_connection() try number 8 <NL> [  630.446330] txid_tracker[4135]: ::::create_confd_subscription_connection() connected <NL> [  656.374150] confd_mgr[2966]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  656.390924] confd_mgr[4201]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:23:53 UTC 2024 <NL> [  656.460287] confd_mgr[4201]: Starting valhdlr.service <NL> [  656.544967] confd_mgr[4201]: Starting validation-handler.service <NL> [  656.599692] confd_mgr[4201]: Starting snmp-fss-fw.service <NL> [  656.782841] python3[2128]: DEBUG No crypto keys configured <NL> [  656.999740] python3[2128]: [.791] hookhdlr 139819433846592 callbackhdlr:401 Unable to install crypto keys! <NL> [  657.249731] confd_mgr[2966]: leaving: sm_startconfd::start_confd_p0 <NL> [  657.470138] confd_mgr[2966]: entering: sm_startconfd::wait_for_p0 <NL> [  658.022943] confd_mgr[2966]: PROCESS1 has not registered yet. <NL> [  658.528255] confd_mgr[2966]: PROCESS_SNMP_CLID has not registered yet. <NL> [  658.642576] confd_mgr[2966]: PROCESS_VALHDLR has not registered yet. <NL> [  659.085925] python3[2128]: [.087] hookhdlr 139819433846592 callbackhdlr:322 Started data handler daemon... <NL> [  659.979081] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  660.483725] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  660.542296] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  660.632973] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  660.647520] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  661.116691] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  661.117552] confd_mgr[2966]: ConfdHA Not supported command CONFIRM"}
{"timestamp_utc": "2024-07-31T08:24:01.471Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:01 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:03.358Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:03 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:06.630Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:06 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:07.193Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  661.282139] confd_mgr[2966]: sm_startconfd::p0_ready_dbc <NL> [  661.323851] confd_mgr[2966]: Find message MESSAGE1 <NL> [  661.555689] confd_mgr[2966]: PROCESS_SNMP_CLID has not registered yet. <NL> [  661.608141] confd_mgr[2966]: PROCESS_VALHDLR has not registered yet. <NL> [  661.613986] confd_mgr[2966]: sm_startconfd::p0_not_ready <NL> [  661.748150] confd_mgr[2966]: Find message MESSAGE1 <NL> [  661.965873] confd_mgr[2966]: PROCESS_SNMP_CLID has not registered yet. <NL> [  662.209067] confd_mgr[2966]: PROCESS_VALHDLR has not registered yet. <NL> [  662.252066] confd_mgr[2966]: leaving: sm_startconfd::wait_for_p0 <NL> [  662.252975] confd_mgr[2966]: entering: sm_startconfd::wait_for_p0 <NL> [  662.293401] confd_mgr[2966]: PROCESS_SNMP_CLID has not registered yet. <NL> [  662.362313] confd_mgr[2966]: PROCESS_VALHDLR has not registered yet. <NL> [  662.461043] confd_mgr[2966]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  662.463394] confd_mgr[2966]: Timer /ConfdAT|wait_for_p0 already created <NL> [  662.546349] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  662.767677] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  663.479786] python3[4209]: [.491] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  663.800954] python3[4209]: [.559] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  663.802538] python3[4209]: [.559] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  663.856343] python3[4209]: [.559] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  664.010902] python3[4209]: [.559] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  664.069657] python3[4209]: [.559] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  664.659925] python3[4209]: [.559] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  664.661472] python3[4209]: [.560] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  664.746772] python3[4209]: [.560] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  664.763033] python3[4209]: [.560] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  664.764334] python3[4209]: [.570] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  664.765536] python3[4209]: [.570] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  664.994856] python3[4209]: [.570] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  664.996413] python3[4209]: [.570] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  665.037895] python3[4209]: [.570] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  665.209995] python3[4209]: [.570] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  665.301475] python3[4209]: [.570] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  665.467897] python3[4209]: [.580] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  665.520207] python3[4209]: [.580] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  665.666826] python3[4209]: [.580] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  665.790820] python3[4209]: [.580] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  665.934974] python3[4209]: [.580] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  666.042504] python3[4209]: [.581] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  666.177660] python3[4209]: [.581] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  666.462690] python3[4209]: [.581] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  666.493614] python3[4209]: [.581] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  666.530237] python3[4209]: [.581] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  666.574400] python3[4209]: [.581] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  666.635279] python3[4209]: [.589] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  666.989818] python3[4209]: [.590] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  667.306361] python3[4209]: [.590] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  667.433651] python3[4209]: [.590] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  667.555331] python3[4209]: [.590] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  667.674042] python3[4209]: [.590] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  667.818554] python3[4209]: [.600] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  667.955942] python3[4209]: [.600] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  668.114987] python3[4209]: [.600] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  668.224497] python3[4209]: [.600] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  668.289179] python3[4209]: [.600] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  668.324455] python3[4209]: [.601] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  668.355720] python3[4209]: [.612] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  668.443799] snmp_clid[4218]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  668.537073] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  668.610667] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  668.669360] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  668.684106] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  668.684938] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  668.685772] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  668.712512] confd_mgr[2966]: ConfdHA Not supported command CONFIRM <NL> [  668.717838] confd_mgr[2966]: sm_startconfd::p0_ready_dbc"}
{"timestamp_utc": "2024-07-31T08:24:07.194Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  668.735851] confd_mgr[2966]: Find message SNMP_CLID_CONFIRM <NL> [  668.764219] confd_mgr[2966]: PROCESS_VALHDLR has not registered yet. <NL> [  668.792971] confd_mgr[2966]: sm_startconfd::p0_not_ready <NL> [  668.800497] confd_mgr[2966]: Find message SNMP_CLID_CONFIRM <NL> [  668.837918] confd_mgr[2966]: PROCESS_VALHDLR has not registered yet. <NL> [  668.865037] confd_mgr[2966]: leaving: sm_startconfd::wait_for_p0 <NL> [  668.865947] confd_mgr[2966]: entering: sm_startconfd::wait_for_p0 <NL> [  668.866852] confd_mgr[2966]: PROCESS_VALHDLR has not registered yet. <NL> [  668.903296] confd_mgr[2966]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  668.927905] confd_mgr[2966]: Timer /ConfdAT|wait_for_p0 already created <NL> [  668.928983] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT"}
{"timestamp_utc": "2024-07-31T08:24:08.557Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:08 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:11.886Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:11 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:13.250Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:13 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:16.514Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:16 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:18.404Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:18 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:21.717Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:21 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:23.605Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:23 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:24.537Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  636.107893] python3[2142]: [.359] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 35 of -1! <NL> [  636.213063] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 4 <NL> [  636.980475] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  636.981561] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  639.135169] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 5 <NL> [  642.028396] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  642.050442] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  642.194927] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 6 <NL> [  645.281229] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 7 <NL> [  646.199373] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  646.724091] python3[2142]: [.422] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 36 of -1! <NL> [  647.176610] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  647.512138] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  648.227238] txid_tracker[4130]: ::::create_confd_subscription_connection() try number 8 <NL> [  651.962768] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  652.285267] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  654.432631] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 1 <NL> [  656.708749] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  656.908314] python3[2142]: [.962] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 37 of -1! <NL> [  657.260859] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  657.498594] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  657.891270] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 2 <NL> [  660.459901] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 3 <NL> [  661.978749] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  662.162300] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  663.463626] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 4 <NL> [  666.470677] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 5 <NL> [  666.843541] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  666.919651] python3[2142]: [.124] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 38 of -1! <NL> [  667.079916] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  667.193232] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  669.496905] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 6 <NL> [  672.036297] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  672.235364] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  672.486667] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 7 <NL> [  675.494312] txid_tracker[4190]: ::::create_confd_subscription_connection() try number 8 <NL> [  676.912987] python3[2142]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  677.332040] python3[2142]: [.287] hookhdlr 140548059326272 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 39 of -1! <NL> [  677.849344] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  678.165334] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  681.094450] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 1 <NL> [  681.996182] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:24:24.538Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  682.054893] confd_phase_sentry[2146]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f48a94ce5c7; Failed to connect to ConfD: Connection refused <NL> [  683.710086] rasis_system_stats.py[2148]: Traceback (most recent call last): <NL> [  684.034189] rasis_system_stats.py[2148]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  684.660420] rasis_system_stats.py[2148]:     main() <NL> [  685.112181] rasis_system_stats.py[2148]:   File \"/usr/bin/rasis_system_stats.py\", line 352, in main <NL> [  685.467520] rasis_system_stats.py[2148]:     maapi.Maapi(port=CONFD_PORT) <NL> [  685.841521] rasis_system_stats.py[2148]:   File \"/usr/lib/python3.10/site-packages/confd/maapi.py\", line 321, in __init__ <NL> [  685.866943] rasis_system_stats.py[2148]:     self.msock = connect(ip, port, path) <NL> [  685.895561] rasis_system_stats.py[2148]:   File \"/usr/lib/python3.10/site-packages/confd/maapi.py\", line 118, in connect <NL> [  685.935737] rasis_system_stats.py[2148]:     _tm.maapi.connect(msock, ip, port) <NL> [  685.962842] rasis_system_stats.py[2148]: _confd.error.EOF: ConfD closed connection <NL> [  685.993048] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 2 <NL> [  687.011992] confd_phase_sentry[2146]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  687.099234] confd_phase_sentry[2146]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  687.249247] python3[2142]: DEBUG EOF on socket to ConfD <NL> [  687.254376] python3[2142]: [.405] hookhdlr 140548059326272 callbackhdlr:457 Exception to create daemon <NL> [  687.313303] python3[2142]: Traceback (most recent call last): <NL> [  687.469662] python3[2142]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  687.730943] python3[2142]:     daemon = self.create_daemon() <NL> [  687.867325] python3[2142]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  688.066114] python3[2142]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  688.198161] python3[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  688.326255] python3[2142]:     self._init_connection() <NL> [  688.438676] python3[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  688.542984] python3[2142]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  688.543788] python3[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  688.576293] python3[2142]:     _tm.dp.connect( <NL> [  688.724397] python3[2142]: _confd.error.EOF: ConfD closed connection <NL> [  688.866841] python3[2142]: [.475] hookhdlr 140548059326272 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  689.149582] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 3"}
{"timestamp_utc": "2024-07-31T08:24:27.081Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:26 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:28.446Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:28 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:31.736Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:31 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:33.650Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:33 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:35.544Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  668.930080] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  668.969226] python3[4209]: [.612] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  669.049933] python3[4209]: [.612] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  669.165266] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  669.252272] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  669.254350] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  669.314761] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  669.366807] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  669.388180] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  669.389479] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  669.390801] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  669.417624] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  669.428658] python3[4209]: [.613] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  669.481858] python3[4209]: [.614] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  669.510831] python3[4209]: [.614] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  669.530790] python3[4209]: [.614] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  669.598818] python3[4209]: [.614] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  669.622076] python3[4209]: [.614] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  669.665534] python3[4209]: [.633] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  669.686741] python3[4209]: [.634] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  669.688340] python3[4209]: [.634] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  669.726604] snmp_clid[4253]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  669.742972] python3[4209]: [.634] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  669.766751] python3[4209]: [.634] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  669.778294] python3[4209]: [.634] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  669.780231] python3[4209]: [.634] valhdlr 139906738673472 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  669.792153] python3[4209]: [.634] valhdlr 139906738673472 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  669.794459] python3[4209]: [.661] valhdlr 139906738673472 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  669.819693] python3[4209]: [.661] valhdlr 139906738673472 callbackhdlr:293 Loading schemas <NL> [  669.825150] python3[4209]: DEBUG item does not exist - shared memory schema not enabled"}
{"timestamp_utc": "2024-07-31T08:24:35.545Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  669.843715] python3[4209]: [.579] valhdlr 139906738673472 callbackhdlr:382 Done load schemas <NL> [  669.873878] python3[4209]: [.580] valhdlr 139906738673472 callbackhdlr:389 Done register transaction callback <NL> [  669.886733] python3[4209]: [.922] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  669.910821] python3[4209]: [.060] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  669.916317] python3[4209]: [.276] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  669.924385] python3[4209]: [.280] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  684.310582] python3[4209]: [.299] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  684.354475] python3[4209]: [.362] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  684.441456] python3[4209]: [.427] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  684.587877] python3[4209]: [.599] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  684.665275] python3[4209]: [.675] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  684.939553] python3[4209]: [.880] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  685.078973] python3[4209]: [.032] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  685.380460] python3[4209]: [.160] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  685.381836] python3[4209]: [.164] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  687.706649] python3[4209]: [.683] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  691.557685] python3[4209]: [.569] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  692.539322] python3[4209]: [.551] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  696.017612] python3[4209]: [.004] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  696.210029] python3[4209]: [.106] valhdlr 139906738673472 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  696.281199] python3[4209]: [.107] valhdlr 139906738673472 callbackhdlr:391 Done register data callbacks <NL> [  696.282286] python3[4209]: DEBUG No crypto keys configured <NL> [  696.282937] python3[4209]: [.108] valhdlr 139906738673472 callbackhdlr:401 Unable to install crypto keys! <NL> [  696.303389] python3[4209]: [.164] valhdlr 139906738673472 callbackhdlr:322 Started data handler daemon... <NL> [  696.305359] python3[4209]: [.165] valhdlr 139906738673472 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  696.343761] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  696.402173] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  696.441503] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  696.592248] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  696.789510] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  696.928193] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  696.955899] confd_mgr[2966]: ConfdHA Not supported command CONFIRM <NL> [  697.015418] confd_mgr[2966]: sm_startconfd::p0_ready_dbc <NL> [  697.056510] confd_mgr[2966]: Find message VALHDLR_CONFIRM <NL> [  697.118305] confd_mgr[2966]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  697.164800] confd_mgr[2966]: sm_startconfd::p0_not_ready <NL> [  697.226692] confd_mgr[2966]: Find message VALHDLR_CONFIRM <NL> [  697.228605] confd_mgr[2966]: sm_startconfd::p0_ready_no_dbc <NL> [  697.295406] confd_mgr[2966]: Find message VALHDLR_CONFIRM <NL> [  697.298569] confd_mgr[2966]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  697.299515] confd_mgr[2966]: leaving: sm_startconfd::wait_for_p0 <NL> [  697.300382] confd_mgr[2966]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  697.301398] confd_mgr[2966]: entering: sm_startconfd::start_confd_p1"}
{"timestamp_utc": "2024-07-31T08:24:36.911Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:24:36.912Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:36 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:38.841Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:38 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:42.123Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:41 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:43.488Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:43 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:46.756Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:46 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:48.648Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:48 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:51.919Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:51 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:53.809Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:53 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:57.073Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:24:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:56 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:58.454Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:24:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:58 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:01.722Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:01 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:03.631Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:03 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:06.898Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:06 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:08.786Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:08 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:12.049Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:11 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:13.938Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:13 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:17.242Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:16 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:18.609Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:18 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:21.890Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:21 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:23.779Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:23 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:27.067Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:26 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:28.992Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:28 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:32.279Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:31 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:33.665Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:33 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:36.945Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  690.414141] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 4 <NL> [  693.389403] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 5 <NL> [  695.367447] healthcheck_result_display.py[2140]: Traceback (most recent call last): <NL> [  695.487972] healthcheck_result_display.py[2140]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  695.509856] healthcheck_result_display.py[2140]:     main(hc_utils.setup_logging(__name__)) <NL> [  695.510843] healthcheck_result_display.py[2140]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  695.512113] healthcheck_result_display.py[2140]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  695.617503] healthcheck_result_display.py[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  696.067348] healthcheck_result_display.py[2140]:     self._init_connection() <NL> [  696.104266] healthcheck_result_display.py[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  696.467952] db_info.py[2134]: Traceback (most recent call last): <NL> [  696.861181] db_info.py[2134]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  697.069059] db_info.py[2134]:     main() <NL> [  697.319809] db_info.py[2134]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  697.814645] db_info.py[2134]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  698.057791] db_info.py[2134]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  698.301352] db_info.py[2134]:     self._init_connection() <NL> [  698.386581] db_info.py[2134]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  698.543526] db_info.py[2134]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  698.570379] db_info.py[2134]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  698.801169] db_info.py[2134]:     _tm.dp.connect( <NL> [  698.885102] db_info.py[2134]: _confd.error.EOF: ConfD closed connection <NL> [  699.148159] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 6"}
{"timestamp_utc": "2024-07-31T08:25:36.946Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  699.276307] healthcheck_result_display.py[2140]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  699.410154] healthcheck_result_display.py[2140]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  699.411511] healthcheck_result_display.py[2140]:     _tm.dp.connect( <NL> [  699.412330] healthcheck_result_display.py[2140]: _confd.error.EOF: ConfD closed connection <NL> [  699.748136] python3[2142]: [.488] hookhdlr 140548059326272 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  700.132035] python3[2142]: DEBUG EOF on socket to ConfD <NL> [  700.254821] python3[2142]: [.778] hookhdlr 140548059326272 callbackhdlr:457 Exception to create daemon <NL> [  700.440494] python3[2142]: Traceback (most recent call last): <NL> [  700.651238] python3[2142]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  700.766212] python3[2142]:     daemon = self.create_daemon() <NL> [  700.766959] python3[2142]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  700.768248] python3[2142]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  700.926258] python3[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  701.278809] python3[2142]:     self._init_connection() <NL> [  701.514084] python3[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  701.828774] python3[2142]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  702.031363] python3[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  702.288616] python3[2142]:     _tm.dp.connect( <NL> [  702.603109] python3[2142]: _confd.error.EOF: ConfD closed connection <NL> [  702.665473] python3[2142]: [.852] hookhdlr 140548059326272 callbackhdlr:471 Failed to run daemon main, retry 2 of -1 <NL> [  702.907751] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 7 <NL> [  703.238121] txid_tracker[4262]: ::::create_confd_subscription_connection() try number 8 <NL> [  707.242261] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 1 <NL> [  707.609404] python3[2142]: [.862] hookhdlr 140548059326272 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  708.041244] python3[2142]: [.293] hookhdlr 140548059326272 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  708.533085] python3[2142]: [.438] hookhdlr 140548059326272 callbackhdlr:293 Loading schemas <NL> [  709.062582] python3[2142]: DEBUG item does not exist - shared memory schema not enabled <NL> [  710.262981] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 2 <NL> [  713.289572] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 3 <NL> [  716.289986] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 4 <NL> [  719.292843] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 5 <NL> [  722.308628] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 6 <NL> [  723.259767] python3[2142]: [.483] hookhdlr 140548059326272 callbackhdlr:382 Done load schemas <NL> [  723.311603] python3[2142]: [.558] hookhdlr 140548059326272 callbackhdlr:389 Done register transaction callback <NL> [  725.317800] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 7 <NL> [  727.915110] python3[2142]: [.168] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  727.985344] python3[2142]: [.239] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  728.340191] txid_tracker[4333]: ::::create_confd_subscription_connection() try number 8 <NL> [  729.163430] python3[2142]: [.416] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  729.456796] python3[2142]: [.678] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  729.642945] python3[2142]: [.761] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  729.944955] python3[2142]: [.981] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  730.381298] python3[2142]: [.570] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  731.085026] python3[2142]: [.339] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  731.231827] python3[2142]: [.420] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  731.619510] python3[2142]: [.858] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  732.314152] python3[2142]: [.078] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  733.567045] python3[2142]: [.820] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  734.114962] python3[2142]: [.106] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  735.617679] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 1 <NL> [  738.621846] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 2 <NL> [  741.653723] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 3 <NL> [  744.003526] python3[2142]: [.196] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  744.658178] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 4 <NL> [  747.657365] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 5 <NL> [  748.336634] python3[2142]: [.589] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  750.665393] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 6 <NL> [  753.670550] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 7 <NL> [  756.722134] txid_tracker[4415]: ::::create_confd_subscription_connection() try number 8 <NL> # 03:25:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:36 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:38.839Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:38 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:42.108Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:41 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:43.998Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:25:43.999Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:43 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:47.264Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:46 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:48.629Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:25:48.886Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:48 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:52.161Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:51 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',) <NL> [  567.699314] layer1_control_layer[2060]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  567.699592] layer1_control_layer[2060]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  567.758588] layer1_control_layer[2060]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  567.841715] layer1_control_layer[2060]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  567.841812] layer1_control_layer[2060]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  567.841929] layer1_control_layer[2060]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  567.842061] layer1_control_layer[2060]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  567.842145] layer1_control_layer[2060]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  567.842238] layer1_control_layer[2060]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  567.842342] layer1_control_layer[2060]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  567.842420] layer1_control_layer[2060]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  567.842492] layer1_control_layer[2060]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf"}
{"timestamp_utc": "2024-07-31T08:25:52.162Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "step_id": "NE1-trib1-console", "message_content": "[  567.842573] layer1_control_layer[2060]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  568.005709] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2363 <NL> [  568.078395] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2363 <NL> [  568.151038] layer1_hal[2088]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  568.151181] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2363 <NL> [  568.151296] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2363 <NL> [  568.151370] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2363 <NL> [  568.240486] layer1_hal[2088]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  568.254204] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2363 <NL> [  568.492387] layer1_control_layer[2060]:    ChalApi Constructor with tid = 2366 <NL> [  573.887929] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  573.891268] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  573.891376] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.003249, delay 0.09891\\n31 Jul 08:22:29 ntpdate[3778]: no server suitable for synchronization found\\n' <NL> [  585.949429] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  585.949887] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  585.949986] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.041514, delay 0.13707\\n31 Jul 08:22:41 ntpdate[3820]: no server suitable for synchronization found\\n' <NL> [  597.843727] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  597.844393] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  597.844490] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.003030, delay 0.02789\\n31 Jul 08:22:53 ntpdate[3846]: no server suitable for synchronization found\\n' <NL> [  609.703508] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  609.704303] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  609.704428] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.000232, delay 0.03976\\n31 Jul 08:23:04 ntpdate[3873]: no server suitable for synchronization found\\n' <NL> [  621.631307] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  621.631944] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  621.632129] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.000569, delay 0.05106\\n31 Jul 08:23:16 ntpdate[3923]: no server suitable for synchronization found\\n' <NL> [  633.458441] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  633.467820] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  633.491707] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.009854, delay 0.04504\\n31 Jul 08:23:28 ntpdate[3951]: no server suitable for synchronization found\\n' <NL> [  645.477652] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  645.478618] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  645.497540] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.008060, delay 0.04268\\n31 Jul 08:23:40 ntpdate[4000]: no server suitable for synchronization found\\n' <NL> [  657.511660] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  657.512331] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  657.512434] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.000131, delay 0.03398\\n31 Jul 08:23:52 ntpdate[4027]: no server suitable for synchronization found\\n' <NL> [  669.181218] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  669.181598] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  669.181718] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.006427, delay 0.03267\\n31 Jul 08:24:04 ntpdate[4053]: no server suitable for synchronization found\\n' <NL> [  681.069817] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  681.070049] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  681.070136] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.004263, delay 0.04677\\n31 Jul 08:24:16 ntpdate[4094]: no server suitable for synchronization found\\n' <NL> [  692.944630] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  692.968574] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  692.985627] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.002211, delay 0.03516\\n31 Jul 08:24:28 ntpdate[4120]: no server suitable for synchronization found\\n' <NL> [  704.802569] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  704.831196] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  704.857314] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.032930, delay 0.10687\\n31 Jul 08:24:39 ntpdate[4161]: no server suitable for synchronization found\\n' <NL> [  716.609700] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  716.637537] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  716.684530] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.007966, delay 0.05719\\n31 Jul 08:24:51 ntpdate[4187]: no server suitable for synchronization found\\n' <NL> [  728.487210] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  728.526704] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  728.547374] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.000181, delay 0.05701\\n31 Jul 08:25:03 ntpdate[4230]: no server suitable for synchronization found\\n' <NL> [  740.359827] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  740.360946] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  740.362537] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset +0.007534, delay 0.04977\\n31 Jul 08:25:15 ntpdate[4273]: no server suitable for synchronization found\\n' <NL> [  752.262355] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  752.262972] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  752.263163] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.044612, delay 0.14056\\n31 Jul 08:25:27 ntpdate[4312]: no server suitable for synchronization found\\n' <NL> [  764.126498] ntputils_client.py[1716]: INFO:root:command failed. <NL> [  764.127482] ntputils_client.py[1716]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  764.127632] ntputils_client.py[1716]: b'server 127.1.254.254, stratum 16, offset -0.005678, delay 0.04100\\n31 Jul 08:25:39 ntpdate[4353]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:25:54.052Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:53 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:57.324Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:25:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:56 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:58.694Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:25:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:58 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:02.023Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:01 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:03.917Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:03 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:07.220Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:06 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:09.109Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:08 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:12.378Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:11 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:13.790Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:26:14.053Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:13 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:17.321Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:16 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:19.218Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:18 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:22.560Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:21 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:23.925Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:23 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:27.223Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:26 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:28.595Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[  580.909779] layer1_control_layer[2076]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  580.909853] layer1_control_layer[2076]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  580.909936] layer1_control_layer[2076]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  580.942422] layer1_control_layer[2076]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  580.997092] layer1_control_layer[2076]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  580.997542] layer1_control_layer[2076]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  581.053696] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2357 <NL> [  581.053797] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2357 <NL> [  581.186949] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2357 <NL> [  581.214910] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2357 <NL> [  581.239702] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2357 <NL> [  581.274722] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2357 <NL> [  581.285189] layer1_hal[2100]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  581.391602] layer1_hal[2100]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  581.497544] layer1_control_layer[2076]:    ChalApi Constructor with tid = 2360 <NL> [  586.569449] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  586.569870] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  586.569982] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.232458, delay 0.53036\\n31 Jul 08:22:40 ntpdate[3846]: no server suitable for synchronization found\\n' <NL> [  598.603436] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  598.609716] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  598.609879] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.029629, delay 0.10561\\n31 Jul 08:22:52 ntpdate[3877]: no server suitable for synchronization found\\n' <NL> [  610.873445] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  610.873834] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:26:28.596Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[  610.873922] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.002145, delay 0.02721\\n31 Jul 08:23:04 ntpdate[3913]: no server suitable for synchronization found\\n' <NL> [  622.970536] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  622.971833] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  622.979681] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.004970, delay 0.03302\\n31 Jul 08:23:16 ntpdate[3949]: no server suitable for synchronization found\\n' <NL> [  634.959200] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  634.966421] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  635.006370] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.005674, delay 0.03383\\n31 Jul 08:23:28 ntpdate[3989]: no server suitable for synchronization found\\n' <NL> [  646.813242] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  646.814240] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  646.821100] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.001768, delay 0.03075\\n31 Jul 08:23:40 ntpdate[4024]: no server suitable for synchronization found\\n' <NL> [  658.725500] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  658.734065] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  658.765325] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.006314, delay 0.03522\\n31 Jul 08:23:52 ntpdate[4050]: no server suitable for synchronization found\\n' <NL> [  670.664216] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  670.664570] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  670.664669] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.000179, delay 0.03876\\n31 Jul 08:24:04 ntpdate[4090]: no server suitable for synchronization found\\n' <NL> [  682.523194] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  682.537378] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  682.539640] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.000326, delay 0.03445\\n31 Jul 08:24:16 ntpdate[4119]: no server suitable for synchronization found\\n' <NL> [  694.364645] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  694.388611] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  694.392083] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.005435, delay 0.03348\\n31 Jul 08:24:28 ntpdate[4155]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:26:28.597Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "step_id": "NE2-trib1-console", "message_content": "[  706.302702] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  706.303583] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  706.304393] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.001413, delay 0.02892\\n31 Jul 08:24:40 ntpdate[4187]: no server suitable for synchronization found\\n' <NL> [  718.161789] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  718.174737] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  718.226444] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.000382, delay 0.03169\\n31 Jul 08:24:52 ntpdate[4213]: no server suitable for synchronization found\\n' <NL> [  730.020983] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  730.021579] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  730.021705] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.003941, delay 0.03085\\n31 Jul 08:25:03 ntpdate[4270]: no server suitable for synchronization found\\n' <NL> [  741.978946] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  741.987221] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  741.988318] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.000915, delay 0.02975\\n31 Jul 08:25:15 ntpdate[4322]: no server suitable for synchronization found\\n' <NL> [  753.817544] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  753.818169] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  753.818287] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.002309, delay 0.02614\\n31 Jul 08:25:27 ntpdate[4348]: no server suitable for synchronization found\\n' <NL> [  765.727134] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  765.727487] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  765.727589] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.002671, delay 0.02861\\n31 Jul 08:25:39 ntpdate[4384]: no server suitable for synchronization found\\n' <NL> [  777.493508] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  777.493803] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  777.493952] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.002441, delay 0.03627\\n31 Jul 08:25:51 ntpdate[4411]: no server suitable for synchronization found\\n' <NL> [  789.384441] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  789.384743] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  789.384919] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset -0.007256, delay 0.06128\\n31 Jul 08:26:03 ntpdate[4439]: no server suitable for synchronization found\\n' <NL> [  801.256002] ntputils_client.py[1730]: INFO:root:command failed. <NL> [  801.256203] ntputils_client.py[1730]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  801.256333] ntputils_client.py[1730]: b'server 127.1.254.254, stratum 16, offset +0.003349, delay 0.02901\\n31 Jul 08:26:15 ntpdate[4485]: no server suitable for synchronization found\\n' <NL> [  813.092320] ntputils_client.py[1730]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:26:28.854Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:28 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:32.126Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:31 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:34.018Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:33 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:37.304Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:37 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:39.223Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:38 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:42.497Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:42 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:44.388Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:43 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:46.312Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  762.392981] python3[2142]: [.545] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  763.246256] txid_tracker[4484]: ::::create_confd_subscription_connection() connected <NL> [  769.374521] python3[2142]: [.567] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  775.555873] python3[2142]: [.809] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  775.802089] python3[2142]: [.915] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  775.875999] python3[2142]: [.117] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  776.010781] python3[2142]: [.248] hookhdlr 140548059326272 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  776.031299] python3[2142]: [.255] hookhdlr 140548059326272 callbackhdlr:391 Done register data callbacks <NL> [  815.844160] confd_mgr[3039]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  815.905037] confd_mgr[4625]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:26:29 UTC 2024 <NL> [  815.939562] confd_mgr[4625]: Starting valhdlr.service <NL> [  816.453566] confd_mgr[4625]: Starting validation-handler.service <NL> [  816.552329] confd_mgr[4625]: Starting snmp-fss-fw.service <NL> [  818.535643] confd_mgr[3039]: leaving: sm_startconfd::start_confd_p0 <NL> [  818.943788] python3[2142]: DEBUG No crypto keys configured <NL> [  819.026770] python3[2142]: [.142] hookhdlr 140548059326272 callbackhdlr:401 Unable to install crypto keys! <NL> [  819.415483] confd_mgr[3039]: entering: sm_startconfd::wait_for_p0 <NL> [  819.634156] confd_mgr[3039]: PROCESS1 has not registered yet. <NL> [  819.649375] confd_mgr[3039]: PROCESS_SNMP_CLID has not registered yet. <NL> [  819.650407] confd_mgr[3039]: PROCESS_VALHDLR has not registered yet. <NL> [  819.736374] python3[2142]: [.378] hookhdlr 140548059326272 callbackhdlr:322 Started data handler daemon... <NL> [  819.994979] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [  820.083768] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  820.405628] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  820.707992] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  820.884951] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  820.886399] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  820.887236] confd_mgr[3039]: ConfdHA Not supported command CONFIRM <NL> [  821.029479] confd_mgr[3039]: sm_startconfd::p0_ready_dbc <NL> [  821.099302] confd_mgr[3039]: Find message MESSAGE1 <NL> [  821.115313] confd_mgr[3039]: PROCESS_SNMP_CLID has not registered yet. <NL> [  821.286795] confd_mgr[3039]: PROCESS_VALHDLR has not registered yet. <NL> [  821.287628] confd_mgr[3039]: sm_startconfd::p0_not_ready <NL> [  821.288344] confd_mgr[3039]: Find message MESSAGE1 <NL> [  821.411610] confd_mgr[3039]: PROCESS_SNMP_CLID has not registered yet. <NL> [  821.475245] confd_mgr[3039]: PROCESS_VALHDLR has not registered yet. <NL> [  821.673670] confd_mgr[3039]: leaving: sm_startconfd::wait_for_p0 <NL> [  821.836791] confd_mgr[3039]: entering: sm_startconfd::wait_for_p0 <NL> [  821.997176] confd_mgr[3039]: PROCESS_SNMP_CLID has not registered yet. <NL> [  822.123218] confd_mgr[3039]: PROCESS_VALHDLR has not registered yet. <NL> [  822.238457] confd_mgr[3039]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  822.490912] confd_mgr[3039]: Timer /ConfdAT|wait_for_p0 already created <NL> [  822.491784] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  822.493097] confd_mgr[3039]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  823.638256] python3[4633]: [.826] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'}"}
{"timestamp_utc": "2024-07-31T08:26:46.313Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  823.755494] python3[4633]: [.931] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  824.026270] python3[4633]: [.931] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  824.228782] python3[4633]: [.933] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  824.387726] python3[4633]: [.933] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  824.549241] python3[4633]: [.933] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  824.732080] python3[4633]: [.933] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  825.056520] python3[4633]: [.933] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  825.657311] python3[4633]: [.933] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  826.160483] python3[4633]: [.934] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  826.539876] python3[4633]: [.937] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  826.917035] python3[4633]: [.938] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  827.217372] python3[4633]: [.938] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  827.574142] python3[4633]: [.939] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  828.074878] python3[4633]: [.939] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  828.076230] python3[4633]: [.939] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  828.275305] python3[4633]: [.940] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  828.305709] python3[4633]: [.943] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  828.466201] python3[4633]: [.943] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  828.636704] python3[4633]: [.944] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  828.768657] python3[4633]: [.945] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  828.854541] python3[4633]: [.945] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  828.955294] python3[4633]: [.945] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  829.154466] python3[4633]: [.945] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  829.540249] python3[4633]: [.947] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  829.829794] python3[4633]: [.991] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  829.983734] python3[4633]: [.991] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  830.143161] python3[4633]: [.991] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  830.478409] python3[4633]: [.002] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  830.813384] python3[4633]: [.003] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  831.154738] python3[4633]: [.085] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  831.516487] python3[4633]: [.085] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  831.907259] python3[4633]: [.085] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'}"}
{"timestamp_utc": "2024-07-31T08:26:47.244Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:47 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:49.135Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:48 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:52.404Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:52 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:54.292Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:53 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:57.559Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:26:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:57 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:59.493Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:26:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:58 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:02.765Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:02 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:04.132Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:04 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:04.696Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  832.192155] python3[4633]: [.085] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'}"}
{"timestamp_utc": "2024-07-31T08:27:04.697Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  832.439869] python3[4633]: [.096] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  832.902450] python3[4633]: [.096] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  833.239511] python3[4633]: [.097] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  833.520200] python3[4633]: [.097] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  833.817282] python3[4633]: [.097] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  834.137096] python3[4633]: [.097] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  834.398996] python3[4633]: [.098] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  834.596676] snmp_clid[4640]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  834.845061] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  834.865033] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  835.245663] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  835.511560] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  835.600659] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  835.611738] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  835.640840] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  835.654440] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  835.665432] python3[4633]: [.099] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  835.667158] python3[4633]: [.220] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  835.701197] python3[4633]: [.220] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  835.741967] python3[4633]: [.220] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  835.798173] python3[4633]: [.220] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  835.893312] python3[4633]: [.220] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  836.012281] python3[4633]: [.221] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  836.201836] python3[4633]: [.221] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  836.210307] python3[4633]: [.221] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  836.211984] python3[4633]: [.229] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  836.386312] python3[4633]: [.230] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  836.497513] python3[4633]: [.230] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  836.585133] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [  836.679542] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  836.796749] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  836.864462] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  836.891246] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  836.916911] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  836.945050] confd_mgr[3039]: ConfdHA Not supported command CONFIRM <NL> [  837.001457] confd_mgr[3039]: sm_startconfd::p0_ready_dbc <NL> [  837.228703] confd_mgr[3039]: Find message SNMP_CLID_CONFIRM <NL> [  837.302335] confd_mgr[3039]: PROCESS_VALHDLR has not registered yet. <NL> [  837.351237] confd_mgr[3039]: sm_startconfd::p0_not_ready <NL> [  837.396893] confd_mgr[3039]: Find message SNMP_CLID_CONFIRM <NL> [  837.451557] confd_mgr[3039]: PROCESS_VALHDLR has not registered yet. <NL> [  837.478039] confd_mgr[3039]: leaving: sm_startconfd::wait_for_p0 <NL> [  837.501632] confd_mgr[3039]: entering: sm_startconfd::wait_for_p0 <NL> [  837.530290] confd_mgr[3039]: PROCESS_VALHDLR has not registered yet. <NL> [  837.557550] confd_mgr[3039]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  837.609962] confd_mgr[3039]: Timer /ConfdAT|wait_for_p0 already created <NL> [  837.651865] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  837.682715] confd_mgr[3039]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  837.713134] snmp_clid[4690]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  837.754299] python3[4633]: [.230] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  837.870267] python3[4633]: [.230] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  837.986819] python3[4633]: [.230] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  838.051317] python3[4633]: [.230] valhdlr 140551445264192 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  838.088974] python3[4633]: [.230] valhdlr 140551445264192 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  838.105629] python3[4633]: [.247] valhdlr 140551445264192 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  838.136762] python3[4633]: [.247] valhdlr 140551445264192 callbackhdlr:293 Loading schemas <NL> [  838.214383] python3[4633]: DEBUG item does not exist - shared memory schema not enabled <NL> [  838.508535] python3[4633]: [.270] valhdlr 140551445264192 callbackhdlr:382 Done load schemas <NL> [  838.556998] python3[4633]: [.270] valhdlr 140551445264192 callbackhdlr:389 Done register transaction callback <NL> [  838.705112] python3[4633]: [.799] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  839.058800] python3[4633]: [.122] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  839.400665] python3[4633]: [.562] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  839.604353] python3[4633]: [.625] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  849.794599] python3[4633]: [.047] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  849.909067] python3[4633]: [.154] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  849.972705] python3[4633]: [.227] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  850.261211] python3[4633]: [.515] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  850.435104] python3[4633]: [.689] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  850.524953] python3[4633]: [.777] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  850.610153] python3[4633]: [.829] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  850.716296] python3[4633]: [.839] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation"}
{"timestamp_utc": "2024-07-31T08:27:07.227Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:07 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:09.118Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:09 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:12.389Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:12 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:14.286Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:14 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:17.600Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:17 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:19.493Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:19 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:22.764Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:22 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:24.242Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:24 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:27.513Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:27 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:29.483Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:29 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:32.754Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:32 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:34.149Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:34 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:37.488Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:37 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:39.380Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:39 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:42.684Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:42 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:44.581Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:44 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:47.875Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:47 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:49.241Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:49 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:50.607Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  697.364570] confd_mgr[2966]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  697.446849] confd_mgr[4330]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:24:33 UTC 2024 <NL> [  697.638775] confd_mgr[4345]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  697.732580] confd_mgr[2966]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  715.194633] systemd-journald[325]: Data hash table of /run/log/journal/baf8261feedd43818b5af63606bf556d/system.journal has a fill level at 75.0 (13655 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  715.641600] systemd-journald[325]: /run/log/journal/baf8261feedd43818b5af63606bf556d/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  784.043862] txid_tracker[4135]: ::::create_confd_subscription_connection() connected <NL> [  793.715888] confd_mgr[2966]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE"}
{"timestamp_utc": "2024-07-31T08:27:50.608Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  793.828813] confd_mgr[4690]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:26:10 UTC 2024 <NL> [  794.175641] confd_mgr[4690]: Invoking confd_load_upgrade_xml.py <NL> [  797.490112] confd_mgr[4697]: confd_load_upgrade_xml.py: Start <NL> [  797.567183] confd_mgr[4697]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  799.249033] confd_mgr[2966]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  799.300365] confd_mgr[4728]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  799.408835] confd_mgr[2966]: CONFD IN PHASE 1 <NL> [  799.409921] confd_mgr[2966]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  799.452413] confd_mgr[2966]: leaving: sm_startconfd::start_confd_p1 <NL> [  799.508818] confd_mgr[2966]: entering: sm_startconfd::wait_for_p1 <NL> [  799.578898] confd_mgr[2966]: PROCESS3 has not registered yet. <NL> [  799.626530] python3[4328]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  799.692231] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  799.791920] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  799.792988] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  799.793723] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  799.861912] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  799.864137] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  799.901261] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  799.948047] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  799.978441] confd_mgr[2966]: ConfdHA Not supported command CONFIRM <NL> [  800.021696] confd_mgr[2966]: sm_startconfd::p1_not_ready <NL> [  800.097537] confd_mgr[2966]: Find message MESSAGE3 <NL> [  800.179283] confd_mgr[2966]: sm_startconfd::p1_ready <NL> [  800.422873] confd_mgr[2966]: Find message MESSAGE3 <NL> [  800.537221] confd_mgr[2966]: leaving: sm_startconfd::wait_for_p1 <NL> [  800.580989] confd_mgr[2966]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  800.669575] confd_mgr[2966]: entering: sm_startconfd::wait_for_rm <NL> [  800.678041] confd_mgr[2966]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  800.706626] confd_mgr[2966]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  800.745225] confd_mgr[4732]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:26:16 UTC 2024 <NL> [  800.815999] confd_mgr[4744]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  800.913746] confd_mgr[4747]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  800.914828] confd_mgr[2966]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  800.966489] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  801.038170] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  801.148322] confd_mgr[4758]: /usr/bin/replay_manager NONE <NL> [  801.235529] confd_mgr[4755]: redundancy_status is STANDALONE <NL> [  801.300782] confd_mgr[4755]: DDS ports will be opened. <NL> [  801.382077] confd_mgr[4755]: execute replay_manager NONE TRUE <NL> [  801.913154] confd_mgr[4763]: TRACE Connected (cdb) to ConfD <NL> [  801.969658] confd_mgr[4763]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  802.016415] confd_mgr[4763]: TRACE Connected (cdb) to ConfD <NL> [  802.057445] confd_mgr[4763]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  807.192938] confd_mgr[4763]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  807.309442] txid_tracker[4135]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  807.518652] txid_tracker[4787]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  807.523283] confd_mgr[4763]: TRACE CDB_TRIGGER_SUBS <NL> [  807.530893] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  807.755280] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  807.821803] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  807.885227] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  807.962693] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  808.152409] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  808.266236] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  808.782611] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  842.212637] systemd-sysv-generator[4891]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  847.588326] systemd-sysv-generator[4914]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  887.792601] dcn_dns_controller[1373]: fin_file is open <NL> [  887.890246] userddssub[5062]: useradd: user 'fujitsu' already exists <NL> [  887.962335] userddssub[2141]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  888.243586] dcn_dns_controller[1373]: fin_file is open <NL> [  889.237865] ntputils[1733]: bool NTPServer::handle_command(const string&) <NL> [  889.656364] ntputils[1733]: bool NTPServer::handle_configure_cmd(const string&) <NL> [  889.693425] ntputils[1733]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  889.701549] ntputils[1733]: parse_time_persistent_topic ddskind create <NL> [  889.769859] ntputils[1733]: parse_time_persistent_topic name key config"}
{"timestamp_utc": "2024-07-31T08:27:50.609Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  889.783561] ntputils[1733]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  889.798417] ntputils[1733]: parse_time_topics command_data enable=yes; <NL> [  889.872387] ntputils[1733]: handle_configure_cmd token is: enable=yes <NL> [  889.875121] ntputils[1733]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  889.896327] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  889.907867] ntputils[1733]: systemctl --no-block stop ntpd <NL> [  889.910503] ntputils[1733]: child pid is 5195 <NL> [  890.449319] ntputils[1733]: exited, status is 0 <NL> [  890.637181] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  890.756882] ntputils[1733]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  890.792791] ntputils[1733]: child pid is 5200 <NL> [  891.011185] ntputils[1733]: exited, status is 0 <NL> [  891.012088] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  891.012842] ntputils[1733]: /bin/systemctl reset-failed ntpd <NL> [  891.133400] ntputils[1733]: child pid is 5210 <NL> [  891.561241] ntputils[1733]: exited, status is 0 <NL> [  892.218054] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  892.225670] ntputils[1733]: systemctl --no-block start ntpd <NL> [  892.288230] ntputils[1733]: child pid is 5212 <NL> [  892.313459] ntputils[1733]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:27:52.502Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:52 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:54.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:27:54.655Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:54 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:57.933Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:27:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:57 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:59.850Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:27:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:59 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:03.127Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:02 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:05.017Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:04 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:07.572Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:07 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:10.092Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:09 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:12.611Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:12 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:14.503Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  892.376669] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  892.634065] ntputils[1733]: systemctl --no-block start ntpscript <NL> [  892.638571] ntputils[1733]: child pid is 5217 <NL> [  893.059629] ntputils[1733]: exited, status is 0 <NL> [  893.358327] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  893.844888] ntputils[1733]: /bin/systemctl --no-block start init_state_check.timer <NL> [  893.907265] ntputils[1733]: child pid is 5221 <NL> [  894.137367] ntputils[1733]: exited, status is 0 <NL> [  894.483585] ntputils[1733]: Configure command handled successfully, writing to RTC <NL> [  894.651577] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  894.753067] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  895.177939] ntputils[1733]: child pid is 5228 <NL> [  895.178692] ntputils[1733]: exited, status is 0 <NL> [  895.179388] ntputils[1733]: bool NTPServer::handle_command(const string&) <NL> [  895.244547] ntputils[1733]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [  895.246345] ntputils[1733]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  895.540789] ntputils[1733]: parse_time_persistent_topic ddskind create <NL> [  896.178102] ntputils[1733]: parse_time_persistent_topic name key setTZ <NL> [  896.459948] ntputils[1733]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  896.696089] ntputils[1733]: parse_time_topics command_data timezone=UTC; <NL> [  896.887302] ntputils[1733]: bool NTPServer::set_timezone(const string&) <NL> [  897.101707] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  897.477897] ntputils[1733]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  897.784932] ntputils[1733]: child pid is 5229 <NL> [  898.035819] ntputils[1733]: exited, status is 0 <NL> [  898.408891] ntputils[1733]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  898.712148] ntputils[1733]: push_local_changes user_changed: 1 delta: 0 <NL> [  898.931765] ntputils[1733]: local_push OK u Platform::Time changedByUser 1 <NL> [  899.011240] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  899.294101] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  899.637121] ntputils[1733]: push_local_changes OK <NL> [  900.096934] ntputils[1733]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  900.098088] ntputils[1733]: publish_local_changes OK <NL> [  901.043244] ntp_alarm_event_monitor.py[5220]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  901.046814] ntp_alarm_event_monitor.py[5220]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  901.598198] confd_mgr[4763]:  --> CONFD_OK <NL> [  901.857215] ntp_alarm_event_monitor.py[5220]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  901.874361] ntp_alarm_event_monitor.py[5220]: INFO:root:redundancy status now set to standalone <NL> [  901.984916] confd_mgr[5248]: openDdsPorts interfaces  eth5.2003 <NL> [  902.004433] confd_mgr[5248]: openDdsPorts Input udpPorts-  7660 <NL> [  902.010432] confd_mgr[5248]: openDdsPorts Output udpPorts-  7660"}
{"timestamp_utc": "2024-07-31T08:28:14.504Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  902.202117] confd_mgr[5248]: openDdsPorts Input udpPorts-  7661 <NL> [  902.204413] confd_mgr[5248]: openDdsPorts Output udpPorts-  7661 <NL> [  902.613729] confd_mgr[5248]: openDdsPorts Input udpPorts-  7650 <NL> [  902.619546] confd_mgr[5248]: openDdsPorts Output udpPorts-  7650 <NL> [  902.633936] confd_mgr[5248]: openDdsPorts Input udpPorts-  7651 <NL> [  902.639899] confd_mgr[5248]: openDdsPorts Output udpPorts-  7651 <NL> [  902.644377] confd_mgr[5248]: openDdsPorts Input udpPorts-  7900 <NL> [  902.783906] confd_mgr[5248]: openDdsPorts Output udpPorts-  7900 <NL> [  902.794333] confd_mgr[5248]: openDdsPorts Input udpPorts-  7901 <NL> [  902.809520] confd_mgr[5248]: openDdsPorts Output udpPorts-  7901 <NL> [  902.810518] confd_mgr[5248]: openDdsPorts Input udpPorts-  7910 <NL> [  902.813912] confd_mgr[5248]: openDdsPorts Output udpPorts-  7910 <NL> [  902.815206] confd_mgr[5248]: openDdsPorts Input udpPorts-  7911 <NL> [  902.827639] confd_mgr[5248]: openDdsPorts Output udpPorts-  7911 <NL> [  902.841610] confd_mgr[5248]: openDdsPorts Input udpPorts-  8150 <NL> [  902.861359] confd_mgr[5248]: openDdsPorts Output udpPorts-  8150 <NL> [  902.936217] confd_mgr[5248]: openDdsPorts Input udpPorts-  8151 <NL> [  902.961848] confd_mgr[5248]: openDdsPorts Output udpPorts-  8151 <NL> [  903.906440] confd_mgr[5248]: openDdsPorts Input udpPorts-  8160 <NL> [  904.498201] confd_mgr[5248]: openDdsPorts Output udpPorts-  8160 <NL> [  904.500123] confd_mgr[5248]: openDdsPorts Input udpPorts-  8161 <NL> [  904.500812] confd_mgr[5248]: openDdsPorts Output udpPorts-  8161 <NL> [  904.939649] ntp_alarm_event_monitor.py[5304]: ntpq: read: Connection refused <NL> [  905.238407] confd_mgr[4763]: TRACE Connected (ha) to ConfD <NL> [  905.263675] confd_mgr[4763]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  905.368385] confd_mgr[4763]: replay_manager:  Start-Wed Jul 31 08:26:18 2024 <NL> [  905.393438] confd_mgr[4763]:  ++++++++++++++++++++++ <NL> [  905.444307] confd_mgr[4763]: replay_manager: TXID NOT FOUND ================================== <NL> [  905.953192] confd_mgr[4763]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  906.098286] confd_mgr[4763]: replay_manager: Need to do trigger full replay. <NL> [  906.211828] confd_mgr[4763]: replay_manager: Creating the purge file. <NL> [  906.225678] confd_mgr[4763]: replay_manager: Open DDS Ports <NL> [  906.227342] confd_mgr[4763]: replay_manager: NOW deleting the purge file. <NL> [  906.796639] confd_mgr[4763]: replay_manager:  End-Wed Jul 31 08:27:58 2024 <NL> [  907.196922] confd_mgr[4763]:  ++++++++++++++++++++++ <NL> [  907.672329] confd_mgr[4763]: 1+1 Mode <NL> [  907.816478] confd_mgr[4763]: Not in Slave Mode - Ready for Phase 2 ========== <NL> [  908.031699] confd_mgr[4763]: DipLog_pimpl destructor called <NL> [  908.033329] confd_mgr[4763]: DipVerbosity Listener ZMQ error <NL> [  908.138950] confd_mgr[4763]:     ret='Context was terminated <NL> [  908.400354] confd_mgr[4763]: deleting subscriber_ socket <NL> [  908.586344] confd_mgr[4763]: Exiting verb listener <NL> [  908.793144] ntp_alarm_event_monitor.py[5220]: INFO:root:Publish Alarm: Raising alarm <NL> [  908.794218] ntp_alarm_event_monitor.py[5220]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  909.018075] confd_mgr[2966]: CommAT::asio_subscriber: Connection accepted <NL> [  909.027634] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  909.087778] confd_mgr[2966]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  909.090469] confd_mgr[2966]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  909.092558] confd_mgr[2966]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  909.096811] confd_mgr[2966]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  909.180858] confd_mgr[2966]: ConfdHA Not supported command CONFIRM <NL> [  909.225960] confd_mgr[2966]: sm_startconfd::rm_ready <NL> [  909.227936] confd_mgr[2966]: leaving: sm_startconfd::wait_for_rm <NL> [  909.418773] confd_mgr[2966]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [  909.434592] confd_mgr[2966]: entering: sm_startconfd::start_confd_p2 <NL> [  909.438846] confd_mgr[2966]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [  909.665846] confd_mgr[5330]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:28:00 UTC 2024 <NL> [  909.705849] confd_mgr[5356]: cmnEvtXML has stopped <NL> [  909.706612] confd_mgr[5356]: start event-handler.service <NL> [  909.751491] confd_mgr[5368]: condition_name: systemRestart <NL> [  909.752334] confd_mgr[5368]: entity_type: COM <NL> [  909.753361] confd_mgr[5368]: num_instances: 1 <NL> [  909.753908] confd_mgr[5368]: num_samples: 1 <NL> [  909.812548] confd_mgr[5368]:  EventNotification does not have condition_group. Skipping. <NL> [  910.371900] confd_mgr[5368]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [  910.526520] confd_mgr[5368]: CmnEvtPublisher::main: returning <NL> [  910.776852] confd_mgr[5356]: /usr/bin/confd_mgr_in_spm.sh <NL> [  912.415080] confd_mgr[5356]: /usr/bin/ui_sys_reset.py NONE <NL> [  912.911493] cia_control_layer[5412]: grep: product_systemData.xml: No such file or directory"}
{"timestamp_utc": "2024-07-31T08:28:14.505Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  916.295888] cia_control_layer[2113]:    ChalApi Constructor with tid = 2751"}
{"timestamp_utc": "2024-07-31T08:28:14.761Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:14 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:18.046Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:17 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:19.939Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:19 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:22.456Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:28:23.384Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:23 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:24.758Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:24 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:28.927Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:28 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:29.855Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:28:29.856Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:29 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:34.026Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:33 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',) <NL> [  300.659206] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  300.705575] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  300.748074] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.346514, delay 0.04784\\n31 Jul 08:17:56 ntpdate[2771]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0"}
{"timestamp_utc": "2024-07-31T08:28:34.027Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  313.717565] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  313.740549] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  313.762091] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.340948, delay 0.05699\\n31 Jul 08:18:09 ntpdate[2802]: no server suitable for synchronization found\\n' <NL> [  325.672823] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  325.676488] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  325.677530] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.356449, delay 0.03679\\n31 Jul 08:18:21 ntpdate[2822]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:18:25,665 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  337.879497] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  337.880896] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  337.932931] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.352733, delay 0.02977\\n31 Jul 08:18:33 ntpdate[2850]: no server suitable for synchronization found\\n' <NL> [  349.798454] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  349.821571] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  349.826441] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.350723, delay 0.06615\\n31 Jul 08:18:45 ntpdate[2905]: no server suitable for synchronization found\\n' <NL> [  362.188082] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  362.198299] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  362.215039] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.347441, delay 0.05243\\n31 Jul 08:18:58 ntpdate[2939]: no server suitable for synchronization found\\n' <NL> [  374.225494] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  374.226326] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  374.226438] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.301543, delay 0.12721\\n31 Jul 08:19:10 ntpdate[3004]: no server suitable for synchronization found\\n' <NL> [  386.217771] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  386.218766] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  386.218864] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.349515, delay 0.03677\\n31 Jul 08:19:22 ntpdate[3031]: no server suitable for synchronization found\\n' <NL> [  398.161505] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  398.162421] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  398.162519] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.354105, delay 0.03996\\n31 Jul 08:19:34 ntpdate[3070]: no server suitable for synchronization found\\n' <NL> [  410.272620] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  410.273482] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  410.273632] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.348794, delay 0.03703\\n31 Jul 08:19:46 ntpdate[3126]: no server suitable for synchronization found\\n' <NL> [  422.179174] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  422.179610] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  422.231711] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.352230, delay 0.04796\\n31 Jul 08:19:58 ntpdate[3159]: no server suitable for synchronization found\\n' <NL> [  434.081409] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  434.081944] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  434.082054] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.352624, delay 0.03569\\n31 Jul 08:20:10 ntpdate[3187]: no server suitable for synchronization found\\n' <NL> [  446.027197] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  446.027829] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  446.027920] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.353201, delay 0.05820\\n31 Jul 08:20:22 ntpdate[3227]: no server suitable for synchronization found\\n' <NL> [  457.878061] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  457.878956] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  457.879094] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.346716, delay 0.03601\\n31 Jul 08:20:33 ntpdate[3264]: no server suitable for synchronization found\\n' <NL> [  469.641277] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  469.642135] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  469.642313] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.350044, delay 0.05110\\n31 Jul 08:20:45 ntpdate[3310]: no server suitable for synchronization found\\n' <NL> [  481.588372] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  481.589083] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  481.589259] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.350455, delay 0.04666\\n31 Jul 08:20:57 ntpdate[3350]: no server suitable for synchronization found\\n' <NL> [  493.763648] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  493.764106] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  493.764205] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset -0.345497, delay 0.03795\\n31 Jul 08:21:09 ntpdate[3393]: no server suitable for synchronization found\\n' <NL> [  904.881199] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  904.882356] ntputils_client.py[1753]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  904.887472] ntputils_client.py[1753]: b'31 Jul 08:28:00 ntpdate[4705]: no server suitable for synchronization found\\n' <NL> [  907.583983] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  907.584240] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  907.584335] ntputils_client.py[1753]: b'31 Jul 08:28:03 ntpdate[4751]: no server suitable for synchronization found\\n' <NL> [  917.455999] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  917.466237] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  917.471432] ntputils_client.py[1753]: b'31 Jul 08:28:13 ntpdate[4799]: no server suitable for synchronization found\\n' <NL> [  931.509612] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  931.516399] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  931.517565] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset +0.001512, delay 0.03329\\n31 Jul 08:28:27 ntpdate[4846]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:28:34.955Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:34 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:38.277Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:28:38.534Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:38 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:39.901Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:39 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:44.112Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:43 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:45.043Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:44 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:49.245Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:48 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:49.808Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:28:50.065Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:49 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:54.234Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:53 retry-ssh-command INFO: attempt 105, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:55.165Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:54 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:58.436Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:28:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:58 retry-ssh-command INFO: attempt 106, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:00.343Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:28:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:59 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:03.612Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:03 retry-ssh-command INFO: attempt 107, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:05.023Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:05 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:07.544Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[  937.041306] confd_director.py[4928]: mkdir: cannot create directory '/var/shared/confd': File exists <NL> [  938.172354] confd_mgr[4956]: ConfdMgrConf: DB signature is NOT supported <NL> [  938.214774] confd_mgr[4956]: Read reset type failed basic_ios::clear: iostream error <NL> [  938.214926] confd_mgr[4956]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  938.606694] confd_mgr[4956]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  938.606919] confd_mgr[4956]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  938.733473] confd_mgr[4988]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:28:34 UTC 2024 <NL> [  939.028642] confd_mgr[4988]: TRIB don't call callback script. <NL> [  939.052747] confd_mgr[4956]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  939.053028] confd_mgr[4956]: entering: wait_for_alarm_event <NL> [  939.141268] confd_mgr[4956]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  939.141501] confd_mgr[4956]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  939.141780] confd_mgr[4956]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  939.142278] confd_mgr[4956]: ha_sm : wait_for_SWDL_s timer is set <NL> [  939.195281] confd_mgr[4956]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  939.195529] confd_mgr[4956]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  939.195624] confd_mgr[4956]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  939.195713] confd_mgr[4956]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  939.195786] confd_mgr[4956]: entering: at_sm::wait_for_SWDL <NL> [  939.262020] confd_mgr[4956]: CommAT::asio_subscriber: Connection accepted <NL> [  939.262452] confd_mgr[4956]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> [  939.262689] confd_mgr[4956]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> [  939.262845] confd_mgr[4956]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  939.262997] confd_mgr[4956]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  939.263129] confd_mgr[4956]: CommAT::asio_worker: ASIO_ID = ASIO"}
{"timestamp_utc": "2024-07-31T08:29:07.545Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "step_id": "NE3-trib1-console", "message_content": "[  939.263336] confd_mgr[4956]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  939.263557] confd_mgr[4956]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  941.446180] confd_mgr[5005]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'TRIB', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  941.713774] confd_mgr[4956]: ConfdMgrConf::reload: DB signature set to false <NL> [  941.714030] confd_mgr[4956]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  941.732066] confd_mgr[5003]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  941.732349] confd_mgr[4956]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  941.787192] confd_mgr[4956]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  941.813669] confd_mgr[4956]: main::/run/rdm_status.sh found. Invoking it. <NL> [  941.822537] confd_mgr[4956]: CommAT::asio_subscriber: Connection accepted <NL> [  941.822728] confd_mgr[4956]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,TRIB,WORK,STANDALONE <NL> [  941.822823] confd_mgr[4956]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,TRIB,WORK,STANDALONE <NL> [  941.822907] confd_mgr[4956]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  941.822988] confd_mgr[4956]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  941.823084] confd_mgr[4956]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  941.823166] confd_mgr[4956]: ConfdMgrConf::reload: DB signature set to false <NL> [  941.823274] confd_mgr[4956]: Start_type: GO_NONE <NL> [  941.823370] confd_mgr[4956]: ha_sm leaving: wait_for_SWDL_s <NL> [  941.823453] confd_mgr[4956]: ha_sm entering: no_ha_s <NL> [  941.823535] confd_mgr[4956]: ConfdMgrConf::reload: DB signature set to false <NL> [  941.823638] confd_mgr[4956]: Start_type: GO_NONE <NL> [  941.823749] confd_mgr[4956]: leaving: at_sm::wait_for_SWDL <NL> [  941.823850] confd_mgr[4956]: entering: at_sm::SDB_sleep <NL> [  941.823934] confd_mgr[4956]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  941.824041] confd_mgr[4956]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  941.824126] confd_mgr[4956]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  941.853263] confd_mgr[5025]: TRUE <NL> [  946.372461] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  946.373585] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  946.376822] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset +0.021534, delay 0.12408\\n31 Jul 08:28:42 ntpdate[5032]: no server suitable for synchronization found\\n' <NL> [  950.091939] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2367 <NL> [  950.103281] layer1_control_layer[2085]: EsalConfig::EsalConfig main 0 <NL> [  950.103554] layer1_control_layer[2085]: EsalConfig::EsalConfig trib 1 <NL> [  950.103658] layer1_control_layer[2085]: EsalConfig::EsalConfig ciRole 0 <NL> [  950.153636] layer1_control_layer[2085]: EsalConfig is not running inside container. <NL> [  950.154105] layer1_control_layer[2085]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  950.154233] layer1_control_layer[2085]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  950.154383] layer1_control_layer[2085]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  950.154564] layer1_control_layer[2085]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  950.154720] layer1_control_layer[2085]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  950.154838] layer1_control_layer[2085]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  950.155035] layer1_control_layer[2085]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  950.155196] layer1_control_layer[2085]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  950.158591] layer1_control_layer[2085]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  950.159603] layer1_control_layer[2085]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  950.159712] layer1_control_layer[2085]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  950.159790] layer1_control_layer[2085]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  950.159860] layer1_control_layer[2085]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  950.159940] layer1_control_layer[2085]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  950.160030] layer1_control_layer[2085]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  950.160104] layer1_control_layer[2085]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  950.160196] layer1_control_layer[2085]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  950.616968] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2366 <NL> [  950.617140] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2366 <NL> [  950.617217] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2366 <NL> [  950.617286] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2366 <NL> [  950.617366] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2366 <NL> [  950.617434] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2366 <NL> [  951.071222] layer1_hal[2101]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  951.096314] layer1_hal[2101]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  951.330947] layer1_control_layer[2085]:    ChalApi Constructor with tid = 2369 <NL> [  958.445022] ntputils_client.py[1753]: INFO:root:command failed. <NL> [  958.445709] ntputils_client.py[1753]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  958.445800] ntputils_client.py[1753]: b'server 127.1.254.254, stratum 16, offset +0.003597, delay 0.04121\\n31 Jul 08:28:54 ntpdate[5130]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:29:08.473Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:08 retry-ssh-command INFO: attempt 108, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:10.365Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:10 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:13.653Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:13 retry-ssh-command INFO: attempt 109, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:15.043Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:15 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:19.230Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:18 retry-ssh-command INFO: attempt 110, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:20.162Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:20 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:24.355Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:23 retry-ssh-command INFO: attempt 111, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:25.285Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:25 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:28.572Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:28 retry-ssh-command INFO: attempt 112, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:30.464Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:30 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:33.737Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  916.416930] cia_control_layer[2113]: EsalConfig::EsalConfig main 1 <NL> [  916.524415] cia_control_layer[2113]: EsalConfig::EsalConfig trib 0 <NL> [  916.533371] cia_control_layer[2113]: EsalConfig::EsalConfig ciRole 0 <NL> [  918.029984] cia_control_layer[2113]: EsalConfig is not running inside container. <NL> [  919.172487] cia_control_layer[2113]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  919.709820] cia_control_layer[2113]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  920.206847] cia_control_layer[2113]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  920.699224] cia_control_layer[2113]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  920.704312] cia_control_layer[2113]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  920.711340] cia_control_layer[2113]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:29:33.738Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  920.720103] cia_control_layer[2113]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  920.725082] cia_control_layer[2113]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  920.781558] cia_control_layer[2113]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  920.801072] cia_control_layer[2113]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  920.858461] cia_control_layer[2113]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  920.936347] cia_control_layer[2113]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  921.067444] cia_control_layer[2113]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  921.435936] cia_control_layer[2113]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  921.795569] cia_control_layer[2113]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  922.192496] cia_control_layer[2113]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  928.119934] cia_control_layer[2113]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  928.824944] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  928.904325] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  930.164676] ntputils[1733]: child pid is 5484 <NL> [  932.957423] ntputils[1733]: exited, status is 0 <NL> [  934.173165] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  934.363373] ntputils[1733]: poller time change delta is: 1 <NL> [  935.411612] ntputils[1733]: push_local_changes user_changed: 0 delta: 1 <NL> [  935.880327] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  936.353293] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  941.207445] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  941.514715] ntputils[1733]: push_local_changes OK <NL> [  942.414560] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  942.415900] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  943.254179] ntputils[1733]: child pid is 5498 <NL> [  944.670234] ntputils[1733]: exited, status is 0 <NL> [  944.671428] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  944.721506] ntputils[1733]: poller time change delta is: 4 <NL> [  944.722343] ntputils[1733]: push_local_changes user_changed: 0 delta: 4 <NL> [  944.723417] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  944.724479] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 4 <NL> [  944.906420] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  945.264257] ntputils[1733]: push_local_changes OK <NL> [  945.354988] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  945.365985] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  945.367607] ntputils[1733]: child pid is 5519 <NL> [  945.369083] ntputils[1733]: exited, status is 0 <NL> [  945.642356] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  945.757077] ntputils[1733]: poller time change delta is: 5 <NL> [  946.437797] ntputils[1733]: push_local_changes user_changed: 0 delta: 5 <NL> [  946.458313] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  947.479810] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [  947.586561] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  947.671787] ntputils[1733]: push_local_changes OK <NL> [  948.128848] ntputils[1733]: NTPServer::execute_cmd spawning: <NL> [  948.129666] ntputils[1733]: /sbin/hwclock -u --systohc <NL> [  948.130333] ntputils[1733]: child pid is 5533 <NL> [  948.130960] ntputils[1733]: exited, status is 0 <NL> [  948.593205] ntputils[1733]: poller time change reason is: local_pub_str.ntp_drift <NL> [  948.841256] ntputils[1733]: poller time change delta is: 5 <NL> [  949.068460] ntputils[1733]: push_local_changes user_changed: 0 delta: 5 <NL> [  949.263189] ntputils[1733]: local_push OK u Platform::Time changedByUser 0 <NL> [  949.286717] ntputils[1733]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [  949.340725] ntputils[1733]: local_push OK w Platform::Time 0 0 <NL> [  949.777791] ntputils[1733]: push_local_changes OK <NL> [  950.053835] confd_mgr[5558]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  950.254896] confd_mgr[5558]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  950.439540] confd_mgr[5560]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  950.636145] confd_mgr[5560]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  950.919970] confd_mgr[5562]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  951.062208] confd_mgr[5562]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  951.362275] confd_mgr[5401]: DDS Peristency is enabled <NL> [  951.511711] confd_mgr[5401]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  951.758424] confd_mgr[5401]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  951.963548] confd_mgr[5401]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  952.122490] confd_mgr[5401]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  952.325807] confd_mgr[5566]: Execute check_db_status.sh"}
{"timestamp_utc": "2024-07-31T08:29:33.739Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  952.590581] confd_mgr[5566]: NE is running a default database! <NL> [  954.681720] confd_mgr[5330]: Starting valhdlr.service if not started already <NL> [  954.853376] confd_mgr[5330]: Starting validation-handler.service if not started already <NL> [  955.449463] confd_mgr[5330]: Starting snmp-fss-fw.service if not started already <NL> [  955.665304] confd_mgr[2966]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [  956.485222] cia_control_layer[2113]:    ChalApi Constructor with tid = 2750 <NL> [  956.662279] cia_control_layer[2113]:    ChalApi Constructor with tid = 2750 <NL> [  956.694223] cia_control_layer[2113]:    ChalApi Constructor with tid = 2750 <NL> [  956.732388] cia_control_layer[2113]:    ChalApi Constructor with tid = 2750 <NL> [  956.943787] cia_control_layer[2113]:    ChalApi Constructor with tid = 2750 <NL> [  956.944983] cia_control_layer[2113]:    ChalApi Constructor with tid = 2750 <NL> [  956.945973] cia_control_layer[2113]:    ChalApi Constructor with tid = 2750 <NL> [  981.065838] ops-service[5821]: rebind_listener \"webui\" <NL> [  981.343564] ops-service[5821]: TRACE Connected (maapi) to ConfD <NL> [  981.807938] ops-service[5821]: TRACE MAAPI_REBIND_LISTENER <NL> [  982.120467] ops-service[5821]:  31-Jul-2024::08:29:18.355 5821/7fcd50eddc40/4 SEND op=407 isrel=0 th=-1 16 <NL> [  982.544153] ops-service[5821]:  --> CONFD_OK <NL> [  982.545015] ops-service[5821]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  982.685519] ops-service[5825]: rebind_listener \"snmp\" <NL> [  982.686463] ops-service[5825]: TRACE Connected (maapi) to ConfD <NL> [  982.893821] ops-service[5825]: TRACE MAAPI_REBIND_LISTENER <NL> [  983.172884] ops-service[5825]:  31-Jul-2024::08:29:19.510 5825/7f619a97cc40/4 SEND op=407 isrel=0 th=-1 4 <NL> [  983.220675] ops-service[5825]:  --> CONFD_OK <NL> [  983.437704] ops-service[5825]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  987.447510] systemd-sysv-generator[5870]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> # 03:29:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:33 retry-ssh-command INFO: attempt 113, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:35.121Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:35 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:39.299Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:38 retry-ssh-command INFO: attempt 114, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:40.229Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:40 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:44.407Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:43 retry-ssh-command INFO: attempt 115, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:45.336Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:45 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:48.608Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:48 retry-ssh-command INFO: attempt 116, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:50.502Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:50 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:53.772Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:53 retry-ssh-command INFO: attempt 117, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:55.675Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:29:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:55 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:58.949Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:29:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:58 retry-ssh-command INFO: attempt 118, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:00.318Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:00 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:04.494Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:03 retry-ssh-command INFO: attempt 119, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:05.423Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:05 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:08.693Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:08 retry-ssh-command INFO: attempt 120, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:10.584Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:10 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:13.853Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:13 retry-ssh-command INFO: attempt 121, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:15.744Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:15 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:19.034Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:18 retry-ssh-command INFO: attempt 122, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:19.597Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  850.775611] python3[4633]: [.842] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation"}
{"timestamp_utc": "2024-07-31T08:30:19.598Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  854.249750] python3[4633]: [.502] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  857.666301] python3[4633]: [.919] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  859.853698] python3[4633]: [.107] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  861.283742] python3[4633]: [.535] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  861.295558] python3[4633]: [.548] valhdlr 140551445264192 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  861.301698] python3[4633]: [.553] valhdlr 140551445264192 callbackhdlr:391 Done register data callbacks <NL> [  861.315565] python3[4633]: DEBUG No crypto keys configured <NL> [  861.318111] python3[4633]: [.559] valhdlr 140551445264192 callbackhdlr:401 Unable to install crypto keys! <NL> [  861.330787] python3[4633]: [.575] valhdlr 140551445264192 callbackhdlr:322 Started data handler daemon... <NL> [  861.365304] python3[4633]: [.619] valhdlr 140551445264192 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  861.416533] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [  861.480589] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  861.485242] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  861.532053] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  861.536179] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  861.536995] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  861.538756] confd_mgr[3039]: ConfdHA Not supported command CONFIRM <NL> [  861.546922] confd_mgr[3039]: sm_startconfd::p0_ready_dbc <NL> [  861.563050] confd_mgr[3039]: Find message VALHDLR_CONFIRM <NL> [  861.583903] confd_mgr[3039]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  861.584758] confd_mgr[3039]: sm_startconfd::p0_not_ready <NL> [  861.585453] confd_mgr[3039]: Find message VALHDLR_CONFIRM <NL> [  861.586192] confd_mgr[3039]: sm_startconfd::p0_ready_no_dbc <NL> [  861.610673] confd_mgr[3039]: Find message VALHDLR_CONFIRM <NL> [  861.611295] confd_mgr[3039]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  861.613924] confd_mgr[3039]: leaving: sm_startconfd::wait_for_p0 <NL> [  861.615442] confd_mgr[3039]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  861.616308] confd_mgr[3039]: entering: sm_startconfd::start_confd_p1 <NL> [  861.643332] confd_mgr[3039]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  861.688143] confd_mgr[4771]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:27:14 UTC 2024 <NL> [  862.486073] systemd-journald[324]: Data hash table of /run/log/journal/ea2b010b2bc34073bd2a7cd9c85a567c/system.journal has a fill level at 75.0 (13656 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  862.578151] systemd-journald[324]: /run/log/journal/ea2b010b2bc34073bd2a7cd9c85a567c/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  862.509152] confd_mgr[4781]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  862.646297] confd_mgr[3039]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  974.992517] txid_tracker[4484]: ::::create_confd_subscription_connection() connected <NL> [  981.425848] python3[4769]: confd_mgr_cmd:: Reply is: Receive failed <NL> [  981.504682] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  981.602991] confd_mgr[3039]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  981.719639] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [  981.720529] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  981.721996] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  981.774343] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  981.900404] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  982.020787] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  982.178854] confd_mgr[3039]: ConfdHA Not supported command CONFIRM <NL> [  987.348825] confd_mgr[3039]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  987.498703] confd_mgr[5187]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:29:20 UTC 2024 <NL> [  987.881906] confd_mgr[5187]: Invoking confd_load_upgrade_xml.py <NL> [  991.014435] confd_mgr[5196]: confd_load_upgrade_xml.py: Start <NL> [  991.015386] confd_mgr[5196]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  992.042131] confd_mgr[3039]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  992.351273] confd_mgr[5231]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  992.414964] confd_mgr[3039]: CONFD IN PHASE 1 <NL> [  992.415969] confd_mgr[3039]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  992.459661] confd_mgr[3039]: leaving: sm_startconfd::start_confd_p1 <NL> [  992.460386] confd_mgr[3039]: entering: sm_startconfd::wait_for_p1 <NL> [  992.511370] confd_mgr[3039]: PROCESS3 has not registered yet. <NL> [  992.512244] confd_mgr[3039]: sm_startconfd::p1_not_ready <NL> [  992.526121] confd_mgr[3039]: Find message MESSAGE3 <NL> [  992.535715] confd_mgr[3039]: sm_startconfd::p1_ready <NL> [  992.537604] confd_mgr[3039]: Find message MESSAGE3 <NL> [  992.539116] confd_mgr[3039]: leaving: sm_startconfd::wait_for_p1 <NL> [  992.541307] confd_mgr[3039]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  992.544393] confd_mgr[3039]: entering: sm_startconfd::wait_for_rm <NL> [  992.545203] confd_mgr[3039]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  992.547231] confd_mgr[3039]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  992.553278] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  992.557712] confd_mgr[3039]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  992.574535] confd_mgr[5234]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:29:25 UTC 2024 <NL> [  993.241845] confd_mgr[5248]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  993.300135] confd_mgr[5251]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  993.624533] confd_mgr[3039]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  993.696410] confd_mgr[5261]: /usr/bin/replay_manager NONE <NL> [  993.759606] confd_mgr[5259]: redundancy_status is STANDALONE <NL> [  993.760821] confd_mgr[5259]: DDS ports will be opened. <NL> [  993.814087] confd_mgr[5259]: execute replay_manager NONE TRUE"}
{"timestamp_utc": "2024-07-31T08:30:19.599Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[  994.461464] confd_mgr[5266]: TRACE Connected (cdb) to ConfD <NL> [  994.551377] confd_mgr[5266]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  994.710407] confd_mgr[5266]: TRACE Connected (cdb) to ConfD <NL> [  994.851656] confd_mgr[5266]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [ 1000.153075] confd_mgr[5266]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [ 1000.278217] txid_tracker[4484]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [ 1000.298563] confd_mgr[5266]: TRACE CDB_TRIGGER_SUBS <NL> [ 1000.310106] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [ 1000.326792] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [ 1000.328055] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [ 1000.354027] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1000.390466] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1000.457320] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1000.587715] txid_tracker[5291]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [ 1000.775235] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [ 1000.927995] confd_mgr[3039]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT"}
{"timestamp_utc": "2024-07-31T08:30:20.530Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:20 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:23.847Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:23 retry-ssh-command INFO: attempt 123, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:25.738Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:30:25.739Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:25 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:29.020Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:28 retry-ssh-command INFO: attempt 124, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:30.420Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:30 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:34.587Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:33 retry-ssh-command INFO: attempt 125, sleep 5: \"rtxoialp79:37245\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:35.514Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:35 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:38.843Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37245, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:30:40.733Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:40 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:45.992Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:45 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:51.273Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:50 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:55.534Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:30:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:55 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:59.700Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "step_id": "s01.p05.s02.NE3-main-cli", "message_content": "# 03:30:59 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:30:59 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:30:59 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"stderr\": DONE <NL> # 03:30:59 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"stdout\": DONE <NL> # 03:30:59 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\": process 3621 terminated with exitcode 0 <NL> # 03:30:59 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:30:59 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:30:59 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p05.main-startup (s))"}
{"timestamp_utc": "2024-07-31T08:30:59.701Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:30:59 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #4 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:30:59 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 1 children running (n01.p09.s01.startup (p)) <NL> # 03:30:59 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.s02.NE3-main-cli\", exit_code 0 <NL> # 03:30:59 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.main-startup (s)\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:31:00.672Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:00 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:05.920Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:05 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:11.167Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:10 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:16.408Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:15 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:21.648Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:20 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:25.820Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:25 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:31.065Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:30 retry-ssh-command INFO: attempt 105, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:36.322Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:35 retry-ssh-command INFO: attempt 106, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:41.595Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:40 retry-ssh-command INFO: attempt 107, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:45.763Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:45 retry-ssh-command INFO: attempt 108, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:51.007Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:50 retry-ssh-command INFO: attempt 109, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:56.252Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:31:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:55 retry-ssh-command INFO: attempt 110, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:56.508Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[ 1045.950141] systemd-sysv-generator[5423]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [ 1053.138882] systemd-sysv-generator[5439]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [ 1112.967694] cia_control_layer[5690]: grep: product_systemData.xml: No such file or directory <NL> [ 1113.255747] userddssub[5668]: useradd: user 'fujitsu' already exists <NL> [ 1113.301723] userddssub[2156]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [ 1114.346511] dcn_dns_controller[1372]: fin_file is open <NL> [ 1115.104110] dcn_dns_controller[1372]: fin_file is open <NL> [ 1116.179168] ntputils[1710]: bool NTPServer::handle_command(const string&) <NL> [ 1116.301640] ntputils[1710]: bool NTPServer::handle_configure_cmd(const string&) <NL> [ 1116.423460] ntputils[1710]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [ 1116.425410] ntputils[1710]: parse_time_persistent_topic ddskind create <NL> [ 1117.031970] ntputils[1710]: parse_time_persistent_topic name key config <NL> [ 1118.173261] ntputils[1710]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [ 1119.076617] ntputils[1710]: parse_time_topics command_data enable=yes; <NL> [ 1119.243365] ntputils[1710]: handle_configure_cmd token is: enable=yes <NL> [ 1119.263827] ntputils[1710]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [ 1119.281954] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1119.400193] ntputils[1710]: systemctl --no-block stop ntpd <NL> [ 1119.762881] ntputils[1710]: child pid is 5788 <NL> [ 1120.279732] ntputils[1710]: exited, status is 0 <NL> [ 1120.477695] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1121.918988] ntputils[1710]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [ 1122.750701] ntputils[1710]: child pid is 5814 <NL> [ 1123.127119] ntputils[1710]: exited, status is 0 <NL> [ 1123.611412] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1124.209785] ntputils[1710]: /bin/systemctl reset-failed ntpd <NL> [ 1124.553273] ntputils[1710]: child pid is 5832 <NL> [ 1124.689495] ntputils[1710]: exited, status is 0 <NL> [ 1124.693128] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1124.754418] ntputils[1710]: systemctl --no-block start ntpd <NL> [ 1124.757159] ntputils[1710]: child pid is 5835 <NL> [ 1125.181535] ntputils[1710]: exited, status is 0 <NL> [ 1125.207855] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1125.518519] ntputils[1710]: systemctl --no-block start ntpscript <NL> [ 1126.074725] ntputils[1710]: child pid is 5839 <NL> [ 1126.479742] ntputils[1710]: exited, status is 0 <NL> [ 1126.637122] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1126.949394] ntputils[1710]: /bin/systemctl --no-block start init_state_check.timer <NL> [ 1127.302767] ntputils[1710]: child pid is 5844 <NL> [ 1127.412829] ntputils[1710]: exited, status is 0 <NL> [ 1127.647504] ntputils[1710]: Configure command handled successfully, writing to RTC <NL> [ 1127.881302] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1128.406191] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [ 1128.901928] ntputils[1710]: child pid is 5846 <NL> [ 1129.547839] ntputils[1710]: exited, status is 0 <NL> [ 1130.151447] ntputils[1710]: bool NTPServer::handle_command(const string&) <NL> [ 1131.015255] ntputils[1710]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [ 1131.514434] ntputils[1710]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [ 1132.108505] ntputils[1710]: parse_time_persistent_topic ddskind create <NL> [ 1132.460352] ntputils[1710]: parse_time_persistent_topic name key setTZ <NL> [ 1132.461216] ntputils[1710]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [ 1132.608698] ntputils[1710]: parse_time_topics command_data timezone=UTC; <NL> [ 1132.701289] ntputils[1710]: bool NTPServer::set_timezone(const string&) <NL> [ 1132.886519] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1133.021950] ntputils[1710]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [ 1133.201792] ntputils[1710]: child pid is 5847 <NL> [ 1133.372219] ntputils[1710]: exited, status is 0 <NL> [ 1133.376379] ntputils[1710]: set new timezone: /usr/share/zoneinfo/UTC <NL> [ 1133.377192] ntputils[1710]: push_local_changes user_changed: 1 delta: 0 <NL> [ 1133.377954] ntputils[1710]: local_push OK u Platform::Time changedByUser 1 <NL> [ 1133.378771] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [ 1133.833141] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [ 1134.819479] ntputils[1710]: push_local_changes OK <NL> [ 1134.820347] ntputils[1710]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [ 1134.821300] ntputils[1710]: publish_local_changes OK <NL> [ 1135.059950] confd_mgr[5266]:  --> CONFD_OK <NL> [ 1135.696588] confd_mgr[5876]: openDdsPorts interfaces  eth5.2003 <NL> [ 1135.726047] confd_mgr[5876]: openDdsPorts Input udpPorts-  7660 <NL> [ 1135.726783] confd_mgr[5876]: openDdsPorts Output udpPorts-  7660 <NL> [ 1136.179051] confd_mgr[5876]: openDdsPorts Input udpPorts-  7661 <NL> [ 1136.179839] confd_mgr[5876]: openDdsPorts Output udpPorts-  7661 <NL> [ 1136.180630] confd_mgr[5876]: openDdsPorts Input udpPorts-  7650 <NL> [ 1137.389391] confd_mgr[5876]: openDdsPorts Output udpPorts-  7650 <NL> [ 1137.807073] confd_mgr[5876]: openDdsPorts Input udpPorts-  7651 <NL> [ 1138.212651] confd_mgr[5876]: openDdsPorts Output udpPorts-  7651 <NL> [ 1138.564387] confd_mgr[5876]: openDdsPorts Input udpPorts-  7900 <NL> [ 1138.770284] confd_mgr[5876]: openDdsPorts Output udpPorts-  7900 <NL> [ 1139.060691] confd_mgr[5876]: openDdsPorts Input udpPorts-  7901 <NL> [ 1139.104824] confd_mgr[5876]: openDdsPorts Output udpPorts-  7901 <NL> [ 1139.106077] confd_mgr[5876]: openDdsPorts Input udpPorts-  7910 <NL> [ 1139.291663] confd_mgr[5876]: openDdsPorts Output udpPorts-  7910 <NL> [ 1139.745610] confd_mgr[5876]: openDdsPorts Input udpPorts-  7911 <NL> [ 1139.760304] confd_mgr[5876]: openDdsPorts Output udpPorts-  7911 <NL> [ 1140.229762] confd_mgr[5876]: openDdsPorts Input udpPorts-  8150 <NL> [ 1140.383395] confd_mgr[5876]: openDdsPorts Output udpPorts-  8150 <NL> [ 1140.410178] confd_mgr[5876]: openDdsPorts Input udpPorts-  8151 <NL> [ 1140.492196] confd_mgr[5876]: openDdsPorts Output udpPorts-  8151 <NL> [ 1140.494111] confd_mgr[5876]: openDdsPorts Input udpPorts-  8160 <NL> [ 1140.494881] confd_mgr[5876]: openDdsPorts Output udpPorts-  8160"}
{"timestamp_utc": "2024-07-31T08:31:56.509Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[ 1140.834168] confd_mgr[5876]: openDdsPorts Input udpPorts-  8161 <NL> [ 1140.835827] confd_mgr[5876]: openDdsPorts Output udpPorts-  8161 <NL> [ 1141.109613] ntp_alarm_event_monitor.py[5843]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [ 1141.184360] ntp_alarm_event_monitor.py[5843]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [ 1141.185533] ntp_alarm_event_monitor.py[5843]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [ 1141.213423] ntp_alarm_event_monitor.py[5843]: INFO:root:redundancy status now set to standalone <NL> [ 1141.416568] confd_mgr[5266]: TRACE Connected (ha) to ConfD <NL> [ 1141.446935] confd_mgr[5266]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [ 1141.543313] confd_mgr[5266]: replay_manager:  Start-Wed Jul 31 08:29:27 2024 <NL> [ 1141.951837] confd_mgr[5266]:  ++++++++++++++++++++++ <NL> [ 1142.183090] confd_mgr[5266]: replay_manager: TXID NOT FOUND ================================== <NL> [ 1142.458259] confd_mgr[5266]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [ 1142.460290] confd_mgr[5266]: replay_manager: Need to do trigger full replay. <NL> [ 1142.462420] confd_mgr[5266]: replay_manager: Creating the purge file. <NL> [ 1142.463233] confd_mgr[5266]: replay_manager: Open DDS Ports <NL> [ 1142.464695] confd_mgr[5266]: replay_manager: NOW deleting the purge file. <NL> [ 1142.466631] confd_mgr[5266]: replay_manager:  End-Wed Jul 31 08:31:48 2024 <NL> [ 1142.468858] confd_mgr[5266]:  ++++++++++++++++++++++"}
{"timestamp_utc": "2024-07-31T08:32:01.771Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:00 retry-ssh-command INFO: attempt 111, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:05.964Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:05 retry-ssh-command INFO: attempt 112, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:07.329Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[  272.287664] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.290661, delay 0.04782\\n31 Jul 08:17:26 ntpdate[2755]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:17:37,504 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  284.170400] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  284.170645] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  284.170752] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.301446, delay 0.03667\\n31 Jul 08:17:38 ntpdate[2784]: no server suitable for synchronization found\\n' <NL> [  296.050501] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  296.051872] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  296.052874] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.309089, delay 0.05597\\n31 Jul 08:17:50 ntpdate[2811]: no server suitable for synchronization found\\n' <NL> [  308.510230] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  308.536375] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  308.592440] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.297231, delay 0.02965\\n31 Jul 08:18:03 ntpdate[2849]: no server suitable for synchronization found\\n' <NL> [  320.538227] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  320.579845] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  320.580824] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.301964, delay 0.03770\\n31 Jul 08:18:15 ntpdate[2883]: no server suitable for synchronization found\\n' <NL> [  333.212430] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  333.214107] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  333.224168] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.305744, delay 0.04568\\n31 Jul 08:18:27 ntpdate[2916]: no server suitable for synchronization found\\n' <NL> [  345.592248] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  345.593063] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  345.616843] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.334817, delay 0.10811\\n31 Jul 08:18:40 ntpdate[2965]: no server suitable for synchronization found\\n' <NL> [  357.835054] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  357.855590] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  357.897262] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.312206, delay 0.06552\\n31 Jul 08:18:52 ntpdate[2997]: no server suitable for synchronization found\\n' <NL> [  369.707752] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  369.708618] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:32:07.330Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "step_id": "NE4-trib1-console", "message_content": "[  369.709594] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.298445, delay 0.03070\\n31 Jul 08:19:04 ntpdate[3056]: no server suitable for synchronization found\\n' <NL> [  381.656890] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  381.657802] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  381.658771] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.301969, delay 0.03963\\n31 Jul 08:19:16 ntpdate[3106]: no server suitable for synchronization found\\n' <NL> [  393.578390] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  393.579282] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  393.584338] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.308636, delay 0.05914\\n31 Jul 08:19:28 ntpdate[3145]: no server suitable for synchronization found\\n' <NL> [  405.751025] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  405.768688] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  405.797856] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.297640, delay 0.02907\\n31 Jul 08:19:40 ntpdate[3180]: no server suitable for synchronization found\\n' <NL> [  417.620205] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  417.622217] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  417.643767] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.297468, delay 0.03156\\n31 Jul 08:19:52 ntpdate[3214]: no server suitable for synchronization found\\n' <NL> [  430.621981] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  430.622194] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  430.622288] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.302896, delay 0.04503\\n31 Jul 08:20:05 ntpdate[3249]: no server suitable for synchronization found\\n' <NL> [  442.522930] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  442.523140] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  442.523220] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.302318, delay 0.03850\\n31 Jul 08:20:17 ntpdate[3292]: no server suitable for synchronization found\\n' <NL> [  454.412931] ntputils_client.py[1701]: INFO:root:command failed. <NL> [  454.413153] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  454.413237] ntputils_client.py[1701]: b'server 127.1.254.254, stratum 16, offset +0.296762, delay 0.02733\\n31 Jul 08:20:29 ntpdate[3343]: no server suitable for synchronization found\\n' <NL> [ 1126.848525] ntputils_client.py[1701]: INFO:root:command failed. <NL> [ 1126.849153] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1126.849236] ntputils_client.py[1701]: b'31 Jul 08:31:41 ntpdate[5524]: no server suitable for synchronization found\\n' <NL> [ 1135.369912] ntputils_client.py[1701]: INFO:root:command failed. <NL> [ 1135.370180] ntputils_client.py[1701]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [ 1135.370263] ntputils_client.py[1701]: b'31 Jul 08:31:50 ntpdate[5539]: no server suitable for synchronization found\\n' <NL> [ 1143.114730] ntputils_client.py[1701]: INFO:root:command failed. <NL> [ 1143.128570] ntputils_client.py[1701]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1143.150617] ntputils_client.py[1701]: b'31 Jul 08:31:58 ntpdate[5592]: no server suitable for synchronization found\\n' <NL> [ 1150.445440] confd_director.py[5648]: mkdir: cannot create directory '/var/shared/confd': File exists <NL> [ 1150.934743] confd_mgr[5652]: ConfdMgrConf: DB signature is NOT supported <NL> [ 1151.014469] confd_mgr[5652]: Read reset type failed basic_ios::clear: iostream error <NL> [ 1151.027594] confd_mgr[5652]: Use reset_type = NONE    rollback_timer = 000000 <NL> [ 1151.173309] confd_mgr[5652]: main:: Creating ResetType file. Writes NONE/000000 <NL> [ 1151.196628] confd_mgr[5652]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [ 1151.223044] confd_mgr[5660]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:32:06 UTC 2024 <NL> [ 1151.287072] confd_mgr[5660]: TRIB don't call callback script. <NL> [ 1151.308130] confd_mgr[5652]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [ 1151.310138] confd_mgr[5652]: entering: wait_for_alarm_event <NL> [ 1151.317589] confd_mgr[5652]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [ 1151.318537] confd_mgr[5652]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [ 1151.322689] confd_mgr[5652]: ha_sm entering: wait_for_SWDL_s 0 <NL> [ 1151.323521] confd_mgr[5652]: ha_sm : wait_for_SWDL_s timer is set <NL> [ 1151.342724] confd_mgr[5652]: CommAT::asio_subscriber: Connection accepted <NL> [ 1151.353419] confd_mgr[5652]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [ 1151.392176] confd_mgr[5652]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [ 1151.406901] confd_mgr[5652]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [ 1151.420402] confd_mgr[5652]: Creating ConfdAT startconfd SM, bank type = 2"}
{"timestamp_utc": "2024-07-31T08:32:10.601Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[  995.698651] systemd-sysv-generator[5905]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [ 1014.336347] confd_phase_sentry[2132]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [ 1014.467790] confd_phase_sentry[2132]: ConfdPhaseSentry: starting confd-ready.service <NL> [ 1015.690079] echo[5938]: Starting confd-ready <NL> [ 1016.699736] confd_mgr[2966]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [ 1016.793454] automater.sh[5941]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [ 1017.098386] confd_mgr[5967]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:29:53 UTC 2024 <NL> [ 1017.151426] netconfEventSyslog[5944]: EventSyslogDaemon: Trying to connect to Confd <NL> [ 1017.555402] snmp_trapd[5950]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [ 1018.898197] snmp_trapd[5950]: gen_util: DDS_P2MP not available <NL> [ 1022.481281] confd_mgr[6032]: Execute common_confd_nb_ready_cb.sh <NL> [ 1025.019583] confd_mgr[5967]: Invoking confd_nb_enable.py <NL> [ 1025.575941] confd_mgr[5322]: confd_mgr_cmd:: Reply is: Receive failed <NL> [ 1026.175904] confd_mgr[2966]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [ 1026.324901] confd_mgr[2966]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [ 1026.460061] confd_mgr[4755]: DDS Ports are opened <NL> [ 1036.913804] confd_mgr[6181]: openDdsPorts interfaces  eth5.2003 <NL> [ 1037.297138] confd_mgr[6181]: openDdsPorts Input udpPorts-  7660 <NL> [ 1038.553504] confd_mgr[6193]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1039.127701] confd_mgr[6181]: openDdsPorts Output udpPorts-  7660 <NL> [ 1039.378246] confd_mgr[6196]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1040.386836] confd_mgr[6181]: openDdsPorts Input udpPorts-  7661 <NL> [ 1041.238938] zero-touch-app[6224]: Another app is currently holding the xtables lock. Perhaps you want to use the -w option?"}
{"timestamp_utc": "2024-07-31T08:32:10.602Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "step_id": "NE3-main-console", "message_content": "[ 1042.567518] confd_mgr[6206]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1042.570927] confd_mgr[6181]: openDdsPorts Output udpPorts-  7661 <NL> [ 1043.072230] confd_mgr[6215]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1043.365253] confd_mgr[6181]: openDdsPorts Input udpPorts-  7650 <NL> [ 1043.535808] confd_mgr[6216]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1044.037817] confd_mgr[6181]: openDdsPorts Output udpPorts-  7650 <NL> [ 1044.687289] confd_mgr[6220]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1045.756058] confd_mgr[6181]: openDdsPorts Input udpPorts-  7651 <NL> [ 1046.070343] confd_mgr[6226]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1047.453769] confd_mgr[6181]: openDdsPorts Output udpPorts-  7651 <NL> [ 1048.954382] confd_mgr[6229]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1049.685853] confd_mgr[6181]: openDdsPorts Input udpPorts-  7900 <NL> [ 1049.991425] confd_mgr[6236]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1050.331518] confd_mgr[6181]: openDdsPorts Output udpPorts-  7900 <NL> [ 1050.362202] confd_mgr[6238]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1050.469319] confd_mgr[6181]: openDdsPorts Input udpPorts-  7901 <NL> [ 1050.500139] confd_mgr[6246]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1050.524825] confd_mgr[6181]: openDdsPorts Output udpPorts-  7901 <NL> [ 1050.526470] confd_mgr[6252]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1050.917410] confd_mgr[6181]: openDdsPorts Input udpPorts-  7910 <NL> [ 1051.011382] confd_mgr[6254]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1052.172030] confd_mgr[6181]: openDdsPorts Output udpPorts-  7910 <NL> [ 1052.392539] confd_mgr[6261]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1052.723065] confd_mgr[6181]: openDdsPorts Input udpPorts-  7911 <NL> [ 1053.139837] confd_mgr[6263]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1053.942077] confd_mgr[6181]: openDdsPorts Output udpPorts-  7911 <NL> [ 1054.242909] confd_mgr[6264]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1054.878665] confd_mgr[6181]: openDdsPorts Input udpPorts-  8150 <NL> [ 1055.800638] confd_mgr[6265]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1058.045212] confd_mgr[6181]: openDdsPorts Output udpPorts-  8150 <NL> [ 1058.503656] confd_mgr[6266]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1058.504767] confd_mgr[6181]: openDdsPorts Input udpPorts-  8151 <NL> [ 1058.505706] confd_mgr[6271]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1058.728811] confd_mgr[6181]: openDdsPorts Output udpPorts-  8151 <NL> [ 1058.734383] confd_mgr[6273]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1058.738324] confd_mgr[6181]: openDdsPorts Input udpPorts-  8160 <NL> [ 1058.772394] confd_mgr[6274]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1058.853838] confd_mgr[6181]: openDdsPorts Output udpPorts-  8160 <NL> [ 1059.091406] confd_mgr[6275]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1059.300975] confd_mgr[6181]: openDdsPorts Input udpPorts-  8161 <NL> [ 1059.596986] confd_mgr[6279]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1059.989840] confd_mgr[6181]: openDdsPorts Output udpPorts-  8161 <NL> [ 1060.358226] confd_mgr[6286]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [ 1062.577674] confd_mgr[6069]: nb_enable.py: INFO: Start <NL> [ 1063.136473] confd_mgr[6069]: Running \"systemctl stop netconf_socket_change.path\" <NL> [ 1063.143480] confd_mgr[6069]: Running \"systemctl stop cli_socket_change.path\" <NL> [ 1063.177474] confd_mgr[6069]: Running \"iptables -w -F chain-incoming-northbound\" <NL> [ 1063.180392] confd_mgr[6069]: Running \"iptables -w -D INPUT -p tcp -j chain-incoming-northbound\" <NL> [ 1063.185031] confd_mgr[6069]: Running \"iptables -w -X chain-incoming-northbound\" <NL> [ 1066.166073] confd_mgr[5967]: Exiting confd_nb_ready_cb.sh - Wed Jul 31 08:30:43 UTC 2024 <NL> [ 1068.220403] confd_mgr[2966]: Sending Startup notif <NL> [ 1087.944523] confd_mgr[6320]:  DB Notif Gen <NL> [ 1093.119131] confd_mgr[2966]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [ 1093.816144] confd_mgr[2966]: leaving: sm_startconfd::start_confd_p2. <NL> [ 1109.566624] confd_mgr[6575]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [ 1141.791925] netconfEventSyslog[5944]: EventSyslogDaemon Waiting for event notifications... <NL> [ 1146.075831] confd_mgr[6575]: ==================== saving database ================== <NL> [ 1146.392711] confd_mgr[6704]: A.cdb <NL> [ 1146.543121] confd_mgr[6704]: A.cdb.sig <NL> [ 1146.555458] confd_mgr[6704]: C.cdb <NL> [ 1151.512989] confd_mgr[6704]: C.cdb.sig <NL> [ 1151.570071] confd_mgr[6704]: DefTxId <NL> [ 1151.712712] confd_mgr[6704]: O.cdb <NL> [ 1151.713315] confd_mgr[6704]: compact.lock <NL> [ 1151.713870] confd_mgr[6704]: dbmgmtdata.conf <NL> [ 1151.714467] confd_mgr[6704]: replay.cdb <NL> [ 1151.783582] confd_mgr[6704]: schema.sig <NL> [ 1151.978084] confd_mgr[2966]: entering: sm_startconfd::exit_to_ready <NL> [ 1151.979281] confd_mgr[2966]: leaving: sm_startconfd::exit_to_ready <NL> [ 1151.999438] confd_mgr[2966]: action at_sm_dbready::do_db_ready_a <NL> [ 1152.001770] confd_mgr[2966]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME <NL> [ 1152.002830] confd_mgr[2966]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME not defined. <NL> [ 1152.080146] confd_mgr[2966]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/recipe-sysroot/usr/include/boost/property_tree/detail/ptree_implementation.hpp(576): Throw in function boost::property_tree::basic_ptree<K, D, C>& boost::property_tree::basic_ptree<Key, Data, KeyCompare>::get_child(const path_type&) [with Key = std::__cxx11::basic_string<char>; Data = std::__cxx11::basic_string<char>; KeyCompare = std::less<std::__cxx11::basic_string<char> >; boost::property_tree::basic_ptree<Key, Data, KeyCompare>::path_type = boost::property_tree::string_path<std::__cxx11::basic_string<char>, boost::property_tree::id_translator<std::__cxx11::basic_string<char> > >]"}
{"timestamp_utc": "2024-07-31T08:32:11.165Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:32:13.061Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:12 retry-ssh-command INFO: attempt 113, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:18.309Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:17 retry-ssh-command INFO: attempt 114, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:23.561Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:22 retry-ssh-command INFO: attempt 115, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:24.928Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[ 1142.469919] confd_mgr[5266]: 1+1 Mode <NL> [ 1142.479900] confd_mgr[5266]: Not in Slave Mode - Ready for Phase 2 ========== <NL> [ 1142.486151] confd_mgr[5266]: DipLog_pimpl destructor called <NL> [ 1142.486910] confd_mgr[5266]: DipVerbosity Listener ZMQ error <NL> [ 1142.494928] confd_mgr[5266]:     ret='Context was terminated <NL> [ 1142.498279] confd_mgr[5266]: deleting subscriber_ socket <NL> [ 1142.502856] confd_mgr[5266]: Exiting verb listener <NL> [ 1142.509605] ntp_alarm_event_monitor.py[5912]: ntpq: read: Connection refused <NL> [ 1142.724528] confd_mgr[3039]: CommAT::asio_subscriber: Connection accepted <NL> [ 1143.062857] confd_mgr[3039]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [ 1143.481173] confd_mgr[3039]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [ 1143.586749] confd_mgr[3039]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1143.676575] confd_mgr[3039]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1143.971942] confd_mgr[3039]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1144.201412] confd_mgr[3039]: ConfdHA Not supported command CONFIRM <NL> [ 1144.202424] confd_mgr[3039]: sm_startconfd::rm_ready <NL> [ 1144.203099] confd_mgr[3039]: leaving: sm_startconfd::wait_for_rm <NL> [ 1144.208828] confd_mgr[3039]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [ 1144.210262] confd_mgr[3039]: entering: sm_startconfd::start_confd_p2 <NL> [ 1144.224272] confd_mgr[3039]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [ 1144.585997] ntp_alarm_event_monitor.py[5843]: INFO:root:Publish Alarm: Raising alarm <NL> [ 1144.853815] ntp_alarm_event_monitor.py[5843]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [ 1146.236759] confd_mgr[5933]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:31:50 UTC 2024 <NL> [ 1146.848058] confd_mgr[5944]: cmnEvtXML has stopped <NL> [ 1146.849697] confd_mgr[5944]: start event-handler.service <NL> [ 1146.851956] confd_mgr[5952]: condition_name: systemRestart <NL> [ 1147.504119] confd_mgr[5952]: entity_type: COM <NL> [ 1147.756750] confd_mgr[5952]: num_instances: 1 <NL> [ 1148.590414] confd_mgr[5952]: num_samples: 1 <NL> [ 1148.769600] confd_mgr[5952]:  EventNotification does not have condition_group. Skipping."}
{"timestamp_utc": "2024-07-31T08:32:24.929Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "step_id": "NE4-main-console", "message_content": "[ 1149.086080] confd_mgr[5952]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [ 1149.240588] confd_mgr[5952]: CmnEvtPublisher::main: returning <NL> [ 1149.320336] confd_mgr[5944]: /usr/bin/confd_mgr_in_spm.sh <NL> [ 1149.385962] confd_mgr[5944]: /usr/bin/ui_sys_reset.py NONE <NL> [ 1151.210338] cia_control_layer[2127]:    ChalApi Constructor with tid = 2744 <NL> [ 1151.229431] cia_control_layer[2127]: EsalConfig::EsalConfig main 1 <NL> [ 1151.406734] cia_control_layer[2127]: EsalConfig::EsalConfig trib 0 <NL> [ 1151.577477] cia_control_layer[2127]: EsalConfig::EsalConfig ciRole 0 <NL> [ 1151.721572] cia_control_layer[2127]: EsalConfig is not running inside container. <NL> [ 1151.837510] cia_control_layer[2127]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1152.180458] cia_control_layer[2127]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1152.396763] cia_control_layer[2127]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1152.697248] cia_control_layer[2127]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1152.953107] cia_control_layer[2127]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [ 1153.144071] cia_control_layer[2127]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [ 1153.244843] cia_control_layer[2127]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [ 1153.365867] cia_control_layer[2127]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [ 1153.419391] cia_control_layer[2127]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [ 1153.477673] cia_control_layer[2127]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [ 1153.508095] cia_control_layer[2127]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [ 1153.531558] cia_control_layer[2127]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [ 1153.579302] cia_control_layer[2127]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [ 1153.602503] cia_control_layer[2127]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [ 1153.624653] cia_control_layer[2127]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [ 1153.645732] cia_control_layer[2127]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [ 1153.672374] cia_control_layer[2127]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [ 1153.709648] confd_mgr[6056]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1153.766122] confd_mgr[6056]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1153.873693] confd_mgr[6057]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1153.961403] confd_mgr[6057]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1154.121907] confd_mgr[6058]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1154.146111] confd_mgr[6058]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1154.530171] confd_mgr[5990]: DDS Peristency is enabled <NL> [ 1154.653419] confd_mgr[5990]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [ 1154.664405] confd_mgr[5990]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [ 1154.993156] confd_mgr[5990]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [ 1154.994141] confd_mgr[5990]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [ 1155.094504] confd_mgr[6060]: Execute check_db_status.sh <NL> [ 1155.220261] confd_mgr[6060]: NE is running a default database! <NL> [ 1160.604767] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1164.338446] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [ 1166.260320] ntputils[1710]: child pid is 6087 <NL> [ 1166.663154] confd_mgr[5933]: Starting valhdlr.service if not started already <NL> [ 1167.154332] confd_mgr[5933]: Starting validation-handler.service if not started already <NL> [ 1168.221615] ntputils[1710]: exited, status is 0 <NL> [ 1168.222360] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1168.309456] ntputils[1710]: poller time change delta is: 2 <NL> [ 1168.318906] ntputils[1710]: push_local_changes user_changed: 0 delta: 2 <NL> [ 1168.656386] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1168.667980] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [ 1168.675292] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [ 1168.676488] ntputils[1710]: push_local_changes OK <NL> [ 1168.718884] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1168.822357] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [ 1168.961668] ntputils[1710]: child pid is 6108 <NL> [ 1169.016718] ntputils[1710]: exited, status is 0 <NL> [ 1169.959059] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1170.023336] ntputils[1710]: poller time change delta is: 5 <NL> [ 1170.280941] ntputils[1710]: push_local_changes user_changed: 0 delta: 5 <NL> [ 1170.436472] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1170.437364] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [ 1170.438688] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [ 1170.466163] ntputils[1710]: push_local_changes OK <NL> [ 1170.466868] ntputils[1710]: NTPServer::execute_cmd spawning: <NL> [ 1170.505986] ntputils[1710]: /sbin/hwclock -u --systohc <NL> [ 1170.506716] ntputils[1710]: child pid is 6121 <NL> [ 1170.564259] ntputils[1710]: exited, status is 0 <NL> [ 1170.564943] ntputils[1710]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1170.565856] ntputils[1710]: poller time change delta is: 1 <NL> [ 1170.792562] ntputils[1710]: push_local_changes user_changed: 0 delta: 1 <NL> [ 1170.894994] ntputils[1710]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1170.895943] ntputils[1710]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1170.977660] ntputils[1710]: local_push OK w Platform::Time 0 0 <NL> [ 1170.978441] ntputils[1710]: push_local_changes OK <NL> [ 1170.998850] confd_mgr[5933]: Starting snmp-fss-fw.service if not started already"}
{"timestamp_utc": "2024-07-31T08:32:28.215Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:32:28.776Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:28 retry-ssh-command INFO: attempt 116, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:34.019Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:33 retry-ssh-command INFO: attempt 117, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:39.268Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:38 retry-ssh-command INFO: attempt 118, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:44.512Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:43 retry-ssh-command INFO: attempt 119, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:49.765Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:48 retry-ssh-command INFO: attempt 120, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:53.929Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:53 retry-ssh-command INFO: attempt 121, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:59.175Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:32:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:58 retry-ssh-command INFO: attempt 122, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:33:04.433Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:33:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:33:03 retry-ssh-command INFO: attempt 123, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:33:09.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:33:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:33:08 retry-ssh-command INFO: attempt 124, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:33:13.854Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "step_id": "s01.p07.s02.NE4-main-cli", "message_content": "# 03:33:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37213, username 'fujitsu', password '1finity', key_filename None <NL> # 03:33:13 retry-ssh-command INFO: attempt 125, sleep 5: \"rtxoialp79:37213\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:33:14.783Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:14 exec-job-tree INFO: process_list_cl::wait: queue EMPTY <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: TIMEOUT: check who timed out <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: TIMEOUT: timeout job tree \"n01.p09.s01.startup (p)\" <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p01.main-startup (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p03.main-startup (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p05.main-startup (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (executing) type \"command\": timeout (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (executing) type \"serial\": timeout (n01.p09.s01.p07.main-startup (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 3)        (executing) type \"parallel\": timeout (n01.p09.s01.startup (p)) <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p09.s01.p07.s02.NE4-main-cli\": send signal Signals.SIGTERM to process group 3723 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\": process 3723 terminated with exitcode -15 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\": process 3723 terminated with exitcode -15 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code -15 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": aborting because child #1 was terminated (n01.p09.s01.p07.main-startup (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p07.main-startup (s))"}
{"timestamp_utc": "2024-07-31T08:33:14.784Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:14 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #6 finished with exit_code 1, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 3)        (finished) type \"parallel\": finished (n01.p09.s01.startup (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (executing) type \"serial\": child #0 finished with exit_code 1 (n01.p09.start+user (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (executing) type \"serial\": aborting because child #0 was terminated (n01.p09.start+user (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"serial\": finished (n01.p09.start+user (s)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #8 finished with exit_code 1, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 8 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p01.NE1-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p02.NE1-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.s02.NE4-main-cli\", exit_code -15 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.main-startup (s)\", exit_code 1 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.startup (p)\", exit_code 1 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.start+user (s)\", exit_code 1 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p01.NE1-main-console\": send signal Signals.SIGKILL to process group 3321 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p02.NE1-trib1-console\": send signal Signals.SIGKILL to process group 3322 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": send signal Signals.SIGKILL to process group 3323 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": send signal Signals.SIGKILL to process group 3324 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": send signal Signals.SIGKILL to process group 3325 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": send signal Signals.SIGKILL to process group 3326 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": send signal Signals.SIGKILL to process group 3327 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": send signal Signals.SIGKILL to process group 3328 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3321 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3322 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3323 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3325 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p01.NE1-main-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p02.NE1-trib1-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p02.NE1-trib1-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3322 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p02.NE1-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #1 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 7 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p01.NE1-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p02.NE1-trib1-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p01.NE1-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3321 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3323 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3325 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p05.NE3-main-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p08.NE4-trib1-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p03.NE2-main-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p05.NE3-main-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3325 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p05.NE3-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #4 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 6 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p01.NE1-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p05.NE3-main-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p01.NE1-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3321 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3323 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p01.NE1-main-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3321 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p01.NE1-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #0 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 5 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console)"}
{"timestamp_utc": "2024-07-31T08:33:14.785Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p01.NE1-main-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3323 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p04.NE2-trib1-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p03.NE2-main-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3323 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p03.NE2-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #2 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 4 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p03.NE2-main-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p07.NE4-main-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p07.NE4-main-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p07.NE4-main-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #6 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 3 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p07.NE4-main-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p04.NE2-trib1-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p04.NE2-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #3 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 2 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p04.NE2-trib1-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p06.NE3-trib1-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p06.NE3-trib1-console\", type \"stderr\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p06.NE3-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #5 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 1 running children to be terminated (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p06.NE3-trib1-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: name \"n01.p08.NE4-trib1-console\", type \"stdout\": DONE <NL> # 03:33:14 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p08.NE4-trib1-console) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #7 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 1)    (finished) type \"parallel\": finished (n01.all (p)) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 0)  (executing) type \"none\": child #0 finished with exit_code 1 (none) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 0)  (executing) type \"none\": aborting because child #0 did not pass (none) <NL> # 03:33:14 exec-job-tree INFO: job_cl::finish: ( 0)  (finished) type \"none\": finished (none) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p08.NE4-trib1-console\", exit_code 0 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.all (p)\", exit_code 1 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"none\", exit_code 1 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: start_time 1722413595.0236914 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait:   end_time 1722414794.541533 <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::wait: done, job(s) ran for 1199.51784157753 second(s) <NL> # 03:33:14 exec-job-tree INFO: process_list_cl::__exit__: exc_type \"None\" <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  Begin           End             Job Name                                ECode Flags                     Notes <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p01.NE1-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p02.NE1-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p03.NE2-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p04.NE2-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p05.NE3-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p06.NE3-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p07.NE4-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p08.NE4-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.031358 n01.p09.s01.p01.s01.NE1-main-debug-ssh      0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031358 20240731.032239 n01.p09.s01.p01.s02.NE1-main-cli            0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.032239 n01.p09.s01.p01.main-startup (s)            0 passed                    all children finished <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.031332 n01.p09.s01.p02.NE1-trib1-debug-ssh         0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.031337 n01.p09.s01.p03.s01.NE2-main-debug-ssh      0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031337 20240731.032250 n01.p09.s01.p03.s02.NE2-main-cli            0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.032250 n01.p09.s01.p03.main-startup (s)            0 passed                    all children finished <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.031327 n01.p09.s01.p04.NE2-trib1-debug-ssh         0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.032010 n01.p09.s01.p05.s01.NE3-main-debug-ssh      0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.032010 20240731.033059 n01.p09.s01.p05.s02.NE3-main-cli            0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033059 n01.p09.s01.p05.main-startup (s)            0 passed                    all children finished <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.031338 n01.p09.s01.p06.NE3-trib1-debug-ssh         0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.032247 n01.p09.s01.p07.s01.NE4-main-debug-ssh      0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.032247 20240731.033314 n01.p09.s01.p07.s02.NE4-main-cli          -15 FAILED,timeout,terminated None"}
{"timestamp_utc": "2024-07-31T08:33:14.786Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "step_id": "NE1-main-console", "message_content": "# 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p09.s01.p07.main-startup (s)            1 FAILED,timeout,terminated all children finished <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.031332 n01.p09.s01.p08.NE4-trib1-debug-ssh         0 passed                    None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p09.s01.startup (p)                     1 FAILED,timeout,terminated all children finished <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  None            None            n01.p09.s02.Warrior                      None unexecuted                None <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.p09.start+user (s)                      1 FAILED                    all children finished <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 n01.all (p)                                 1 FAILED                    all children finished <NL> # 03:33:14 exec-job-tree INFO: summary_cl::show:  20240731.031314 20240731.033314 none                                        1 FAILED                    all children finished <NL> # 03:33:14 exec-job-tree INFO: main: result 1 <NL> [  649.624673] python3[3929]: DEBUG Bad path </eqpt/shelf20240731.033314 stdout:n01.p02.NE1-trib1-console # [  776.001053]20240731.033314 stdout:n01.p05.NE3-main-console # [ 1152.156133] confd_mgr[2966]: Dyn20240731.033314 stdout:n01.p03.NE2-main-console # [  596.944063] confd_mgr[527220240731.033314 stdout:n01.p04.NE2-trib1-console # [  813.092506] ntpu20240731.033314 stdout:n01.p07.NE4-main-console # [ 1171.095618] ntputils[1710]: NTPServer::execute_cmd spawnin20240731.033314 stdout:n01.p06.NE3-trib1-console # [  970.387036] ntputils_client.py[1753]20240731.033314 stdout:n01.p08.NE4-trib1-console # [ 115pip3-virtualenv-install-and-execute-cmd: ERROR: failed executing: \"exec-job-tree\" \"--timeout\" \"28800\" \"--job-begin-parallel\" \"--name\" \"all (p)\" \"--job-begin-command\" \"--name\" \"NE1-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37315\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37286\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37283\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37253\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37249\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37221\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37217\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37194\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"start+user (s)\" \"--parallel-siblings-terminate-on-my-completion\" \"--job-begin-parallel\" \"--name\" \"startup (p)\" \"--timeout\" \"1200\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE1-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37313\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37311\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37285\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE2-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37281\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37279\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37251\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE3-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37247\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37245\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37219\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE4-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37215\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37213\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37193\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"Warrior\" \"--cmd-begin\" \"run_init\" \"--runinit_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\" \"--services_env\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\" \"--work_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\" \"-v\" \"-e\" \"warrior\" \"--test_engine_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\" \"--test_engine\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-end\" <NL> pip3-virtualenv-install-and-execute-cmd: removing VIRTUALENV_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\" <NL> pip3-virtualenv-install-and-execute-cmd: done \"1\" <NL> # 03:33:14 ntp-wait-for-devices INFO: main: result 1 <NL> # 03:33:14 tfwk-exec-test-agent INFO: main: caught exception CalledProcessError(1, ['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json', '--cmd-end', '--job-end']) <NL> # 03:33:14 tfwk-exec-test-agent INFO: main: finally block: caught_exception_flag True <NL> # 03:33:14 tfwk-exec-test-agent INFO: main: args_obj.teardown_topology_action 'teardown-always' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main: teardown_topology_flag True <NL> # 03:33:14 tfwk-exec-test-agent INFO: main: - current exec status info: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   topology_active_flag=True <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   topology_state='running' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   topology info for work dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148': <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     topology_tag_name: ['DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1'] <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     topology_pre_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json'] <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     topology_post_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json'] <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:main' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:trib1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:main' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:33:14.787Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:trib1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:main' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:trib1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:main' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:trib1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:14 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:14 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-teardown', '-v', '-v', '--ntp-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--no-backup-shared-store'] <NL> # 03:33:14 ntp-topology-teardown INFO: args: { <NL> \"backup_shared_store_flag\": false, <NL> \"ntp_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"shared_store_backup_fname\": null, <NL> \"show_container_logs_flag\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:33:14 ntp-topology-teardown INFO: main: ===== ===== starting cleanup ===== ===== <NL> # 03:33:14 ntp-topology-teardown INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json', '--action', 'delete']"}
{"timestamp_utc": "2024-07-31T08:33:15.043Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:14 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace' <NL> # 03:33:14 ntp-topology INFO: main: starting action 'delete'"}
{"timestamp_utc": "2024-07-31T08:33:15.604Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:15 ntp-topology INFO: terminate_containers_command: - terminating container main command processes: <NL> # 03:33:15 ntp-topology INFO: get_container_env_exec_command: network_topology_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology <NL> # 03:33:15 ntp-topology INFO: exec_cmd: ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/preStop.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/preStop.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-delete']"}
{"timestamp_utc": "2024-07-31T08:33:16.165Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:16 ntp-topology INFO: wait_for_containers_command_status: - waiting max 300s for container_logs_command_status_fname files: <NL> # 03:33:16 ntp-topology INFO: wait_for_containers_command_status:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json' <NL> # 03:33:16 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:16 ntp-topology INFO: wait_for_containers_command_status: 0.000s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:17.093Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:17 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:17 ntp-topology INFO: wait_for_containers_command_status: 1.001s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:18.458Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:18 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:18 ntp-topology INFO: wait_for_containers_command_status: 2.002s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:19.386Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:19 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:19 ntp-topology INFO: wait_for_containers_command_status: 3.003s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:20.312Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:20 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:20 ntp-topology INFO: wait_for_containers_command_status: 4.004s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:21.240Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:21 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:21 ntp-topology INFO: wait_for_containers_command_status: 5.005s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:22.171Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:22 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:22 ntp-topology INFO: wait_for_containers_command_status: 6.006s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:23.098Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:23 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:23 ntp-topology INFO: wait_for_containers_command_status: 7.007s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:24.465Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:24 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:24 ntp-topology INFO: wait_for_containers_command_status: 8.008s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:25.394Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:25 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:25 ntp-topology INFO: wait_for_containers_command_status: 9.009s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:26.323Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:26 ntp-topology INFO: wait_for_containers_command_status: status for fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/command.status.json': { <NL> \"exit_code\": 0 <NL> } <NL> # 03:33:26 ntp-topology INFO: wait_for_containers_preStop_status: - waiting max 300s for container_logs_preStop_status_fname files: <NL> # 03:33:26 ntp-topology INFO: wait_for_containers_preStop_status:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-logs/topology-group-device-group-type-qemu-01/preStop.status.json' <NL> # 03:33:26 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'ps', '--all', '--no-trunc', '--format', '{{.ID}}:{{.Names}}'] <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05:hopeful_mirzakhani <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52:quirky_brattain <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d:nervous_cori <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c:condescending_boyd <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 863fc4d8d70d1b4a5e62454a9919f7317f5d7175c2c3517f800f3e37fd56a835:compassionate_visvesvaraya <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 8be8c7226a5e37253ed43fb6b7b1ca034b5ca9e3ed21264949690f6e22a4e67c:jolly_gates <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 53d787c99a720d29084736a373fd3706e6d0080365fb6e1567ac579b5a1c0b3d:quirky_wright <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 622e1549ca3da2607b8815f2439aef62f990b54e26175a7ea64f2aec41713834:brave_visvesvaraya <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: e1996a6295107b4c0a5a89b97a2300526fb626b49dc3144d44de907a48b07178:quirky_thompson <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 14ae89e97f81d955829ac15b5cf9490d85dd0aedfa62ef12a05608186e6d2e0d:compassionate_lichterman <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 878f7152b281d9161916121152f9852a8a98b010613ee61acfbc45fb72a84d3a:unruffled_wozniak <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 4f8730fb77ce966611338a23f89060641f596bd660fe734e1b51325082944545:pensive_sinoussi <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: ad49f325d562b63b05603399bfab4d4b23fc6d3606d9b419e6c18b8419945a5b:elegant_galileo <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: f0015dc6171f611684f9cbc599a7f95d8bb1958f38b5cf1dbf7eab1c3ba40b20:dazzling_varahamihira <NL> # 03:33:26 ntp-topology INFO: delete_single_docker_container: docker_container_name quirky_brattain <NL> # 03:33:26 ntp-topology INFO: delete_single_docker_container: docker_container_id 13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52 <NL> # 03:33:26 ntp-topology INFO: delete_single_docker_container: delete Docker container \"13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52(quirky_brattain)\" (delete an existing container) <NL> # 03:33:26 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'stop', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52']"}
{"timestamp_utc": "2024-07-31T08:33:32.857Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:32 ntp-topology INFO: docker_command: stdout: 13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52 <NL> # 03:33:32 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'rm', '--force', '13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52']"}
{"timestamp_utc": "2024-07-31T08:33:33.422Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:33 ntp-topology INFO: docker_command: stdout: 13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52 <NL> # 03:33:33 ntp-topology INFO: handle_delete_phase_1: show_container_logs_setting 'on-error-only' <NL> # 03:33:33 ntp-topology INFO: main: completed action 'delete' <NL> # 03:33:33 ntp-topology INFO: done <NL> # 03:33:33 ntp-topology-teardown INFO: main: removing container_workspace_basedir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace' <NL> # 03:33:33 ntp-topology-teardown INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01/container-workspace']"}
{"timestamp_utc": "2024-07-31T08:33:35.339Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:35 ntp-topology-teardown INFO: main: removing shared_store_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01' <NL> # 03:33:35 ntp-topology-teardown INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.957366c1c358416bb5fd33c0fa3f1e01'] <NL> # 03:33:35 ntp-topology-teardown INFO: main: ===== ===== done cleanup ===== ===== <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 4635, in <module> <NL> main(args_obj=args_obj) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 1329, in main <NL> exec_cmd(command) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 40, in exec_cmd <NL> raise subprocess.CalledProcessError(result, command) <NL> subprocess.CalledProcessError: Command '['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json', '--cmd-end', '--job-end']' returned non-zero exit status 1. <NL> ci-job-info: job returned result \"1\" <NL> ci-job-info: end_job: 1"}
{"timestamp_utc": "2024-07-31T08:33:35.601Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: end_artifact_job: ----- ----- ----- ----- ----- <NL> ci-job-info: end_artifact_job: 20240731.033335: ending job with status \"FAILED\" <NL> ci-job-info: end_artifact_job: saving ci-data directory \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/ci-data\" into \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44.ci-data\" <NL> ./ <NL> ./gitscm-info.json <NL> ./manifest.json <NL> ./project-info-recipe-repo.json <NL> ./project-info-complete.json"}
{"timestamp_utc": "2024-07-31T08:33:42.173Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info.json <NL> ./project-info-extended.json"}
{"timestamp_utc": "2024-07-31T08:33:42.433Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info-status.json <NL> ./data.json <NL> end_job: Wed Jul 31 03:33:42 CDT 2024 <NL> ci-job-info: ended on Wed Jul 31 03:33:42 CDT 2024 <NL> ci-get-archive-artifacts: failed executing command:  \"ci-job-info\" \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml\" <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 107, in <module> <NL> main(args=arg_dict) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 68, in main <NL> subprocess.run(command_list, check=True) <NL> File \"/usr/lib64/python3.6/subprocess.py\", line 438, in run <NL> output=stdout, stderr=stderr) <NL> subprocess.CalledProcessError: Command '['ci-get-archive-artifacts', '--project-info-basename', 'project-info.json', '--project-info-extended-basename', 'project-info-extended.json', '--', 'ci-job-info', 'ci-project-sanity-tfwk', '--', '--testcases-project-name', 'fss3', '--', '--test-engine', 'Warrior', '--topology-tag-name', 'DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1', '--define-attr-defaults', 'machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute', '--define-instance-attr', 'NE1/main', 'shelf-num=1', '--define-instance-attr', 'NE1/main', 'image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2', '--define-instance-attr', 'NE1/trib1', 'shelf-num=2', '--define-instance-attr', 'NE1/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE2/main', 'shelf-num=1', '--define-instance-attr', 'NE2/main', 'image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2', '--define-instance-attr', 'NE2/trib1', 'shelf-num=2', '--define-instance-attr', 'NE2/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE3/main', 'shelf-num=200', '--define-instance-attr', 'NE3/main', 'image-name=fss-aggr-image-validation-T,image-info-config-name=main', '--define-instance-attr', 'NE3/trib1', 'shelf-num=1', '--define-instance-attr', 'NE3/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE4/main', 'shelf-num=200', '--define-instance-attr', 'NE4/main', 'image-name=fss-aggr-image-validation-T,image-info-config-name=main', '--define-instance-attr', 'NE4/trib1', 'shelf-num=1', '--define-instance-attr', 'NE4/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--add-instance', 'NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1', '--device-wait-startup-timeout', '1200', '--test-engine-begin', '--no_logger', '--test-engine-end', '--', 'warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat44.xml']' returned non-zero exit status 1. <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 107, in <module> <NL> main(args=arg_dict) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 68, in main <NL> subprocess.run(command_list, check=True) <NL> File \"/usr/lib64/python3.6/subprocess.py\", line 438, in run <NL> output=stdout, stderr=stderr) <NL> subprocess.CalledProcessError: Command '['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/continuous-integration/continuous-integration-common/bin/ci-setup-and-execute', 'ci-execute-json-command-list', '--command-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/jenkins-job-command-list.json']' returned non-zero exit status 1."}
{"timestamp_utc": "2024-07-31T08:33:42.441Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:33:42.453Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:33:42.730Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker stop ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c"}
{"timestamp_utc": "2024-07-31T08:33:44.104Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c <NL> + docker rm -f --volumes ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c"}
{"timestamp_utc": "2024-07-31T08:33:44.360Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c"}
{"timestamp_utc": "2024-07-31T08:33:44.365Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.371Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:33:44.378Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.387Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:33:44.396Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> pipeline_execute: Execute stage: catch section of try block: currentBuild.result 'SUCCESS' <NL> pipeline_execute: Execute stage: catch section of try block: exception: hudson.AbortException: script returned exit code 1 <NL> [Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.403Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:33:44.410Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage <NL> [Pipeline] { (Cleanup)"}
{"timestamp_utc": "2024-07-31T08:33:44.417Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:33:44.424Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:33:44.694Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +x <NL> ci-job-post-build-cleanup: ----- /bin/docker ps -a <NL> CONTAINER ID        IMAGE                                                    COMMAND                  CREATED             STATUS              PORTS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                NAMES <NL> 863fc4d8d70d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago   Up About an hour    22/tcp, 0.0.0.0:37051->5000/tcp, 0.0.0.0:37050->5001/tcp, 0.0.0.0:37049->5002/tcp, 0.0.0.0:37048->5003/tcp, 0.0.0.0:37047->5004/tcp, 0.0.0.0:37046->5005/tcp, 0.0.0.0:37045->5006/tcp, 0.0.0.0:37044->5007/tcp, 0.0.0.0:37043->5008/tcp, 0.0.0.0:37042->5009/tcp, 0.0.0.0:37041->5010/tcp, 0.0.0.0:37040->5011/tcp, 0.0.0.0:37039->5012/tcp, 0.0.0.0:37038->5013/tcp, 0.0.0.0:37037->5014/tcp, 0.0.0.0:37036->5015/tcp, 0.0.0.0:37035->5016/tcp, 0.0.0.0:37034->5017/tcp, 0.0.0.0:37033->5018/tcp, 0.0.0.0:37032->5019/tcp, 0.0.0.0:37031->5020/tcp, 0.0.0.0:37030->5021/tcp, 0.0.0.0:37029->5022/tcp, 0.0.0.0:37028->5023/tcp, 0.0.0.0:37027->5024/tcp, 0.0.0.0:37026->5025/tcp, 0.0.0.0:37025->5026/tcp, 0.0.0.0:37024->5027/tcp, 0.0.0.0:37023->5028/tcp, 0.0.0.0:37022->5029/tcp, 0.0.0.0:37021->5030/tcp, 0.0.0.0:37020->5031/tcp, 0.0.0.0:37019->5032/tcp, 0.0.0.0:37018->5033/tcp, 0.0.0.0:37017->5034/tcp, 0.0.0.0:37016->5035/tcp, 0.0.0.0:37015->5036/tcp, 0.0.0.0:37014->5037/tcp, 0.0.0.0:37013->5038/tcp, 0.0.0.0:37012->5039/tcp, 0.0.0.0:37011->5040/tcp, 0.0.0.0:37010->5041/tcp, 0.0.0.0:37009->5042/tcp, 0.0.0.0:37008->5043/tcp, 0.0.0.0:37007->5044/tcp, 0.0.0.0:37006->5045/tcp, 0.0.0.0:37005->5046/tcp, 0.0.0.0:37004->5047/tcp, 0.0.0.0:37003->5048/tcp, 0.0.0.0:37002->5049/tcp, 0.0.0.0:37001->5050/tcp, 0.0.0.0:37000->5051/tcp, 0.0.0.0:36999->5052/tcp, 0.0.0.0:36998->5053/tcp, 0.0.0.0:36997->5054/tcp, 0.0.0.0:36996->5055/tcp, 0.0.0.0:36995->5056/tcp, 0.0.0.0:36994->5057/tcp, 0.0.0.0:36993->5058/tcp, 0.0.0.0:36992->5059/tcp, 0.0.0.0:36991->5060/tcp, 0.0.0.0:36990->5061/tcp, 0.0.0.0:36989->5062/tcp, 0.0.0.0:36988->5063/tcp, 0.0.0.0:36987->5064/tcp, 0.0.0.0:36986->5065/tcp, 0.0.0.0:36985->5066/tcp, 0.0.0.0:36984->5067/tcp, 0.0.0.0:36983->5068/tcp, 0.0.0.0:36982->5069/tcp, 0.0.0.0:36981->5070/tcp, 0.0.0.0:36980->5071/tcp, 0.0.0.0:36979->5072/tcp, 0.0.0.0:36978->5073/tcp, 0.0.0.0:36977->5074/tcp, 0.0.0.0:36976->5075/tcp   compassionate_visvesvaraya <NL> 8be8c7226a5e        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago   Up About an hour    0.0.0.0:36975->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                jolly_gates"}
{"timestamp_utc": "2024-07-31T08:33:44.695Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "53d787c99a72        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago   Up About an hour    0.0.0.0:36974->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                quirky_wright <NL> 622e1549ca3d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   2 hours ago         Up 2 hours          22/tcp, 0.0.0.0:36973->5000/tcp, 0.0.0.0:36972->5001/tcp, 0.0.0.0:36971->5002/tcp, 0.0.0.0:36970->5003/tcp, 0.0.0.0:36969->5004/tcp, 0.0.0.0:36968->5005/tcp, 0.0.0.0:36967->5006/tcp, 0.0.0.0:36966->5007/tcp, 0.0.0.0:36965->5008/tcp, 0.0.0.0:36964->5009/tcp, 0.0.0.0:36963->5010/tcp, 0.0.0.0:36962->5011/tcp, 0.0.0.0:36961->5012/tcp, 0.0.0.0:36960->5013/tcp, 0.0.0.0:36959->5014/tcp, 0.0.0.0:36958->5015/tcp, 0.0.0.0:36957->5016/tcp, 0.0.0.0:36956->5017/tcp, 0.0.0.0:36955->5018/tcp, 0.0.0.0:36954->5019/tcp, 0.0.0.0:36953->5020/tcp, 0.0.0.0:36952->5021/tcp, 0.0.0.0:36951->5022/tcp, 0.0.0.0:36950->5023/tcp, 0.0.0.0:36949->5024/tcp, 0.0.0.0:36948->5025/tcp, 0.0.0.0:36947->5026/tcp, 0.0.0.0:36946->5027/tcp, 0.0.0.0:36945->5028/tcp, 0.0.0.0:36944->5029/tcp, 0.0.0.0:36943->5030/tcp, 0.0.0.0:36942->5031/tcp, 0.0.0.0:36941->5032/tcp, 0.0.0.0:36940->5033/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             brave_visvesvaraya <NL> e1996a629510        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   2 hours ago         Up 2 hours          0.0.0.0:36939->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                quirky_thompson <NL> 14ae89e97f81        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          22/tcp, 0.0.0.0:36906->5000/tcp, 0.0.0.0:36905->5001/tcp, 0.0.0.0:36904->5002/tcp, 0.0.0.0:36903->5003/tcp, 0.0.0.0:36902->5004/tcp, 0.0.0.0:36901->5005/tcp, 0.0.0.0:36900->5006/tcp, 0.0.0.0:36899->5007/tcp, 0.0.0.0:36898->5008/tcp, 0.0.0.0:36897->5009/tcp, 0.0.0.0:36896->5010/tcp, 0.0.0.0:36895->5011/tcp, 0.0.0.0:36894->5012/tcp, 0.0.0.0:36893->5013/tcp, 0.0.0.0:36892->5014/tcp, 0.0.0.0:36891->5015/tcp, 0.0.0.0:36890->5016/tcp, 0.0.0.0:36889->5017/tcp, 0.0.0.0:36888->5018/tcp, 0.0.0.0:36887->5019/tcp, 0.0.0.0:36886->5020/tcp, 0.0.0.0:36885->5021/tcp, 0.0.0.0:36884->5022/tcp, 0.0.0.0:36883->5023/tcp, 0.0.0.0:36882->5024/tcp, 0.0.0.0:36881->5025/tcp, 0.0.0.0:36880->5026/tcp, 0.0.0.0:36879->5027/tcp, 0.0.0.0:36878->5028/tcp, 0.0.0.0:36877->5029/tcp, 0.0.0.0:36876->5030/tcp, 0.0.0.0:36875->5031/tcp, 0.0.0.0:36874->5032/tcp, 0.0.0.0:36873->5033/tcp, 0.0.0.0:36872->5034/tcp, 0.0.0.0:36871->5035/tcp, 0.0.0.0:36870->5036/tcp, 0.0.0.0:36869->5037/tcp, 0.0.0.0:36868->5038/tcp, 0.0.0.0:36867->5039/tcp, 0.0.0.0:36866->5040/tcp, 0.0.0.0:36865->5041/tcp, 0.0.0.0:36864->5042/tcp, 0.0.0.0:36863->5043/tcp, 0.0.0.0:36862->5044/tcp, 0.0.0.0:36861->5045/tcp, 0.0.0.0:36860->5046/tcp, 0.0.0.0:36859->5047/tcp, 0.0.0.0:36858->5048/tcp, 0.0.0.0:36857->5049/tcp, 0.0.0.0:36856->5050/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    compassionate_lichterman <NL> 878f7152b281        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          0.0.0.0:36855->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                unruffled_wozniak <NL> 4f8730fb77ce        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          22/tcp, 0.0.0.0:36839->5000/tcp, 0.0.0.0:36837->5001/tcp, 0.0.0.0:36835->5002/tcp, 0.0.0.0:36833->5003/tcp, 0.0.0.0:36831->5004/tcp, 0.0.0.0:36829->5005/tcp, 0.0.0.0:36827->5006/tcp, 0.0.0.0:36825->5007/tcp, 0.0.0.0:36823->5008/tcp, 0.0.0.0:36821->5009/tcp, 0.0.0.0:36819->5010/tcp, 0.0.0.0:36817->5011/tcp, 0.0.0.0:36815->5012/tcp, 0.0.0.0:36813->5013/tcp, 0.0.0.0:36811->5014/tcp, 0.0.0.0:36809->5015/tcp, 0.0.0.0:36807->5016/tcp, 0.0.0.0:36805->5017/tcp, 0.0.0.0:36803->5018/tcp, 0.0.0.0:36801->5019/tcp, 0.0.0.0:36799->5020/tcp, 0.0.0.0:36796->5021/tcp, 0.0.0.0:36793->5022/tcp, 0.0.0.0:36790->5023/tcp, 0.0.0.0:36787->5024/tcp, 0.0.0.0:36784->5025/tcp, 0.0.0.0:36781->5026/tcp, 0.0.0.0:36778->5027/tcp, 0.0.0.0:36775->5028/tcp, 0.0.0.0:36772->5029/tcp, 0.0.0.0:36769->5030/tcp, 0.0.0.0:36766->5031/tcp, 0.0.0.0:36763->5032/tcp, 0.0.0.0:36760->5033/tcp, 0.0.0.0:36757->5034/tcp, 0.0.0.0:36754->5035/tcp, 0.0.0.0:36751->5036/tcp, 0.0.0.0:36748->5037/tcp, 0.0.0.0:36745->5038/tcp, 0.0.0.0:36743->5039/tcp, 0.0.0.0:36741->5040/tcp, 0.0.0.0:36739->5041/tcp, 0.0.0.0:36737->5042/tcp, 0.0.0.0:36735->5043/tcp, 0.0.0.0:36733->5044/tcp, 0.0.0.0:36731->5045/tcp, 0.0.0.0:36729->5046/tcp, 0.0.0.0:36727->5047/tcp, 0.0.0.0:36725->5048/tcp, 0.0.0.0:36723->5049/tcp, 0.0.0.0:36721->5050/tcp, 0.0.0.0:36719->5051/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           pensive_sinoussi <NL> ad49f325d562        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          0.0.0.0:36605->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                elegant_galileo <NL> f0015dc6171f        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   29 hours ago        Up 29 hours         22/tcp, 0.0.0.0:36205->5000/tcp, 0.0.0.0:36204->5001/tcp, 0.0.0.0:36203->5002/tcp, 0.0.0.0:36202->5003/tcp, 0.0.0.0:36201->5004/tcp, 0.0.0.0:36200->5005/tcp, 0.0.0.0:36199->5006/tcp, 0.0.0.0:36198->5007/tcp, 0.0.0.0:36197->5008/tcp, 0.0.0.0:36196->5009/tcp, 0.0.0.0:36195->5010/tcp, 0.0.0.0:36194->5011/tcp, 0.0.0.0:36193->5012/tcp, 0.0.0.0:36192->5013/tcp, 0.0.0.0:36191->5014/tcp, 0.0.0.0:36190->5015/tcp, 0.0.0.0:36189->5016/tcp, 0.0.0.0:36188->5017/tcp, 0.0.0.0:36187->5018/tcp, 0.0.0.0:36186->5019/tcp, 0.0.0.0:36185->5020/tcp, 0.0.0.0:36184->5021/tcp, 0.0.0.0:36183->5022/tcp, 0.0.0.0:36182->5023/tcp, 0.0.0.0:36181->5024/tcp, 0.0.0.0:36180->5025/tcp, 0.0.0.0:36179->5026/tcp, 0.0.0.0:36178->5027/tcp, 0.0.0.0:36177->5028/tcp, 0.0.0.0:36176->5029/tcp, 0.0.0.0:36175->5030/tcp, 0.0.0.0:36174->5031/tcp, 0.0.0.0:36173->5032/tcp, 0.0.0.0:36172->5033/tcp, 0.0.0.0:36171->5034/tcp, 0.0.0.0:36170->5035/tcp, 0.0.0.0:36169->5036/tcp, 0.0.0.0:36168->5037/tcp, 0.0.0.0:36167->5038/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                dazzling_varahamihira <NL> ci-job-post-build-cleanup: ----- ci-resource-tracker -v -v -v --del-all <NL> # DEBUG 2024-07-31 03:33:44,606 ci-resource-tracker: arg_dict: { <NL> \"action\": \"del-all\", <NL> \"command\": null, <NL> \"data_fname\": null, <NL> \"force_flag\": false, <NL> \"hostname\": null, <NL> \"type\": null, <NL> \"verbosity\": 3 <NL> } <NL> # DEBUG 2024-07-31 03:33:44,606 ci-resource-tracker: data_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/ci-data/ci-resource-tracker.json\" <NL> # INFO 2024-07-31 03:33:44,606 ci-resource-tracker: action_del_all: current_hostname \"rtxoialp79\""}
{"timestamp_utc": "2024-07-31T08:33:44.696Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# INFO 2024-07-31 03:33:44,607 ci-resource-tracker: action_del_all: nothing to do, data file not there: \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/ci-data/ci-resource-tracker.json\" <NL> ci-job-post-build-cleanup: exit_code \"0\""}
{"timestamp_utc": "2024-07-31T08:33:44.700Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.709Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:33:44.715Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.722Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:33:44.728Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.735Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // timeout"}
{"timestamp_utc": "2024-07-31T08:33:44.742Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] archive"}
{"timestamp_utc": "2024-07-31T08:33:44.745Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "The archive step is deprecated, please use archiveArtifacts instead."}
{"timestamp_utc": "2024-07-31T08:33:55.014Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:33:55.023Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:33:55.296Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.003/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat44/7/node.003/node-info.json"}
{"timestamp_utc": "2024-07-31T08:33:55.305Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:55.312Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T08:33:55.321Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> pipeline_execute: currentBuild.result 'FAILURE' <NL> ===== ===== ===== ===== ===== <NL> [Pipeline] End of Pipeline"}
{"timestamp_utc": "2024-07-31T08:33:55.544Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Finished: FAILURE"}
